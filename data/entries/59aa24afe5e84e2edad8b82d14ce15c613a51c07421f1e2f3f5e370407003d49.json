{"title":"Researchers cause GitLab AI developer assistant to turn safe code malicious","link":"https://arstechnica.com/security/2025/05/researchers-cause-gitlab-ai-developer-assistant-to-turn-safe-code-malicious/","date":1748027219000,"content":"<p>Marketers promote AI-assisted developer tools as workhorses that are essential for today’s software engineer. Developer platform GitLab, for instance, claims its Duo chatbot can “instantly generate a to-do list” that eliminates the burden of “wading through weeks of commits.” What these companies don’t say is that these tools are, by temperament if not default, easily tricked by malicious actors into performing hostile actions against their users.</p>\n<p>Researchers from security firm Legit on Thursday <a href=\"https://www.legitsecurity.com/blog/remote-prompt-injection-in-gitlab-duo\">demonstrated</a> an attack that induced Duo into inserting malicious code into a script it had been instructed to write. The attack could also leak private code and confidential issue data, such as zero-day vulnerability details. All that’s required is for the user to instruct the chatbot to interact with a merge request or similar content from an outside source.</p>\n<h2>AI assistants’ double-edged blade</h2>\n<p>The mechanism for triggering the attacks is, of course, prompt injections. Among the most common forms of chatbot exploits, prompt injections are embedded into content a chatbot is asked to work with, such as an email to be answered, a calendar to consult, or a webpage to summarize. Large language model-based assistants are so eager to follow instructions that they’ll take orders from just about anywhere, including sources that can be controlled by malicious actors.</p><p><a href=\"https://arstechnica.com/security/2025/05/researchers-cause-gitlab-ai-developer-assistant-to-turn-safe-code-malicious/\">Read full article</a></p>\n<p><a href=\"https://arstechnica.com/security/2025/05/researchers-cause-gitlab-ai-developer-assistant-to-turn-safe-code-malicious/#comments\">Comments</a></p>","author":"Dan Goodin","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"59aa24afe5e84e2edad8b82d14ce15c613a51c07421f1e2f3f5e370407003d49","category":"Tech"}