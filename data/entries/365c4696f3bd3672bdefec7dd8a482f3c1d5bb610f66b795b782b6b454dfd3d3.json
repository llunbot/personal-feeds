{"title":"Company apologizes after AI support agent invents policy that causes user uproar","link":"https://arstechnica.com/ai/2025/04/cursor-ai-support-bot-invents-fake-policy-and-triggers-user-uproar/","date":1744929743000,"content":"<p>On Monday, a developer using the popular AI-powered code editor <a href=\"https://www.cursor.com/\">Cursor</a> noticed something strange: Switching between machines instantly logged them out, breaking a common workflow for programmers who use multiple devices. When the user contacted Cursor support, an agent named \"Sam\" told them it was expected behavior under a new policy. But no such policy existed, and Sam was a bot. The AI model made the policy up, sparking a wave of complaints and cancellation threats documented on <a href=\"https://news.ycombinator.com/item?id=43683012\">Hacker News</a> and <a href=\"https://old.reddit.com/r/cursor/comments/1jyy5am/psa_cursor_now_restricts_logins_to_a_single/\">Reddit</a>.</p>\n<p>This marks the latest instance of AI <a href=\"https://arstechnica.com/information-technology/2023/04/why-ai-chatbots-are-the-ultimate-bs-machines-and-how-people-hope-to-fix-them/\">confabulations</a> (also called \"hallucinations\") causing potential business damage. Confabulations are a type of \"creative gap-filling\" response where AI models invent plausible-sounding but false information. Instead of admitting uncertainty, AI models often prioritize creating plausible, confident responses, even when that means manufacturing information from scratch.</p>\n<p>For companies deploying these systems in customer-facing roles without human oversight, the consequences can be immediate and costly: frustrated customers, damaged trust, and, in Cursor's case, potentially canceled subscriptions.</p><p><a href=\"https://arstechnica.com/ai/2025/04/cursor-ai-support-bot-invents-fake-policy-and-triggers-user-uproar/\">Read full article</a></p>\n<p><a href=\"https://arstechnica.com/ai/2025/04/cursor-ai-support-bot-invents-fake-policy-and-triggers-user-uproar/#comments\">Comments</a></p>","author":"Benj Edwards","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"365c4696f3bd3672bdefec7dd8a482f3c1d5bb610f66b795b782b6b454dfd3d3","category":"Tech"}