{"title":"Alibaba ปล่อยโมเดล Marco-o1 โมเดลคิดทบทวนในตัวก่อนตอบ เก่งขึ้นแม้เป็นโมเดลขนาดเล็ก","link":"https://www.blognone.com/node/143383","date":1732802081000,"content":"<div><div><div><p>Alibaba International Digital Commerce บริษัทฝั่งเว็บอีคอมเมิร์ชของ Alibaba ปล่อยโมเดลปัญญาประดิษฐ์ LLM ในชื่อ  Marco-o1 เป็นโมเดลที่ทำผลทดสอบปัญหาคณิตศาสตร์ MGSM ได้สูงขึ้นถึงระดับ 90% แม้จะเป็นโมเดลขนาดเล็ก โดยอาศัยการคิดแบบค่อยเป็นค่อยไป</p>\n<p>Marco-o1 สร้างจาก Qwen2-7B แต่อาศัย 4 เทคนิคทำให้โมเดลเก่งขึ้น ได้แก่</p>\n<ul>\n<li>ฝึกด้วยชุดข้อมูล chain-of-thought: โดยทีมงานสร้างชุดข้อมูลสังเคราะห์การวิเคราะห์ปัญหาเป็นขั้นก่อนตอบ</li>\n<li>Monte Carlo Tree Search (MCTS): สร้างคำตอบที่เป็นไปได้หลายทาง แล้วเลือกทางที่ดีที่สุด</li>\n<li>ให้เหตุผลของกรทำงานแต่ละขั้น</li>\n</ul>\n<p>ผลของการปรับปรุงเหล่านี้ทำให้ผลทดสอบ MGSM ดีขึ้นอย่างมีนัยสำคัญ และเมื่อทดสอบใหแปลประโยคจากภาษาจีนเป็นภาษาอังกฤษก็พบว่าผลดีขึ้นมาก</p>\n<p>ทีมงานระบุว่า Marco-o1 นั้นพัฒนาตามแนวทางของ OpenAI o1 แต่ก็ยังตามหลังอยู่มาก (ขนาดโมเดลก็เล็กกว่ามาก) ในรายงานครั้งนี้ก็มีเพียงผลทดสอบ MGSM ที่ดีขึ้นชัดเจน โดยไม่มีคะแนนทดสอบอื่น น่าสนใจว่าทีมงานปล่อยโมเดลนี้ใกล้ๆ กับ<a href=\"https://www.blognone.com/node/143371\">ทีมงาน Qwen ปล่อยโมเดล QwQ</a></p>\n<p>ที่มา - <a href=\"https://huggingface.co/AIDC-AI/Marco-o1\">HuggingFace: AIDC-AI</a></p>\n<p><img alt=\"No Description\" src=\"https://www.blognone.com/sites/default/files/externals/762c2335ee461c18c59a289be7b865c2.png\" /></p>\n</div></div></div><div><div>Topics: </div><div><div><a href=\"/topics/alibaba\">Alibaba</a></div><div><a href=\"/topics/llm\">LLM</a></div></div></div>","author":"lew","siteTitle":"Blognone","siteHash":"ededadcf18490b3937e7dd89ebe8c00dc129addbdf1ebe4aff1f458146693da0","entryHash":"0705e143cf9afef32dbde4ea53a5f4fed6c05d8f504b1eaa6513ac961e2b84fa","category":"Thai"}