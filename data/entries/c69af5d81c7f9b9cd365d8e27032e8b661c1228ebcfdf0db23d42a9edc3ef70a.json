{"title":"Getting an all-optical AI to handle non-linear math","link":"https://arstechnica.com/science/2025/01/getting-an-all-optical-ai-to-handle-non-linear-math/","date":1736683636000,"content":"<p>A standard digital camera used in a car for stuff like emergency braking has a perceptual latency of a hair above 20 milliseconds. That’s just the time needed for a camera to transform the photons hitting its aperture into electrical charges using either CMOS or CCD sensors. It doesn’t count the further milliseconds needed to send that information to an onboard computer or process it there.</p>\n<p>A team of MIT researchers figured that if you had a chip that could process photons directly, you could skip the entire digitization step and perform calculations with the photons themselves, which has the potential to be mind-bogglingly faster.</p>\n<p>“We’re focused on a very specific metric here, which is latency. We aim for applications where what matters the most is how fast you can produce a solution. That’s why we are interested in systems where we’re able to do all the computations optically,” says Saumil Bandyopadhyay, an MIT researcher. The team implemented a complete deep neural network on a photonic chip, achieving a latency of 410 picoseconds. To put that in perspective, Bandyopadhyay’s chip could process the entire neural net it had onboard around 58 times within a single tick of the 4 GHz clock on a standard CPU.</p><p><a href=\"https://arstechnica.com/science/2025/01/getting-an-all-optical-ai-to-handle-non-linear-math/\">Read full article</a></p>\n<p><a href=\"https://arstechnica.com/science/2025/01/getting-an-all-optical-ai-to-handle-non-linear-math/#comments\">Comments</a></p>","author":"Jacek Krywko","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"c69af5d81c7f9b9cd365d8e27032e8b661c1228ebcfdf0db23d42a9edc3ef70a","category":"Tech"}