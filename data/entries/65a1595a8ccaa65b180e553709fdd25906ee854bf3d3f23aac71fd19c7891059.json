{"title":"Androidâ€™s AI-era includes eavesdropping on phone calls, warning you about scams","link":"https://arstechnica.com/?p=2024371","date":1715716635000,"content":"<div>\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n  <ul>\n          <li>\n        <div>\n          <div><img src=\"https://cdn.arstechnica.net/wp-content/uploads/2024/05/ScoakVvKrn-980x551.png\" /></div>\n          <p>\n            The \"ask this PDF\" feature.                       </p>\n        </div>\n      </li>\n      </ul>\n\n<p>Google's \"<a href=\"https://arstechnica.com/information-technology/2023/01/fearing-chatgpt-google-enlists-founders-brin-and-page-in-ai-fight/\">code-red</a>\" demands that AI be part of every single Google product, and that includes Android. At Google I/O, the company <a href=\"https://blog.google/products/android/google-ai-android-update-io-2024/#gemini-on-android\">announced</a> a \"multi-year journey to reimagine Android with AI at the core,\" but only demoed a few minor AI enhancements.</p>\n<p>Gemini will soon be able to be brought up via the power button as an overlay panel, where it will have access to whatever's on your screen. The demo involved opening a PDF in Android's PDF reader, summarizing it, and answering questions based on the content. You can do the same with a YouTube video. It also showed generating images based on a text prompt and then sending that image in a text message. Another demo involved Gemini understanding a chat log and suggesting future actions.</p>\n<p>Talkback, Android's system for low-vision users, will soon be able to use AI to describe images that lack descriptive text.</p></div><p><a href=\"https://arstechnica.com/?p=2024371#p3\">Read 3 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=2024371&amp;comments=1\">Comments</a></p>","author":"Ron Amadeo","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"65a1595a8ccaa65b180e553709fdd25906ee854bf3d3f23aac71fd19c7891059","category":"Tech"}