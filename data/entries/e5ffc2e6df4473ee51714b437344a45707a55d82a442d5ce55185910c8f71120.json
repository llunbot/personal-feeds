{"title":"What’s Good for the Goose, AI Training Edition","link":"https://www.theinformation.com/articles/openais-latest-rivals-are-getting-help-from-openai","date":1733434110000,"content":"\n<p>Stephanie Palazzolo, writing for The Information (paywalled, alas):</p>\n\n<blockquote>\n  <p>Researchers at OpenAI believe that some rival AI developers are\ntraining their reasoning models by using OpenAI’s o1 reasoning\nmodels to generate training data, according to a person who has\nspoken to the company’s researchers about it. In short, the rivals\ncan ask the o1 models to solve various problems and then use the\nmodels’ <em>chain of thought</em> — the “thought process” the models use\nto solve those problems — as training data, the person said.</p>\n\n<p>You might be wondering how rival developers can do that. OpenAI\nhas explicitly said it hides its reasoning models’ raw chains of\nthought due in part to competitive concerns.</p>\n\n<p>But in answering questions, o1 models include a summarized version\nof the chain of thought to help the customer understand how the\nmodels arrived at the answer. Rivals can simply ask another LLM to\ntake that summarized chain of thought and predict what the raw\nchain of thought might have been, the person who spoke with the\nresearchers said.</p>\n</blockquote>\n\n<p>And I’m sure these OpenAI researchers are happy to provide this training data to competitors, without having granted permission, in the same way they trained (and continue to train) their own models on publicly available web pages, without having been granted permission. Right?</p>\n\n<div>\n<a href=\"https://daringfireball.net/linked/2024/12/05/whats-good-for-the-goose-openai\"> ★ </a>\n</div>\n\n\t","author":"John Gruber","siteTitle":"Daring Fireball","siteHash":"fc569638025dadf22a867470f8215f38855cf50e975782a6c989909474292a36","entryHash":"e5ffc2e6df4473ee51714b437344a45707a55d82a442d5ce55185910c8f71120","category":"Tech"}