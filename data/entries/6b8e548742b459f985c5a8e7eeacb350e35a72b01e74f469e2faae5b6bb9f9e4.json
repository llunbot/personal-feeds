{"title":"AWS แนะนำ 8 ข้อควรระวังความปลอดภัยแอปแชต LLM ระบุการพัฒนาอย่างไม่ระวังเปิดทางข้อมูลรั่วไหล","link":"https://www.blognone.com/node/141577","date":1724335564000,"content":"<div><div><div><p>บริการ large language model (LLM) บนคลาวด์รายต่างๆ เปิดทางให้องค์กรสร้างแอปพลิเคชั่นสสำหรับงานเฉพาะทาง เช่น โดยเฉพาะการทำ Retrieval Augmented Generation (RAG) เพื่อสร้างแชตบอตสอบถามข้อมูลเฉพาะทาง ทาง AWS ก็ออกมาแนะนำ 8 ประเด็นที่ต้องระวังด้านความปลอดภัย</p>\n<p>แอปแชตที่ AWS  ยกตัวอย่างมาประกอบไปด้วย หน้าจอเว็บที่พัฒนาด้วย Streamlit, ตัวแอปพลิเคชั่นหลักพัฒนาด้วย Lambda, ฐานข้อมูล DynamoDB สำหรับการเก็บข้อมูลประวัติการแชตก่อนหน้า, เชื่อมต่อกับ LLM หลักคือ Cluade 3 Sonnet, ดึงข้อมูลเอกสารจาก S3 เข้าไปยัง OpenSearch โดยแปลงข้อความเป็นเวคเตอร์ด้วย Titan Embedding</p>\n<p>ข้อควรระวัง 8 ประการที่ AWS แนะนำไว้ได้แก่</p>\n<ol>\n<li>ไม่ได้ป้องกันแอปด้วยการล็อกอิน: การเปิดให้ใช้งานแอปโดยไม่ได้ล็อกให้ผู้ใช้ที่ยืนยันตัวตนแล้วนำมาสู่ปัญหาจำนวนมาก ผู้ใช้ที่ไม่ได้ผ่านการยืนยันตัวตนอาจจะปลอมตัวเป็นผู้ใช้คนอื่นเพื่อขโมยข้อมูล หรือโจมตีระบบ</li>\n<li>ไม่กรองอินพุตผู้ใช้: แอปไม่ได้กรอง (sanitize) ข้อความแชตที่เข้ามาให้ดีพอ ทำให้คนร้ายสามารถโจมตีแอปก่อนที่จะเชื่อมต่อกับ LLM เสียอีก เช่น เข้าไปดึงข้อมูลจาก DynamoDB คนร้ายใส่สัญลักษณ์ต่างๆ ที่แอปพลิเคชั่นไม่ได้รองรับไว้ดีพอ</li>\n<li>การเชื่อมต่อระหว่างส่วนต่างๆ ไม่ปลอดภัย: การเชื่อมต่อระหว่างส่วนต่างๆ ในแอปพลิเคชั่นไม่ได้มีการป้องกันดีพอ อาจจะเปิดทางให้มีการทำ man-in-the-middle หรือเชื่อมต่อเข้าไปยังส่วนต่างๆ ได้โดยตรง</li>\n<li>เก็บ log ไม่ละเอียดพอ: กระบวนการเก็บ log ไม่เพียงพอที่จะตรวจสอบย้อนกลับได้ ทำให้วิเคราะห์ปัญหาได้ยากในกรณีที่ถูกโจมตีขึ้นมา</li>\n<li>เก็บข้อมูลไม่ปลอดภัย: ข้อมูลที่เก็บไว้ เช่น ฐานข้อมูลความรู้ภายในที่เก็บบน S3 หรือประวัติการใช้งานใน DynamoDB ไม่ได้มีการกำหนดสิทธิ์การเข้าถึงอย่างละเอียด ไม่ได้เข้ารหัสข้อมูลสำคัญ</li>\n<li>ละเลยควาามปลอดภัยตัวโมเดล LLM: แม้ตัว LLM จะเป็นโมเดลที่ตอบตามอินพุต แต่การใช้งานอย่างไม่ระมัดระวังเปิดทางให้คนร้ายโจมตีจนแอปล่ม หรือสับเปลี่ยนโมเดลจนคำตอบเปลี่ยนไป</li>\n<li>ไม่มีนโยบายควบคุมจริยธรรมในการใช้ AI: ควรมีแนวทางควบคุมการใช้งาน มีการวัดผลความเสี่ยงต่างๆ อย่างเป็นระบบ ตรวจสอบชุดข้อมูลที่ใช้ฝึกว่าไม่มีการลำเอียงกับคนกลุ่มใดเป็นพิเศษ</li>\n<li>ไม่มีการทดสอบเต็มรูปแบบ: ระบบควรมีการทดสอบเต็มรูปแบบครบทั้งแอปพลิเคชั่นว่าแอปมีความสามารถตอบคำถามได้อย่างถูกต้อง</li>\n</ol>\n<p>AWS ระบุว่าแอปพลิเคชั่นแชต LLM นั้นยังคงจำเป็นต้องมีความปลอดภัยเทียบเท่ากับแอปพลิเคชั่นองค์กรอื่นๆ การควบคุมการดูแลความปลอดภัยจึงมีการควบคุมแบบเดียวกัน</p>\n<p>ที่มา - <a href=\"https://aws.amazon.com/blogs/security/hardening-the-rag-chatbot-architecture-powered-by-amazon-bedrock-blueprint-for-secure-design-and-anti-pattern-migration/\">AWS Blog</a></p>\n<p><img alt=\"No Description\" src=\"https://www.blognone.com/sites/default/files/externals/d69bc6b7e50caa0bdcc9043047b7766d.png\" /></p>\n</div></div></div><div><div>Topics: </div><div><div><a href=\"/topics/aws\">AWS</a></div><div><a href=\"/topics/llm\">LLM</a></div></div></div>","author":"lew","siteTitle":"Blognone","siteHash":"ededadcf18490b3937e7dd89ebe8c00dc129addbdf1ebe4aff1f458146693da0","entryHash":"6b8e548742b459f985c5a8e7eeacb350e35a72b01e74f469e2faae5b6bb9f9e4","category":"Thai"}