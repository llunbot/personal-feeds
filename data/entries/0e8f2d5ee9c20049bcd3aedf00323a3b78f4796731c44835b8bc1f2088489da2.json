{"title":"Downranking won’t stop Google’s deepfake porn problem, victims say","link":"https://arstechnica.com/?p=2024472","date":1715724046000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2024/05/GettyImages-1404749040-800x450.jpg\" alt=\"Downranking won’t stop Google’s deepfake porn problem, victims say\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2024/05/GettyImages-1404749040.jpg\">Enlarge</a> (credit: <a href=\"https://www.gettyimages.com/detail/photo/human-vs-robot-royalty-free-image/1404749040?phrase=ai+woman&amp;adppopup=true\">imaginima | E+</a>)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>After backlash over Google's search engine becoming the primary traffic source for deepfake porn websites, Google has started burying these links in search results, Bloomberg <a href=\"https://www.bloomberg.com/news/articles/2024-05-14/google-moves-deepfake-porn-sites-lower-in-its-search-rankings\">reported</a>.</p>\n<p>Over the past year, Google has been driving millions to controversial sites distributing AI-generated pornography depicting real people in fake sex videos that were created without their consent, Similarweb found. While anyone can be targeted—police already are bogged down with dealing with a <a href=\"https://arstechnica.com/tech-policy/2024/01/surge-of-fake-ai-child-sex-images-thwarts-investigations-into-real-child-abuse/\">flood of fake AI child sex images</a>—female celebrities are the most common victims. And their fake non-consensual intimate imagery is more easily discoverable on Google by searching just about any famous name with the keyword \"deepfake,\" Bloomberg noted.</p>\n<p>Google refers to this content as \"involuntary fake\" or \"synthetic pornography.\" The search engine provides a <a href=\"https://support.google.com/websearch/answer/9116649?hl=en\">path</a> for victims to report that content whenever it appears in search results. And when processing these requests, Google also removes duplicates of any flagged deepfakes.</p></div><p><a href=\"https://arstechnica.com/?p=2024472#p3\">Read 20 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=2024472&amp;comments=1\">Comments</a></p>","author":"Ashley Belanger","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"0e8f2d5ee9c20049bcd3aedf00323a3b78f4796731c44835b8bc1f2088489da2","category":"Tech"}