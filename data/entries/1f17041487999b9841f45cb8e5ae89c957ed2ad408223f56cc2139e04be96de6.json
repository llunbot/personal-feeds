{"title":"How much COVID misinformation is on Facebook? Its execs don’t want to know","link":"https://arstechnica.com/?p=1781577","date":1626793955000,"content":"<div>\n<figure><img src=\"https://cdn.arstechnica.net/wp-content/uploads/2018/04/facebook-phone-800x533.jpg\" /><p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2018/04/facebook-phone.jpg\">Enlarge</a> (credit: <a href=\"http://www.kjparish.com/portfolio/conceptual-editorial-photography\">KJ Parish</a>)</p>  </figure><div><a name=\"page-1\"></a></div>\n<p>For years, misinformation has flourished on Facebook. Falsehoods, misrepresentations, and outright lies posted on the site have shaped the discourse on everything from national politics to public health.</p>\n<p>But despite their role in facilitating communications for billions of people, Facebook executives refused to commit resources to understand the extent to which COVID-19-related misinformation pervaded its platform, according to a report in <a href=\"https://www.nytimes.com/2021/07/19/technology/facebook-misinformation-blind-spot.html\">The New York Times</a>.</p>\n<p>Early in the pandemic, a group of data scientists at Facebook met with executives to propose a project that would determine how many users saw misleading or false information about COVID. It wasn’t a small task—they estimated that the process could take up to a year or more to complete—but it would give the company a solid understanding of the extent to which misinformation spread on its platform.</p></div><p><a href=\"https://arstechnica.com/?p=1781577#p3\">Read 7 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=1781577&amp;comments=1\">Comments</a></p>","author":"Tim De Chant","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"1f17041487999b9841f45cb8e5ae89c957ed2ad408223f56cc2139e04be96de6","category":"Tech"}