{"title":"Nvidia’s AI software tricked into leaking data","link":"https://arstechnica.com/?p=1946739","date":1686331579000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2021/11/nvidia-sign-1-800x534.jpg\" alt=\"Nvidia’s AI software tricked into leaking data\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2021/11/nvidia-sign-1.jpg\">Enlarge</a> (credit: VGG | Getty Images)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>A feature in Nvidia’s artificial intelligence software can be manipulated into ignoring safety restraints and reveal private information, according to new research.</p>\n<p>Nvidia has created a system called the “NeMo Framework,” which allows developers to work with a range of large language models—the underlying technology that powers generative AI products such as chatbots.</p>\n<p>The chipmaker’s framework is designed to be adopted by businesses, such as using a company’s proprietary data alongside language models to provide responses to questions—a feature that could, for example, replicate the work of customer service representatives, or advise people seeking simple health care advice.</p></div><p><a href=\"https://arstechnica.com/?p=1946739#p3\">Read 18 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=1946739&amp;comments=1\">Comments</a></p>","author":"Financial Times","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"c873222629f5a97a81d7c4d53184fa569de73927517623cae066821d48a25890","category":"Tech"}