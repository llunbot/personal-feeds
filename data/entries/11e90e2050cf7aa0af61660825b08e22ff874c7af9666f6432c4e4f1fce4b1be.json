{"title":"OpenAI’s flawed plan to flag deepfakes ahead of 2024 elections","link":"https://arstechnica.com/?p=2022700","date":1715120348000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2024/05/GettyImages-1335171779-800x500.jpg\" alt=\"OpenAI’s flawed plan to flag deepfakes ahead of 2024 elections\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2024/05/GettyImages-1335171779.jpg\">Enlarge</a> (credit: <a href=\"https://www.gettyimages.com/detail/photo/fake-or-real-royalty-free-image/1335171779?phrase=true%20false\">Boris Zhitkov | Moment</a>)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>As the US moves toward criminalizing deepfakes—deceptive AI-generated audio, images, and videos that are increasingly hard to discern from authentic content online—tech companies have rushed to roll out tools to help everyone better detect AI content.</p>\n<p>But efforts so far have been imperfect, and experts fear that social media platforms may not be ready to handle the ensuing AI chaos during major global elections in 2024—despite <a href=\"https://www.aielectionsaccord.com/uploads/2024/02/Press-Release-AI-Elections-Accord-16-Feb-2024.pdf\">tech giants committing</a> to making tools specifically to combat AI-fueled election disinformation. The best AI detection remains observant humans, who, by paying close attention to deepfakes, can pick up on flaws like AI-generated people with extra fingers or AI voices that speak without pausing for a breath.</p>\n<p>Among the splashiest tools announced this week, OpenAI <a href=\"https://openai.com/index/understanding-the-source-of-what-we-see-and-hear-online\">shared</a> details today about a new AI image detection classifier that it claims can detect about 98 percent of AI outputs from its own <a href=\"https://arstechnica.com/information-technology/2023/11/from-toy-to-tool-dall-e-3-is-a-wake-up-call-for-visual-artists-and-the-rest-of-us/\">sophisticated image generator, DALL-E 3</a>. It also \"currently flags approximately 5 to 10 percent of images generated by other AI models,\" OpenAI's blog said.</p></div><p><a href=\"https://arstechnica.com/?p=2022700#p3\">Read 31 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=2022700&amp;comments=1\">Comments</a></p>","author":"Ashley Belanger","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"11e90e2050cf7aa0af61660825b08e22ff874c7af9666f6432c4e4f1fce4b1be","category":"Tech"}