{"title":"What happened to OpenAI’s long-term AI risk team?","link":"https://arstechnica.com/?p=2025250","date":1716047666000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2023/10/openai_glowing_blue-800x450.jpg\" alt=\"A glowing OpenAI logo on a blue background.\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2023/10/openai_glowing_blue.jpg\">Enlarge</a> (credit: Benj Edwards)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>In July last year, OpenAI <a href=\"https://openai.com/index/introducing-superalignment/\">announced the formation of a new research team</a> that would prepare for the advent of supersmart <a href=\"https://www.wired.com/tag/artificial-intelligence/\">artificial intelligence</a> capable of outwitting and overpowering its creators. Ilya Sutskever, OpenAI’s chief scientist and one of the company’s co-founders, was named as the co-lead of this new team. OpenAI said the team would receive 20 percent of its computing power.</p>\n<p>Now OpenAI’s “superalignment team” is no more, the company confirms. That comes after the departures of several researchers involved, <a href=\"https://arstechnica.com/information-technology/2024/05/chief-scientist-ilya-sutskever-leaves-openai-six-months-after-altman-ouster/\">Tuesday’s news</a> that Sutskever was leaving the company, and the <a href=\"https://twitter.com/janleike/status/1790603862132596961\">resignation</a> of the team’s other co-lead. The group’s work will be absorbed into OpenAI’s other research efforts.</p>\n<p></p></div><p><a href=\"https://arstechnica.com/?p=2025250#p3\">Read 14 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=2025250&amp;comments=1\">Comments</a></p>","author":"WIRED","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"859b423fd6059f8c3753b5c56adbaf9c574d79e8d1bdeafec75a593ed9f06e78","category":"Tech"}