{"title":"Weâ€™ve outsourced our confirmation biases to search engines","link":"https://arstechnica.com/science/2025/03/weve-outsourced-our-confirmation-biases-to-search-engines/","date":1742931671000,"content":"<p>People are often quite selective about the information they'll accept, seeking out sources that will confirm their biases, while discounting those that will challenge their beliefs. In theory, search engines can potentially change that. By prioritizing results from high-quality, credible sources, a search engine could ensure that people found accurate information more frequently, potentially opening them to the possibility of updating their beliefs.</p>\n<p>Obviously, that hasn't worked out on the technology side, as people quickly learned how to game the algorithms used by search engines, meaning that the webpages that get returned have been created by people with no interest in quality or credibility. But a new study is suggesting that the concept fails on the human side, too, as people tend to devise search terms that are specific enough to ensure that the results of the search will end up reinforcing their existing beliefs.</p>\n<p>The study showed that invisibly swapping search terms to something more general can go a long way toward enabling people to change their mind.</p><p><a href=\"https://arstechnica.com/science/2025/03/weve-outsourced-our-confirmation-biases-to-search-engines/\">Read full article</a></p>\n<p><a href=\"https://arstechnica.com/science/2025/03/weve-outsourced-our-confirmation-biases-to-search-engines/#comments\">Comments</a></p>","author":"John Timmer","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"53eaf4f2dbfdc906c0a8c950c8fd868c715e014066bcdb2856d07ccc5b0b28f2","category":"Tech"}