{"title":"อ่านไม่ทันแน่นอน Cerebras โชว์บริการ Llama 3.1 405B ความเร็ว 969 token/s โทเค็นแรกใช้เวลาแค่ 240ms","link":"https://www.blognone.com/node/143203","date":1731998988000,"content":"<div><div><div><p>Cerebras ผู้พัฒนาชิปเฉพาะทางในการรันโมเดลปัญญาประดิษฐ์ขนาดใหญ่ โชว์บริการ Cerebras Inference ที่ให้บริการโมเดล Llama 3.1 405B แบบความละเอียดเต็ม 16-bit แต่ได้ควมเร็วสูงมากถึง 969 token/s และเริ่มตอบโทเค็นแรกในเวลาเพียง 240ms ใกล้เคียงการตอบแบบทันที</p>\n<p>ทาง Cerebras โชว์ความเร็วของชิปตัวเองเป็นระยะ เดือนที่แล้วก็เพิ่งโชว์การรัน Llama 3.2 70B ที่ระดับ 2,100 token/s ไป แต่ก็ไม่เปิดเผยว่าจะให้บริการจริงเมื่อใด แต่มารอบนี้ทาง Cerebras ระบุว่าจะเปิดให้บริการตลาวด์ไตรมาสแรกของปี 2025 และยังประกาศราคาอินพุต 6 ดอลลาร์ต่อล้านโทเค็น และเอาท์พุต 12 ดอลลาร์ต่อล้านโทเค็น (<a href=\"https://www.blognone.com/node/141059\">เทียบกับ Azure ที่อินพุต 5.33 ดอลาร์และเอาท์พุต 15 ดอลลาร์</a>)</p>\n<p>ตอนนี้เริ่มเปิดบริการแบบวงปิดแล้ว คนที่สนใจสามารถไปลงชื่อรอคิวได้</p>\n<p>ที่มา - <a href=\"https://cerebras.ai/blog/llama-405b-inference\">Cerebras</a></p>\n<p><img alt=\"No Description\" src=\"https://www.blognone.com/sites/default/files/externals/d4e4a2555f04b34a0a81264bfbeb4377.jpeg\" /></p>\n</div></div></div><div><div>Topics: </div><div><div><a href=\"/topics/cerebras\">Cerebras</a></div><div><a href=\"/topics/llm\">LLM</a></div></div></div>","author":"lew","siteTitle":"Blognone","siteHash":"ededadcf18490b3937e7dd89ebe8c00dc129addbdf1ebe4aff1f458146693da0","entryHash":"22e4429df6eee5ee21d3eb52d23b398e936430e3e07a16263135e5404ac7d763","category":"Thai"}