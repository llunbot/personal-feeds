{"title":"ทรงกลมในมิติสูง และการย่อ/ขยายมิติดีเทอร์มิแนนต์","link":"https://neizod.dev/2023/07/25/hypersphere-and-resizing-determinant-dimension.html","date":1690299102000,"content":"<p>พิจารณาทรงกลมใน $n$ มิติ (<a href=\"//en.wikipedia.org/wiki/N-sphere\">$n$-ทรงกลม</a>) ที่เรายังไม่รู้จุดศูนย์กลางหรือขนาดรัศมี อย่างไรก็ตามหากเราสุ่มตัวอย่างจุดซึ่งอยู่บนขอบทรงกลมมา $n+1$ จุด เราก็จะสามารถคำนวณย้อนกลับไปหาข้อมูลต่างๆ เกี่ยวกับทรงกลมนั้นได้ โดยระบบสมการของทรงกลมในมิติ $n$ นี้ก็คือ</p>\n\n\\[(a_{k1}-x_1)^2 + (a_{k2}-x_2)^2 + \\cdots + (a_{kn}-x_n)^2 = r^2\n\\tag{1}\n\\label{eq:sphere}\\]\n\n<p>เมื่อจุดต่างๆ ที่อยู่บนขอบทรงกลมได้แก่ $p_k = (a_{k1},a_{k2},\\dots,a_{kn})$ สำหรับ $0\\le k\\le n$ ซึ่งจะทำให้เราได้จุดศูนย์กลางทรงกลมที่ตำแหน่ง $f=(x_1,x_2,\\dots,x_n)$ และรัศมีความยาวเท่ากับ $r$</p>\n\n<blockquote>\n  <p><img src=\"/images/math/hypersphere.png\" alt /></p>\n\n  <p>ตัวอย่างทรงกลมใน 4 มิติ และการตีความข้อมูลด้วยเมทริกซ์ที่แตกต่างกัน</p>\n</blockquote>\n\n<p>แน่นอนว่าเราต้องการแก้ระบบสมการ $\\eqref{eq:sphere}$ เพื่อหาจุดศูนย์กลางและรัศมีของทรงกลม แต่ตอนนี้เรายังทำงานกับระบบสมการดังกล่าวได้ยากหน่อย เพราะตัวแปร $x_i$ แต่ละตัวนั้นติดแนบแน่นอยู่กับข้อมูลภายใต้วงเล็บกำลังสอง ดังนั้นเราจะกระจายมันออกมาเป็น</p>\n\n\\[\\begin{align}\n(a_{k1}^2 - 2a_{k1}x_1 + x_1^2) + \\cdots + (a_{kn}^2 - 2a_{kn}x_n + x_n^2) &amp;= \\\\\n(a_{k1}^2 + \\cdots + a_{kn}^2) - 2(a_{k1}x_1 + \\cdots + a_{kn}x_n) + (x_1 + \\cdots + x_n)^2 &amp;= \\\\\n\\abs{p_k}^2 - 2(a_{k1}x_1 + \\cdots + a_{kn}x_n) + \\abs{f}^2 &amp;= r^2\n\\end{align}\\]\n\n<p>หรือก็คือ</p>\n\n\\[2a_{k1}x_1 + 2a_{k2}x_2 + \\cdots + 2a_{kn}x_n + (r^2{-}\\abs{f}^2) = \\abs{p_k}^2\n\\tag{2}\n\\label{eq:row}\\]\n\n<p>นี่หมายความว่าเราสามารถมองพจน์ $(r^2{-}\\abs{f}^2)$ ให้กลายเป็นตัวแปรตัวเดียวได้ และทำให้ $\\eqref{eq:row}$ กลายเป็นสมการเชิงเส้น $n+1$ ตัวแปรไปในทันที! ส่งผลให้เราได้เมทริกซ์</p>\n\n\\[\\begin{bmatrix}\na_{01} &amp; a_{02} &amp; \\cdots &amp; a_{0n} &amp; 1 \\\\\na_{11} &amp; a_{12} &amp;        &amp; a_{1n} &amp; 1 \\\\\n\\vdots &amp;        &amp; \\ddots &amp; \\vdots &amp; \\vdots \\\\\na_{n1} &amp; a_{n2} &amp; \\cdots &amp; a_{nn} &amp; 1\n\\end{bmatrix}\n\\begin{bmatrix}\n2x_1 \\\\ \\vdots \\\\ 2x_n \\\\ r^2{-}\\abs{f}^2\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\abs{p_0}^2 \\\\ \\abs{p_1}^2 \\\\ \\vdots \\\\ \\abs{p_n}^2\n\\end{bmatrix}\\]\n\n<p>ถึงตรงนี้ก็ง่ายแล้ว เพราะจาก<a href=\"//en.wikipedia.org/wiki/Cramer%27s_rule\">กฎของ Cramer</a> ก็จะทำให้เราได้พิกัดต่างๆ ออกมาว่า</p>\n\n\\[2x_i = \\frac{\n\\det\\begin{bmatrix}\na_{01} &amp; \\cdots &amp; a_{0,i-1} &amp; \\abs{p_0}^2 &amp; a_{0,i+1} &amp; \\cdots &amp; a_{0n} &amp; 1 \\\\\n\\vdots &amp; \\ddots &amp; \\vdots    &amp; \\vdots      &amp; \\vdots    &amp; \\ddots &amp; \\vdots &amp; \\vdots \\\\\na_{n1} &amp; \\cdots &amp; a_{n,i-1} &amp; \\abs{p_n}^2 &amp; a_{n,i+1} &amp; \\cdots &amp; a_{nn} &amp; 1\n\\end{bmatrix}\n}{\n\\det\\begin{bmatrix}\na_{01} &amp; \\cdots &amp; a_{0n} &amp; 1 \\\\\n\\vdots &amp; \\ddots &amp; \\vdots &amp; \\vdots \\\\\na_{n1} &amp; \\cdots &amp; a_{nn} &amp; 1\n\\end{bmatrix}\n}\n\\tag{3}\n\\label{eq:full-det}\\]\n\n<p>ส่วนการหารัศมีก็ทำได้ในทำนองเดียวกัน เพียงแค่เปลี่ยนหลักสุดท้ายของเมทริกซ์ที่มีแต่เลขหนึ่ง ให้กลายเป็นเวกเตอร์ $[\\abs{p_1}^2,\\dots,\\abs{p_n}^2]$ แทนนั่นเอง</p>\n\n<p>อย่างไรก็ตาม วิธีการข้างต้นมีจุดที่เรารู้สึกแปลกๆ ตอนคำนวณค่ารัศมี $r$ ที่รายละเอียดของดีเทอร์มิแนนต์มันแตกต่างจากตอนคำนวณตำแหน่ง $x_i$ ไปไกลเลย และในทางปฏิบัติ หลังจากคำนวณแต่ละ $x_i$ จนได้ตำแหน่ง $f$ มาแล้ว เราก็ไม่จำเป็นต้องใช้ดีเทอร์มิแนนต์เพื่อแก้หา $r$ อีกต่อไป เพียงแค่ใช้<a href=\"//en.wikipedia.org/wiki/Pythagorean_theorem\">พีทาโกรัส</a>ก็เพียงพอ</p>\n\n<p>ดังนั้นเราอาจมองปัญหานี้ใหม่ว่า เราแค่ต้องการหาจุดศูนย์กลางของทรงกลมก็พอ ซึ่งก็คือเราจะลดขนาดสมการให้เหลือเพียง $n$ ตัวแปรแทน โดยเราจะเริ่มจากการกลับไปดูระบบสมการ $\\eqref{eq:row}$ ที่จะเห็นว่าทุกสมการย่อยๆ ในแต่ละแถวนั้นใช้ตัวแปร $(r^2{-}\\abs{f}^2)$ เหมือนกันทั้งหมด ดังนั้นเราจะหยิบแถวของ $p_0$ มาเป็นตัวตั้ง แล้วเอาไปลบกับแถวอื่นๆ ที่เหลือ จึงทำให้ได้ระบบสมการนี้ออกมาแทน</p>\n\n\\[2(a_{01}{-}a_{k1})x_1 + 2(a_{02}{-}a_{k2})x_2 + \\cdots + 2(a_{0n}{-}a_{kn})x_n = \\abs{p_0}^2{-}\\abs{p_k}^2\\]\n\n<p>หรือเขียนในรูปเมทริกซ์ได้ว่า</p>\n\n\\[\\begin{bmatrix}\na_{01}{-}a_{11} &amp; a_{02}{-}a_{12} &amp; \\cdots &amp; a_{0n}{-}a_{1n} \\\\\na_{01}{-}a_{21} &amp; a_{02}{-}a_{22} &amp;        &amp; a_{0n}{-}a_{2n} \\\\\n\\vdots          &amp;                 &amp; \\ddots &amp; \\vdots \\\\\na_{01}{-}a_{n1} &amp; a_{02}{-}a_{n2} &amp; \\cdots &amp; a_{0n}{-}a_{nn} \\\\\n\\end{bmatrix}\n\\begin{bmatrix}\n2x_1 \\\\ 2x_2 \\\\ \\vdots \\\\ 2x_n\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\abs{p_0}^2{-}\\abs{p_1}^2 \\\\ \\abs{p_0}^2{-}\\abs{p_2}^2 \\\\ \\vdots \\\\ \\abs{p_0}^2{-}\\abs{p_n}^2\n\\end{bmatrix}\\]\n\n<p>ซึ่งทำให้ได้คำตอบพิกัดต่างๆ ดังนี้</p>\n\n\\[2x_i = \\frac{\n\\det\\begin{bmatrix}\na_{01}{-}a_{11} &amp; \\cdots &amp; a_{0,i-1}{-}a_{1,i-1} &amp; \\abs{p_0}^2{-}\\abs{p_1}^2 &amp; a_{0,i+1}{-}a_{1,i+1} &amp; \\cdots &amp; a_{0n}{-}a_{1n} \\\\\n\\vdots          &amp; \\ddots &amp; \\vdots                &amp; \\vdots                    &amp; \\vdots                &amp; \\ddots &amp; \\vdots \\\\\na_{01}{-}a_{n1} &amp; \\cdots &amp; a_{0,i-1}{-}a_{n,i-1} &amp; \\abs{p_0}^2{-}\\abs{p_n}^2 &amp; a_{0,i+1}{-}a_{n,i+1} &amp; \\cdots &amp; a_{0n}{-}a_{nn} \\\\\n\\end{bmatrix}\n}{\n\\det\\begin{bmatrix}\na_{01}{-}a_{11} &amp; \\cdots &amp; a_{0n}{-}a_{1n} \\\\\n\\vdots          &amp; \\ddots &amp; \\vdots \\\\\na_{01}{-}a_{n1} &amp; \\cdots &amp; a_{0n}{-}a_{nn} \\\\\n\\end{bmatrix}\n}\n\\tag{4}\n\\label{eq:sub-det}\\]\n\n<p>แม้ว่าสมการ $\\eqref{eq:full-det}$ กับ $\\eqref{eq:sub-det}$ ที่เป็นการหารกันของดีเทอร์มิแนนต์จะมีรายละเอียดภายในดีเทอร์มิแนนต์ที่ไม่เหมือนกันเลยก็ตาม แต่คำตอบทั้งสองสมการของมันต้องออกมาเท่ากันแน่ๆ ถ้าเราสนใจเพียงแค่ดีเทอร์มิแนนต์ที่เป็นตัวส่วนจากทั้งสองสมการ เราอาจเดาได้ว่ามันควรจะมีค่าเท่ากัน (หรือไม่งั้นก็อาจติดตัวคูณอะไรซักอย่างที่ตัดกับฝั่งตัวเศษได้พอดี เช่นตัวคูณ $-1$) ดังนั้นเราจะตั้งข้อคาดการณ์ว่า</p>\n\n<p><strong>ข้อคาดการณ์ 1</strong>: ให้เวกเตอร์ $\\color{red}\\vec{u}$ และเมทริกซ์ $M=[\\vec{v}_1,\\cdots,\\vec{v}_n]$ เราจะได้</p>\n\n\\[\\det\\left[\\begin{array}{cccc:c}\n\\color{red}u_1 &amp; \\color{red}u_2 &amp; \\color{red}\\cdots &amp; \\color{red}u_n &amp; 1 \\\\\n\\hdashline\nv_{11} &amp; v_{12} &amp; \\cdots &amp; v_{1n} &amp; 1 \\\\\nv_{21} &amp; v_{22} &amp;        &amp; v_{2n} &amp; 1 \\\\\n\\vdots &amp;        &amp; \\ddots &amp; \\vdots &amp; \\vdots \\\\\nv_{n1} &amp; v_{n2} &amp; \\cdots &amp; v_{nn} &amp; 1\n\\end{array}\\right]\n=\n\\det\\begin{bmatrix}\n{\\color{red}u_1}{-}v_{11} &amp; {\\color{red}u_2}{-}v_{12} &amp; \\cdots &amp; {\\color{red}u_n}{-}v_{1n} \\\\\n{\\color{red}u_1}{-}v_{21} &amp; {\\color{red}u_2}{-}v_{22} &amp;        &amp; {\\color{red}u_n}{-}v_{2n} \\\\\n\\vdots                    &amp;                           &amp; \\ddots &amp; \\vdots \\\\\n{\\color{red}u_1}{-}v_{n1} &amp; {\\color{red}u_2}{-}v_{n2} &amp; \\cdots &amp; {\\color{red}u_n}{-}v_{nn} \\\\\n\\end{bmatrix}\\]\n\n<p>การจะพิสูจน์ว่าข้อคาดการณ์นี้จริงนั้นค่อนข้างซับซ้อนเล็กน้อย ดังนั้นเราจะเริ่มจากการกลับไปทบทวนสมบัติบางประการของดีเทอร์มิแนนต์กันก่อน</p>\n\n<p><strong>สมบัติ 2</strong>: เพื่อความสะดวก เราจะให้สัญลักษณ์ $M(k:\\vec{u})$ แทนการ<em>เขียนทับ</em>เมทริกซ์ $M$ ในหลักที่ $k$ ด้วยเวกเตอร์หลัก $\\vec{u}$ (และในทำนองเดียวกัน $M(k:c) = M(k:c{\\cdot}\\vec{1})$ เมื่อ $c$ เป็นสเกลาร์)</p>\n\n<ol>\n  <li>ดึงตัวคูณสเกลาร์จากหนึ่งหลัก: $r{\\cdot}\\det M = \\det M(k:r{\\cdot}\\vec{v}_k)$ สำหรับจำนวนจริง $r$ ใดๆ</li>\n  <li>กระจายผลบวกในหนึ่งหลัก: $\\det M(k:\\vec{u}{+}\\vec{w}) = \\det M(k:\\vec{u}) + \\det M(k:\\vec{w})$</li>\n  <li>สองหลักเหมือนแล้วดีเทอร์มิแนนต์เป็นศูนย์: $\\det M(i: \\vec{u}, j: \\vec{u}) = 0$</li>\n  <li>สลับสองหลักแล้วดีเทอร์มิแนนต์ติดลบ: $\\det M = -\\det M(i:\\vec{v}_j,j:\\vec{v}_i)$</li>\n</ol>\n\n<p><strong>บทตั้ง 3</strong>: $\\det M + \\det M(k:c) = \\det M(k:\\vec{v}_k{+}c)$</p>\n\n<p><strong>บทตั้ง 4</strong>: $\\det M + \\det M(i:c_i) + \\det M(j:c_j) = \\det M(i:\\vec{v}_i{+}c_i,j:\\vec{v}_j{+}c_j)$</p>\n\n<p><strong>พิสูจน์</strong> ก่อนอื่น สังเกตว่าจากสมบัติ 2.1 และ 2.3 เรามี</p>\n\n\\[\\det M(i:c_i,j:c_j) = c_ic_j \\det M(i:\\vec{1},j:\\vec{1}) = 0\\]\n\n<p>ดังนั้น</p>\n\n\\[\\begin{align}\n\\det M + \\det M(i:c_i) + \\det M(j:c_j)\n&amp;= \\det M(i:\\vec{v}_i{+}c_i) + \\det M(j:c_j) \\\\\n&amp;= \\det M(i:\\vec{v}_i{+}c_i) + \\det M(j:c_j) + \\det M(i:c_i,j:c_j) \\\\\n&amp;= \\det M(i:\\vec{v}_i{+}c_i) + \\det M(i:\\vec{v}_i{+}c_i,j:c_j) \\\\\n&amp;= \\det M(i:\\vec{v}_i{+}c_i,j:\\vec{v}_j{+}c_j)\n\\tag*{$\\blacksquare$}\n\\end{align}\\]\n\n<p><strong>ผลพลอยได้ 5</strong>: $\\det M + \\sum_{k\\in K}\\det M(k:c_k) = \\det M(i:\\vec{v}_k{+}c_k \\mid k\\in K)$ สำหรับทุกเซตดัชนี $K$</p>\n\n<p>ถึงตอนนี้เราก็มีข้อมูลเพียงพอต่อการกลับไปพิสูจน์ข้อคาดการณ์ 1 แล้ว</p>\n\n<p><strong>พิสูจน์ (ข้อคาดการณ์ 1)</strong> จาก<a href=\"//en.wikipedia.org/wiki/Laplace_expansion\">การกระจาย Laplace</a> เราสามารถเขียนกระจายดีเทอร์มิแนนต์ให้อยู่ในรูปของผลบวกดีเทอร์มิแนนต์ที่มีมิติเล็กลงหนึ่งขั้นได้ ดังนี้</p>\n\n\\[\\det\\left[\\begin{array}{cccc:c}\n\\color{red}u_1 &amp; \\color{red}u_2 &amp; \\color{red}\\cdots &amp; \\color{red}u_n &amp; \\color{blue}1 \\\\\n\\hdashline\nv_{11} &amp; v_{12} &amp; \\cdots &amp; v_{1n} &amp; 1 \\\\\nv_{21} &amp; v_{22} &amp;        &amp; v_{2n} &amp; 1 \\\\\n\\vdots &amp;        &amp; \\ddots &amp; \\vdots &amp; \\vdots \\\\\nv_{n1} &amp; v_{n2} &amp; \\cdots &amp; v_{nn} &amp; 1\n\\end{array}\\right]\n=\n{\\color{red}u_1}\n\\det\\begin{bmatrix}\nv_{12} &amp; \\cdots &amp; v_{1n} &amp; 1 \\\\\n\\vdots &amp; \\ddots &amp; \\vdots &amp; \\vdots \\\\\nv_{n2} &amp; \\cdots &amp; v_{nn} &amp; 1\n\\end{bmatrix}\n-\n\\cdots\n\\pm\n{\\color{blue}1}\n\\det\\begin{bmatrix}\nv_{11} &amp; \\cdots &amp; v_{1n} \\\\\n\\vdots &amp; \\ddots &amp; \\vdots \\\\\nv_{n1} &amp; \\cdots &amp; v_{nn}\n\\end{bmatrix}\\]\n\n<p>สังเกตว่าแต่ละพจน์ (ยกเว้นพจน์สุดท้าย) จะมีหลักที่เป็นเวกเตอร์หนึ่งติดอยู่เสมอ เราจะสลับให้หลักนั้นไปอยู่ในหลักที่เวกเตอร์ $\\vec{v}_k$ หายไป (จากการกระจายไมเนอร์) ซึ่งแต่ละพจน์ก็จะต้องสลับหลักเป็นจำนวนครั้งไม่เท่ากัน เช่น ที่พจน์รองสุดท้ายไม่ต้องสลับเลย ไล่ไปจนถึงพจน์แรกสุดที่ต้องสลับ $n{-}1$ ครั้ง เสร็จแล้วเราจะรวบพจน์ให้เหลือดีเทอร์มิแนนต์ตัวเดียว (ด้วยผลพลอยได้ 5) ซึ่งก็คือ</p>\n\n\\[\\begin{align}\n\\det\\left[\\begin{array}{c:c} \\color{red}\\vec{u} &amp; 1 \\\\ \\hdashline M &amp; \\vec{1} \\end{array}\\right]\n&amp;= (-1)^{n-1} {\\color{red}u_1}\\det M(1:\\vec{1})\n + \\cdots\n + (-1)^{n-1} {\\color{red}u_n}\\det M(n:\\vec{1})\n + (-1)^n \\det M \\\\\n&amp;= (-1)^n\n   \\Big( \\det M(1:{\\color{red}-u_1})\n        + \\cdots\n        + \\det M(n:{\\color{red}-u_n})\n        + \\det M\n   \\Big) \\\\\n&amp;= (-1)^n \\det M(k:\\vec{v}_k{\\color{red}-u_k} \\mid k \\in \\lbrace 1,\\cdots,n \\rbrace) \\\\\n&amp;= (-1)^n \\det\\begin{bmatrix}\nv_{11}{\\color{red}-u_1} &amp; v_{12}{\\color{red}-u_2} &amp; \\cdots &amp; v_{1n}{\\color{red}-u_n} \\\\\nv_{21}{\\color{red}-u_1} &amp; v_{22}{\\color{red}-u_2} &amp;        &amp; v_{2n}{\\color{red}-u_n} \\\\\n\\vdots                  &amp;                         &amp; \\ddots &amp; \\vdots \\\\\nv_{n1}{\\color{red}-u_1} &amp; v_{n2}{\\color{red}-u_2} &amp; \\cdots &amp; v_{nn}{\\color{red}-u_n}\n\\end{bmatrix}\n\\end{align}\\]\n\n<p>สังเกตว่าทุกหลักในเมทริกซ์นั้นเขียนว่า $\\vec{v}_{k}{\\color{red}-u_k}$ ทั้งที่ข้อคาดการณ์ที่เราอยากได้คือ ${\\color{red}u_k}{-}\\vec{v}_k$ ตรงนี้แก้ได้ง่ายๆ แค่กระจาย $(-1)^n$ จากนอกดีเทอร์มิแนนต์เข้าไปในแต่ละแถวนั่นเอง ซ.ต.พ.</p>","author":"","siteTitle":"neizod's speculation","siteHash":"939338c5557b1743f2c128736c6006e145dcabc81da9970f1c0dc8ae2feb0830","entryHash":"5128a57cc259c536e7a693fce77ab0718cda22de79f99dcc37020db2d45cec26","category":"Thai"}