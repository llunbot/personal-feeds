{"title":"Announcing the new Amazon S3 Express One Zone high performance storage class","link":"https://aws.amazon.com/blogs/aws/new-amazon-s3-express-one-zone-high-performance-storage-class/","date":1701188138000,"content":"<p>The new <a href=\"https://aws.amazon.com/s3/storage-classes/express-one-zone/\">Amazon S3 Express One Zone</a> storage class is designed to deliver up to 10x better performance than the S3 Standard storage class while handling hundreds of thousands of requests per second with consistent single-digit millisecond latency, making it a great fit for your most frequently accessed data and your most demanding applications. Objects are stored and replicated on purpose built hardware within a single AWS Availability Zone, allowing you to co-locate storage and compute (Amazon EC2, Amazon ECS, and Amazon EKS) resources to further reduce latency.</p> \n<p><strong><span>Amazon S3</span><span> Express One Zone</span></strong><br /> With very low latency between compute and storage, the Amazon S3 Express One Zone storage class can help to deliver a significant reduction in runtime for data-intensive applications, especially those that use hundreds or thousands of parallel compute nodes to process large amounts of data for AI/ML training, financial modeling, media processing, real-time ad placement, high performance computing, and so forth. These applications typically keep the data around for a relatively short period of time, but access it very frequently during that time.</p> \n<p>This new storage class can handle objects of any size, but is especially awesome for smaller objects. This is because for smaller objects the time to first byte is very close to the time for last byte. In all storage systems, larger objects take longer to stream because there is more data to download during the transfer, and therefore the storage latency has less impact on the total time to read the object. As a result, smaller objects receive an outsized benefit from lower storage latency compared to large objects. Because of S3 Express One Zone’s consistent very low latency, small objects can be read up to 10x faster compared to S3 Standard.</p> \n<p>The extremely low latency provided by Amazon S3 Express One Zone, combined with request costs that are 50% lower than for the S3 Standard storage class, means that your <a href=\"https://aws.amazon.com/ec2/spot/\">Spot</a> and <a href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-on-demand-instances.html\">On-Demand</a> compute resources are used more efficiently and can be shut down earlier, leading to an overall reduction in processing costs.</p> \n<p>Each Amazon S3 Express One Zone directory bucket exists in a single Availability Zone that you choose, and can be accessed using the usual set of S3 API functions: <code><a href=\"https://docs.aws.amazon.com/AmazonS3/latest/API/API_CreateBucket.html\">CreateBucket</a></code>, <code><a href=\"https://docs.aws.amazon.com/AmazonS3/latest/API/API_PutObject.html\">PutObject</a></code>, <code><a href=\"https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetObject.html\">GetObject</a></code>, <code><a href=\"https://docs.aws.amazon.com/AmazonS3/latest/API/API_ListObjectsV2.html\">ListObjectsV2</a></code>, and so forth. The buckets also support a carefully chosen set of S3 features including <a href=\"https://docs.aws.amazon.com/whitepapers/latest/s3-optimizing-performance-best-practices/use-byte-range-fetches.html\">byte-range fetches</a>, <a href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/mpuoverview.html\">multi-part upload</a>, <a href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/CopyingObjectsMPUapi.html\">multi-part copy</a>, <a href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/ShareObjectPreSignedURL.html\">presigned URLs</a>, and <a href=\"https://aws.amazon.com/blogs/storage/protect-amazon-s3-buckets-using-access-analyzer-for-s3/\">Access Analyzer for S3</a>. You can upload objects directly, write code that uses <code><a href=\"https://docs.aws.amazon.com/AmazonS3/latest/API/API_CopyObject.html\">CopyObject</a></code>, or use <a href=\"https://aws.amazon.com/s3/features/batch-operations/\">S3 Batch Operations</a>,</p> \n<p>In order to reduce latency and to make this storage class as efficient &amp; scalable as possible, we are introducing a new bucket type, a new authentication model, and a bucket naming convention:</p> \n<p><strong>New bucket type</strong> – The new directory buckets are specific to this storage class, and support hundreds of thousands of requests per second. They have a hierarchical namespace and store object key names in a directory-like manner. The path delimiter must be “<code>/</code>“, and any prefixes that you supply to <code>ListObjectsV2</code> must end with a delimiter. Also, list operations return results without first sorting them, so you cannot do a “start after” retrieval.</p> \n<p><strong>New authentication model</strong> – The new <code>CreateSession</code> function returns a session token that grants access to a specific bucket for five minutes. You must include this token in the requests that you make to other S3 API functions that operate on the bucket or the objects in it, with the exception of <code>CopyObject</code>, which requires IAM credentials. The newest versions of the AWS SDKs handle session creation automatically.</p> \n<p><strong>Bucket naming</strong> – Directory bucket names must be unique within their AWS Region, and must specify an Availability Zone ID in a specially formed suffix. If my base bucket name is <code>jbarr</code> and it exists in Availability Zone <strong>use1-az5 </strong>(Availability Zone 5 in the US East (N. Virginia) Region) the name that I supply to <code>CreateBucket</code> would be <code>jbarr--use1-az5--x-s3</code>. Although the bucket exists within a specific Availability Zone, it is accessible from the other zones in the region, and there are no data transfer charges for requests from compute resources in one Availability Zone to directory buckets in another one in the same region.</p> \n<p><span><strong>Amazon S3 Express One Zone in action</strong></span><br /> Let’s put this new storage class to use. I will focus on the command line, but AWS Management Console and API access are also available.</p> \n<p>My EC2 instance is running in my <strong>us-east-1f</strong> Availability Zone. I use <code><a href=\"https://jqlang.github.io/jq/\">jq</a></code> to map this value to an Availability Zone Id:</p> \n<div> \n <pre><code>$ aws ec2 describe-availability-zones --output json | \\\n  jq -r  '.AvailabilityZones[] | select(.ZoneName == \"us-east-1f\") | .ZoneId'\nuse1-az5\n</code></pre> \n</div> \n<p>I create a bucket configuration (<code>s3express-bucket-config.json</code>) and include the Id:</p> \n<div> \n <pre><code>{\n        \"Location\" :\n        {\n                \"Type\" : \"AvailabilityZone\",\n                \"Name\" : \"use1-az5\"\n        },\n        \"Bucket\":\n        {\n                \"DataRedundancy\" : \"SingleAvailabilityZone\",\n                \"Type\"           : \"Directory\"\n        }\n}\n</code></pre> \n</div> \n<p>After installing the newest version of the <a href=\"https://aws.amazon.com/cli/\">AWS Command Line Interface (AWS CLI)</a>, I create my directory bucket:</p> \n<div> \n <pre><code>$ aws s3api create-bucket --bucket jbarr--use1-az5--x-s3 \\\n  --create-bucket-configuration file://s3express-bucket-config.json \\\n  --region us-east-1\n-------------------------------------------------------------------------------------------\n|                                       CreateBucket                                      |\n+----------+------------------------------------------------------------------------------+\n|  Location|  https://jbarr--use1-az5--x-s3.s3express-use1-az5.us-east-1.amazonaws.com/   |\n+----------+------------------------------------------------------------------------------+\n</code></pre> \n</div> \n<p>Then I can use the directory bucket as the destination for other CLI commands as usual (the second <code>aws</code> is the directory where I unzipped the AWS CLI):</p> \n<div> \n <pre><code>$ aws s3 sync aws s3://jbarr--use1-az5--x-s3</code></pre> \n</div> \n<p>When I list the directory bucket’s contents, I see that the <code>StorageClass</code> is <code>EXPRESS_ONEZONE</code>:</p> \n<div> \n <pre><code>$ aws s3api list-objects-v2 --bucket jbarr--use1-az5--x-s3 --output json | \\\n  jq -r '.Contents[] | {Key: .Key, StorageClass: .StorageClass}'\n...\n{\n  \"Key\": \"install\",\n  \"StorageClass\": \"EXPRESS_ONEZONE\"\n}\n...\n</code></pre> \n</div> \n<p>The Management Console for S3 shows General purpose buckets and Directory buckets on separate tabs:</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2023/11/02/s3_express_dir_buckets_1.png\" width=\"901\" height=\"431\" /></p> \n<p>I can import the contents of an existing bucket (or a prefixed subset of the contents) into a directory bucket using the<strong> Import</strong> button, as seen above. I select a source bucket, click Import, and enter the parameters that will be used to generate an inventory of the source bucket and to create and an <a href=\"https://aws.amazon.com/s3/features/batch-operations/\">S3 Batch Operations</a> job.</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2023/11/02/s3_express_batch_setup_2.png\" width=\"800\" height=\"1295\" /></p> \n<p>The job is created and begins to execute:</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2023/11/02/s3_express_running_2.png\" width=\"901\" height=\"396\" /></p> \n<p><span><strong>Things to know</strong></span><br /> Here are some important things to know about this new S3 storage class:</p> \n<p><strong>Regions</strong> – Amazon S3 Express One Zone is available in the US East (N. Virginia), US West (Oregon), Asia Pacific (Tokyo), and Europe (Stockholm) Regions, with plans to expand to others over time.</p> \n<p><strong>Other AWS Services</strong> – You can use Amazon S3 Express One Zone with other AWS services including <a href=\"https://aws.amazon.com/sagemaker/train/\">Amazon SageMaker Model Training</a>, <a href=\"https://aws.amazon.com/athena\">Amazon Athena</a>, <a href=\"https://aws.amazon.com/emr\">Amazon EMR</a>, and <a href=\"https://aws.amazon.com/glue/\">AWS Glue</a> Data Catalog to accelerate your machine learning and analytics workloads. You can also use <a href=\"https://github.com/awslabs/mountpoint-s3\">Mountpoint for Amazon S3</a> to process your S3 objects in file-oriented fashion.</p> \n<p><strong>Pricing</strong> – Pricing, like the other S3 storage classes, is on a pay-as-you-go basis. You pay $0.16/GB/month in the US East (N. Virginia) Region, with a one-hour minimum billing time for each object, and additional charges for certain request types. You pay an additional per-GB fee for the portion of any request that exceeds 512 KB. For more information, see the <a href=\"https://aws.amazon.com/s3/pricing/?did=ap_card&amp;trk=ap_card\">Amazon S3 Pricing</a> page.</p> \n<p><strong>Durability –</strong> In the unlikely case of the loss or damage to all or part of an AWS Availability Zone, data in a One Zone storage class may be lost. For example, events like fire and water damage could result in data loss. Apart from these types of events, our One Zone storage classes use similar engineering designs as our Regional storage classes to protect objects from independent disk, host, and rack-level failures, and each are designed to deliver 99.999999999% data durability.</p> \n<p><strong>SLA</strong> – Amazon S3 Express One Zone is designed to deliver 99.95% availability with an availability SLA of 99.9%; for information see the <a href=\"https://aws.amazon.com/s3/sla/\">Amazon S3 Service Level Agreement</a> page.</p> \n<p>This new storage class is available now and you can start using it today!</p> \n<p><span><strong>Learn more<br /> </strong></span><a href=\"https://aws.amazon.com/s3/storage-classes/express-one-zone/\">Amazon S3 Express One Zone</a></p> \n<p>— <a href=\"https://twitter.com/jeffbarr\">Jeff</a>;</p>","author":"Jeff Barr","siteTitle":"AWS News Blog","siteHash":"6093e072e4117ec22616e844cb857d03ca62c57a411a8affc77cb5e8b6b15bf6","entryHash":"091c3a5aea04c122050271bb76df6e5622d7f5f80964e513f6d541044126182a","category":"Tech"}