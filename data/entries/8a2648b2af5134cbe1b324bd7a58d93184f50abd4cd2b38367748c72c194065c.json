{"title":"Simplify analytics and AI/ML with new Amazon SageMaker Lakehouse","link":"https://aws.amazon.com/blogs/aws/simplify-analytics-and-aiml-with-new-amazon-sagemaker-lakehouse/","date":1733252705000,"content":"<p>Today, I’m very excited to announce the general availability of Amazon SageMaker Lakehouse, a capability that unifies data across <a href=\"https://aws.amazon.com/s3/\">Amazon Simple Storage Service (Amazon S3)</a> data lakes and <a href=\"https://aws.amazon.com/redshift/\">Amazon Redshift</a> data warehouses, helping you build powerful analytics and artificial intelligence and machine learning (AI/ML) applications on a single copy of data. SageMaker Lakehouse is a part of the next generation of <a href=\"https://aws.amazon.com/blogs/aws/introducing-the-next-generation-of-amazon-sagemaker-the-center-for-all-your-data-analytics-and-ai\">Amazon SageMaker</a>, which is a unified platform for data, analytics and AI, that brings together widely-adopted AWS machine learning and analytics capabilities and delivers an integrated experience for analytics and AI.</p> \n<p>Customers want to do more with data. To move faster with their analytics journey, they are picking the right storage and databases to store their data. The data is spread across data lakes, data warehouses, and different applications, creating data silos that make it difficult to access and utilize. This fragmentation leads to duplicate data copies and complex data pipelines, which in turn increases costs for the organization. Furthermore, customers are constrained to use specific query engines and tools, as the way and where the data is stored limits their options. This restriction hinders their ability to work with the data as they would prefer. Lastly, the inconsistent data access makes it challenging for customers to make informed business decisions.</p> \n<p>SageMaker Lakehouse addresses these challenges by helping you to unify data across Amazon S3 data lakes and Amazon Redshift data warehouses. It offers you the flexibility to access and query data in-place with all engines and tools compatible with Apache Iceberg. With SageMaker Lakehouse, you can define fine-grained permissions centrally and enforce them across multiple AWS services, simplifying data sharing and collaboration. Bringing data into your SageMaker Lakehouse is easy. In addition to seamlessly accessing data from your existing data lakes and data warehouses, you can use zero-ETL from operational databases such as <a href=\"https://aws.amazon.com/rds/aurora/\">Amazon Aurora</a>, <a href=\"https://aws.amazon.com/rds/mysql/\">Amazon RDS for MySQL</a>, <a href=\"https://aws.amazon.com/dynamodb/\">Amazon DynamoDB</a>, as well as applications such as Salesforce and SAP. SageMaker Lakehouse fits into your existing environments.</p> \n<p><span><strong>Get started with SageMaker Lakehouse<br /> </strong></span>For this demonstration, I use a preconfigured environment that has multiple AWS data sources. I go to the Amazon SageMaker Unified Studio (preview) console, which provides an integrated development experience for all your data and AI. Using Unified Studio, you can seamlessly access and query data from various sources through SageMaker Lakehouse, while using familiar AWS tools for analytics and AI/ML.</p> \n<p>This is where you can create and manage projects, which serve as shared workspaces. These projects allow team members to collaborate, work with data, and develop AI models together. Creating a project automatically sets up AWS Glue Data Catalog databases, establishes a catalog for Redshift Managed Storage (RMS) data, and provisions necessary permissions. You can get started by creating a new project or continue with an existing project.</p> \n<p>To create a new project, I choose <strong>Create project</strong>.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/11/25/07-LaunchMarketingIntake1213.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/11/25/07-LaunchMarketingIntake1213.png\" width=\"1924\" height=\"996\" /></a></p> \n<p>I have 2 project profile options to build a lakehouse and interact with it. First one is <strong>Data analytics and AI-ML model development</strong>, where you can analyze data and build ML and generative AI models powered by <a href=\"https://aws.amazon.com/emr\">Amazon EMR</a>, <a href=\"https://aws.amazon.com/glue/\">AWS Glue</a>, Amazon Athena, Amazon SageMaker AI, and SageMaker Lakehouse. Second one is <strong>SQL analytics</strong>, where you can analyze your data in SageMaker Lakehouse using SQL. For this demo, I proceed with <strong>SQL analytics</strong>.</p> \n<p>I enter a project name in the <strong>Project name</strong> field and choose <strong>SQL analytics</strong> under <strong>Project profile</strong>. I choose <strong>Continue</strong>.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/11/29/25-LaunchMarketingIntake1213-1.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/11/29/25-LaunchMarketingIntake1213-1.png\" width=\"1924\" height=\"1072\" /></a></p> \n<p>I enter the values for all the parameters under <strong>Tooling</strong>. I enter the values to create my <strong>Lakehouse</strong> databases. I enter the values to create my <strong>Redshift Serverless</strong> resources. Finally, I enter a name for my catalog under <strong>Lakehouse Catalog</strong>.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/11/27/12-LaunchMarketingIntake1213.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/11/27/12-LaunchMarketingIntake1213.png\" width=\"1924\" height=\"1384\" /></a></p> \n<p>On the next step, I review the resources and choose <strong>Create project</strong>.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/11/27/13-LaunchMarketingIntake1213.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/11/27/13-LaunchMarketingIntake1213.png\" width=\"1924\" height=\"782\" /></a></p> \n<p>After the project is created, I observe the project details.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/11/27/14-LaunchMarketingIntake1213.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/11/27/14-LaunchMarketingIntake1213.png\" width=\"1924\" height=\"1200\" /></a></p> \n<p>I go to <strong>Data</strong> in the navigation pane and choose the + (plus) sign to Add data. I choose <strong>Create catalog</strong> to create a new catalog and choose <strong>Add data</strong>.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/11/27/21-LaunchMarketingIntake1213-1.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/11/27/21-LaunchMarketingIntake1213-1.png\" width=\"958\" height=\"996\" /></a></p> \n<p>After the RMS catalog is created, I choose <strong>Build</strong> from the navigation pane and then choose <strong>Query Editor</strong> under <strong>Data Analysis &amp; Integration</strong> to create a schema under RMS catalog, create a table, and then load table with sample sales data.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/11/27/22-LaunchMarketingIntake1213.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/11/27/22-LaunchMarketingIntake1213.png\" width=\"1924\" height=\"996\" /></a></p> \n<p>After entering the SQL queries into the designated cells, I choose <strong>Select data source</strong> from the right dropdown menu to establish a database connection to Amazon Redshift data warehouse. This connection allows me to execute the queries and retrieve the desired data from the database.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/11/27/23a-LaunchMarketingIntake1213.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/11/27/23a-LaunchMarketingIntake1213.png\" width=\"1924\" height=\"996\" /></a></p> \n<p>Once the database connection is successfully established, I choose <strong>Run all</strong> to execute all queries and monitor the execution progress until all results are displayed.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/11/27/24a-LaunchMarketingIntake1213.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/11/27/24a-LaunchMarketingIntake1213.png\" width=\"1920\" height=\"1730\" /></a></p> \n<p>For this demonstration, I use two additional pre-configured catalogs. A catalog is a container that organizes your lakehouse object definitions such as schema and tables. The first is an Amazon S3 data lake catalog (<strong>test-s3-catalog</strong>) that stores customer records, containing detailed transactional and demographic information. The second is a lakehouse catalog (<strong>churn_lakehouse</strong>) dedicated to storing and managing customer churn data. This integration creates a unified environment where I can analyze customer behavior alongside churn predictions.</p> \n<p>From the navigation pane, I choose <strong>Data</strong> and locate my catalogs under the <strong>Lakehouse</strong> section. SageMaker Lakehouse offers multiple analysis options, including <strong>Query with Athena</strong>, <strong>Query with Redshift</strong>, and <strong>Open in Jupyter Lab notebook</strong>.</p> \n<p>Note that you need to choose <strong>Data analytics and AI-ML model development</strong> profile when you create a project, if you want to use <strong>Open in Jupyter Lab notebook</strong> option. If you choose <strong>Open in Jupyter Lab notebook</strong>, you can interact with SageMaker Lakehouse using Apache Spark via EMR 7.5.0 or AWS Glue 5.0 by configuring the Iceberg REST catalog, enabling you to process data across your data lakes and data warehouses in a unified manner.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/11/27/20-LaunchMarketingIntake1213.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/11/27/20-LaunchMarketingIntake1213.png\" width=\"1924\" height=\"996\" /></a></p> \n<p>Here’s how querying using Jupyter Lab notebook looks like:</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/11/27/25-LaunchMarketingIntake1213.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/11/27/25-LaunchMarketingIntake1213.png\" width=\"2888\" height=\"1202\" /></a></p> \n<p>I continue by choosing <strong>Query with Athena</strong>. With this option, I can use serverless query capability of Amazon Athena to analyze the sales data directly within SageMaker Lakehouse. Upon selecting <strong>Query with Athena</strong>, the <strong>Query Editor</strong> launches automatically, providing an workspace where I can compose and execute SQL queries against the lakehouse. This integrated query environment offers a seamless experience for data exploration and analysis, complete with syntax highlighting and auto-completion features to enhance productivity.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/11/27/19-LaunchMarketingIntake1213.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/11/27/19-LaunchMarketingIntake1213.png\" width=\"1924\" height=\"996\" /></a></p> \n<p>I can also use <strong>Query with Redshift</strong> option to run SQL queries against the lakehouse.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/11/27/18-LaunchMarketingIntake1213.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/11/27/18-LaunchMarketingIntake1213.png\" width=\"1924\" height=\"996\" /></a></p> \n<p>SageMaker Lakehouse offers a comprehensive solution for modern data management and analytics. By unifying access to data across multiple sources, supporting a wide range of analytics and ML engines, and providing fine-grained access controls, SageMaker Lakehouse helps you make the most of your data assets. Whether you’re working with data lakes in Amazon S3, data warehouses in Amazon Redshift, or operational databases and applications, SageMaker Lakehouse provides the flexibility and security you need to drive innovation and make data-driven decisions. You can use hundreds of connectors to integrate data from various sources. Additionally, you can access and query data in-place with federated query capabilities across third-party data sources.</p> \n<p><span><strong>Now available</strong></span><br /> You can access SageMaker Lakehouse through the <a href=\"https://console.aws.amazon.com/lakeformation\">AWS Management Console</a>, APIs, <a href=\"https://aws.amazon.com/cli/\">AWS Command Line Interface (AWS CLI)</a>, or <a href=\"https://aws.amazon.com/developer/tools/\">AWS SDKs</a>. You can also access through <a href=\"https://docs.aws.amazon.com/glue/latest/dg/catalog-and-crawler.html\">AWS Glue Data Catalog</a> and <a href=\"https://console.aws.amazon.com/lakeformation/\">AWS Lake Formation</a>. SageMaker Lakehouse is available in US East (N. Virginia), US West (Oregon), US East (Ohio), Europe (Ireland), Europe (Frankfurt), Europe (Stockholm), Asia Pacific (Sydney), Asia Pacific (Hong Kong), Asia Pacific (Tokyo), and Asia Pacific (Singapore) <a href=\"https://docs.aws.amazon.com/glossary/latest/reference/glos-chap.html#region\">AWS Regions</a>.</p> \n<p>For pricing information, visit the <a href=\"https://aws.amazon.com/sagemaker/lakehouse/pricing/\">Amazon SageMaker Lakehouse pricing</a>.</p> \n<p>For more information on Amazon SageMaker Lakehouse and how it can simplify your data analytics and AI/ML workflows, visit the <a href=\"https://docs.aws.amazon.com/sagemaker-unified-studio/latest/userguide/lakehouse.html\">Amazon SageMaker Lakehouse</a> documentation.</p> \n<a href=\"https://www.linkedin.com/in/esrakayabali/\">— Esra</a>","author":"Esra Kayabali","siteTitle":"AWS News Blog","siteHash":"6093e072e4117ec22616e844cb857d03ca62c57a411a8affc77cb5e8b6b15bf6","entryHash":"8a2648b2af5134cbe1b324bd7a58d93184f50abd4cd2b38367748c72c194065c","category":"Tech"}