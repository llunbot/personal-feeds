{"title":"Jamba 1.5 family of models by AI21 Labs is now available in Amazon Bedrock","link":"https://aws.amazon.com/blogs/aws/jamba-1-5-family-of-models-by-ai21-labs-is-now-available-in-amazon-bedrock/","date":1727114358000,"content":"<p>Today, we are announcing the availability of AI21 Labs’ powerful new Jamba 1.5 family of large language models (LLMs) in <a href=\"https://aws.amazon.com/bedrock/\">Amazon Bedrock</a>. These models represent a significant advancement in long-context language capabilities, delivering speed, efficiency, and performance across a wide range of applications. The Jamba 1.5 family of models includes Jamba 1.5 Mini and Jamba 1.5 Large. Both models support a 256K token context window, structured JSON output, function calling, and are capable of digesting document objects.</p> \n<p>AI21 Labs is a leader in building foundation models and artificial intelligence (AI) systems for the enterprise. Together, AI21 Labs and AWS are empowering customers across industries to build, deploy, and scale <a href=\"https://aws.amazon.com/what-is/generative-ai/\">generative AI</a> applications that solve real-world challenges and spark innovation through a strategic collaboration. With AI21 Labs’ advanced, production-ready models together with Amazon’s dedicated services and powerful infrastructure, customers can leverage LLMs in a secure environment to shape the future of how we process information, communicate, and learn.</p> \n<p><strong><u>What is Jamba 1.5?<br /> </u></strong>Jamba 1.5 models leverage a unique hybrid architecture that combines the transformer model architecture with <a href=\"https://arxiv.org/abs/2111.00396\">Structured State Space model (SSM)</a> technology. This innovative approach allows Jamba 1.5 models to handle long context windows up to 256K tokens, while maintaining the high-performance characteristics of traditional transformer models. You can learn more about this hybrid SSM/transformer architecture in the <a href=\"https://arxiv.org/pdf/2403.19887\">Jamba: A Hybrid Transformer-Mamba Language Model</a> whitepaper.</p> \n<p>You can now use two new Jamba 1.5 models from AI21 in Amazon Bedrock:</p> \n<ul> \n <li><strong>Jamba 1.5 Large</strong> excels at complex reasoning tasks across all prompt lengths, making it ideal for applications that require high quality outputs on both long and short inputs.</li> \n <li><strong>Jamba 1.5 Mini</strong> is optimized for low-latency processing of long prompts, enabling fast analysis of lengthy documents and data.</li> \n</ul> \n<p>Key strengths of the Jamba 1.5 models include:</p> \n<ul> \n <li><strong>Long context handling </strong>– With 256K token context length, Jamba 1.5 models can improve the quality of enterprise applications, such as lengthy document summarization and analysis, as well as agentic and RAG workflows.</li> \n <li><strong>Multilingual</strong> – Support for English, Spanish, French, Portuguese, Italian, Dutch, German, Arabic, and Hebrew.</li> \n <li><strong>Developer-friendly</strong> – Native support for structured JSON output, function calling, and capable of digesting document objects.</li> \n <li><strong>Speed and efficiency</strong> – AI21 measured the performance of Jamba 1.5 models and shared that the models demonstrate up to 2.5X faster inference on long contexts than other models of comparable sizes. For detailed performance results, visit the <a href=\"https://www.ai21.com/blog/announcing-jamba-model-family\">Jamba model family announcement on the AI21 website</a>.</li> \n</ul> \n<p><strong><u>Get started with Jamba 1.5 models in Amazon Bedrock<br /> </u></strong>To get started with the new Jamba 1.5 models, go to the <a href=\"https://console.aws.amazon.com/bedrock\">Amazon Bedrock console</a>, choose <strong>Model access</strong> on the bottom left pane, and request access to Jamba 1.5 Mini or Jamba 1.5 Large.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/06/2024-bedrock-model-access-ai21-jamba-15.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/06/2024-bedrock-model-access-ai21-jamba-15.png\" alt=\"Amazon Bedrock - Model access to AI21 Jamba 1.5 models\" width=\"1352\" height=\"873\" /></a></p> \n<p>To test the Jamba 1.5 models in the Amazon Bedrock console, choose the <strong>Text</strong> or <strong>Chat</strong> playground in the left menu pane. Then, choose <strong>Select model</strong> and select <strong>AI21</strong> as the category and <strong>Jamba 1.5 Mini</strong> or <strong>Jamba 1.5 Large</strong> as the model.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/25/2024-bedrock-ai21-jamba-inference.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/25/2024-bedrock-ai21-jamba-inference.png\" alt=\"Jamba 1.5 in the Amazon Bedrock text playground\" width=\"2488\" height=\"1610\" /></a></p> \n<p>By choosing <strong>View API request</strong>, you can get a code example of how to invoke the model using the <a href=\"https://aws.amazon.com/cli/\">AWS Command Line Interface (AWS CLI)</a> with the current example prompt.</p> \n<p>You can follow the <a href=\"https://docs.aws.amazon.com/bedrock/latest/userguide/service_code_examples_bedrock-runtime.html\">code examples in the Amazon Bedrock documentation</a> to access available models using <a href=\"https://aws.amazon.com/developer/tools/\">AWS SDKs</a> and to build your applications using various programming languages.</p> \n<p>The following Python code example shows how to send a text message to Jamba 1.5 models using the Amazon Bedrock Converse API for text generation.</p> \n<pre><code>import boto3\nfrom botocore.exceptions import ClientError\n\n# Create a Bedrock Runtime client.\nbedrock_runtime = boto3.client(\"bedrock-runtime\", region_name=\"us-east-1\")\n\n# Set the model ID.\n# modelId = \"ai21.jamba-1-5-mini-v1:0\"\nmodel_id = \"ai21.jamba-1-5-large-v1:0\"\n\n# Start a conversation with the user message.\nuser_message = \"What are 3 fun facts about mambas?\"\nconversation = [\n    {\n        \"role\": \"user\",\n        \"content\": [{\"text\": user_message}],\n    }\n]\n\ntry:\n    # Send the message to the model, using a basic inference configuration.\n    response = bedrock_runtime.converse(\n        modelId=model_id,\n        messages=conversation,\n        inferenceConfig={\"maxTokens\": 200, \"temperature\": 0.4, \"topP\": 1},\n    )\n\n    # Extract and print the response text.\n    response_text = response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n    print(response_text)\n\nexcept (ClientError, Exception) as e:\n    print(f\"ERROR: Can't invoke '{model_id}'. Reason: {e}\")\n    exit(1)</code></pre> \n<p>The Jamba 1.5 models are perfect for use cases like paired document analysis, compliance analysis, and question answering for long documents. They can easily compare information across multiple sources, check if passages meet specific guidelines, and handle very long or complex documents. You can find example code in the <a href=\"https://github.com/aws-samples/AI21-on-AWS/\">AI21-on-AWS GitHub repo</a>. To learn more about how to prompt Jamba models effectively, check out <a href=\"https://docs.ai21.com/docs/prompt-engineering\">AI21’s documentation</a>.</p> \n<p><strong><u>Now available<br /> </u></strong>AI21 Labs’ Jamba 1.5 family of models is generally available today in Amazon Bedrock in the US East (N. Virginia) <a href=\"https://aws.amazon.com/about-aws/global-infrastructure/regions_az/\">AWS Region</a>. Check the <a href=\"https://docs.aws.amazon.com/bedrock/latest/userguide/models-regions.html\">full Region list</a> for future updates. To learn more, check out the <a href=\"https://aws.amazon.com/bedrock/ai21/\">AI21 Labs in Amazon Bedrock</a> product page and <a href=\"https://aws.amazon.com/bedrock/pricing/\">pricing page</a>.</p> \n<p>Give Jamba 1.5 models a try in the <a href=\"https://console.aws.amazon.com/bedrock\">Amazon Bedrock console</a> today and send feedback to <a href=\"https://repost.aws/tags/TAQeKlaPaNRQ2tWB6P7KrMag/amazon-bedrock\">AWS re:Post for Amazon Bedrock</a> or through your usual AWS Support contacts.</p> \n<p>Visit our <a href=\"https://community.aws/generative-ai?trk=5aadd1a3-56ee-4a3b-9314-21a4f0e684ed&amp;sc_channel=el\">community.aws</a> site to find deep-dive technical content and to discover how our Builder communities are using Amazon Bedrock in their solutions.</p> \n<p>— <a href=\"https://www.linkedin.com/in/antje-barth/\" target=\"_blank\">Antje</a></p> \n<p><em><strong>September 25, 2024</strong> – Updated screenshot and code example with optimized inference parameter settings.</em></p>","author":"Antje Barth","siteTitle":"AWS News Blog","siteHash":"6093e072e4117ec22616e844cb857d03ca62c57a411a8affc77cb5e8b6b15bf6","entryHash":"0163464d72b9d7a83f1e705f2f38143be11d1705065aa6f627cb23f143cef115","category":"Tech"}