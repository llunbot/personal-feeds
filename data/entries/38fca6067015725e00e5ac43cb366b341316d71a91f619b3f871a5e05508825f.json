{"title":"New Amazon EC2 P6-B200 instances powered by NVIDIA Blackwell GPUs to accelerate AI innovations","link":"https://aws.amazon.com/blogs/aws/new-amazon-ec2-p6-b200-instances-powered-by-nvidia-blackwell-gpus-to-accelerate-ai-innovations/","date":1747349227000,"content":"<p>Today, we’re announcing the general availability of <a href=\"https://aws.amazon.com/ec2\">Amazon Elastic Compute Cloud (Amazon EC2)</a> <a href=\"https://aws.amazon.com/ec2/instance-types/p6\">P6-B200 instances</a> accelerated by NVIDIA Blackwell GPUs to address customer needs for high performance and scalability in <a href=\"https://aws.amazon.com/ai/\">artificial intelligence (AI)</a>, <a href=\"https://aws.amazon.com/ai/machine-learning/\">machine learning (ML)</a>, and <a href=\"https://aws.amazon.com/hpc/\">high performance computing (HPC)</a> applications.</p> \n<p>Amazon EC2 P6-B200 instances accelerate a broad range of GPU-enabled workloads but are especially well-suited for large-scale distributed AI training and inferencing for <a href=\"https://aws.amazon.com/what-is/foundation-models/\">foundation models (FMs)</a> with reinforcement learning (RL) and distillation, multimodal training and inference, and HPC applications such as climate modeling, drug discovery, seismic analysis, and insurance risk modeling.</p> \n<p>When combined with <a href=\"https://aws.amazon.com/hpc/efa/\">Elastic Fabric Adapter</a> (EFAv4) networking, hyperscale clustering by <a href=\"https://aws.amazon.com/ec2/ultraclusters/\">EC2 UltraClusters</a>, and advanced virtualization and security capabilities by <a href=\"https://aws.amazon.com/ec2/nitro/\">AWS Nitro System</a>, you can train and serve FMs with increased speed, scale, and security. These instances also deliver up to two times the performance for AI training (time to train) and inference (tokens/sec) compared to <a href=\"https://aws.amazon.com/ec2/instance-types/p5/\">EC2 P5en instances</a>.</p> \n<p>You can accelerate time-to-market for training FMs and deliver faster inference throughput, which lowers inference cost and helps increase adoption of generative AI applications as well as increased processing performance for HPC applications.</p> \n<p><strong><u>EC2 P6-B200 instances specifications</u></strong><br /> New EC2 P6-B200 instances provide eight NVIDIA Blackwell GPUs with 1440 GB of high bandwidth GPU memory, 5th Generation Intel Xeon Scalable processors (Emerald Rapids), 2 TiB of system memory, and 30 TB of local NVMe storage.</p> \n<p>Here are the specs for EC2 P6-B200 instances:</p> \n<table> \n <tbody> \n  <tr> \n   <td><strong>Instance size</strong></td> \n   <td><strong>GPUs (NVIDIA B200)</strong></td> \n   <td><strong>GPU<br /> memory (GB)</strong></td> \n   <td><strong>vCPUs</strong></td> \n   <td><strong>GPU Peer to peer (GB/s)</strong></td> \n   <td><strong>Instance storage (TB)</strong></td> \n   <td><strong>Network bandwidth (Gbps)</strong></td> \n   <td><strong>EBS bandwidth (Gbps)</strong></td> \n  </tr> \n  <tr> \n   <td><strong>P6-b200.48xlarge</strong></td> \n   <td>8</td> \n   <td>1440 HBM3e</td> \n   <td>192</td> \n   <td>1800</td> \n   <td>8 x 3.84 NVMe SSD</td> \n   <td>8 x 400</td> \n   <td>100</td> \n  </tr> \n </tbody> \n</table> \n<p>These instances feature up to 125 percent improvement in GPU TFLOPs, 27 percent increase in GPU memory size, and 60 percent increase in GPU memory bandwidth compared to P5en instances.</p> \n<p><strong><u>P6-B200 instances in action</u></strong><br /> You can use P6-B200 instances in the US West (Oregon) <a href=\"https://docs.aws.amazon.com/glossary/latest/reference/glos-chap.html#region\">AWS Region</a> through <a href=\"https://aws.amazon.com/ec2/capacityblocks/\">EC2 Capacity Blocks for ML</a>. To reserve your EC2 Capacity Blocks, choose <strong>Capacity Reservations</strong> on the <a href=\"https://us-east-2.console.aws.amazon.com/ec2/home?region=us-east-2#CapacityReservations:\">Amazon EC2 console</a>.</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/05/15/2025-ec2-p6-b200-instance-capacity-block.jpg\" alt=\"\" width=\"2514\" height=\"1798\" /></p> \n<p>Select <strong>Purchase Capacity Blocks for ML</strong> and then choose your total capacity and specify how long you need the EC2 Capacity Block for <strong>p6-b200.48xlarge</strong> instances. The total number of days that you can reserve EC2 Capacity Blocks is 1-14 days, 21 days, 28 days, or multiples of 7 up to 182 days. You can choose your earliest start date for up to 8 weeks in advance.</p> \n<p>Now, your EC2 Capacity Block will be scheduled successfully. The total price of an EC2 Capacity Block is charged up front, and the price doesn’t change after purchase. The payment will be billed to your account within 12 hours after you purchase the EC2 Capacity Blocks. To learn more, visit <a href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-capacity-blocks.html\">Capacity Blocks for ML</a> in the Amazon EC2 User Guide.</p> \n<p>When launching P6-B200 instances, you can use <a href=\"https://aws.amazon.com/machine-learning/amis/\">AWS Deep Learning AMIs</a> (DLAMI) to support EC2 P6-B200 instances. DLAMI provides ML practitioners and researchers with the infrastructure and tools to quickly build scalable, secure, distributed ML applications in preconfigured environments.</p> \n<p>To run instances, you can use <a href=\"https://console.aws.amazon.com/ec2\">AWS Management Console</a>, <a href=\"https://aws.amazon.com/cli/\">AWS Command Line Interface (AWS CLI)</a> or <a href=\"http://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/EC2.html\">AWS SDKs</a>.</p> \n<p>You can integrate EC2 P6-B200 instances seamlessly with various AWS managed services such as <a href=\"https://aws.amazon.com/eks/\">Amazon Elastic Kubernetes Services (Amazon EKS)</a>, <a href=\"https://aws.amazon.com/s3\">Amazon Simple Storage Service (Amazon S3)</a>, and <a href=\"https://aws.amazon.com/fsx/lustre/\">Amazon FSx for Lustre</a>. Support for <a href=\"https://aws.amazon.com/sagemaker-ai/hyperpod/\">Amazon SageMaker HyperPod</a> is also coming soon.</p> \n<p><strong><u>Now available</u></strong><br /> Amazon EC2 P6-B200 instances are available today in the US West (Oregon) Region and can be purchased as <a href=\"https://aws.amazon.com/ec2/capacityblocks/\">EC2 Capacity blocks for ML</a>.</p> \n<p>Give Amazon EC2 P6-B200 instances a try in the <a href=\"https://console.aws.amazon.com/ec2/\">Amazon EC2 console</a>. To learn more, refer to the <a href=\"https://aws.amazon.com/ec2/instance-types/p6/\">Amazon EC2 P6 instance page</a> and send feedback to <a href=\"https://repost.aws/tags/TAO-wqN9fYRoyrpdULLa5y7g/amazon-ec-2\">AWS re:Post for EC2</a> or through your usual AWS Support contacts.</p> \n<p>— <a href=\"https://twitter.com/channyun\">Channy</a></p> \n<hr /> \n<p>How is the News Blog doing? Take this <a href=\"https://amazonmr.au1.qualtrics.com/jfe/form/SV_eyD5tC5xNGCdCmi\">1 minute survey</a>!</p> \n<p><em>(This <a href=\"https://amazonmr.au1.qualtrics.com/jfe/form/SV_eyD5tC5xNGCdCmi\">survey</a> is hosted by an external company. AWS handles your information as described in the <a href=\"https://aws.amazon.com/privacy/?trk=4b29643c-e00f-4ab6-ab9c-b1fb47aa1708&amp;sc_channel=blog\">AWS Privacy Notice</a>. AWS will own the data gathered via this survey and will not share the information collected with survey respondents.)</em></p>","author":"Channy Yun (윤석찬)","siteTitle":"AWS News Blog","siteHash":"6093e072e4117ec22616e844cb857d03ca62c57a411a8affc77cb5e8b6b15bf6","entryHash":"38fca6067015725e00e5ac43cb366b341316d71a91f619b3f871a5e05508825f","category":"Tech"}