{"title":"Tad Friend’s 2016 Profile of Sam Altman for The New Yorker","link":"https://www.newyorker.com/magazine/2016/10/10/sam-altmans-manifest-destiny","date":1679949024000,"content":"\n<p>I remember reading and enjoying this profile of Sam Altman that was published in The New Yorker in October 2016, but I stumbled across it again over the weekend, and read it with new eyes. When published, Altman was running Y Combinator, and the profile largely focuses on that. But OpenAI — then new and mysterious — was mentioned quite a bit, and those are the bits that struck me now:</p>\n\n<blockquote>\n  <p>A.I. technology hardly seems almighty yet. After Microsoft\nlaunched a chatbot, called Tay, bullying Twitter users quickly\ntaught it to tweet such remarks as “gas the kikes race war now”;\nthe recently released “Daddy’s Car,” the first pop song created by\nsoftware, sounds like the Beatles, if the Beatles were cyborgs.\nBut, Musk told me, “just because you don’t see killer robots\nmarching down the street doesn’t mean we shouldn’t be concerned.”\nApple’s Siri, Amazon’s Alexa, and Microsoft’s Cortana serve\nmillions as aides-de-camp, and simultaneous-translation and\nself-driving technologies are now taken for granted. Y Combinator\nhas even begun using an A.I. bot, Hal9000, to help it sift\nadmission applications: the bot’s neural net trains itself by\nassessing previous applications and those companies’ outcomes.\n“What’s it looking for?” I asked Altman. “I have no idea,” he\nreplied. “That’s the unsettling thing about neural networks — you\nhave no idea what they’re doing, and they can’t tell you.”</p>\n\n<p>OpenAI’s immediate goals, announced in June, include a household\nrobot able to set and clear a table. One longer-term goal is to\nbuild a general A.I. system that can pass the Turing test — can\nconvince people, by the way it reasons and reacts, that it is\nhuman. Yet Altman believes that a true general A.I. should do more\nthan deceive; it should create, discovering a property of quantum\nphysics or devising a new art form simply to gratify its own itch\nto know and to make. While many A.I. researchers were correcting\nerrors by telling their systems, “That’s a dog, not a cat,” OpenAI\nwas focussed on having its system teach itself how things work.\n“Like a baby does?” I asked Altman. “The thing people forget about\nhuman babies is that they take years to learn anything\ninteresting,” he said. “If A.I. researchers were developing an\nalgorithm and stumbled across the one for a human baby, they’d get\nbored watching it, decide it wasn’t working, and shut it down.”</p>\n</blockquote>\n\n<p>To my mind, OpenAI’s GPT chat passes the Turing test. Artificial general intelligence is nascent, to be sure, but it’s no longer in the future. It’s the present.</p>\n\n<div>\n<a href=\"https://daringfireball.net/linked/2023/03/27/friend-altman-new-yorker\"> ★ </a>\n</div>\n\n\t","author":"John Gruber","siteTitle":"Daring Fireball","siteHash":"fc569638025dadf22a867470f8215f38855cf50e975782a6c989909474292a36","entryHash":"410b49e5bb9168c2dc8a686620749f237717361bb7dc37975070d50203f10861","category":"Tech"}