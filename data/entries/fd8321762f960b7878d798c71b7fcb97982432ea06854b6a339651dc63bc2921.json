{"title":"Google’s AI Overview is flawed by design, and a new company blog post hints at why","link":"https://arstechnica.com/?p=2027953","date":1717184877000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2024/05/mascots-g-16x9-v02_aJfUAiF.width-1600.format-webp-800x450.png\" alt=\"A selection of Google mascot characters created by the company.\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2024/05/mascots-g-16x9-v02_aJfUAiF.width-1600.format-webp.png\">Enlarge</a> <span>/</span> The Google \"G\" logo surrounded by whimsical characters, all of which look stunned and surprised. (credit: <a href=\"https://blog.google/products/search/doodle-for-google-2024-state-territory-winners/\">Google</a>)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>On Thursday, Google capped off a rough week of providing <a href=\"https://arstechnica.com/information-technology/2024/05/googles-ai-overview-can-give-false-misleading-and-dangerous-answers/\">inaccurate and sometimes dangerous</a> answers through its experimental AI Overview feature by authoring a follow-up <a href=\"https://blog.google/products/search/ai-overviews-update-may-2024/\">blog post</a> titled, \"AI Overviews: About last week.\" In the post, attributed to Google VP Liz Reid, head of Google Search, the firm formally acknowledged issues with the feature and outlined steps taken to improve a system that appears flawed by design, even if it doesn't realize it is admitting it.</p>\n\n<p>To recap, the AI Overview feature—which <a href=\"https://arstechnica.com/gadgets/2024/05/google-is-reimagining-search-in-the-gemini-era-with-improved-ai-options/\">the company showed off</a> at Google I/O a few weeks ago—aims to provide search users with summarized answers to questions by using an AI model integrated with Google's web ranking systems. Right now, it's an experimental feature that is not active for everyone, but when a participating user searches for a topic, they might see an AI-generated answer at the top of the results, pulled from highly ranked web content and summarized by an AI model.</p>\n<p>While Google claims this approach is \"highly effective\" and on par with its <a href=\"https://developers.google.com/search/docs/appearance/featured-snippets\">Featured Snippets</a> in terms of accuracy, the past week has seen numerous examples of the AI system generating bizarre, incorrect, or even potentially harmful responses, as we detailed in a <a href=\"https://arstechnica.com/information-technology/2024/05/googles-ai-overview-can-give-false-misleading-and-dangerous-answers/\">recent feature</a> where Ars reporter Kyle Orland replicated many of the unusual outputs.</p></div><p><a href=\"https://arstechnica.com/?p=2027953#p3\">Read 11 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=2027953&amp;comments=1\">Comments</a></p>","author":"Benj Edwards","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"fd8321762f960b7878d798c71b7fcb97982432ea06854b6a339651dc63bc2921","category":"Tech"}