{"title":"OpenAI Releases New O1 Reasoning Model","link":"https://www.theverge.com/2024/9/12/24242439/openai-o1-model-reasoning-strawberry-chatgpt","date":1726181034000,"content":"\n<p>Kylie Robison, reporting for The Verge:</p>\n\n<blockquote>\n  <p>OpenAI is releasing a new model called o1, the first in a planned\nseries of “reasoning” models that have been trained to answer more\ncomplex questions, faster than a human can. It’s being released\nalongside o1-mini, a smaller, cheaper version. And yes, if you’re\nsteeped in AI rumors: this is, in fact, <a href=\"https://www.theinformation.com/articles/new-details-on-openais-strawberry-apples-siri-makeover-larry-ellison-doubles-down-on-data-centers?rc=mshudk\">the extremely hyped\nStrawberry</a> model.</p>\n\n<p>For OpenAI, o1 represents a step toward its broader goal of\nhuman-like artificial intelligence. More practically, it does a\nbetter job at writing code and solving multistep problems than\nprevious models. But it’s also more expensive and slower to use\nthan GPT-4o. OpenAI is calling this release of o1 a “preview” to\nemphasize how nascent it is. [...]</p>\n\n<p>“The model is definitely better at solving the AP math test than I\nam, and I was a math minor in college,” OpenAI’s chief research\nofficer, Bob McGrew, tells me. He says OpenAI also tested o1\nagainst a qualifying exam for the International Mathematics\nOlympiad, and while GPT-4o only correctly solved only 13 percent\nof problems, o1 scored 83 percent.</p>\n</blockquote>\n\n<p>Putting aside the politics and other legitimate social and legal concerns around AI, scoring that well in a difficult math exam is just incredible. </p>\n\n<div>\n<a href=\"https://daringfireball.net/linked/2024/09/12/openai-o1\"> ★ </a>\n</div>\n\n\t","author":"John Gruber","siteTitle":"Daring Fireball","siteHash":"fc569638025dadf22a867470f8215f38855cf50e975782a6c989909474292a36","entryHash":"55cdf2a933096d734137deacfdac0323263e83eb4a7a0e9dbc3af32ad0cf0f0f","category":"Tech"}