{"title":"Mountpoint for Amazon S3 – Generally Available and Ready for Production Workloads","link":"https://aws.amazon.com/blogs/aws/mountpoint-for-amazon-s3-generally-available-and-ready-for-production-workloads/","date":1691592667000,"content":"<p><strong>Update (September 2023)</strong> – Add information about enabling file deletion.</p> \n<hr /> \n<p><a href=\"https://github.com/awslabs/mountpoint-s3\">Mountpoint for Amazon S3</a> is an open source file client that makes it easy for your file-aware Linux applications to connect directly to <a href=\"https://aws.amazon.com/s3/\">Amazon Simple Storage Service (Amazon S3)</a> buckets. <a href=\"https://aws.amazon.com/blogs/storage/the-inside-story-on-mountpoint-for-amazon-s3-a-high-performance-open-source-file-client/\">Announced</a> earlier this year as an alpha release, it is now generally available and ready for production use on your large-scale read-heavy applications: data lakes, machine learning training, image rendering, autonomous vehicle simulation, ETL, and more. It supports file-based workloads that perform sequential and random reads, sequential (append only) writes, and that don’t need full POSIX semantics.</p> \n<p><span><strong>Why Files?</strong></span><br /> Many AWS customers use the <a href=\"https://docs.aws.amazon.com/AmazonS3/latest/API/Welcome.html\">S3 APIs</a> and the <a href=\"https://aws.amazon.com/tools/\">AWS SDKs</a> to build applications that can list, access, and process the contents of an S3 bucket. However, many customers have existing applications, commands, tools, and workflows that know how to access files in UNIX style: reading directories, opening &amp; reading existing files, and creating &amp; writing new ones. These customers have asked us for an official, enterprise-ready client that supports performant access to S3 at scale. After speaking with these customers and asking lots of questions, we learned that performance and stability were their primary concerns, and that POSIX compliance was not a necessity.</p> \n<p>When I <a href=\"https://aws.amazon.com/blogs/aws/amazon_s3/\">first wrote about</a> Amazon S3 back in 2006 I was very clear that it was intended to be used as an object store, not as a file system. While you would not want use the Mountpoint / S3 combo to store your Git repositories or the like, using it in conjunction with tools that can read and write files, while taking advantage of S3’s scale and durability, makes sense in many situations.</p> \n<p><span><strong>All About <span>Mountpoint</span></strong></span><br /> <span>Mountpoint</span> is conceptually very simple. You create a mount point and mount an Amazon S3 bucket (or a path within a bucket) at the mount point, and then access the bucket using shell commands (<code>ls</code>, <code>cat</code>, <code>dd</code>, <code>find</code>, and so forth), library functions (<code>open</code>, <code>close</code>, <code>read</code>, <code>write</code>, <code>creat</code>, <code>opendir</code>, and so forth) or equivalent commands and functions as supported in the tools and languages that you already use.</p> \n<p>Under the covers, the <a href=\"https://tldp.org/LDP/khg/HyperNews/get/fs/vfstour.html\">Linux Virtual Filesystem</a> (VFS) translates these operations into calls to Mountpoint, which in turns translates them into calls to S3: <code>LIST</code>,<code> GET</code>, <code>PUT</code>, and so forth. <span>Mountpoint</span> strives to make good use of network bandwidth, increasing throughput and allowing you to reduce your compute costs by getting more work done in less time.</p> \n<p><span>Mountpoint</span> can be used from an <a href=\"https://aws.amazon.com/ec2/\">Amazon Elastic Compute Cloud (Amazon EC2)</a> instance, or within an <a href=\"https://aws.amazon.com/ecs/\">Amazon Elastic Container Service (Amazon ECS)</a> or <a href=\"https://aws.amazon.com/eks/\">Amazon Elastic Kubernetes Service (EKS)</a> container. It can also be installed on your existing on-premises systems, with access to S3 either directly or over an <a href=\"https://aws.amazon.com/directconnect/\">AWS Direct Connect</a> connection via <a href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/privatelink-interface-endpoints.html\">AWS PrivateLink for Amazon S3</a>.</p> \n<p><span><strong>Installing and Using</strong> <strong>Mountpoint for Amazon S3</strong></span><br /> <span>Mountpoint</span> is available in RPM format and can easily be installed on an EC2 instance running Amazon Linux. I simply fetch the RPM and install it using <code>yum</code>:</p> \n<div> \n <pre><code>$ wget https://s3.amazonaws.com/mountpoint-s3-release/latest/x86_64/mount-s3.rpm\n$ sudo yum install ./mount-s3.rpm\n</code></pre> \n</div> \n<p>For the last couple of years I have been regularly fetching images from several of the <a href=\"https://www.wsdot.com/ferries/vesselwatch/CameraDetail.aspx\">Washington State Ferry</a> webcams and storing them in my <strong>wsdot-ferry</strong> bucket:</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2023/08/07/mp_s3_ferry_1.jpg\" alt width=\"730\" height=\"806\" /></p> \n<p>I collect these images in order to track the comings and goings of the ferries, with a goal of analyzing them at some point to find the best times to ride. My goal today is to create a movie that combines an entire day’s worth of images into a nice time lapse. I start by creating a mount point and mounting the bucket:</p> \n<div> \n <pre><code>$ mkdir wsdot-ferry\n$  mount-s3 wsdot-ferry wsdot-ferry</code></pre> \n</div> \n<p>I can traverse the mount point and inspect the bucket:</p> \n<div> \n <pre><code>$ cd wsdot-ferry\n$ ls -l | head -10\ntotal 0\ndrwxr-xr-x 2 jeff jeff 0 Aug  7 23:07 2020_12_30\ndrwxr-xr-x 2 jeff jeff 0 Aug  7 23:07 2020_12_31\ndrwxr-xr-x 2 jeff jeff 0 Aug  7 23:07 2021_01_01\ndrwxr-xr-x 2 jeff jeff 0 Aug  7 23:07 2021_01_02\ndrwxr-xr-x 2 jeff jeff 0 Aug  7 23:07 2021_01_03\ndrwxr-xr-x 2 jeff jeff 0 Aug  7 23:07 2021_01_04\ndrwxr-xr-x 2 jeff jeff 0 Aug  7 23:07 2021_01_05\ndrwxr-xr-x 2 jeff jeff 0 Aug  7 23:07 2021_01_06\ndrwxr-xr-x 2 jeff jeff 0 Aug  7 23:07 2021_01_07\n$\n$  cd 2020_12_30\n$ ls -l\ntotal 0\ndrwxr-xr-x 2 jeff jeff 0 Aug  7 23:07 fauntleroy_holding\ndrwxr-xr-x 2 jeff jeff 0 Aug  7 23:07 fauntleroy_way\ndrwxr-xr-x 2 jeff jeff 0 Aug  7 23:07 lincoln\ndrwxr-xr-x 2 jeff jeff 0 Aug  7 23:07 trenton\ndrwxr-xr-x 2 jeff jeff 0 Aug  7 23:07 vashon_112_north\ndrwxr-xr-x 2 jeff jeff 0 Aug  7 23:07 vashon_112_south\ndrwxr-xr-x 2 jeff jeff 0 Aug  7 23:07 vashon_bunker_north\ndrwxr-xr-x 2 jeff jeff 0 Aug  7 23:07 vashon_bunker_south\ndrwxr-xr-x 2 jeff jeff 0 Aug  7 23:07 vashon_holding\n$\n$ cd fauntleroy_holding\n$  ls -l | head -10\ntotal 2680\n-rw-r--r-- 1 jeff jeff  19337 Feb 10  2021 17-12-01.jpg\n-rw-r--r-- 1 jeff jeff  19380 Feb 10  2021 17-15-01.jpg\n-rw-r--r-- 1 jeff jeff  19080 Feb 10  2021 17-18-01.jpg\n-rw-r--r-- 1 jeff jeff  17700 Feb 10  2021 17-21-01.jpg\n-rw-r--r-- 1 jeff jeff  17016 Feb 10  2021 17-24-01.jpg\n-rw-r--r-- 1 jeff jeff  16638 Feb 10  2021 17-27-01.jpg\n-rw-r--r-- 1 jeff jeff  16713 Feb 10  2021 17-30-01.jpg\n-rw-r--r-- 1 jeff jeff  16647 Feb 10  2021 17-33-02.jpg\n-rw-r--r-- 1 jeff jeff  16750 Feb 10  2021 17-36-01.jpg\n$\n</code></pre> \n</div> \n<p>I can create my animation with a single command:</p> \n<div> \n <pre><code>$ ffmpeg -framerate 10 -pattern_type glob -i \"*.jpg\" ferry.gif</code></pre> \n</div> \n<p>And here’s what I get:</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2023/08/07/ferry.gif\" alt width=\"352\" height=\"261\" /></p> \n<p>As you can see, I used <span>Mountpoint</span> to access the existing image files and to write the newly created animation back to S3. While this is a fairly simple demo, it does show how you can use your existing tools and skills to process objects in an S3 bucket. Given that I have collected several million images over the years, being able to process them without explicitly syncing them to my local file system is a big win.</p> \n<p><span><strong>Mountpoint for Amazon S3 Facts</strong></span><br /> Here are a couple of things to keep in mind when using <span>Mountpoint</span>:</p> \n<p><strong>Pricing</strong> – There are no new charges for the use of <span>Mountpoint</span>; you pay only for the underlying S3 operations. You can also use <span>Mountpoint</span> to access requester-pays buckets.</p> \n<p><strong>Performance</strong> – <span>Mountpoint</span> is able to take advantage of the elastic throughput offered by S3, including <a href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/optimizing-performance.html\">data transfer at up to 100 Gb/second</a> between each EC2 instance and S3.</p> \n<p><strong>Credentials</strong> – <span>Mountpoint</span> accesses your S3 buckets using the AWS credentials that are in effect when you mount the bucket. See the <a href=\"https://github.com/awslabs/mountpoint-s3/blob/main/doc/CONFIGURATION.md\">CONFIGURATION</a> doc for more information on credentials, bucket configuration, use of requester pays, some tips for the use of S3 Object Lambda, and more.</p> \n<p><strong>Operations</strong> <strong>&amp; Semantics</strong> – <span>Mountpoint</span> supports basic file operations, and can read files up to 5 TB in size. It can list and read existing files, and it can create new ones. It cannot modify existing files or delete directories, and it does not support symbolic links or file locking (if you need POSIX semantics, take a look at <a href=\"https://aws.amazon.com/fsx/lustre/\">Amazon FSx for Lustre</a>). To enable deletion of existing files, pass the <code>--allow-delete</code> flag to the <code>mount-s3</code> command. For more information about the supported operations and their interpretation, read the <a href=\"https://github.com/awslabs/mountpoint-s3/blob/main/doc/SEMANTICS.md\">SEMANTICS</a> document.</p> \n<p><strong>Storage Classes</strong> – You can use <span>Mountpoint</span> to access S3 objects in all storage classes except S3 Glacier Flexible Retrieval, S3 Glacier Deep Archive, S3 Intelligent-Tiering Archive Access Tier, and S3 Intelligent-Tiering Deep Archive Access Tier.</p> \n<p><strong>Open Source</strong> – <span>Mountpoint</span> is open source and has a public roadmap. Your contributions are welcome; be sure to read our <a href=\"https://github.com/awslabs/mountpoint-s3/blob/main/doc/CONTRIBUTING.md\">Contributing Guidelines</a> and our <a href=\"https://github.com/awslabs/mountpoint-s3/blob/main/doc/CODE_OF_CONDUCT.md\">Code of Conduct</a> first.</p> \n<p><span><strong>Hop On</strong></span><br /> As you can see, <span>Mountpoint</span> is really cool and I am guessing that you are going to find some awesome ways to put it to use in your applications. Check it out and let me know what you think!</p> \n<p>— <a href=\"https://twitter.com/jeffbarr\">Jeff</a>;</p>","author":"Jeff Barr","siteTitle":"AWS News Blog","siteHash":"6093e072e4117ec22616e844cb857d03ca62c57a411a8affc77cb5e8b6b15bf6","entryHash":"de19b00a04875a2dfa0e0243760429ba393ee7d537bc5429fefbe4a710e95f09","category":"Tech"}