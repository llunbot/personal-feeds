{"title":"Stable Diffusion Turbo XL can generate AI images as fast as you can type","link":"https://arstechnica.com/?p=1987046","date":1701292822000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2023/11/sdxl_turbo_4-800x450.jpg\" alt=\"Example images generated using Stable Diffusion XL Turbo.\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2023/11/sdxl_turbo_4.jpg\">Enlarge</a> <span>/</span> Example images generated using Stable Diffusion XL Turbo. (credit: Stable Diffusion XL Turbo / Benj Edwards)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>On Tuesday, Stability AI launched <a href=\"https://stability.ai/news/stability-ai-sdxl-turbo\">Stable Diffusion XL Turbo</a>, an AI image-synthesis model that can rapidly generate imagery based on a written prompt. So rapidly, in fact, that the company is billing it as \"real-time\" image generation, since it can also quickly transform images from a source, <a href=\"https://x.com/radamar/status/1729702545340137804?s=20\">such as a webcam</a>, quickly.</p>\n\n<p>SDXL Turbo's primary innovation lies in its ability to produce image outputs in a single step, a significant reduction from the 20â€“50 steps required by its predecessor. Stability attributes this leap in efficiency to a technique it calls <a href=\"https://stability.ai/research/adversarial-diffusion-distillation\">Adversarial Diffusion Distillation</a> (ADD). ADD uses score distillation, where the model learns from existing image-synthesis models, and adversarial loss, which enhances the model's ability to differentiate between real and generated images, improving the realism of the output.</p>\n<p>Stability detailed the model's inner workings in a <a href=\"https://static1.squarespace.com/static/6213c340453c3f502425776e/t/65663480a92fba51d0e1023f/1701197769659/adversarial_diffusion_distillation.pdf\">research paper</a> released Tuesday that focuses on the ADD technique. One of the claimed advantages of SDXL Turbo is its similarity to <a href=\"https://en.wikipedia.org/wiki/Generative_adversarial_network\">Generative Adversarial Networks</a> (GANs), especially in producing single-step image outputs.</p></div><p><a href=\"https://arstechnica.com/?p=1987046#p3\">Read 6 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=1987046&amp;comments=1\">Comments</a></p>","author":"Benj Edwards","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"0fecb73b96f6ca4ef33c4b4d521bdab3f110e3fa2bb67e166cd16048946e52ee","category":"Tech"}