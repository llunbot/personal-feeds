{"title":"นักพัฒนาพบโมเดล NeuralHash สำหรับตรวจภาพโป๊เด็กบน iOS 14.3 ขึ้นไป แปลงให้รันบนพีซีได้แล้ว","link":"https://www.blognone.com/node/124288","date":1629278160000,"content":"<div><div><div><p>ผู้ใช้ GitHub ชื่อบัญชี AsuharietYgvar ระบุว่าเขาพบโมเดลปัญญาประดิษฐ์สำหรับการแฮชภาพแบบ NeuralHash ที่แอปเปิลระบุว่าจะใช้งานสำหรับการตรวจสอบภาพโป๊เด็กก่อนอัพโหลดขึ้น iCloud Photos</p>\n<p><a href=\"https://github.com/AsuharietYgvar/AppleNeuralHash2ONNX\">โมเดลที่ AsuharietYgvar อ้างว่าอยู่ใน iOS</a> รับภาพขนาด 360x360 พิกเซล และคืนค่าออกมาเป็นแมทริกซ์ขนาด 96x128 แต่โค้ดส่วนต่อมาของแอปเปิลจะแปลงค่าแฮชจนเหลือขนาด 96 บิตเท่านั้น</p>\n<p>ไม่แน่ชัดว่าทำไมแอปเปิลจึงใส่ฟังก์ชั่น NeuralHash เข้ามาใน iOS ก่อนใช้งานระบบตรวจสอบภาพโป๊เด็ก อย่างไรก็ดีฟังก์ชั่นนี้จะใช้งานได้ต่อเมื่อมีฐานข้อมูลค่าแฮชให้มาตรวจเทียบกัน โดยแอปเปิลเคยระบุว่าจะปล่อยฐานข้อมูลค่าแฮชพร้อมกับการอัพเดตระบบปฎิบัติการ การอัพเดตจะแจ้งทั้งค่า root hash ของตัวฐานข้อมูล และจำนวนภาพที่แอปเปิลจะแบนบัญชีเพื่อตรวจสอบ</p>\n<p>หากในอนาคตนักวิจัยสามารถถอดรหัสฐานข้อมูลค่าแฮชภาพโป๊เด็กของแอปเปิลออกมาได้ ก็เป็นไปได้ที่จะสร้างปัญญาประดิษฐ์ที่สร้างภาพจนค่าแฮชตรงกันในที่สุด</p>\n<p>ที่มา - <a href=\"https://www.reddit.com/r/MachineLearning/comments/p6hsoh/p_appleneuralhash2onnx_reverseengineered_apple/\">reddit: r/MachineLearning</a></p>\n<p><img src=\"https://www.blognone.com/sites/default/files/externals/ba7ce76bd4e1ffeb074eaf03a4158a6a.jpg\" /></p>\n</div></div></div><div><div>Topics: </div><div><div><a href=\"/topics/ios\">iOS</a></div><div><a href=\"/topics/apple\">Apple</a></div><div><a href=\"/topics/artificial-intelligence\">Artificial Intelligence</a></div><div><a href=\"/topics/privacy\">Privacy</a></div></div></div>","author":"lew","siteTitle":"Blognone","siteHash":"ededadcf18490b3937e7dd89ebe8c00dc129addbdf1ebe4aff1f458146693da0","entryHash":"a6b8ae7c8dbbd3608fa2dc6152678d3ad6ee23446d268b0712e76c96eb6a2d10","category":"Thai"}