{"title":"GPT-3 aces tests of reasoning by analogy","link":"https://arstechnica.com/?p=1957885","date":1690833306000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2023/07/GettyImages-177274989-800x532.jpg\" alt=\"A hammer being used to force a square block through a round hole.\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2023/07/GettyImages-177274989.jpg\">Enlarge</a> (credit: <a href=\"https://www.gettyimages.com/detail/photo/brute-force-royalty-free-image/177274989?phrase=square+peg%2C+round+hole&amp;adppopup=true\">zoom</a>)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p><a href=\"https://arstechnica.com/science/2023/07/a-jargon-free-explanation-of-how-ai-large-language-models-work/\">Large language models</a> are a class of AI algorithm that relies on a high number computational nodes and an equally large number of connections among them. They can be trained to perform a variety of functions—<a href=\"https://arstechnica.com/science/2023/03/large-language-models-also-work-for-protein-structures/\">protein folding, anyone</a>?—but they're mostly recognized for their capabilities with human languages.</p>\n<p>LLMs trained to simply predict the next word that will appear in text can produce human-sounding conversations and essays, although with some worrying accuracy issues. The systems have demonstrated a variety of behaviors that appear to go well beyond the simple language capabilities they were trained to handle.</p>\n<p>We can apparently add analogies to the list of items that LLMs have inadvertently mastered. A team from University of California, Los Angeles has tested the GPT-3 LLM using questions that should be familiar to any Americans that have spent time on standardized tests like the SAT. In all but one variant of these questions, GPT-3 managed to outperform undergrads who presumably had mastered these tests just a few years earlier. The researchers suggest that this indicates that Large Language Models are able to master reasoning by analogy.</p></div><p><a href=\"https://arstechnica.com/?p=1957885#p3\">Read 12 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=1957885&amp;comments=1\">Comments</a></p>","author":"John Timmer","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"3f350a292a1496623cc1b9dae7f92f35eaaffe4eb62a35d0974226fb2899ecb2","category":"Tech"}