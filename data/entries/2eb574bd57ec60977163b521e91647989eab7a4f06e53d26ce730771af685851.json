{"title":"GPU-Rich, GPU-Poor and TPU","link":"https://markpeak.net/gpu-rich-gpu-poor-tpu/","date":1693537848000,"content":"<p>เคยเขียนบทความเรื่อง <a href=\"https://markpeak.net/three-pillars-of-large-ai/\">3 เสาหลักของการสร้าง AI ขนาดใหญ่</a> ว่ามันเป็นเกมของยักษ์ เพราะ AI ขนาดใหญ่ต้องเกิดจาก data, compute, algorithm ประกอบเข้าด้วยกัน</p>\n<p>คำว่า compute ในที่นี้ย่อมหมายถึง GPU หรือชิปเฉพาะทางอื่นๆ ตามที่เขียนไว้แล้ว</p>\n<p>SemiAnalysis เว็บวิเคราะห์อุตสาหกรรมเซมิคอนดักเตอร์ที่ติดตามอยู่ ได้เขียนบทความเรื่องปริมาณ GPU ในวงการ AI ไว้น่าสนใจ</p>\n<p>ตัวบทความฉบับเต็มต้องเสียเงินค่าสมาชิกเพื่ออ่าน แต่ช่วงแรกของบทความที่เปิดให้อ่านฟรีก็ค่อนข้างยาวประมาณหนึ่งแล้ว อ่านได้เนื้อหาใจความเยอะโดยไม่ต้องจ่ายเงิน</p>\n<div>\n\t\t\t<div>\n\t\t\t\t<a href=\"https://www.semianalysis.com/p/google-gemini-eats-the-world-gemini\">\n\t\t\t\t\t<img src=\"https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F789fb8bc-b4f3-44cb-bb95-68ed79d2a119_2000x844.png\" alt=\"Google Gemini Eats The World – Gemini Smashes GPT-4 By 5X, The GPU-Poors\" />\t\t\t\t</a>\n\t\t</div>\n\t\n\t<div>\n\t\t<a href=\"https://www.semianalysis.com/p/google-gemini-eats-the-world-gemini\">\n\t\t\tGoogle Gemini Eats The World – Gemini Smashes GPT-4 By 5X, The GPU-Poors\t\t</a>\n\t</div>\n\t<div>\n\t\t<a href=\"https://www.semianalysis.com/p/google-gemini-eats-the-world-gemini\">\n\t\t\t<p>Compute Resources That Make Everyone Look GPU-Poor</p>\n\t\t</a>\n\t</div>\n\t<div>\n\t\t<img src=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F78f716ef-b012-4809-8543-abd5e3b9f7a5%2Ffavicon.ico\" alt=\"www.semianalysis.com\" />\t\twww.semianalysis.com\t</div>\n</div>\n<p>ประเด็นหลักที่ SemiAnalysis กล่าวถึงคือการจัดกลุ่มบริษัทที่มี GPU จำนวนมากหรือน้อย (ในที่นี้หมายถึง GPU ระดับศูนย์ข้อมูล NVIDIA A100/H100 ตัวละเป็นล้าน) ซึ่งกระทบต่อความสามารถในการเทรนโมเดลขนาดใหญ่อย่างมาก</p>\n<p><strong>GPU-Rich</strong></p>\n<p>กลุ่มที่มี GPU จำนวนเยอะ (ในที่นี้คือมากกว่า 20,000 ตัวต่อบริษัท)</p>\n<ul>\n<li>OpenAI (เข้าใจว่ารวม Microsoft)</li>\n<li>Google</li>\n<li>Anthropic</li>\n<li>Inflection</li>\n<li>X/Tesla</li>\n<li>Meta</li>\n</ul>\n<p>อาจมีพวกบริษัทจีนบางรายที่มี GPU ระดับ 100,000 ตัวขึ้นไป แต่ข้อมูลฝั่งจีนมีน้อย</p>\n<p>บริษัทกลุ่ม elite พวกนี้มีการรวมตัวกันเองในชื่อว่า <a href=\"https://www.blognone.com/node/135025\">Frontier Model Forum</a> เพราะสามารถสร้างโมเดลขนาดใหญ่ที่ใช้บุกเบิกอนาคต (frontier) ได้</p>\n<p>แม้แต่บริษัทใหญ่ระดับ Microsoft ก็ยังมีปัญหานี้ โดย <a href=\"https://www.theverge.com/23733388/microsoft-kevin-scott-open-ai-chat-gpt-bing-github-word-excel-outlook-copilots-sydney\">Kevin Scott CTO ของ Microsoft เคยให้สัมภาษณ์เอาไว้</a>ว่าเขาต้องดึงงบซื้อ GPU ของทั้งบริษัทมาถือไว้คนเดียว เพื่อจัดสรรทรัพยากรใหม่ให้เหมาะสม ซึ่งไม่ใช่เรื่องดีเพราะคนเกลียดเขาทั้งบริษัทเลย แต่เป็นสิ่งที่จำเป็นต้องทำ</p>\n<p>แสดงให้เห็นว่าเรื่อง GPU มันบีบคั้นมาก แข่งขันสูงมาก (NVIDIA รวย!)</p>\n<p>https://twitter.com/Podcast_GPT/status/1661743320425721860</p>\n<p><strong>GPU-Poor</strong></p>\n<p>ก็คือบริษัทสตาร์ตอัพเล็กๆ หรือนักวิจัยอิสระที่ไม่ได้อยู่ในกลุ่มแรก ข้อเสียเปรียบของกลุ่มนี้คือต่อให้คิดอัลกอริทึมหรือโมเดลที่ดีแค่ไหนก็ตาม แต่การไม่มีเครื่องมือ (GPU) ทำให้เทรนโมเดลขนาดใหญ่ได้ช้ากว่ากลุ่มแรกมาก</p>\n<p>ทางออกของบริษัทหรือนักวิจัยกลุ่มนี้ จึงเป็นการนำโมเดลขนาดใหญ่ที่เป็นโอเพนซอร์ส (เช่น Meta Llama) มาปรับจูนอีกที หรือทำโครงการขนาดเล็กลง โมเดลแบบแน่นขึ้น (dense model vs sparse model) เพื่อให้ GPU เกรดทั่วไป เกรดเกมมิ่ง สามารถใช้แทนได้</p>\n<p>อีกทางเลือกของบริษัทกลุ่มหลังคือการเช่า GPU ผ่านคลาวด์แทน ถ้าไม่ใช่กลุ่ม cloud provider ขนาดใหญ่ ตัวอย่างผู้ให้บริการรายย่อยคือ HuggingFace (<a href=\"https://huggingface.co/pricing\">pricing</a>) แต่ตลาดนี้กำลังจะถูกทำลายเช่นกัน เพราะ NVIDIA จะลงมาทำแข่งภายใต้บริการชื่อ <a href=\"https://www.nvidia.com/en-us/data-center/dgx-cloud/\">DGX Cloud</a> ซึ่งเหนือกว่าทุกคนตรงที่มี GPU ของตัวเองกันไว้ใช้เองอยู่แล้ว</p>\n<p><strong>TPU</strong></p>\n<p>ทางออกอีกแบบไปเลยของวงการ GPU สำหรับเทรนโมเดล คือ การใช้ชิปแบบอื่นอย่าง TPU (Tensor Processing Unit) ซึ่งมี Google เพียงบริษัทเดียวที่มีอะไรแบบนี้</p>\n<p>ผมเคยเขียนเรื่อง TPU เอาไว้บ้าง ความน่ากลัวที่สุดของ TPU คือการที่ Google รู้ปริมาณ workload ของตัวเองว่าโมเดลแบบไหนมีเยอะน้อย ขึ้นลงตามยุคสมัย</p>\n<div>\n\t\t\t<div>\n\t\t\t\t<a href=\"https://www.blognone.com/node/133357\">\n\t\t\t\t\t<img src=\"https://www.blognone.com/sites/default/files/externals/b997fdc91df8894c78f68b6564b7efa5.jpg\" alt=\"กูเกิลเผยรายละเอียดเครื่อง TPU v4 ใช้สวิตช์แสงเชื่อมต่อชิป, แรงกว่า NVIDIA A100 | Blognone\" />\t\t\t\t</a>\n\t\t</div>\n\t\n\t<div>\n\t\t<a href=\"https://www.blognone.com/node/133357\">\n\t\t\tกูเกิลเผยรายละเอียดเครื่อง TPU v4 ใช้สวิตช์แสงเชื่อมต่อชิป, แรงกว่า NVIDIA A100 | Blognone\t\t</a>\n\t</div>\n\t<div>\n\t\t<a href=\"https://www.blognone.com/node/133357\">\n\t\t\t\t\t</a>\n\t</div>\n\t<div>\n\t\t<img src=\"https://www.blognone.com/sites/default/files/bn96.png\" alt=\"www.blognone.com\" />\t\twww.blognone.com\t</div>\n</div>\n<p>จากตารางจะเห็นว่า งานบางประเภท เช่น Deep learning recommendation models (DLRM) ที่แนะนำสิ่งที่ผู้ใช้น่าจะชอบ (เช่น คลิปใน YouTube) เริ่มลดปริมาณลง แต่งานรันโมเดล Transformer ขนาดใหญ่ (LLM) เพิ่มขึ้นในช่วงหลัง</p>\n<p><img loading=\"lazy\" src=\"https://markpeak.net/wp-content/uploads/2023/09/tpu-workloads.png\" width=\"559\" height=\"410\" srcset=\"https://markpeak.net/wp-content/uploads/2023/09/tpu-workloads.png 559w, https://markpeak.net/wp-content/uploads/2023/09/tpu-workloads-300x220.png 300w\" /></p>\n<p>การที่ Google มองเห็นเทรนด์พวกนี้ จึงสามารถออกแบบ TPU ให้เหมาะสมตามปริมาณงานได้ (เช่น การมีฮาร์ดแวร์ SparseCore สำหรับงาน DLRM) ในแง่ efficiency ย่อมดีกว่าคู่แข่งรายอื่นๆ ที่ใช้ Generic GPU อยู่แล้ว (<a href=\"https://www.blognone.com/node/135515\">ข่าวล่าสุดเรื่อง TPU v5e ที่เน้น efficiency แบบสุดๆ</a>) Google จึงได้เปรียบการแข่งขันเรื่องต้นทุนรวมในการเทรน-รันโมเดลอย่างมาก</p>\n<p>ความน่ากลัวของการมี TPU เอง สามารถดูได้จากคลิปนี้ คู่แข่งดูแล้วก็ไม่รู้จะเอาอะไรไปสู้อีกเหมือนกัน</p>\n<p></p>\n<p>หลังบทความนี้เผยแพร่ออกไป Sam Altman ซีอีโอของ OpenAI ถึงกับโพสต์แซะว่า กูเกิลจ้าง SemiAnalysis มาเขียนโปรโมทเลยเหรอ</p>\n<blockquote>\n<p>incredible google got that semianalysis guy to publish their internal marketing/recruiting chart lol</p>\n<p>— Sam Altman (@sama) <a href=\"https://twitter.com/sama/status/1696340377098453440?ref_src=twsrc%5Etfw\">August 29, 2023</a></p></blockquote>\n<p></p>The post <a href=\"https://markpeak.net/gpu-rich-gpu-poor-tpu/\">GPU-Rich, GPU-Poor and TPU</a> first appeared on <a href=\"https://markpeak.net\">markpeak.net</a>.","author":"Isriya Paireepairit","siteTitle":"markpeak.net","siteHash":"174209a41ef21fd794de2993285c799df6ec31048fd82206fb5c8fe38898acfe","entryHash":"2eb574bd57ec60977163b521e91647989eab7a4f06e53d26ce730771af685851","category":"Thai"}