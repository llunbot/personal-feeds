{"title":"Runway’s latest AI video generator brings giant cotton candy monsters to life","link":"https://arstechnica.com/?p=2032130","date":1718746916000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2024/06/runway_cotton_candy_monster_screenshot-800x480.jpg\" alt=\"Screen capture of a Runway Gen-3 Alpha video generated with the prompt \" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2024/06/runway_cotton_candy_monster_screenshot.jpg\">Enlarge</a> <span>/</span> Screen capture of a Runway Gen-3 Alpha video generated with the prompt \"A giant humanoid, made of fluffy blue cotton candy, stomping on the ground, and roaring to the sky, clear blue sky behind them.\" (credit: <a href=\"https://runwayml.com/blog/introducing-gen-3-alpha/\">Runway</a>)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>On Sunday, Runway announced a new AI video synthesis model called <a href=\"https://runwayml.com/blog/introducing-gen-3-alpha/\">Gen-3 Alpha</a> that's still under development, but it appears to create video of similar quality to <a href=\"https://arstechnica.com/information-technology/2024/02/openai-collapses-media-reality-with-sora-a-photorealistic-ai-video-generator/\">OpenAI's Sora</a>, which debuted earlier this year (and has also not yet been released). It can generate novel, high-definition video from text prompts that range from realistic humans to surrealistic monsters stomping the countryside.</p>\n\n<p>Unlike Runway's <a href=\"https://research.runwayml.com/gen2\">previous best model</a> from June 2023, which could only create two-second-long clips, Gen-3 Alpha can reportedly create 10-second-long video segments of people, places, and things that have a consistency and coherency that easily surpasses Gen-2. If 10 seconds sounds short compared to Sora's full minute of video, consider that the company is working with a shoestring budget of compute compared to more lavishly funded OpenAI—and actually has a history of shipping video generation capability to commercial users.</p>\n<p>Gen-3 Alpha does not generate audio to accompany the video clips, and it's highly likely that temporally coherent generations (those that keep a character consistent over time) are dependent on <a href=\"https://x.com/bcmerchant/status/1758537510618304669\">similar high-quality training material</a>. But Runway's improvement in visual fidelity over the past year is difficult to ignore.</p></div><p><a href=\"https://arstechnica.com/?p=2032130#p3\">Read 20 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=2032130&amp;comments=1\">Comments</a></p>","author":"Benj Edwards","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"4d2ee962913cc0c32ac020a127671a2a50c621bc957b32ae018c7dd7b9e82779","category":"Tech"}