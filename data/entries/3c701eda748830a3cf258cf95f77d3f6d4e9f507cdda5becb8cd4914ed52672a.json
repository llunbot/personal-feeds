{"title":"New Amazon DynamoDB zero-ETL integration with Amazon SageMaker Lakehouse","link":"https://aws.amazon.com/blogs/aws/new-amazon-dynamodb-zero-etl-integration-with-amazon-sagemaker-lakehouse/","date":1733252346000,"content":"<p><a href=\"https://aws.amazon.com/dynamodb/\">Amazon DynamoDB</a>, a serverless NoSQL database, has been a go-to solution for over one million customers to build low-latency and high-scale applications. As data grows, organizations are constantly seeking ways to extract valuable insights from operational data, which is often stored in DynamoDB. However, to make the most of this data in Amazon DynamoDB for analytics and machine learning (ML) use cases, customers often build custom data pipelines—a time-consuming infrastructure task that adds little unique value to their core business.</p> \n<p>Starting today, you can use Amazon DynamoDB zero-ETL integration with Amazon SageMaker Lakehouse to run analytics and ML workloads in just a few clicks without consuming your DynamoDB table capacity. Amazon SageMaker Lakehouse unifies all your data across Amazon S3 data lakes and Amazon Redshift data warehouses, helping you build powerful analytics and AI/ML applications on a single copy of data.</p> \n<p>Zero-ETL is a set of integrations that eliminates or minimizes the need to build ETL data pipelines. This zero-ETL integration reduces the complexity of engineering efforts required to build and maintain data pipelines, benefiting users running analytics and ML workloads on operational data in Amazon DynamoDB without impacting production workflows.</p> \n<p><strong><span>Let’s get started<br /></span></strong>For the following demo, I need to set up zero-ETL integration for my data in Amazon DynamoDB with an <a href=\"https://aws.amazon.com/s3/?nc2=type_a\">Amazon Simple Storage Service</a> data lake managed by Amazon SageMaker Lakehouse. Before setting up the zero-ETL integration, there are prerequisites to complete. If you want to learn more on how to set up, refer to this <a href=\"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/amazon-sagemaker-lakehouse-for-DynamoDB.html\">Amazon DynamoDB documentation</a> page.</p> \n<p>With all the prerequisites completed, I can get started with this integration. I navigate to the <a href=\"https://aws.amazon.com/glue/\">AWS Glue</a> console and select <strong>Zero-ETL integrations</strong> under <strong>Data Integration and ETL</strong>. Then, I choose <strong>Create zero-ETL integration</strong>.</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/11/26/news-2024-riv-ddb-glue-lakehouse-0.png\" width=\"3840\" height=\"1938\" /></p> \n<p>Here, I have options to select my data source. I choose <strong>Amazon DynamoDB</strong> and choose <strong>Next</strong>.</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/11/26/news-2024-riv-ddb-glue-lakehouse-1.png\" width=\"3098\" height=\"2615\" /></p> \n<p>Next, I need to configure the source and target details. In the <strong>Source details</strong> section, I select my Amazon DynamoDB table. In the <strong>Target details</strong> section, I specify the S3 bucket that I’ve set up in the AWS Glue Data Catalog.</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/11/26/news-2024-riv-ddb-glue-lakehouse-2.png\" width=\"3430\" height=\"1804\" /></p> \n<p>To set up this integration, I need an IAM role that grants AWS Glue the necessary permissions. For guidance on configuring IAM permissions, visit the <a href=\"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/amazon-sagemaker-lakehouse-for-DynamoDB.html\">Amazon DynamoDB documentation</a> page. Also, if I haven’t configured a resource policy for my AWS Glue Data Catalog, I can select <strong>Fix it for me</strong> to automatically add the required resource policies.</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/11/26/news-2024-riv-ddb-glue-lakehouse-3-1.png\" width=\"3456\" height=\"1817\" /></p> \n<p>Here, I have options to configure the output. Under <strong>Data partitioning</strong>, I can either use DynamoDB table keys for partitioning or specify custom partition keys. After completing the configuration, I choose <strong>Next</strong>.</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/11/26/news-2024-riv-ddb-glue-lakehouse-5-1.png\" width=\"3456\" height=\"1815\" /></p> \n<p>Because I select the <strong>Fix it for me</strong> checkbox, I need to review the required changes and choose <strong>Continue</strong> before I can proceed to the next step.</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/11/26/news-2024-riv-ddb-glue-lakehouse-4.png\" width=\"1781\" height=\"939\" /></p> \n<p>On the next page, I have the flexibility to configure data encryption. I can use <a href=\"https://aws.amazon.com/kms/\">AWS Key Management Service (AWS KMS)</a> or a custom encryption key. Then, I assign a name to the integration and choose <strong>Next</strong>.</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/11/29/news-2024-riv-ddb-glue-lakehouse-6-2.png\" width=\"3456\" height=\"1815\" /></p> \n<p>On the last step, I need to review the configurations. When I’m happy, I choose <strong>Next</strong> to create the zero-ETL integration.</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/11/26/news-2024-riv-ddb-glue-lakehouse-7.png\" width=\"3456\" height=\"1815\" /></p> \n<p>After the initial data ingestion completes, my zero-ETL integration will be ready for use. The completion time varies depending on the size of my source DynamoDB table.</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/11/26/news-2024-riv-ddb-glue-lakehouse-8.png\" width=\"3456\" height=\"1815\" /></p> \n<p>If I navigate to <strong>Tables</strong> under <strong>Data Catalog</strong> in the left navigation panel, I can observe more details including <strong>Schema</strong>. Under the hood, this zero-ETL integration uses <a href=\"https://iceberg.apache.org/\">Apache Iceberg</a> to transform related to data format and structure in my DynamoDB data into Amazon S3.</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/11/26/news-2024-riv-ddb-glue-lakehouse-9-1.png\" width=\"3456\" height=\"1713\" /></p> \n<p>Lastly, I can tell that all my data is available in my S3 bucket. </p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/11/26/news-2024-riv-ddb-glue-lakehouse-10.png\" width=\"3456\" height=\"1713\" /></p> \n<p>This zero-ETL integration significantly reduces the complexity and operational burden of data movement, and I can therefore focus on extracting insights rather than managing pipelines.</p> \n<p><strong><span>Available now</span><br /></strong>This new zero-ETL capability is available in the following AWS Regions: US East (N. Virginia, Ohio), US West (Oregon), Asia Pacific (Hong Kong, Singapore, Sydney, Tokyo), Europe (Frankfurt, Ireland, Stockholm).</p> \n<p>Explore how to streamline your data analytics workflows using Amazon DynamoDB zero-ETL integration with Amazon SageMaker Lakehouse. Learn more how to get started on the <a href=\"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/amazon-sagemaker-lakehouse-for-DynamoDB.html\">Amazon DynamoDB documentation</a> page.</p> \n<p>Happy building!<br />— <a href=\"https://linkedin.com/in/donnieprakoso\">Donnie</a></p>","author":"Donnie Prakoso","siteTitle":"AWS News Blog","siteHash":"6093e072e4117ec22616e844cb857d03ca62c57a411a8affc77cb5e8b6b15bf6","entryHash":"3c701eda748830a3cf258cf95f77d3f6d4e9f507cdda5becb8cd4914ed52672a","category":"Tech"}