{"title":"ChatGPT-4o allows real-time audio-video conversations with an “emotional” AI chatbot","link":"https://arstechnica.com/?p=2023751","date":1715623088000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2024/05/colorful_waveform_1-800x450.jpg\" alt=\"Abstract multicolored waveform\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2024/05/colorful_waveform_1.jpg\">Enlarge</a> (credit: <a href=\"https://www.gettyimages.com/detail/photo/abstract-multicolored-curve-chart-stock-photo-royalty-free-image/1469448038\">Getty Images</a>)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>On Monday, OpenAI debuted <a href=\"https://openai.com/index/hello-gpt-4o/\">GPT-4o</a> (o for \"omni\"), a major new AI model that can reportedly converse using speech in realtime, reading emotional cues and responding to visual input. It operates faster than OpenAI's previous best model, <a href=\"https://arstechnica.com/information-technology/2023/11/openai-introduces-gpt-4-turbo-larger-memory-lower-cost-new-knowledge/\">GPT-4 Turbo</a>, and will be free for ChatGPT users and available as a service through API, rolling out over the next few weeks.</p>\n\n<p>OpenAI revealed the new audio conversation and vision comprehension capabilities in a YouTube <a href=\"https://www.youtube.com/watch?v=DQacCB9tDaw&amp;t=2s\">livestream</a> titled \"OpenAI Spring Update,\" presented by OpenAI CTO Mira Murati and employees Mark Chen and Barret Zoph that included live demos of GPT-4o in action.</p>\n<p>OpenAI claims that GPT-4o responds to audio inputs in about 320 milliseconds on average, which is similar to human response times in conversation, according to a <a href=\"https://www.pnas.org/doi/10.1073/pnas.0903616106\">2009 study</a>. With GPT-4o, OpenAI says it trained a brand new AI model end-to-end using text, vision, and audio in a way that all inputs and outputs \"are processed by the same neural network.\"</p></div><p><a href=\"https://arstechnica.com/?p=2023751#p3\">Read 12 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=2023751&amp;comments=1\">Comments</a></p>","author":"Benj Edwards","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"3296a1e05139f789dfb05e0c2895dc5e352b1dadffa596da64b46d97650e6e85","category":"Tech"}