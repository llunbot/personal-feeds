{"title":"The real Apple Intelligence is the AI we met along the way","link":"https://www.macworld.com/article/2550775/apples-long-game-on-ai.html","date":1733830200000,"content":"<p><a href=\"https://www.macworld.com\">Macworld</a></p>\n\n<div>\n<section><div></div></section>\n\n\n\n<p>Despite what you might have heard from AI companies, Apple doesn’t think the Singularity is coming any time soon.</p>\n\n\n\n<p>Writing for Wired, Steven Levy gives us <a href=\"https://www.wired.com/story/plaintext-the-inside-story-of-apple-intelligence/\">“The Inside Story of Apple Intelligence”</a> (subscription required) via an interview with Apple executives, including senior vice president of machine learning and AI strategy John Giannandrea.</p>\n\n\n\n<blockquote>\n<p>All of the executives, including Cook, emphasized that despite the massively disruptive potential of AI, Apple was going to handle this game-changing tech with the same clarity and meticulousness the company is known for.</p>\n</blockquote>\n\n\n\n<p>No running around screaming and flipping over tables and seat cushions looking for spare bits of AI to cobble together into something for <em>this</em> company! Leave <em>that</em> to the competitors.</p>\n\n\n\n<p>Apple loves to tell us that iPhones are already chock full o’ AI.</p>\n\n\n\n<blockquote>\n<p>“Face ID is a feature you use every day, many, many times a day to unlock your phone, and you have no idea how it really works,” [Giannandrea] said.</p>\n</blockquote>\n\n\n\n<p>Buddy, the Macalope doesn’t have any idea how <em>most</em> things work, let alone Face ID.</p>\n\n\n\n<p>Center Stage.</p>\n\n\n\n<p>Message Effects.</p>\n\n\n\n<p>Kittens.</p>\n\n\n\n<p>Soup.</p>\n\n\n\n<p>Is it a solid or a liquid? <em>I don’t know. No one does.</em></p>\n\n\n\n<p>Giannandrea’s point is one that Apple makes every chance it gets: We’re already doin’ so much AI, y’all! Which, of course, is true, it’s just not that <em>new</em> AI that you can ask questions to and sometimes even get a correct answer. But at least you’ll always get an answer! And confidently. Until you tell the AI it’s wrong and it folds like a cheap suit.</p>\n\n\n<div><figure><img src=\"https://images.idgesg.net/images/idge/imported/imageapi/2021/12/28/13/macalope-2021-100915055-orig.jpg?quality=50&amp;strip=all&amp;auto=webp&amp;quality=85,70\" alt=\"Macalope\" width=\"1500\" height=\"1000\" loading=\"lazy\" />\n\t\t\t\n\t\t\t\t\n\t\t\t\n\t\t</figure><p>IDG</p></div>\n\n\n\n\n<p>[obsequiously] “Ohhh, I’m so sorrry. How could I have made such a mistake? Maybe because I’m just a ridiculously large number of regular expressions stuffed into some code and run against the entire internet using a coal furnace to power me. Maybe that had something to do with it. Again, a thousand pardons.”</p>\n\n\n\n<blockquote>\n<p>Apple decided early on that Apple Intelligence wouldn’t be a separate product, but instead something implemented on a systems level.</p>\n</blockquote>\n\n\n\n<p>Much like that famous meeting <a href=\"https://www.forbes.com/sites/victoriabarret/2011/10/18/dropbox-the-inside-story-of-techs-hottest-startup/\">between Apple and Dropbox</a>, Apple has correctly assessed that AI is not the thing you sell, it’s a thing that goes into the thing that you sell. We can certainly argue whether or not iCloud has ever achieved Dropbox’s level of reliability, but the fact that the latter has since switched focus to enterprise customers tells you it doesn’t consider itself a consumer product. AI is the same, which is why AI companies are currently having a collective identity crisis. Also because they asked an AI who they were and the AI said they were a type of congealed meat product akin to pimento loaf.</p>\n\n\n\n<p>Not entirely wrong but also not correct.</p>\n\n\n\n<p>The great thing about writing jokes about AI online is that after the next round of scraping the internet for material, an AI is very likely to regurgitate said jokes as valid answers.</p>\n\n\n\n<p>Another reason AI is currently floundering? While AI is definitely A, it is not, in fact, I.</p>\n\n\n\n<blockquote>\n<p>“The most credible researchers in the field believe there are many unsolved problems and breakthroughs required,” says Giannandrea. “The idea that you’re scaling up these technologies to go to AGI [Artificial General Intelligence] is very naive.”</p>\n</blockquote>\n\n\n\n<p>Large language models can do some neat tricks, but they’re about as far from AGI as an abacus is from a M4 MacBook Pro and there’s only <a href=\"https://finance.yahoo.com/news/openai-google-anthropic-struggling-build-100020816.html\">so much you can do with an abacus</a>.</p>\n\n\n\n<blockquote>\n<p>He says that Apple may very well be involved in important breakthroughs–not to kickstart the Singularity, but to improve its products.</p>\n</blockquote>\n\n\n\n<p>Okay, well… that’s good. And that’s what it <em>should</em> be doing.</p>\n\n\n\n<p>Sometimes it’s hard to separate truth from grandiosely making excuses for yourself, but it might just be both when Apple executives tell Levy that one of the reasons it doesn’t have an in-your-face AI model of its own is because taking AI to the next step requires access to personal data at the data center level and Apple wanted to do it right to protect peoples privacy. One thing is certain, the AI companies that are touted as being in the lead are <em>very</em> comfortable cutting corners.</p>\n\n\n\n<p><a href=\"https://9to5mac.com/2024/11/21/openai-accidentally-erased-chatgpt-training-findings-as-lawyers-seek-copyright-violations/\">“OpenAI accidentally erased ChatGPT training findings as lawyers seek copyright violations”</a></p>\n\n\n\n<p>Uh-huh. Sure.</p>\n\n\n\n<p>Of course, the Macalope has been saying this for months but it is better that Apple is not doing what these other companies are in running pell-mell into making these word and image and logic sausage machines and, according to many, breaking copyright laws left and right in order to do so just to be first. These technologies are going to get better but they are just that–technologies, not products. It’s good that Apple knows the difference.</p>\n\n\n\n<p></p>\n\n</div>","author":"","siteTitle":"Macworld","siteHash":"37e84dd5a21fa961d6d6630e269546024dbb7741b2e2fadbe74f47383c70dfbb","entryHash":"c0473925baba9c6bbe8ab8cb5bc0910c035b5946768399d8bb80b60d7e0bfa2f","category":"Apple"}