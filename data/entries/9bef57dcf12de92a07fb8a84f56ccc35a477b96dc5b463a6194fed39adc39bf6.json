{"title":"Automating Screen Reader Testing On macOS Using Auto VO","link":"https://smashingmagazine.com/2021/06/automating-screen-reader-testing-macos-autovo/","date":1624440600000,"content":"<p>If you’re an accessibility nerd like me, or just curious about assistive technology, you’ll dig Auto-VO. Auto-VO is a node module and CLI for automated testing of web content with the VoiceOver screen reader on macOS.</p>\n<p>I created <a href=\"https://github.com/ckundo/auto-vo\">Auto VO</a> to make it easier for developers, PMs, and QA to more quickly perform repeatable, automated tests with real assistive technology, without the intimidation factor of learning how to use a screen reader.</p>\nLet’s Go!\n<p>First, let’s see it in action, and then I’ll go into more detail about how it works. Here’s running <code>auto-vo</code> CLI on smashingmagazine.com to get all the VoiceOver output as text.</p>\n<pre><code>$ auto-vo --url https://smashingmagazine.com --limit 200 &gt; output.txt\n$ cat output.txt\nlink Jump to all topics\nlink Jump to list of all articles\nlink image Smashing Magazine\nlist 6 items\nlink Articles\nlink Guides 2 of 6\nlink Books 3 of 6\nlink Workshops 4 of 6\nlink Membership 5 of 6\nMore menu pop up collapsed button 6 of 6\nend of list\nend of navigation\n...(truncated)\n</code></pre>\n\n<p>Seems like a reasonable page structure: we’ve got skip navigation links, well-structured lists, and semantic navigation. Great work! Let’s dig a little deeper though. How’s the heading structure?</p>\n<pre><code>$ cat output.txt | grep heading\nheading level 2 link A Complete Guide To Accessibility Tooling\nheading level 2 link Spinning Up Multiple WordPress Sites Locally With DevKinsta\nheading level 2 link Smashing Podcast Episode 39 With Addy Osmani: Image Optimization\nheading level 2 2 items A SMASHING GUIDE TO Accessible Front-End Components\nheading level 2 2 items A SMASHING GUIDE TO CSS Generators &amp; Tools\nheading level 2 2 items A SMASHING GUIDE TO Front-End Performance 2021\nheading level 4 LATEST POSTS\nheading level 1 link When CSS Isn’t Enough: JavaScript Requirements For Accessible Components\nheading level 1 link Web Design Done Well: Making Use Of Audio\nheading level 1 link Useful Front-End Boilerplates And Starter Kits\nheading level 1 link Three Front-End Auditing Tools I Discovered Recently\nheading level 1 link Meet :has, A Native CSS Parent Selector (And More)\nheading level 1 link From AVIF to WebP: A New Smashing Book By Addy Osmani\n</code></pre>\n\n<p>Hmm! Something’s a little funky with our heading hierarchy. We ought to see an outline, with one heading level one and an ordered hierarchy after that. Instead, we see a bit of a mishmash of level 1, level 2, and an errant level 4. This needs attention since it impacts screen reader users' experience navigating the page.</p>\n<p>Having the screen reader output as text is great because this sort of analysis becomes much easier.</p>\nSome Background\n<p>VoiceOver is the screen reader on macOS. Screen readers let people read application content aloud, and also interact with content. That means that people with low vision or who are blind can in theory access content, including web content. In practice though, 98% of landing pages on the web have obvious errors that can be captured with automated testing and review.</p>\n<p>There are many automated testing and review tools out there, including <a href=\"https://accesslint.com\">AccessLint.com</a> for automated code review (disclosure: I built AccessLint), and Axe, a common go-to for automation. These tools are important and useful, but they are only part of the picture. Manual testing is equally or perhaps more important, but it’s also more time-consuming and can be intimidating.</p>\n<p>You may have heard guidance to \"just turn on your screen reader and listen\" to give you a sense of the blind experience. I think this is misguided. Screen readers are sophisticated applications that can take months or years to master, and are overwhelming at first. Using it haphazardly to simulate the blind experience might lead you to feel sorry for blind people, or worse, try to \"fix\" the experience the wrong ways.</p>\n<p>I’ve seen people panic when they enable VoiceOver, not knowing how to turn it off. Auto-VO manages the lifecycle of the screen reader for you. It automates the launch, control, and closing of VoiceOver, so you don’t have to. Instead of trying to listen and keep up, the output is returned as text, which you can then read, evaluate, and capture for later as a reference in a bug or for automated snapshotting.</p>\nUsage\n<h3>Caveat</h3>\n<p>Right now, because of the requirement to enable AppleScript for VoiceOver, this may require custom configuration of CI build machines to run.</p>\n<h4>Scenario 1: QA &amp; Acceptance</h4>\n<p>Let’s say I (the developer) have a design with blueline annotations - where the designer has added descriptions of things like accessible name and role. Once I’ve built the feature and reviewed the markup in Chrome or Firefox dev tools, I want to output the results to a text file so that when I mark the feature as complete, my PM can compare the screen reader output with the design specs. I can do that using the auto-vo CLI and outputting the results to a file or the terminal. We saw an example of this earlier in the article:</p>\n<pre><code>$ auto-vo --url https://smashingmagazine.com --limit 100\n</code></pre>\n\n<h4>Scenario 2: Test Driven Development</h4>\n<p>Here I am again as the developer, building out my feature with a blueline annotated design. I want to test drive the content so that I don’t have to refactor the markup afterward to match the design. I can do that using the auto-vo node module imported into my preferred test runner, e.g. Mocha.</p>\n<pre><code>$ npm install --save-dev auto-vo\nimport { run } from 'auto-vo';\nimport { expect } from 'chai';\n\ndescribe('loading example.com', async () =&gt; {\n  it('returns announcements', async () =&gt; {\n    const options = { url: 'https://www.example.com', limit: 10, until: 'Example' };\n\n    const announcements = await run(options);\n\n    expect(announcements).to.include.members(['Example Domain web content']);\n  }).timeout(5000);\n});\n</code></pre>\n\nUnder the Hood\n<p>Auto-VO uses a combination of shell scripting and AppleScript to drive VoiceOver. While digging into the VoiceOver application, I came across a CLI that supports starting VoiceOver from the command line.</p>\n<pre><code>/System/Library/CoreServices/VoiceOver.app/Contents/MacOS/VoiceOverStarter\n</code></pre>\n\n<p>Then, a series of JavaScript executables manage the AppleScript instructions to navigate and capture VoiceOver announcements. For example, this script gets the last phrase from the screen reader announcements:</p>\n<pre><code>function run() {\n  const voiceOver = Application('VoiceOver');\n  return voiceOver.lastPhrase.content();\n}\n</code></pre>\n\nIn Closing\n<p>I’d love to hear your experience with <code>auto-vo</code>, and welcome contributions on GitHub. Try it out and let me know how it goes!</p>","author":"","siteTitle":"Articles on Smashing Magazine — For Web Designers And Developers","siteHash":"ab069ca35bf300e9db0da36f49701f66485a5b0d2db0471dfeee07cef6204939","entryHash":"9bef57dcf12de92a07fb8a84f56ccc35a477b96dc5b463a6194fed39adc39bf6","category":"Tech"}