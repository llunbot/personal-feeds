{"title":"Anthorpic แนะทางแก้ปัญหา Claude ไม่ยอมตอบคำถามจากเอกสารยาวๆ ต้องให้หาข้อความที่เกี่ยวข้องก่อน","link":"https://www.blognone.com/node/137165","date":1702095916000,"content":"<div><div><div><p>Anthorpic ผู้พัฒนา Claude ปัญญาประดิษฐ์สำคัญที่ชูจุดแข็งว่าสามารถรับอินพุตขนาดใหญ่ รายงานถึงผลการทดสอบการถามตอบเอกสารขนาดใหญ่ว่ามักได้ผลไม่ค่อยดีนัก โดยเฉพาะในกรณีที่ข้อความที่ใช้ตอบคำถามนั้นล้อมด้วยเรื่องที่ไม่เกี่ยวข้องกันนัก</p>\n<p>รายงานระบุว่า Claude 2.1 นั้นถูกฝึกให้เลี่ยงการตอบคำถามหากไม่มีข้อความสนับสนุนคำตอบมากพอ แนวทางนี้มีเพื่อลดการตอบคำถามอย่างผิดๆ ทีมงานทดสอบโดยการถามคำถามถึงประโยคหนึ่งที่อยู่ในข้อความยาวๆ ที่พูดเรื่องเดียวกัน จากนั้นนำข้อความชุดนี้ไปผสมกับเอกสารอื่นจนเต็ม context 200k แล้วสลับตำแหน่งไปมา พบว่า Claude สามารถตอบคำถามได้เสมอไม่ว่าข้อความที่ใช้ตอบคำถามจะอยู่ตำแหน่งใดๆ แม้ประสิทธิภาพจะดีขึ้นเล็กน้อยหากข้อความอยู่ส่วนท้าย</p>\n<p>หลังจากนั้นทีมงานเล่าว่าระหว่างการทดสอบภายใน ทีมงานพบว่าหากเติม prompt ให้ Claude ระบุข้อความที่เกี่ยวข้องก่อนที่จะตอบคำถาม Cluade จะตอบคำถามได้ดีขึ้นมาก จากการทดสอบข้อมูลชุด <a href=\"https://github.com/gkamradt/LLMTest_NeedleInAHaystack\">Needle in A Haystack</a> ที่ Claude เคยตอบได้เพียง 27% เมื่อใส่ context เต็มความจุ คะแนนก็จะพุ่งขึ้นมาเป็น 98% ทีเดียว</p>\n<p>ที่มา - <a href=\"https://www.anthropic.com/index/claude-2-1-prompting\">Anthropic</a></p>\n<p><img alt=\"No Description\" src=\"https://www.blognone.com/sites/default/files/externals/6aec8d463000f12a82d766b7003e32aa.jpg\" /></p>\n</div></div></div><div><div>Topics: </div><div><div><a href=\"/topics/anthropic\">Anthropic</a></div><div><a href=\"/topics/llm\">LLM</a></div></div></div>","author":"lew","siteTitle":"Blognone","siteHash":"ededadcf18490b3937e7dd89ebe8c00dc129addbdf1ebe4aff1f458146693da0","entryHash":"82a008df3684cb669b951c8d58c48b927a20963b9edbd07e80b64e7016484a85","category":"Thai"}