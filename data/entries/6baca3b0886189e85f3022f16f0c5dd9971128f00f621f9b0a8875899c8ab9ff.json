{"title":"How To Measure The Impact Of Features","link":"https://smashingmagazine.com/2025/12/how-measure-impact-features-tars/","date":1766138400000,"content":"<p>So we design and ship a <strong>shiny new feature</strong>. How do we know if itâ€™s working? How do we measure and track its impact? There is <a href=\"https://measuringu.com/an-overview-of-70-ux-metrics/\">no shortage in UX metrics</a>, but what if we wanted to establish a <strong>simple, repeatable</strong>, meaningful UX metric â€” specifically for our features? Well, letâ€™s see how to do just that.</p>\n<p><img src=\"https://files.smashing.media/articles/how-measure-impact-features-tars/1-impact-features-tars.jpg\" /></p>\n<p>I first heard about the <strong>TARS framework</strong> from Adrian H. Raudschlâ€™s wonderful article on â€œ<a href=\"https://uxdesign.cc/tars-a-product-metric-game-changer-c523f260306a?sk=v2%2F2a9d7d1e-bae9-4875-9063-4b6a10ae110c\">How To Measure Impact of Features</a>â€. Here, Adrian highlighted how his team tracks and decides which features to focus on â€” and then maps them against each other in a <strong>2Ã—2 quadrants matrix</strong>.</p>\n<p>It turned out to be a very useful framework to <strong>visualize</strong> the impact of UX work through the lens of business metrics.</p>\n<p>Letâ€™s see how it works.</p>\n1. Target Audience (%)\n<p>We start by quantifying the <strong>target audience</strong> by exploring what percentage of a productâ€™s users have the specific problem that a feature aims to solve. We can study existing or similar features that try to solve similar problems, and how many users engage with them.</p>\n<p>Target audience <strong>isnâ€™t the same</strong> as feature usage though. As Adrian noted, if we know that an existing Export Button feature is used by 5% of all users, it doesnâ€™t mean that the target audience is 5%. <strong>More users</strong> might have the problem that the export feature is trying to solve, but they canâ€™t find it.</p>\n<blockquote>Question we ask: â€œWhat percentage of all our productâ€™s users have that specific problem that a new feature aims to solve?â€</blockquote>\n\n2. A = Adoption (%)\n<p>Next, we measure how well we are <strong>â€œacquiringâ€</strong> our target audience. For that, we track how many users actually engage <em>successfully</em> with that feature over a specific period of time.</p>\n<p>We <strong>donâ€™t focus on CTRs or session duration</strong> there, but rather if users <em>meaningfully</em> engage with it. For example, if anything signals that they found it valuable, such as sharing the export URL, the number of exported files, or the usage of filters and settings.</p>\n<p><img src=\"https://files.smashing.media/articles/how-measure-impact-features-tars/2-impact-features-tars.jpg\" /></p>\n<p>High <strong>feature adoption</strong> (&gt;60%) suggests that the problem was impactful. Low adoption (&lt;20%) might imply that the problem has simple workarounds that people have relied upon. Changing habits takes time, too, and so low adoption in the beginning is expected.</p>\n<p>Sometimes, low feature adoption has nothing to do with the feature itself, but rather <strong>where it sits in the UI</strong>. Users might never discover it if itâ€™s hidden or if it has a confusing label. It must be obvious enough for people to stumble upon it.</p>\n<p>Low adoption doesnâ€™t always equal failure. If a problem only affects 10% of users, hitting 50â€“75% adoption within that specific niche means the feature is a <strong>success</strong>.</p>\n<blockquote>Question we ask: â€œWhat percentage of active target users actually use the feature to solve that problem?â€</blockquote>\n\n3. Retention (%)\n<p>Next, we study whether a feature is actually used repeatedly. We measure the frequency of use, or specifically, how many users who engaged with the feature actually keep using it over time. Typically, itâ€™s a strong signal for <strong>meaningful impact</strong>.</p>\n<p>If a feature has &gt;50% retention rate (avg.), we can be quite confident that it has a <strong>high strategic importance</strong>. A 25â€“35% retention rate signals medium strategic significance, and retention of 10â€“20% is then low strategic importance.</p>\n<blockquote>Question we ask: â€œOf all the users who meaningfully adopted a feature, how many came back to use it again?â€</blockquote>\n\n4. Satisfaction Score (CES)\n<p>Finally, we measure the <strong>level of satisfaction</strong> that users have with that feature that weâ€™ve shipped. We donâ€™t ask everyone â€” we ask only â€œretainedâ€ users. It helps us spot hidden troubles that might not be reflected in the retention score.</p>\n<p><img src=\"https://files.smashing.media/articles/how-measure-impact-features-tars/3-impact-features-tars.jpg\" /></p>\n<p>Once users actually used a feature multiple times, we ask them <strong>how easy it was to solve</strong> a problem after they used that feature â€” between â€œmuch more difficultâ€ and â€œmuch easier than expectedâ€. We know how we want to score.</p>\nUsing TARS For Feature Strategy\n<p>Once we start measuring with TARS, we can calculate an <strong>SÃ·T score</strong> â€” the percentage of Satisfied Users Ã· Target Users. It gives us a sense of how well a feature is performing for our intended target audience. Once we do that for every feature, we can map all features across 4 quadrants in a <strong>2Ã—2 matrix</strong>.</p>\n<p><img src=\"https://files.smashing.media/articles/how-measure-impact-features-tars/4-impact-features-tars.jpg\" /></p>\n<p><strong>Overperforming features</strong> are worth paying attention to: they have low retention but high satisfaction. It might simply be features that users donâ€™t have to use frequently, but when they do, itâ€™s extremely effective.</p>\n<p><strong>Liability features</strong> have high retention but low satisfaction, so perhaps we need to work on them to improve them. And then we can also identify <strong>core features</strong> and project features â€” and have a conversation with designers, PMs, and engineers on what we should work on next.</p>\nConversion Rate Is Not a UX Metric\n<p>TARS doesnâ€™t cover conversion rate, and for a good reason. As <a href=\"https://www.linkedin.com/posts/fabian-lenz-digital-experience-leadership_conversion-rate-is-not-a-ux-metric-yes-activity-7394261839506739200-78G9\">Fabian Lenz noted</a>, conversion is often considered to be the <strong>ultimate indicator of success</strong> â€” yet in practice itâ€™s always very difficult to present a clear connection between smaller design initiatives and big conversion goals.</p>\n<p><img src=\"https://files.smashing.media/articles/how-measure-impact-features-tars/5-impact-features-tars.png\" /></p>\n<p>The truth is that almost everybody on the team is working towards better conversion. An uptick might be connected to <strong>many different initiatives</strong> â€” from sales and marketing to web performance boost to seasonal effects to UX initiatives.</p>\n<p>UX can, of course, improve conversion, but itâ€™s not really a UX metric. Often, people simply <strong>canâ€™t choose the product</strong> they are using. And often a desired business outcome comes out of necessity and struggle, rather than trust and appreciation.</p>\n<h3>High Conversion Despite Bad UX</h3>\n<p>As Fabian <a href=\"https://www.linkedin.com/posts/fabian-lenz-digital-experience-leadership_conversion-rate-is-not-a-ux-metric-yes-activity-7394261839506739200-78G9/\">writes</a>, <strong>high conversion rate</strong> can happen despite poor UX, because:</p>\n<ul>\n<li><strong>Strong brand power</strong> pulls people in,</li>\n<li>Aggressive but effective <strong>urgency tactics</strong>,</li>\n<li>Prices are extremely attractive,</li>\n<li>Marketing performs brilliantly,</li>\n<li>Historical customer loyalty,</li>\n<li>Users simply have no alternative.</li>\n</ul>\n<p><img src=\"https://files.smashing.media/articles/how-measure-impact-features-tars/6-impact-features-tars.jpg\" /></p>\n<h3>Low Conversion Despite Great UX</h3>\n<p>At the same time, a low conversion rate can occur despite great UX, because:</p>\n<ul>\n<li><strong>Offers arenâ€™t relevant</strong> to the audience,</li>\n<li><strong>Users donâ€™t trust the brand</strong>,</li>\n<li>Poor business model or high risk of failure,</li>\n<li>Marketing doesnâ€™t reach the right audience,</li>\n<li>External factors (price, timing, competition).</li>\n</ul>\n<p>An improved conversion is the <strong>positive outcome of UX initiatives</strong>. But good UX work typically improves task completion, reduces time on task, minimizes errors, and avoids decision paralysis. And there are plenty of <a href=\"https://www.linkedin.com/posts/vitalyfriedman_how-to-measure-ux-httpslnkdine5uedtzy-activity-7332664809382952960-HERA\">actionable design metrics we could use</a> to track UX and drive sustainable success.</p>\nWrapping Up\n<p><strong>Product metrics</strong> alone donâ€™t always provide an accurate view of how well a product performs. Sales might perform well, but users might be extremely inefficient and frustrated. Yet the churn is low because users canâ€™t choose the tool they are using.</p>\n<p><img src=\"https://files.smashing.media/articles/how-measure-impact-features-tars/7-impact-features-tars.jpg\" /></p>\n<p>We need UX metrics to understand and improve user experience. What I love most about TARS is that itâ€™s a neat way to connect customersâ€™ usage and <strong>customersâ€™ experience with relevant product metrics</strong>. Personally, I would extend TARS with <a href=\"https://www.linkedin.com/posts/vitalyfriedman_ux-design-activity-7140641630507687936-YTI7\">UX-focused metrics and KPIs</a> as well â€” depending on the needs of the project.</p>\n<p>Huge thanks to <a href=\"https://www.linkedin.com/in/adrian-raudaschl/\">Adrian H. Raudaschl</a> for putting it together. And if you are interested in metrics, I highly recommend you follow him for practical and useful guides all around just that!</p>\nMeet â€œHow To Measure UX And Design Impactâ€\n<p>You can find more details on <strong>UX Strategy</strong> in ğŸª´Â <a href=\"https://measure-ux.com/\"><strong>Measure UX &amp; Design Impact</strong></a> (8h), a practical guide for designers and UX leads to measure and show your UX impact on business. Use the code ğŸŸ <code>IMPACT</code> to save 20% off today. <a href=\"https://measure-ux.com/\">Jump to the details</a>.</p>\n\n\n    <a href=\"https://measure-ux.com/\">\n    <img src=\"https://files.smashing.media/articles/ux-metrics-video-course-release/measure-ux-and-design-impact-course.png\" />\n    </a>\n\n\n<div><div><ul><li><a href=\"#\">\nVideo + UX Training</a></li><li><a href=\"#\">Video only</a></li></ul><div><h3>Video + UX Training</h3>$Â 495.00 $Â 799.00\n<a href=\"https://smart-interface-design-patterns.thinkific.com/enroll/3081832?price_id=3951439\">\nGet Video + UX Training<div></div></a><p>25 video lessons (8h) + <a href=\"https://smashingconf.com/online-workshops/workshops/vitaly-friedman-impact-design/\">Live UX Training</a>.<br />100 days money-back-guarantee.</p></div><div><h3>Video only</h3><div>$Â 250.00$Â 395.00</div>\n<a href=\"https://smart-interface-design-patterns.thinkific.com/enroll/3081832?price_id=3950630\">\nGet the video course<div></div></a><p>25 video lessons (8h). Updated yearly.<br />Also available as a <a href=\"https://smart-interface-design-patterns.thinkific.com/enroll/3570306?price_id=4503439\">UX Bundle with 3 video courses.</a></p></div></div></div>\n\nUseful Resources\n<ul>\n<li>â€œ<a href=\"https://measure-ux.com\">How To Measure UX and Design Impact</a>â€, by yours truly</li>\n<li>â€œ<a href=\"https://thecdo.school/books\">Business Thinking For Designers</a>â€, by Ryan Rumsey</li>\n<li>â€œ<a href=\"https://www.linkedin.com/feed/update/urn:li:activity:7338462034763661312/\">ROI of Design Project</a></li>\n<li>â€œ<a href=\"https://articles.centercentre.com/how-the-right-ux-metrics-show-game-changing-value/\">How the Right UX Metrics Show Game-Changing Value</a>â€, by Jared Spool</li>\n<li>â€œ<a href=\"https://www.linkedin.com/posts/vitalyfriedman_ux-design-research-activity-7164173642887606274-rEqq\">Research Sample Size Calculators</a>â€</li>\n</ul>\n<h3>Further Reading</h3>\n<ul>\n<li>â€œ<a href=\"https://www.smashingmagazine.com/2025/11/designing-for-stress-emergency/\">Designing For Stress And Emergency</a>â€, Vitaly Friedman</li>\n<li>â€œ<a href=\"https://www.smashingmagazine.com/2025/10/ai-ux-achieve-more-with-less/\">AI In UX: Achieve More With Less</a>â€, Paul Boag</li>\n<li>â€œ<a href=\"https://www.smashingmagazine.com/2025/11/accessibility-problem-authentication-methods-captcha/\">The Accessibility Problem With Authentication Methods Like CAPTCHA</a>â€, Eleanor Hecks</li>\n<li>â€œ<a href=\"https://www.smashingmagazine.com/2025/09/from-prompt-to-partner-designing-custom-ai-assistant/\">From Prompt To Partner: Designing Your Custom AI Assistant</a>â€, Lyndon Cerejo</li>\n</ul>","author":"","siteTitle":"Articles on Smashing Magazine â€” For Web Designers And Developers","siteHash":"ab069ca35bf300e9db0da36f49701f66485a5b0d2db0471dfeee07cef6204939","entryHash":"6baca3b0886189e85f3022f16f0c5dd9971128f00f621f9b0a8875899c8ab9ff","category":"Tech"}