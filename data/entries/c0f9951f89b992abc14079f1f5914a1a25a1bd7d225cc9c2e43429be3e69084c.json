{"title":"OpenAI ออกโมเดล text-to-speech และ speech-to-text ใหม่ ทำงานดีขึ้น","link":"https://www.blognone.com/node/145395","date":1742556893000,"content":"<div><div><div><p>OpenAI ออกโมเดลแปลงข้อความเป็นเสียงใหม่ กำหนดโทนได้มากขึ้น และเสียงเป็นข้อความที่ผิดพลาดน้อยลง</p>\n<p>โมเดล text-to-speech หลักตัวใหม่คือ <code>gpt-4o-mini-tts</code> มีจุดเด่นคือนักพัฒนาสามารถกำหนดรูปแบบนำเสียงการพูด เช่น ให้พูดแนว mad scientist หรือพูดในโทนเสียงคุณครูที่อบอุ่น เป็นต้น <a href=\"https://www.openai.fm/\">สามารถทดลองรูปแบบใช้งานได้ที่นี่</a></p>\n<p>ส่วนโมเดล speech-to-text ตัวใหม่ได้แก่ <code>gpt-4o-transcribe</code> และ <code>gpt-4o-mini-transcribe</code> จะนำมาแทนที่<a href=\"https://www.blognone.com/node/142386\">โมเดล Whisper</a> โดยโมเดลใหม่นี้ถูกฝึกฝนด้วยข้อมูลเสียงคุณภาพสูง สามารถจับเสียงพูดในสำเนียงที่หลากหลายมากกว่า และหลอนน้อยกว่า Whisper แบบเดิม เมื่อได้ยินคำที่ไม่รู้จัก</p>\n<p>OpenAI ยังรายงานผลการทดสอบ โดย gpt-4o-transcribe มีอัตราผิดพลาดที่ต่ำลงมาก ในหลายภาษาที่ Whisper ไม่เก่ง ก็ปรับปรุงจนดีขึ้นกว่าเดิมมาก ภาษาไทยจาก 12% ลดเหลือ 5%</p>\n<p>ที่มา: <a href=\"https://openai.com/index/introducing-our-next-generation-audio-models/\">OpenAI</a> และ <a>TechCrunch</a></p>\n<p><img alt=\"No Description\" src=\"https://www.blognone.com/sites/default/files/externals/f1bc69ff7c4adafe34380141b2ee42d2.png\" /></p>\n<p><img alt=\"No Description\" src=\"https://www.blognone.com/sites/default/files/externals/4b1a4de044eff3636c7c1e061960153c.png\" /></p>\n</div></div></div><div><div>Topics: </div><div><div><a href=\"/topics/openai\">OpenAI</a></div><div><a href=\"/topics/artificial-intelligence\">Artificial Intelligence</a></div><div><a href=\"/topics/speech-recognition\">Speech Recognition</a></div><div><a href=\"/topics/text-speech\">Text-to-Speech</a></div></div></div>","author":"arjin","siteTitle":"Blognone","siteHash":"ededadcf18490b3937e7dd89ebe8c00dc129addbdf1ebe4aff1f458146693da0","entryHash":"c0f9951f89b992abc14079f1f5914a1a25a1bd7d225cc9c2e43429be3e69084c","category":"Thai"}