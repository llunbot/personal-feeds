{"title":"NIST ออกเอกสารรวบรวมการโจมตีปัญญาประดิษฐ์ และแนวทางป้องกัน","link":"https://www.blognone.com/node/137557","date":1704778796000,"content":"<div><div><div><p>NIST องค์การมาตรฐานอุตสาหกรรมสหรัฐฯ ออกเอกสารรวบรวมภัยจากการโจมตี machine learning และแนวทางเพื่อลดความเสี่ยงลง พร้อมกับเตือนว่าตอนนี้ยังไม่มีทางใดที่ป้องกันการโจมตีได้ทั้งหมด และนักพัฒนาควรระมัดระวัง</p>\n<p>เอกสาร NIST AI 100-2e2023 ไม่ใช่มาตรฐานอุตสาหกรรมแต่เป็นการรวบรวมการโจมตีรูปแบบต่างๆ และแนวทางการลดความเสี่ยงเท่านั้น โดยเอกสารจัดรูปแบบการโจมตี 4 รูปแบบใหญ่ๆ ได้แก่</p>\n<ul>\n<li>Evasion attack: ผู้โจมตีพยายามใส่อินพุตเพื่อเปลี่ยนพฤติกรรมของ machine learning เช่นเหตุการณ์ผู้คนพยายามวางป้ายสัญญาณจราจรปลอมๆ เพื่อหลอกรถไร้คนขับ</li>\n<li>Poisoning attack: ใส่ข้อมูลมุ่งร้ายเข้าไปในชุดข้อมูลสำหรับฝึก machine learning เช่นการใส่ข้อความคำหยาบเข้าไปเพื่อให้ AI ตอบคำหยาบออกมา</li>\n<li>Privacy attack: พยายามล่อลวงให้ AI เปิดเผยข้อมูลส่วนบุคคลหรือข้อมูลความลับที่เกี่ยวกับตัว AI หรือเกี่ยวกับชุดข้อมูลที่ใช้ฝึก</li>\n<li>Abuse attack: ใส่ข้อมูลผิดๆ เพื่อให้ปัญญาประดิษฐ์ตอบผิด เช่น สร้างเว็บให้ข้อมูลหลอกเพื่อให้ AI ไปอ่านมาตอบ</li>\n</ul>\n<p>เอกสารรวบรวมงานวิจัยที่มีการนำเสนอก่อนหน้านี้ ทั้งการโจมตีแบบย่อยๆ ภายใน 4 หมวดนี้ และเทคนิคการป้องกันการโจมตี อย่างไรก็ดีแนวทางการป้องกันที่มีการเสนอมาก็ยังป้องกันได้ไม่ครบถ้วน จึงนับว่าเป็นปัญหาที่ยังไม่สามารถหาทางออกได้ชัดเจนนัก</p>\n<p>ที่มา - <a href=\"https://www.nist.gov/news-events/news/2024/01/nist-identifies-types-cyberattacks-manipulate-behavior-ai-systems\">NIST</a></p>\n<p><img alt=\"No Description\" src=\"https://www.blognone.com/sites/default/files/externals/da4fd2a5dafbd20c4b0999b58bbac062.png\" /></p>\n</div></div></div><div><div>Topics: </div><div><div><a href=\"/topics/nist\">NIST</a></div><div><a href=\"/topics/artificial-intelligence\">Artificial Intelligence</a></div></div></div>","author":"lew","siteTitle":"Blognone","siteHash":"ededadcf18490b3937e7dd89ebe8c00dc129addbdf1ebe4aff1f458146693da0","entryHash":"c5cd27a388262499b9a6df188bee5f17f7625f21d363d584ccd4265b5baf45a2","category":"Thai"}