{"title":"กูเกิลเปิดตัวโมเดล PaLM-E ปัญญาประดิษฐ์ควบคุมหุ่นยนต์ สั่งงานได้ทั้งภาพและเสียง","link":"https://www.blognone.com/node/132974","date":1678546890000,"content":"<div><div><div><p>ทีมวิจัยของกูเกิลเปิดตัวโมเดล PaLM-E ปัญญาประดิษฐ์สำหรับควบคุมหุ่นยนต์ โดยเป็นการปรับปรุงจาก <a href=\"https://www.blognone.com/node/127921\">PaLM โมเดลปัญญาประดิษฐ์ด้านภาษา (LLM) ขนาดใหญ่ 540,000 ล้านพารามิเตอร์</a> นำมารวมร่างกับปัญญาประดิษฐ์ด้านภาพ (vison) ชื่อ ViT-22B กลายมาเป็น PaLM-E (E ย่อมาจาก Embodied) ขนาด 562,000 ล้านพารามิเตอร์</p>\n<p>การรวมโมเดลภาษา LLM กับโมเดลวิเคราะห์ภาพ Vision เข้าด้วยกัน ทำให้ PaLM-E เป็นโมเดลที่สามารถทำงานได้หลากหลาย (generalist) รองรับการสั่งงานหุ่นยนต์ทั้งสองแบบ ทั้งการแยกแยะวัตถุ แยกแยะฉากทัศน์ รับคำสั่งเป็นเสียงแล้วแปลงเป็นข้อความ หรือใช้ทั้งสองอย่างคือให้ดูภาพแล้วทำตามคำบรรยายบอกก็ได้เช่นกัน</p>\n<p>กูเกิลบอกว่า PaLM-E ถือเป็นตัวอย่างของการสร้างโมเดลที่รองรับวิธีการสั่งงานหลายแบบ (multi-modal) โดยใช้โมเดลทั่วๆ ไปแล้วได้ผลออกมาดี ซึ่งจะเป็นก้าวสำคัญสู่การพัฒนาโมเดลแบบ multi-modal อื่นในอนาคต</p>\n<p><img alt=\"No Description\" src=\"https://www.blognone.com/sites/default/files/externals/da32a8302a173f3481febe1b0b38d3c1.png\" /></p>\n<p><img alt=\"No Description\" src=\"https://www.blognone.com/sites/default/files/externals/37527c8b8165aa253f0d8267969ac8d5.png\" /></p>\n<p>ที่มา - <a href=\"http://ai.googleblog.com/2023/03/palm-e-embodied-multimodal-language.html\">Google AI Blog</a></p>\n</div></div></div><div><div>Topics: </div><div><div><a href=\"/topics/google\">Google</a></div><div><a href=\"/topics/artificial-intelligence\">Artificial Intelligence</a></div><div><a href=\"/topics/robotics\">Robotics</a></div></div></div>","author":"mk","siteTitle":"Blognone","siteHash":"490b3937e7dd89ebe8c00dc129addbdf1ebe4aff1f458146693da0","entryHash":"787302451e2097399dfb15884a6c41718e32dabc0e81f7cde2ff18","category":"Thai"}