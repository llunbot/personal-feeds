{"title":"Introducing default data integrity protections for new objects in Amazon S3","link":"https://aws.amazon.com/blogs/aws/introducing-default-data-integrity-protections-for-new-objects-in-amazon-s3/","date":1733085996000,"content":"<p>At <a href=\"https://aws.amazon.com/\">Amazon Web Services (AWS)</a>, the vast majority of new capabilities are driven by your direct feedback. <a href=\"https://aws.amazon.com/blogs/aws/new-additional-checksum-algorithms-for-amazon-s3/\">Two years ago, Jeff announced</a> additional checksum algorithms and the optional client-side computation of checksums to make sure the objects stored on Amazon S3 are exactly what you sent. You told us you love this extra verification because it gives you confidence the object stored is the one you sent. You also told us you would prefer to have this extra verification enabled automatically, freeing you from developing additional code.</p> \n<p>Starting today, we’re updating the <a href=\"https://aws.amazon.com/s3/\">Amazon Simple Storage Service (Amazon S3)</a> default behavior when you upload objects. To build upon its existing durability posture, Amazon S3 now automatically verifies that your data is correctly transmitted over the network from your applications to your S3 bucket.</p> \n<p>Amazon S3 is designed for 99.999999999% data durability (<a href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/DataDurability.html\">that’s 11 nines</a>). Amazon S3 has always verified the integrity of object uploads by calculating checksums when objects reach our servers, before they are written to multiple storage devices. Once your data is stored in Amazon S3, it continually monitors data durability over time with periodic integrity checks of data at rest. Amazon S3 also actively monitors the redundancy of your data to help verify that your objects can tolerate the concurrent failure of multiple storage devices.</p> \n<p>But data can still face integrity risks as it traverses the public internet before reaching our servers. Issues such as faulty hardware on networks we don’t manage or client software bugs could potentially corrupt or drop data before Amazon S3 has a chance to validate it. Previously, you could extend the integrity protection by providing your own precomputed checksums with your <a href=\"https://docs.aws.amazon.com/AmazonS3/latest/API/API_PutObject.html\">PutObject</a> or <a href=\"https://docs.aws.amazon.com/AmazonS3/latest/API/API_UploadPart.html\">UploadPart</a> requests. However, this requires configuring tools and applications to generate and track checksums, which can be complex to implement consistently across all your client applications uploading objects to Amazon S3.</p> \n<p>The new default behavior builds upon existing data integrity protections without requiring any changes to your applications. Additionally, the new checksums are stored in the object’s metadata, making them accessible for integrity verification at any time.</p> \n<p><span><strong>Automatic client-side integrity protection<br /> </strong></span>Amazon S3 now extends data integrity protection all the way to client-side applications by default. The latest versions of our <a href=\"https://aws.amazon.com/tools/\">AWS SDKs</a> automatically calculate a <a href=\"https://en.wikipedia.org/wiki/Cyclic_redundancy_check\">cyclic redundancy check (CRC)-based checksum</a> for each upload and send it to Amazon S3. Amazon S3 independently calculates a checksum on the server side and validates it against the provided value before durably storing the object and its checksum in the object’s metadata.</p> \n<p>When your client application doesn’t send a CRC checksum (maybe it uses an old version of our SDK or you haven’t updated your application custom code yet), Amazon S3 computes a CRC-based checksum anyway and stores it in the object metadata for future reference. You can compare at a later stage the stored CRC with a CRC computed on your side and verify the network transmission was correct.</p> \n<p>This new capability provides you with an automatic checksum calculation and validation for new uploads from the latest versions of the AWS SDKs, the <a href=\"https://aws.amazon.com/cli/\">AWS Command Line Interface (AWS CLI)</a>, and the <a href=\"https://console.aws.amazon.com\">AWS Management Console</a>. You can also verify the checksum stored in the object’s metadata at any time. The new default data integrity protections use the existing <a href=\"https://docs.aws.amazon.com/AmazonS3/latest/API/API_Checksum.html\">CRC32 and CRC32C algorithms or the new CRC64NVME algorithm</a>. Amazon S3 also provides developers with consistent full-object checksums across single-part and multipart uploads.</p> \n<p>When uploading files in multiple parts, the SDKs calculate checksums for each part. Amazon S3 uses these checksums to verify the integrity of each part through the <code>UploadPart</code> API. Additionally, S3 validates the entire file’s size and checksum when you call the <code>CompleteMultipartUpload</code> API.</p> \n<p>The <code>CreateMultiPartUpload</code> API introduces a new HTTP header, <code>x-amz-checksum-type</code>, which lets you specify the type of checksum to use. You can choose either a full object checksum (calculated by combining the checksums of all individual parts) or a composite checksum.</p> \n<p>The full object checksum is stored with the object metadata for future reference. This new protection works seamlessly with <a href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/serv-side-encryption.html\">server-side encryption</a>. The consistent behavior across uploads, multipart uploads, downloads, and encryption modes simplifies client-side integrity checks. The ability to use full-object checksums to validate integrity and store them for use later can help you streamline your applications.</p> \n<p><span><strong>Let’s see it in action</strong></span><br /> To start using this additional integrity protection, update to the latest version of the AWS SDK or AWS CLI. No code changes are required to enable the new integrity protections.</p> \n<p><strong>Case 1: Amazon S3 now attaches a checksum to objects on the server side when objects are uploaded without a checksum</strong></p> \n<p>I wrote a simple Python script to upload and download content to and from an S3 bucket. I enabled maximum logging verbosity to see the actual HTTP headers sent to and from Amazon S3.</p> \n<pre><code>import boto3\nimport logging\n\nBUCKET_NAME=\"aws-news-blog-20241111\"\nCONTENT='Hello World!'\nOBJECT_NAME='test.txt'\n\n# Enable debug logging for boto3 and botocore to stdout (this is verbose !!!)\nlogging.basicConfig(level=logging.DEBUG)\n\n# create a s3 client\nclient = boto3.client('s3')\n\n# put an object\nclient.put_object(Bucket=BUCKET_NAME, Key=OBJECT_NAME, Body=CONTENT)\n\n# get the object \nresponse = client.get_object(Bucket=BUCKET_NAME, Key=OBJECT_NAME)\nprint(response['Body'].read().decode('utf-8'))</code></pre> \n<p>In the first step of this demo, I use an old AWS SDK for Python that doesn’t compute the CRC checksum on the client side. Despite this, I can observe that Amazon S3 now responds with a checksum it computed upon receiving the object.</p> \n<pre><code>S3 RESPONSE:\n{\n    ...\n    \"x-amz-checksum-crc64nvme\": \"AuUcyF784aU=\",\n    \"x-amz-checksum-type\": \"FULL_OBJECT\",\n    ...\n}</code></pre> \n<p><strong>Case 2: Upload with manually pre-computed CRC64NVME checksum, a new checksum type</strong></p> \n<p>When I don’t have the option to use the latest version of the AWS SDK, or when I use my own code to upload objects to S3 buckets, I can compute the checksum and send it in the <code>PutObject</code> API request. Here is how I compute the checksum on my content before sending it to Amazon S3. To keep this code short, I use the <code>checksums</code> package available in the new AWS SDK for Python.</p> \n<pre><code>from awscrt import checksums\nimport base64\n\nchecksum = checksums.crc64nvme(\"Hello World!\")\nchecksum_bytes = checksum.to_bytes(8, byteorder='big')  # CRC64 is 8 bytes\nchecksum_base64 = base64.b64encode(checksum_bytes)\nprint(checksum_base64)</code></pre> \n<p>And when I run it, I see the CRC64NVME checksum is the same as the one returned by Amazon S3 in the previous step.</p> \n<pre><code>$ python crc.py\nb'AuUcyF784aU='</code></pre> \n<p>I can provide this checksum as part of the <code>PutObject</code> API call.</p> \n<pre><code>response = s3.put_object(\n    Bucket=BUCKET_NAME,\n    Key=OBJECT_NAME,\n    Body=b'Hello World!',\n    ChecksumAlgorithm='CRC64NVME', \n    ChecksumCRC64NVME=checksum_base64\n)</code></pre> \n<p><strong>Case 3: The new SDKs compute the checksum on the client-side</strong></p> \n<p>Now, I run the upload and download script again. This time, I use the latest version of the AWS SDK for Python. I observe that the SDK now sends the CRC headers in the request. The response also contains the checksum. I can easily compare the versions in the request and in the response to make sure the object received is the one I sent.</p> \n<pre><code>REQUEST:\n{\n    ...\n    \"x-amz-checksum-crc64nvme\": \"AuUcyF784aU=\",\n    \"x-amz-checksum-type\": \"FULL_OBJECT\",\n    ... \n}</code></pre> \n<p>At any time, I can request the object checksum to verify the integrity of my local copy using the <code>HeadObject</code> or <code>GetObject</code> APIs.</p> \n<pre><code> get_response = s3.get_object(\n        Bucket=BUCKET_NAME,\n        Key=OBJECT_NAME,\n        ChecksumMode='ENABLED'\n    )</code></pre> \n<p>The response object contains the checksum in the <code>HTTPHeaders</code> field.</p> \n<pre><code>{\n...\n    \"x-amz-checksum-crc64nvme\": \"AuUcyF784aU=\",\n    \"x-amz-checksum-type\": \"FULL_OBJECT\",\n...\n}</code></pre> \n<p><strong>Case 4: Multi-part uploads with new CRC-based whole-object checksum</strong></p> \n<p>When uploading large objects using the <code>CreateMultipartUpload</code>, <code>UploadPart</code>, and <code>CompleteMultipartUpload</code> APIs, the latest version of the SDK will automatically compute the checksums for you.</p> \n<p>If you want to validate the integrity of your data by using a known content checksum, you can pre-compute the CRC-based whole-object checksum for multi-part uploads to simplify your client side tooling. When using full object checksums for multi-part uploads, you no longer have to keep track of part level checksums as you upload objects.</p> \n<pre><code>\n# precomputed CRC64NVME checksum for the full object\nfull_object_crc64_nvme_checksum = 'Naz0uXkYBPM='\n\n# start multipart upload\ncreate_response = s3.create_multipart_upload(\n            Bucket=BUCKET_NAME,\n            Key=OBJECT_NAME,\n            ChecksumAlgorithm='CRC64NVME',\n            ChecksumType='FULL_OBJECT'\n        )\nupload_id = create_response['UploadId']\n\n# Upload parts\nuploaded_parts = []\n\n# part 1\ndata_part_1 = b'0' * (5 * 1024 * 1024) # minimum part size\nupload_part_response_1 = s3.upload_part(\n    Body=data_part_1,\n    Bucket=BUCKET_NAME,\n    Key=OBJECT_NAME,\n    PartNumber=1,\n    UploadId=upload_id,\n    ChecksumAlgorithm='CRC64NVME'\n)\nuploaded_parts.append({'PartNumber': 1, 'ETag': upload_part_response_1['ETag']})\n\n# part 2\ndata_part_2 = b'0' * (5 * 1024 * 1024)\nupload_part_response_2 = s3.upload_part(\n    Body=data_part_2,\n    Bucket=BUCKET_NAME,\n    Key=OBJECT_NAME,\n    PartNumber=2,\n    UploadId=upload_id,\n    ChecksumAlgorithm='CRC64NVME'\n)\nuploaded_parts.append({'PartNumber': 2, 'ETag': upload_part_response_2['ETag']})\n\n# Complete the multipart upload with the FULL_OBJECT CRC64NVME checksum to validate the integrity of your entire object. \ncomplete_response = s3.complete_multipart_upload(\n            Bucket=BUCKET_NAME,\n            Key=OBJECT_NAME,\n            UploadId=upload_id,\n            ChecksumCRC64NVME=full_object_crc64_nvme_checksum,\n            ChecksumType='FULL_OBJECT',\n            MultipartUpload={'Parts': uploaded_parts}\n        )\nprint(complete_response)</code></pre> \n<p><span><strong>Things to know<br /> </strong></span>For your existing objects, the checksum will be added when you copy them. We updated the <code>CopyObject</code> API so you can choose the desired checksum algorithm for the destination object.</p> \n<p>This new client-side checksum calculation is implemented in the latest version of the AWS SDKs. When you use an old SDK or custom code that doesn’t pre-compute checksums, Amazon S3 computes the checksum on all new objects it receives and stores it in the object’s metadata, even for multipart uploads.</p> \n<p><span><strong>Pricing and availability<br /> </strong></span>This extended checksum computation and storage is available in all <a href=\"https://docs.aws.amazon.com/glossary/latest/reference/glos-chap.html#region\">AWS Regions</a> at no additional cost.</p> \n<p>Update your AWS SDK and AWS CLI today to automatically benefit from this additional integrity protection for data in transit.</p> \n<p>To learn more about data integrity protection on Amazon S3, visit <a href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-integrity.html\">Checking object integrity</a> in the Amazon S3 User Guide.</p> \n<p><a href=\"https://twitter.com/sebsto\">-- seb</a></p>","author":"Sébastien Stormacq","siteTitle":"AWS News Blog","siteHash":"6093e072e4117ec22616e844cb857d03ca62c57a411a8affc77cb5e8b6b15bf6","entryHash":"9b20f6eae4a908ca1848d152ca6499a7d14a7a2642a63c62bb263b2df728e29f","category":"Tech"}