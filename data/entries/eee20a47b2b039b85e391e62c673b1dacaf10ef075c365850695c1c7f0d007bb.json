{"title":"Googleâ€™s new robot AI can fold delicate origami, close zipper bags without damage","link":"https://arstechnica.com/ai/2025/03/googles-origami-folding-ai-brain-may-power-new-wave-of-humanoid-robots/","date":1741808337000,"content":"<p>On Wednesday, Google DeepMind <a href=\"https://deepmind.google/discover/blog/gemini-robotics-brings-ai-into-the-physical-world/\">announced</a> two new AI models designed to control robots: Gemini Robotics and Gemini Robotics-ER. The company claims these models will help robots of many shapes and sizes understand and interact with the physical world more effectively and delicately than previous systems, paving the way for applications such as humanoid robot assistants.</p>\n<p>It's worth noting that even though hardware for robot platforms appears to be advancing at a steady pace (well, <a href=\"https://arstechnica.com/gadgets/2025/02/dangling-twitching-human-robot-with-synthetic-muscles-makes-its-debut/\">maybe not always</a>), creating a capable AI model that can pilot these robots autonomously through novel scenarios with safety and precision has proven elusive. What the industry calls \"embodied AI\" is a <a href=\"https://arstechnica.com/information-technology/2024/03/nvidia-announces-moonshot-to-create-embodied-human-level-ai-in-robot-form/\">moonshot goal</a> of Nvidia, for example, and it remains a holy grail that could potentially turn robotics into general-use laborers in the physical world.</p>\n<p>Along those lines, Google's new models build upon its <a href=\"https://arstechnica.com/information-technology/2024/12/google-goes-agentic-with-gemini-2-0s-ambitious-ai-agent-features/\">Gemini 2.0</a> large language model foundation, adding capabilities specifically for robotic applications. Gemini Robotics includes what Google calls \"vision-language-action\" (VLA) abilities, allowing it to process visual information, understand language commands, and generate physical movements. By contrast, Gemini Robotics-ER focuses on \"embodied reasoning\" with enhanced spatial understanding, letting roboticists connect it to their existing robot control systems.</p><p><a href=\"https://arstechnica.com/ai/2025/03/googles-origami-folding-ai-brain-may-power-new-wave-of-humanoid-robots/\">Read full article</a></p>\n<p><a href=\"https://arstechnica.com/ai/2025/03/googles-origami-folding-ai-brain-may-power-new-wave-of-humanoid-robots/#comments\">Comments</a></p>","author":"Benj Edwards","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"eee20a47b2b039b85e391e62c673b1dacaf10ef075c365850695c1c7f0d007bb","category":"Tech"}