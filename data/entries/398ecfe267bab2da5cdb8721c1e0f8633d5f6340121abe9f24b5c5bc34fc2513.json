{"title":"งานวิจัยพบ โมเดล AI มีปัญหาด้านการอ้างอิง เกินครึ่งให้คำตอบที่ผิด โดยเฉพาะ Grok 3 และ Gemini","link":"https://www.blognone.com/node/145674","date":1743751083000,"content":"<div><div><div><p>งานวิจัย Generative Search Tools and the Impact on News Content ที่จัดทำโดย Tow Center for Digital Journalism สำรวจว่าเครื่องมือค้นหา AI สามารถดึงข้อมูล และอ้างอิงเนื้อหาข่าวได้ดีแค่ไหน โดยเลือกบทความ 10 ชิ้นจากผู้เผยแพร่แต่ละราย ด้วยคำถามทั้งหมด 1,600 ข้อ</p>\n<p>ในการทดสอบครั้งนี้ มีเครื่องมือค้นหา AI  ทั้งหมด 8 โมเดล: ChatGPT, Perplexity, Perplexity Pro, DeepSeek, Copilot, Grok 2, Grok 3, และ Gemini</p>\n<p>จากการทดสอบพบว่า เครื่องมือ AI มีความผิดพลาดมากกว่า 60% โดยเฉพาะ Perplexity ตอบคำถามผิด 37%, Gemini 76%, และ Grok 3 94% แต่ยังตอบคำถามด้วยความมั่นใจที่น่าตกใจ ขณะที่ ChatGPT ระบุบทความพลาด 134 ชิ้นจากทั้งหมด 200 บทความ แต่ยอมรับว่าไม่มั่นใจกับคำตอบแค่ 15 ครั้ง</p>\n<p>ซึ่งโมเดลพรีเมียม หรือที่ต้องเสียเงินรายเดือนอย่าง Perplexity Pro และ Grok 3 ถึงจะตอบคำถามได้ถูกต้องมากกว่าโมเดลฟรี แต่ก็ตอบคำถามผิดมากกว่าเช่นกัน แม้มีต้นทุนที่สูงกว่า และมีข้อได้เปรียบในการคำนวณมากกว่าก็ตาม</p>\n<p><img alt=\"alt=&quot;Research&quot;\" src=\"https://www.blognone.com/sites/default/files/externals/671d3dbde0e45a9e45040c790b148c81.jpeg\" /></p>\n<p>อีกปัญหาที่พบคือ การละเมิดการตั้งค่าไฟล์ robots.txt ที่ใช้บอกบ็อตของเครื่องมือค้นหาว่า เว็บไซต์ไหนบ้างไม่ต้องการให้อ่านข้อมูลไปทำดัชนีค้นหาแต่ Perplexity กลับเข้าถึง และระบุบทความจาก National Geographic ได้อย่างถูกต้อง แม้เว็บไซต์ใช้ robots.txt ก็ตาม</p>\n<p>ขณะที่ Copilot แม้จะใช้โปรแกรมค้นหาแบบเดียวกับ Bing (เข้าถึงเนื้อหาจำนวนมากบนเว็บได้) แต่กลับปฏิเสธคำถามมากกว่าตอบคำถามตรง ๆ เป็นการย้ำว่า การเข้าถึงเนื้อหาจำนวนมาก ไม่ได้การันตีว่าเครื่องมือ AI จะให้คำตอบที่ถูกต้องหรือเป็นประโยชน์เสมอไป</p>\n<p>นอกจากนี้ เครื่องมือ AI หลายตัวอ้างอิงที่มาบทความผิด หรือใช้เนื้อหาที่ซินดิเคต (syndicated) แทนการอ้างอิงข้อมูลต้นฉบับ เช่น DeepSeek ระบุแหล่งที่มาผิด 115 ครั้งจาก 200 ครั้ง</p>\n<p>ซึ่งบางโมเดลแม้ระบุบทความถูกต้อง แต่ก็ให้ลิงก์ต้นฉบับที่ผิด เช่น Perplexity Pro ที่อ้างอิงบทความที่ซินดิเคตจาก Yahoo News และ AOL แม้ได้ทำข้อตกลงกับผู้เผยแพร่บางรายแล้ว</p>\n<p><img alt=\"alt=&quot;Syndicate&quot;\" src=\"https://www.blognone.com/sites/default/files/externals/adb3a5c3e21e7cf4811f9d8ddd29dabd.jpeg\" /></p>\n<p>หรือเครื่องมือ AI บางรุ่นใช้เนื้อหาที่ถูกซินดิเคต หรือไม่ถูกต้องตามลิขสิทธิ์ เช่นเคสของสำนักข่าว USA Today ที่บล็อกไม่ให้โมเดล ChatGPT เข้าถึงเนื้อหา แต่เครื่องมือกลับอ้างอิงบทความจาก Yahoo News ซึ่งเผยแพร่บทความของ USA Today ได้</p>\n<p>ยิ่งไปกว่านั้น โมเดล Gemini และ Grok 3 มักเชื่อมโยงคำตอบไปยังลิงก์ต้นฉบับผิด ๆ หรือสร้าง URL ขึ้นใหม่ โดยเฉพาะ Grok 3 ที่อ้างอิงลิงก์ที่ผิดทั้งหมด 154 ครั้งจากทั้งหมด 200 คำถาม ขณะที่แชทบอทอื่น ๆ พบผิดพลาดน้อยกว่าในประเด็นนี้</p>\n<p>สรุปแล้ว งานวิจัยชิ้นนี้พบปัญหาที่เคยศึกษาเกี่ยวกับ ChatGPT ในเดือนพฤศจิกายน 2024 นั่นก็คือ เครื่องมือ AI มักให้คำตอบผิด ๆ ด้วยความมั่นใจ, ระบุแหล่งที่มาผิด, และดึงข้อมูลที่ไม่สอดคล้องกัน</p>\n<p>ตรงนี้นักวิจารณ์ Chirag Shah และ Emily M. Bender ชี้ว่าเครื่องมือเหล่านี้ขาดความโปร่งใส และมักให้คำตอบที่ไม่ถูกต้องหรือมีอคติ ซึ่งไม่ได้รับการตรวจสอบอย่างเหมาะสม</p>\n<p>แต่ด้านประธานเจ้าหน้าที่ฝ่ายปฏิบัติการของนิตยสาร Time มองว่าเมื่อทีมวิศวกรรมเติบโตขึ้น และมีการลงทุนมากขึ้นในเครื่องมือเหล่านี้ ผลลัพธ์จะดีขึ้นเรื่อย ๆ แม้โมเดลฟรีจะตอบไม่แม่นยำ 100% ได้ในตอนนี้</p>\n<p>จากงานวิจัยนี้ OpenAI ยืนยันว่าจะปรับปรุงการอ้างอิง และเคารพความต้องการของผู้เผยแพร่ ขณะที่ Microsoft ระบุว่าได้ปฏิบัติตามมาตรฐาน robots.txt เพื่อเคารพข้อกำหนดของเว็บไซต์ต่าง ๆ ที่ไม่ต้องการให้เนื้อหาของพวกเขาถูกใช้กับโมเดล AI ของบริษัท</p>\n<p>ที่มา: <a href=\"https://www.digitaltrends.com/computing/your-favorite-ai-chatbot-might-not-be-telling-the-truth/#google_vignette\">Digital Trends</a> via <a href=\"https://www.cjr.org/tow_center/we-compared-eight-ai-search-engines-theyre-all-bad-at-citing-news.php\">Columbia Journalism Review</a></p>\n<p><img alt=\"alt=&quot;CRJ&quot;\" src=\"https://www.blognone.com/sites/default/files/externals/bc52aae38dfe38efe4cdd59bfb93ea61.png\" /></p>\n</div></div></div><div><div>Topics: </div><div><div><a href=\"/topics/artificial-intelligence\">Artificial Intelligence</a></div><div><a href=\"/topics/research\">Research</a></div></div></div>","author":"boompw","siteTitle":"Blognone","siteHash":"ededadcf18490b3937e7dd89ebe8c00dc129addbdf1ebe4aff1f458146693da0","entryHash":"398ecfe267bab2da5cdb8721c1e0f8633d5f6340121abe9f24b5c5bc34fc2513","category":"Thai"}