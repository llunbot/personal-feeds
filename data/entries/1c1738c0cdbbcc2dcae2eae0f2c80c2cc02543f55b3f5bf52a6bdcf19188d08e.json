{"title":"Political deepfakes are the most popular way to misuse AI","link":"https://arstechnica.com/?p=2033304","date":1719323031000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2024/06/deepfake-800x457.jpg\" alt=\"Political deepfakes are the most popular way to misuse AI\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2024/06/deepfake.jpg\">Enlarge</a> (credit: <a href=\"https://www.gettyimages.com/detail/photo/deep-fake-hoax-and-manipulation-news-titles-on-royalty-free-image/1482445987\">Arkadiusz Warguła via Getty</a>)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>Artificial intelligence-generated “deepfakes” that impersonate politicians and celebrities are far more prevalent than efforts to use AI to assist cyber attacks, according to the first research by Google’s DeepMind division into the most common malicious uses of the cutting-edge technology.</p>\n<p><a href=\"https://arxiv.org/abs/2406.13843\">The study</a> said the creation of realistic but fake images, video, and audio of people was almost twice as common as the next highest misuse of generative AI tools: the falsifying of information using text-based tools, such as chatbots, to generate misinformation to post online.</p>\n<p>The most common goal of actors misusing generative AI was to shape or influence public opinion, the analysis, conducted with the search group’s research and development unit Jigsaw, found. That accounted for 27 percent of uses, feeding into fears over how deepfakes might influence elections globally this year.</p></div><p><a href=\"https://arstechnica.com/?p=2033304#p3\">Read 13 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=2033304&amp;comments=1\">Comments</a></p>","author":"Financial Times","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"1c1738c0cdbbcc2dcae2eae0f2c80c2cc02543f55b3f5bf52a6bdcf19188d08e","category":"Tech"}