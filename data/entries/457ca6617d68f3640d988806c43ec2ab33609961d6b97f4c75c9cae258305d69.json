{"title":"Wall Street Journal Investigation Shows Instagram Serving Skeevy Videos, Alongside Mainstream Ads, to Adults Who Follow Accounts Featuring Young Gymnasts and Cheerleaders","link":"https://www.wsj.com/tech/meta-instagram-video-algorithm-children-adult-sexual-content-72874155","date":1701200230000,"content":"\n<p>Jeff Horwitz and Katherine Blunt, reporting for The Wall Street Journal:</p>\n\n<blockquote>\n  <p>The Journal sought to determine what Instagram’s Reels algorithm \nwould recommend to test accounts set up to follow only young \ngymnasts, cheerleaders and other teen and preteen influencers \nactive on the platform. Instagram’s system served jarring doses of \nsalacious content to those test accounts, including risqué footage \nof children as well as overtly sexual adult videos — and ads for \nsome of the biggest U.S. brands. </p>\n\n<p>The Journal set up the test accounts after observing that the \nthousands of followers of such young people’s accounts often \ninclude large numbers of adult men, and that many of the accounts \nwho followed those children also had demonstrated interest in sex \ncontent related to both children and adults. The Journal also \ntested what the algorithm would recommend after its accounts \nfollowed some of those users as well, which produced \nmore-disturbing content interspersed with ads. </p>\n\n<p>In a stream of videos recommended by Instagram, an ad for the \ndating app Bumble appeared between a video of someone stroking the \nface of a life-size latex doll and a video of a young girl with a \ndigitally obscured face lifting up her shirt to expose her \nmidriff. In another, a Pizza Hut commercial followed a video of a \nman lying on a bed with his arm around what the caption said was a \n10-year-old girl. </p>\n</blockquote>\n\n<p>Worse, Meta has known of the Journal’s findings since August and the problem continues:</p>\n\n<blockquote>\n  <p>The Journal informed Meta in August about the results of its \ntesting. In the months since then, tests by both the Journal and \nthe Canadian Centre for Child Protection show that the platform \ncontinued to serve up a series of videos featuring young children, \nadult content and apparent promotions for child sex material \nhosted elsewhere. </p>\n\n<p>As of mid-November, the center said Instagram is continuing to \nsteadily recommend what the nonprofit described as “adults and \nchildren doing sexual posing.” </p>\n</blockquote>\n\n<p>There’s no plausible scenario where Instagram <em>wants</em> to cater to pedophiles, but it’s seemingly beyond their current moderation capabilities to determine the content of videos at scale. Solving this ought to be their highest priority.</p>\n\n<div>\n<a href=\"https://daringfireball.net/linked/2023/11/28/instagram-wsj-footage-of-children\"> ★ </a>\n</div>\n\n\t","author":"John Gruber","siteTitle":"Daring Fireball","siteHash":"fc569638025dadf22a867470f8215f38855cf50e975782a6c989909474292a36","entryHash":"457ca6617d68f3640d988806c43ec2ab33609961d6b97f4c75c9cae258305d69","category":"Tech"}