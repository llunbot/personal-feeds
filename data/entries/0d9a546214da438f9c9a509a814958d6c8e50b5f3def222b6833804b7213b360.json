{"title":"What happens if we remove 50 percent of Llama?","link":"https://neuralmagic.com/blog/24-sparse-llama-smaller-models-for-efficient-gpu-inference/","date":1732660029000,"content":"<a href=\"https://news.ycombinator.com/item?id=42250773\">Comments</a>","author":"","siteTitle":"Hacker News","siteHash":"37bb545430005dba450c1e40307450d8e4e791b434e83f3d38915ebad510fd50","entryHash":"0d9a546214da438f9c9a509a814958d6c8e50b5f3def222b6833804b7213b360","category":"Tech"}