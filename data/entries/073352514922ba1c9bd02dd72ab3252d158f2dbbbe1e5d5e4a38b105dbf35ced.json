{"title":"AI language models can exceed PNG and FLAC in lossless compression, says study","link":"https://arstechnica.com/?p=1969616","date":1695915785000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2023/09/compression_clamp-800x450.jpg\" alt=\"Photo of a C-clamp compressing books.\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2023/09/compression_clamp.jpg\">Enlarge</a> (credit: <a href=\"https://www.gettyimages.com/detail/photo/press-book-royalty-free-image/175598141\">Getty Images</a>)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n\n<p>Effective compression is about finding patterns to make data smaller without losing information. When an algorithm or model can accurately guess the next piece of data in a sequence, it shows it's good at spotting these patterns. This links the idea of making good guesses—which is what large language models like GPT-4 <a href=\"https://arstechnica.com/science/2023/07/a-jargon-free-explanation-of-how-ai-large-language-models-work/\">do very well</a>—to achieving good compression.</p>\n<p>In an arXiv research paper titled \"<a href=\"https://arxiv.org/abs/2309.10668\">Language Modeling Is Compression</a>,\" researchers detail their discovery that the DeepMind large language model (LLM) called <a href=\"https://en.wikipedia.org/wiki/Chinchilla_AI\">Chinchilla 70B</a> can perform <a href=\"https://en.wikipedia.org/wiki/Lossless_compression\">lossless compression</a> on image patches from the <a href=\"https://www.image-net.org/\">ImageNet</a> image database to 43.4 percent of their original size, beating the <a href=\"https://en.wikipedia.org/wiki/PNG\">PNG</a> algorithm, which compressed the same data to 58.5 percent. For audio, Chinchilla compressed samples from the <a href=\"https://www.openslr.org/12\">LibriSpeech</a> audio data set to just 16.4 percent of their raw size, outdoing <a href=\"https://en.wikipedia.org/wiki/FLAC\">FLAC</a> compression at 30.3 percent.</p>\n<p>In this case, lower numbers in the results mean more compression is taking place. And lossless compression means that no data is lost during the compression process. It stands in contrast to a lossy compression technique like <a href=\"https://arstechnica.com/information-technology/2017/03/google-jpeg-guetzli-encoder-file-size/\">JPEG</a>, which sheds some data and reconstructs some of the data with approximations during the decoding process to significantly reduce file sizes.</p></div><p><a href=\"https://arstechnica.com/?p=1969616#p3\">Read 7 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=1969616&amp;comments=1\">Comments</a></p>","author":"Benj Edwards","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"073352514922ba1c9bd02dd72ab3252d158f2dbbbe1e5d5e4a38b105dbf35ced","category":"Tech"}