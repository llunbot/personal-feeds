{"title":"Amazon Bedrock adds reinforcement ﬁne-tuning simplifying how developers build smarter, more accurate AI models","link":"https://aws.amazon.com/blogs/aws/improve-model-accuracy-with-reinforcement-fine-tuning-in-amazon-bedrock/","date":1764778094000,"content":"<p>Organizations face a challenging trade-off when adapting AI models to their specific business needs: settle for generic models that produce average results, or tackle the complexity and expense of advanced model customization. Traditional approaches force a choice between poor performance with smaller models or the high costs of deploying larger model variants and managing complex infrastructure. Reinforcement fine-tuning is an advanced technique that trains models using feedback instead of massive labeled datasets, but implementing it typically requires specialized ML expertise, complicated infrastructure, and significant investment—with no guarantee of achieving the accuracy needed for specific use cases.</p> \n<p>Today, we’re announcing reinforcement fine-tuning in <a href=\"https://aws.amazon.com/bedrock/?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;sc_channel=el\">Amazon Bedrock</a>, a new <a href=\"https://aws.amazon.com/bedrock/customize/?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;sc_channel=el\">model customization</a> capability that creates smarter, more cost-effective models that learn from feedback and deliver higher-quality outputs for specific business needs. Reinforcement fine-tuning uses a feedback-driven approach where models improve iteratively based on reward signals, delivering 66% accuracy gains on average over base models.</p> \n<p>Amazon Bedrock automates the reinforcement fine-tuning workflow, making this advanced model customization technique accessible to everyday developers without requiring deep <a href=\"https://aws.amazon.com/ai/machine-learning/\">machine learning (ML)</a> expertise or large labeled datasets.</p> \n<p><span><strong>How reinforcement fine-tuning works<br /> </strong></span>Reinforcement fine-tuning is built on top of <a href=\"https://aws.amazon.com/what-is/reinforcement-learning/?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;sc_channel=el\">reinforcement learning</a> principles to address a common challenge: getting models to consistently produce outputs that align with business requirements and user preferences.</p> \n<p>While traditional fine-tuning requires large, labeled datasets and expensive human annotation, reinforcement fine-tuning takes a different approach. Instead of learning from fixed examples, it uses reward functions to evaluate and judge which responses are considered good for particular business use cases. This teaches models to understand what makes a quality response without requiring massive amounts of pre-labeled training data, making advanced model customization in Amazon Bedrock more accessible and cost-effective.</p> \n<p>Here are the benefits of using reinforcement fine-tuning in Amazon Bedrock:</p> \n<ul> \n <li><strong>Ease of use</strong> – Amazon Bedrock automates much of the complexity, making reinforcement fine-tuning more accessible to developers building AI applications. Models can be trained using existing API logs in Amazon Bedrock or by uploading datasets as training data, eliminating the need for labeled datasets or infrastructure setup.</li> \n <li><strong>Better model performance</strong> – Reinforcement fine-tuning improves model accuracy by 66% on average over base models, enabling optimization for price and performance by training smaller, faster, and more efficient model variants. This works with <a href=\"https://aws.amazon.com/nova/?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;sc_channel=el\">Amazon Nova 2 Lite</a> model, improving quality and price performance for specific business needs, with support for additional models coming soon.</li> \n <li><strong>Security – </strong>Data remains within the secure AWS environment throughout the entire customization process, mitigating security and compliance concerns.</li> \n</ul> \n<p>The capability supports two complementary approaches to provide flexibility for optimizing models:</p> \n<ul> \n <li><strong>Reinforcement Learning with Verifiable Rewards (RLVR)</strong> uses rule-based graders for objective tasks like code generation or math reasoning.</li> \n <li><strong>Reinforcement Learning from AI Feedback (RLAIF)</strong> employs AI-based judges for subjective tasks like instruction following or content moderation.</li> \n</ul> \n<p><span><strong>Getting started with reinforcement fine-tuning in Amazon Bedrock</strong></span><br /> Let’s walk through creating a reinforcement fine-tuning job.</p> \n<p>First, I access the <a href=\"https://console.aws.amazon.com/bedrock/?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;sc_channel=el\">Amazon Bedrock console</a>. Then, I navigate to the <strong>Custom models</strong> page. I choose <strong>Create</strong> and then choose <strong>Reinforcement fine-tuning job</strong>.</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/28/2025-news-bedrock-rev-3-1.png\" alt=\"\" width=\"1440\" height=\"917\" /></p> \n<p>I start by entering the name of this customization job and then select my base model. At launch, reinforcement fine-tuning supports <a href=\"https://aws.amazon.com/nova/?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;sc_channel=el\">Amazon Nova 2 Lite</a>, with support for additional models coming soon.</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/18/2025-news-bedrock-rl-2-0.png\" alt=\"\" width=\"1146\" height=\"607\" /></p> \n<p>Next, I need to provide training data. I can use my stored invocation logs directly, eliminating the need to upload separate datasets. I can also upload new JSONL files or select existing datasets from <a href=\"https://aws.amazon.com/s3/?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;sc_channel=el\">Amazon Simple Storage Service (Amazon S3)</a>. Reinforcement fine-tuning automatically validates my training dataset and supports the OpenAI Chat Completions data format. If I provide invocation logs in the Amazon Bedrock <a href=\"https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_InvokeModel.html\">invoke</a> or <a href=\"https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_Converse.html\">converse</a> format, Amazon Bedrock automatically converts them to the Chat Completions format.</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/28/2025-news-bedrock-rev-3-2.png\" alt=\"\" width=\"1337\" height=\"381\" /></p> \n<p>The reward function setup is where I define what constitutes a good response. I have two options here. For objective tasks, I can select <strong>Custom code</strong> and write custom Python code that gets executed through <a href=\"https://aws.amazon.com/lambda/?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;sc_channel=el\">AWS Lambda</a> functions. For more subjective evaluations, I can select <strong>Model as judge</strong> to use <a href=\"https://aws.amazon.com/what-is/foundation-models/?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;sc_channel=el\">foundation models (FMs)</a> as judges by providing evaluation instructions.</p> \n<p>Here, I select <strong>Custom code</strong>, and I create a new Lambda function or use an existing one as a reward function. I can start with one of the provided templates and customize it for my specific needs.</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/28/2025-news-bedrock-rev-3-3.png\" alt=\"\" width=\"1440\" height=\"474\" /></p> \n<p>I can optionally modify default hyperparameters like learning rate, batch size, and epochs.</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/28/2025-news-bedrock-rev-3-4.png\" alt=\"\" width=\"1334\" height=\"1133\" /></p> \n<p>For enhanced security, I can configure virtual private cloud (VPC) settings and <a href=\"https://aws.amazon.com/kms/\">AWS Key Management Service (AWS KMS)</a> encryption to meet my organization’s compliance requirements. Then, I choose <strong>Create</strong> to start the model customization job.</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/28/2025-news-bedrock-rev-3-6.png\" alt=\"\" width=\"1264\" height=\"882\" /></p> \n<p>During the training process, I can monitor real-time metrics to understand how the model is learning. The training metrics dashboard shows key performance indicators including reward scores, loss curves, and accuracy improvements over time. These metrics help me understand whether the model is converging properly and if the reward function is effectively guiding the learning process.</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/27/2025-news-bedrock-rev-4.png\" alt=\"\" width=\"2207\" height=\"2279\" /></p> \n<p>When the reinforcement fine-tuning job is completed, I can see the final job status on the <strong>Model details</strong> page.</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/27/2025-news-bedrock-rev-3.png\" alt=\"\" width=\"2194\" height=\"1388\" /></p> \n<p>Once the job is completed, I can deploy the model with a single click. I select <strong>Set up inference</strong>, then choose <strong>Deploy for on-demand</strong>.</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/27/2025-news-bedrock-rev-5.png\" alt=\"\" width=\"2224\" height=\"957\" /></p> \n<p>Here, I provide a few details for my model.</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/27/2025-news-bedrock-rev-6.png\" alt=\"\" width=\"2659\" height=\"1269\" /></p> \n<p>After deployment, I can quickly evaluate the model’s performance using the Amazon Bedrock playground. This helps me to test the fine-tuned model with sample prompts and compare its responses against the base model to validate the improvements. I select <strong>Test in playground.</strong></p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/27/2025-news-bedrock-rev-7.png\" alt=\"\" width=\"2166\" height=\"1102\" /></p> \n<p>The playground provides an intuitive interface for rapid testing and iteration, helping me confirm that the model meets my quality requirements before integrating it into production applications.</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/27/2025-news-bedrock-rev-8.png\" alt=\"\" width=\"2783\" height=\"1628\" /></p> \n<p><span><strong>Interactive demo</strong></span><br /> Learn more by navigating an interactive demo of <a href=\"https://aws.storylane.io/share/2wbkrcppkxdr\">Amazon Bedrock reinforcement fine-tuning</a> in action.</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/11/27/2025-news-bedrock-rev-9.png\" alt=\"\" width=\"1798\" height=\"967\" /></p> \n<p><span><strong>Additional things to know</strong></span><br /> Here are key points to note:</p> \n<ul> \n <li><strong>Templates — </strong>There are seven ready-to-use reward function templates covering common use cases for both objective and subjective tasks.</li> \n <li><strong>Pricing — </strong>To learn more about pricing, refer to the <a href=\"https://aws.amazon.com/bedrock/pricing/?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;sc_channel=el\">Amazon Bedrock pricing page</a>.</li> \n <li><strong>Security —</strong> Training data and custom models remain private and aren’t used to improve FMs for public use. It supports VPC and AWS KMS encryption for enhanced security.</li> \n</ul> \n<p>Get started with reinforcement fine-tuning by visiting the <a href=\"https://docs.aws.amazon.com/bedrock/latest/userguide/reinforcement-fine-tuning.html\">reinforcement fine-tuning documentation</a> and by accessing the <a href=\"https://console.aws.amazon.com/bedrock?trk=c4ea046f-18ad-4d23-a1ac-cdd1267f942c&amp;sc_channel=el\">Amazon Bedrock console</a>.</p> \n<p>Happy building!<br /> — <a href=\"https://www.linkedin.com/in/donnieprakoso\">Donnie</a></p>","author":"Donnie Prakoso","siteTitle":"AWS News Blog","siteHash":"6093e072e4117ec22616e844cb857d03ca62c57a411a8affc77cb5e8b6b15bf6","entryHash":"37811564b438aaac92d666c1f1357fd943d538c02f5bc6a2a926baf5c57bc220","category":"Tech"}