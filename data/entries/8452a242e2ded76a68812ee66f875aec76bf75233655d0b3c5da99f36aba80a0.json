{"title":"Apple Used Google Tensor Chips to Develop Apple Intelligence","link":"https://www.macrumors.com/2024/07/30/google-chips-used-to-develop-apple-intelligence/","date":1722344169000,"content":"Apple used Tensor Processing Units (TPUs) developed by Google instead of Nvidia's widely-used graphics processing units (GPUs) to construct two critical components of Apple Intelligence.\r<br />\n\r<br />\n<img src=\"https://images.macrumors.com/article-new/2024/06/Apple-Intelligence-General-Feature.jpg\" width=\"2500\" height=\"1406\" />\r<br />\nThe decision is detailed in a <a href=\"https://machinelearning.apple.com/papers/apple_intelligence_foundation_language_models.pdf\">new research paper</a> published by Apple that highlights its reliance on Google's cloud hardware (via <em><a href=\"https://www.cnbc.com/2024/07/29/apple-says-its-ai-models-were-trained-on-googles-custom-chips-.html\">CNBC</a></em>). The paper reveals that Apple utilized 2,048 of Google's TPUv5p chips to build AI models and 8,192 TPUv4 processors for server AI models. The research paper does not mention Nvidia explicitly, but the absence of any reference to Nvidia's hardware in the description of Apple's AI infrastructure is telling and this omission suggests a deliberate choice to favor Google's technology. \r<br />\n\r<br />\nThe decision is noteworthy given Nvidia's dominance in the AI processor market and since Apple very rarely discloses its hardware choices for development purposes. Nvidia's GPUs are highly sought after for AI applications due to their performance and efficiency. Unlike Nvidia, which sells its chips and systems as standalone products, Google provides access to its TPUs through cloud services. Customers using Google's TPUs have to develop their software within Google's ecosystem, which offers integrated tools and services to streamline the development and deployment of AI models. \r<br />\n\r<br />\nIn the paper, Apple's engineers explain that the TPUs allowed them to train large, sophisticated AI models efficiently. They describe how Google's TPUs are organized into large clusters, enabling the processing power necessary for training Apple's AI models. Apple has announced plans to invest over $5 billion in AI server enhancements over the next two years, which should bolster its AI capabilities and reduce its dependence on external hardware providers. \r<br />\n\r<br />\nIn addition to detailing its use of Google's TPUs, the paper addresses ethical considerations in AI development. Apple emphasized its adherence to responsible data practices, claiming that no private user data was used in training its AI models. The company relied on a mix of publicly available, licensed, and open-sourced datasets for training purposes. Apple added that its training data set, which includes publicly available web data and licensed content, was curated to protect user privacy.<div>Tags: <a href=\"https://www.macrumors.com/guide/google/\">Google</a>, <a href=\"https://www.macrumors.com/guide/artificial-intelligence/\">Artificial Intelligence</a>, <a href=\"https://www.macrumors.com/guide/nvidia/\">Nvidia</a>, <a href=\"https://www.macrumors.com/guide/apple-intelligence/\">Apple Intelligence</a></div><br />This article, \"<a href=\"https://www.macrumors.com/2024/07/30/google-chips-used-to-develop-apple-intelligence/\">Apple Used Google Tensor Chips to Develop Apple Intelligence</a>\" first appeared on <a href=\"https://www.macrumors.com\">MacRumors.com</a><br /><br /><a href=\"https://forums.macrumors.com/threads/apple-used-google-tensor-chips-to-develop-apple-intelligence.2432521/\">Discuss this article</a> in our forums<br /><br />","author":"Hartley Charlton","siteTitle":"MacRumors: Mac News and Rumors - All Stories","siteHash":"4c0f1b1ecc2ed084c9f5be50f1058e33a55cdf9b904dadc33a2071fc2d63e8c1","entryHash":"8452a242e2ded76a68812ee66f875aec76bf75233655d0b3c5da99f36aba80a0","category":"Apple"}