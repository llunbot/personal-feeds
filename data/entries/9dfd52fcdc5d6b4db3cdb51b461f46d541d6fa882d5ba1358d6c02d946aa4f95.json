{"title":"OpenAI’s new “reasoning” AI models are here: o1-preview and o1-mini","link":"https://arstechnica.com/?p=2049445","date":1726167673000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2024/09/digital_strawberry-800x450.jpg\" alt=\"An illustration of a strawberry made out of pixel-like blocks.\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2024/09/digital_strawberry.jpg\">Enlarge</a> (credit: <a href=\"https://www.gettyimages.com/detail/photo/close-up-strawberry-made-of-cube-blocks-against-royalty-free-image/1448124201\">Vlatko Gasparic via Getty Images</a>)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>OpenAI finally unveiled its rumored \"Strawberry\" AI language model on Thursday, claiming significant improvements in what it calls \"reasoning\" and problem-solving capabilities over previous large language models (LLMs). Formally named \"<a href=\"https://openai.com/index/learning-to-reason-with-llms/\">OpenAI o1</a>,\" the model family will initially launch in two forms, <a href=\"https://openai.com/index/introducing-openai-o1-preview/\">o1-preview</a> and <a href=\"https://openai.com/index/openai-o1-mini-advancing-cost-efficient-reasoning/\">o1-mini</a>, available today for ChatGPT Plus and certain API users.</p>\n\n<p>OpenAI claims that o1-preview outperforms its predecessor, <a href=\"https://arstechnica.com/information-technology/2024/05/chatgpt-4o-lets-you-have-real-time-audio-video-conversations-with-emotional-chatbot/\">GPT-4o</a>, on multiple benchmarks, including competitive programming, mathematics, and \"scientific reasoning.\" However, people who have used the model say it does not yet outclass GPT-4o in every metric. Other users have <a href=\"https://www.theinformation.com/articles/new-details-on-openais-strawberry-apples-siri-makeover-larry-ellison-doubles-down-on-data-centers\">criticized</a> the delay in receiving a response from the model, owing to the multi-step processing occurring behind the scenes before answering a query.</p>\n<p>In a rare display of public hype-busting, OpenAI product manager Joanne Jang <a href=\"https://x.com/joannejang/status/1834286774140498368\">tweeted</a>, \"There's a lot of o1 hype on my feed, so I'm worried that it might be setting the wrong expectations. what o1 is: the first reasoning model that shines in really hard tasks, and it'll only get better. (I'm personally psyched about the model's potential &amp; trajectory!) what o1 isn't (yet!): a miracle model that does everything better than previous models. you might be disappointed if this is your expectation for today's launch—but we're working to get there!\"</p></div><p><a href=\"https://arstechnica.com/?p=2049445#p3\">Read 18 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=2049445&amp;comments=1\">Comments</a></p>","author":"Benj Edwards","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"9dfd52fcdc5d6b4db3cdb51b461f46d541d6fa882d5ba1358d6c02d946aa4f95","category":"Tech"}