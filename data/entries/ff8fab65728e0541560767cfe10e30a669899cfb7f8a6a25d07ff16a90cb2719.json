{"title":"Google ชี้แจงปัญหา AI Overviews ให้คำตอบแปลก ๆ ยืนยัน แก้ไขเร็ว-ปรับปรุงต่อเนื่อง","link":"https://www.blognone.com/node/140065","date":1717149139000,"content":"<div><div><div><p>กูเกิลอธิบายปัญหาที่เกิดขึ้นของฟีเจอร์ <strong>AI Overviews</strong> ที่อยู่ด้านบนสุดของหน้าผลการค้นหา โดยให้คำตอบแบบสรุปจากสิ่งที่ถาม ซึ่งเมื่อขยายให้กับผู้ใช้มากขึ้นเมื่อไม่กี่สัปดาห์ที่ผ่านมาในอเมริกา ทำให้เกิดรายงานการให้คำตอบแปลก ๆ หลายต่อหลายกรณี</p>\n<p>กูเกิลเริ่มต้นด้วยการอธิบายวิธีการทำงานของ AI Overviews โดยย้ำว่าการทำงานนั้นแตกต่างจากแชทบอตหรือ LLM ตัวอื่น เป้าหมายคือการสรุปเนื้อหาเพื่อให้ผู้ใช้งานได้คำตอบเร็วที่สุด การเขียนคำตอบทำด้วยโมเดลภาษาที่ปรับแต่ง อิงจากอันดับผลการค้นหา การทำงานหลักจึงอยู่ที่ส่วนของ Search คำตอบที่ได้จึงมีลิงก์ให้ไปหาข้อมูลเพิ่มเติมด้วย</p>\n<p>สิ่งที่กูเกิลต้องการย้ำคือ AI Overviews ไม่ได้ทำงานแบบ LLM ที่พยายามเขียนคำตอบออกมาเรื่อย ๆ ถูกบ้างผิดบ้าง แต่เมื่อ AI Overviews ให้คำตอบที่ไม่ถูก สาเหตุก็คือระบบตีความคิวรีไม่ถูกต้อง และไปเลือกข้อมูลที่ไม่ถูกต้องในเว็บมาเขียนคำตอบอีก กรณีนี้เกิดได้โดยเฉพาะกับคิวรีที่แม้แต่การค้นหาปกติก็ไม่เจอเว็บที่มีคำตอบถูกต้อง</p>\n<p><img src=\"https://www.blognone.com/sites/default/files/externals/649440e256f5acd02f95d5abd6c375a9.png\" /></p>\n<p>กูเกิลยกกรณีที่เป็นไวรัลในอินเทอร์เน็ตว่าเกิดขึ้นได้อย่างไร ดังนี้</p>\n<ul>\n<li>คำถามเราควรกินหินกี่ก้อน - กูเกิลอธิบายว่าเพราะปกติไม่มีใครถามคำถามนี้ ข้อมูลในอินเทอร์เน็ตจึงมีน้อย และที่มีก็เป็นการตอบแบบตลก กูเกิลจึงไปเลือกคำตอบที่พอมีนี้มา</li>\n<li>คำถามวิธีทำพิซซ่าให้ชีสไม่ไหลหลุดจากแป้ง แล้วบอกว่าผสมกาว - กูเกิลบอกว่าปกติคำถามลักษณะนี้ ฟอรัมในอินเทอร์เน็ตคือแหล่งข้อมูลที่ดี แต่กรณีดังกล่าวไม่ใช่ จึงถือเป็นส่วนน้อยมากที่เกิดขึ้นได้</li>\n</ul>\n<p>กูเกิลบอกว่าลักษณะปัญหานี้ที่เกิดขึ้นได้ถูกแก้ไขไปแล้วอย่างรวดเร็ว พร้อมกับพัฒนาหาแนวทางป้องกันมากขึ้น ซึ่งที่ทำไปแล้วมีหลายอย่างเช่น</p>\n<ul>\n<li>ตรวจสอบคำถามที่ไม่ควรนำมาถาม ไม่ให้ AI Overviews ทำงาน รวมทั้งจำกัดการนำผลค้นหาจากเว็บที่เน้นตลกขบขัน</li>\n<li>จำกัดการใช้คำตอบจากเว็บประเภท user-generated content ที่อาจให้คำตอบผิด</li>\n<li>ปิดการทำงาน AI Overviews ในบางประเภทคำถามที่พิสูจน์แล้วว่าไม่สามารถให้คำตอบที่ดีได้</li>\n<li>ปิดการทำงาน หากเป็นคำถามเรื่องข่าวสารบ้านเมืองที่สำคัญ และคำถามเกี่ยวกับสุขภาพ</li>\n</ul>\n<p>กูเกิลบอกว่าในตอนนี้พบการส่งคิวรีที่ผิดเงื่อนไขของ AI Overviews น้อยมาก ในระดับน้อยกว่า 1 ครั้ง ต่อ 7 ล้านคิวรีที่แสดงคำตอบ ซึ่งแปลว่าคำตอบแปลก ๆ ยังสามารถเกิดขึ้นได้ แต่เป็นจำนวนที่น้อยมากนั่นเอง</p>\n<p>ที่มา: <a href=\"https://blog.google/products/search/ai-overviews-update-may-2024/\">กูเกิล</a></p>\n<p><img src=\"https://www.blognone.com/sites/default/files/externals/e0cf4e4aa9d6ae3ed397cb4692b367d9.jpg\" /></p>\n</div></div></div><div><div>Topics: </div><div><div><a href=\"/topics/google-search\">Google Search</a></div><div><a href=\"/topics/google\">Google</a></div><div><a href=\"/topics/artificial-intelligence\">Artificial Intelligence</a></div></div></div>","author":"arjin","siteTitle":"Blognone","siteHash":"ededadcf18490b3937e7dd89ebe8c00dc129addbdf1ebe4aff1f458146693da0","entryHash":"ff8fab65728e0541560767cfe10e30a669899cfb7f8a6a25d07ff16a90cb2719","category":"Thai"}