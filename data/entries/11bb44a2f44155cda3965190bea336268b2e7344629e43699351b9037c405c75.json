{"title":"Guardrails for Amazon Bedrock now available with new safety filters and privacy controls","link":"https://aws.amazon.com/blogs/aws/guardrails-for-amazon-bedrock-now-available-with-new-safety-filters-and-privacy-controls/","date":1713871551000,"content":"<p>Today, I am happy to announce the general availability of <a href=\"https://aws.amazon.com/bedrock/guardrails/\">Guardrails for Amazon Bedrock</a>, first released in preview at <a href=\"https://www.youtube.com/watch?v=-osfvAqydt0\">re:Invent 2023</a>. With Guardrails for Amazon Bedrock, you can implement safeguards in your generative artificial intelligence (generative AI) applications that are customized to your use cases and responsible AI policies. You can create multiple guardrails tailored to diﬀerent use cases and apply them across multiple foundation models (FMs), improving end-user experiences and standardizing safety controls across generative AI applications. You can use Guardrails for Amazon Bedrock with all large language models (LLMs) in Amazon Bedrock, including fine-tuned models.</p> \n<p>Guardrails for Bedrock offers industry-leading safety protection on top of the native capabilities of FMs, helping customers block as much as 85% more harmful content than protection natively provided by some foundation models on Amazon Bedrock today. Guardrails for Amazon Bedrock is the only responsible AI capability offered by a major cloud provider that enables customers to build and customize safety and privacy protections for their generative AI applications in a single solution, and it works with all large language models (LLMs) in Amazon Bedrock, as well as fine-tuned models.</p> \n<p><a href=\"https://www.aha.io/\">Aha!</a> is a software company that helps more than 1 million people bring their product strategy to life. “Our customers depend on us every day to set goals, collect customer feedback, and create visual roadmaps,” said Dr. Chris Waters, co-founder and Chief Technology Officer at Aha!. “That is why we use Amazon Bedrock to power many of our generative AI capabilities. Amazon Bedrock provides responsible AI features, which enable us to have full control over our information through its data protection and privacy policies, and block harmful content through Guardrails for Bedrock. We just built on it to help product managers discover insights by analyzing feedback submitted by their customers. This is just the beginning. We will continue to build on advanced AWS technology to help product development teams everywhere prioritize what to build next with confidence.”</p> \n<p><a href=\"https://aws.amazon.com/blogs/aws/guardrails-for-amazon-bedrock-helps-implement-safeguards-customized-to-your-use-cases-and-responsible-ai-policies-preview/\">In the preview post</a>, <a href=\"https://aws.amazon.com/blogs/aws/author/antjebar/\">Antje</a> showed you how to use guardrails to configure thresholds to filter content across harmful categories and define a set of topics that need to be avoided in the context of your application. The Content filters feature now has two additional safety categories: <strong>Misconduct</strong> for detecting criminal activities and <strong>Prompt Attack</strong> for detecting prompt injection and jailbreak attempts. We also added important new features, including sensitive information filters to detect and redact personally identifiable information (PII) and word filters to block inputs containing profane and custom words (for example, harmful words, competitor names, and products).</p> \n<p>Guardrails for Amazon Bedrock sits in between the application and the model. Guardrails automatically evaluates everything going into the model from the application and coming out of the model to the application to detect and help prevent content that falls into restricted categories.</p> \n<p>You can recap the steps in the <a href=\"https://aws.amazon.com/blogs/aws/guardrails-for-amazon-bedrock-helps-implement-safeguards-customized-to-your-use-cases-and-responsible-ai-policies-preview/\">preview release</a> blog to learn how to configure <strong>Denied topics</strong> and <strong>Content filters</strong>. Let me show you how the new features work.</p> \n<p><strong><u>New features</u></strong><br /> To start using Guardrails for Amazon Bedrock, I go to the <a href=\"https://console.aws.amazon.com\">AWS Management Console</a> for Amazon Bedrock, where I can create guardrails and configure the new capabilities. In the navigation pane in the Amazon Bedrock console, I choose <strong>Guardrails</strong>, and then I choose <strong>Create guardrail</strong>.</p> \n<p>I enter the guardrail <strong>Name</strong> and <strong>Description</strong>. I choose <strong>Next</strong> to move to the <strong>Add sensitive information filters </strong>step.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/04/19/AWSNEWS-1963-figure0-add.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/04/19/AWSNEWS-1963-figure0-add.png\" width=\"2432\" height=\"1048\" /></a></p> \n<p>I use <strong>Sensitive information filters</strong> to detect sensitive and private information in user inputs and FM outputs. Based on the use cases, I can select a set of entities to be either blocked in inputs (for example, a FAQ-based chatbot that doesn’t require user-specific information) or redacted in outputs (for example, conversation summarization based on chat transcripts). The sensitive information filter supports a set of predefined PII types. I can also define custom regex-based entities specific to my use case and needs.</p> \n<p>I add two <strong>PII types</strong> (Name, Email) from the list and add a regular expression pattern using <code>Booking ID</code> as <strong>Name</strong> and <code>[0-9a-fA-F]{8}</code> as the <strong>Regex pattern</strong>.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/04/22/AWSNEWS-1963-figure1-sensitive-information-filters-addv3.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/04/22/AWSNEWS-1963-figure1-sensitive-information-filters-addv3.png\" width=\"2438\" height=\"1183\" /></a></p> \n<p>I choose <strong>Next</strong> and enter custom messages that will be displayed if my guardrail blocks the input or the model response in the <strong>Define blocked messaging</strong> step. I review the configuration at the last step and choose <strong>Create guardrail</strong>.</p> \n<p>I navigate to the <strong>Guardrails Overview page</strong> and choose the <strong>Anthropic Claude Instant 1.2</strong> model using the <strong>Test</strong> section. I enter the following call center transcript in the <strong>Prompt</strong> field and choose <strong>Run</strong>.</p> \n<p><code>Please summarize the below call center transcript. Put the name, email and the booking ID to the top:<br /> Agent: Welcome to ABC company. How can I help you today?<br /> Customer: I want to cancel my hotel booking.<br /> Agent: Sure, I can help you with the cancellation. Can you please provide your booking ID?<br /> Customer: Yes, my booking ID is 550e8408.<br /> Agent: Thank you. Can I have your name and email for confirmation?<br /> Customer: My name is Jane Doe and my email is jane.doe@gmail.com<br /> Agent: Thank you for confirming. I will go ahead and cancel your reservation.</code></p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/04/22/AWSNEWS-1963-figure2-sensitive-information-filters-runv2.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/04/22/AWSNEWS-1963-figure2-sensitive-information-filters-runv2.png\" width=\"2432\" height=\"1188\" /></a></p> \n<p><strong>Guardrail action</strong> shows there are three instances where the guardrails came in to effect. I use <strong>View trace</strong> to check the details. I notice that the guardrail detected the <strong>Name, Email </strong>and <strong>Booking ID</strong> and masked them in the final response.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/04/22/AWSNEWS-1963-figure3-sensitive-information-filters-view-trace-v3.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/04/22/AWSNEWS-1963-figure3-sensitive-information-filters-view-trace-v3.png\" width=\"2451\" height=\"1185\" /></a></p> \n<p>I use <strong>Word filters</strong> to block inputs containing profane and custom words (for example, competitor names or offensive words). I check the <strong>Filter profanity</strong> box. The profanity list of words is based on the global definition of profanity. Additionally, I can specify up to 10,000 phrases (with a maximum of three words per phrase) to be blocked by the guardrail. A blocked message will show if my input or model response contain these words or phrases.</p> \n<p>Now, I choose <strong>Custom words and phrases</strong> under <strong>Word filters</strong> and choose <strong>Edit</strong>. I use <strong>Add words and phrases manually</strong> to add a custom word <code>CompetitorY</code>. Alternatively, I can use <strong>Upload from a local file</strong> or <strong>Upload from S3 object</strong> if I need to upload a list of phrases. I choose <strong>Save and exit</strong> to return to my guardrail page.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/04/19/AWSNEWS-1963-figure5-word-filters-edit-v2.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/04/19/AWSNEWS-1963-figure5-word-filters-edit-v2.png\" width=\"1724\" height=\"1007\" /></a></p> \n<p>I enter a prompt containing information about a fictional company and its competitor and add the question <code>What are the extra features offered by CompetitorY?</code>. I choose <strong>Run</strong>.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/04/22/AWSNEWS-1963-figure6-word-filters-run-annotated-v4.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/04/22/AWSNEWS-1963-figure6-word-filters-run-annotated-v4.png\" width=\"2431\" height=\"1188\" /></a></p> \n<p>I use <strong>View trace</strong> to check the details. I notice that the guardrail intervened according to the policies I configured.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/04/22/AWSNEWS-1963-figure7-word-filters-view-trace-annotated-v2-1.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/04/22/AWSNEWS-1963-figure7-word-filters-view-trace-annotated-v2-1.png\" width=\"2451\" height=\"1183\" /></a></p> \n<p><strong><u>Now available</u></strong><br /> Guardrails for Amazon Bedrock is now available in US East (N. Virginia) and US West (Oregon) Regions.</p> \n<p>For pricing information, visit the <a href=\"https://aws.amazon.com/bedrock/pricing/\">Amazon Bedrock pricing page</a>.</p> \n<p>To get started with this feature, visit the <a href=\"https://aws.amazon.com/bedrock/guardrails/\">Guardrails for Amazon Bedrock</a> web page.</p> \n<p>For deep-dive technical content and to learn how our Builder communities are using Amazon Bedrock in their solutions, visit our <a href=\"https://community.aws/generative-ai?trk=e8665609-785f-4bbe-86e8-750a3d3e9e61&amp;sc_channel=el\">community.aws</a> website.</p> \n<a href=\"https://www.linkedin.com/in/esrakayabali/\">— Esra</a>","author":"Esra Kayabali","siteTitle":"AWS News Blog","siteHash":"6093e072e4117ec22616e844cb857d03ca62c57a411a8affc77cb5e8b6b15bf6","entryHash":"11bb44a2f44155cda3965190bea336268b2e7344629e43699351b9037c405c75","category":"Tech"}