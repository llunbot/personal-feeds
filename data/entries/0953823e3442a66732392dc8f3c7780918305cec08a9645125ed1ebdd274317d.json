{"title":"Show HN: Flash Attention in ~100 lines of CUDA","link":"https://github.com/tspeterkim/flash-attention-minimal","date":1710603119000,"content":"<a href=\"https://news.ycombinator.com/item?id=39726781\">Comments</a>","author":"","siteTitle":"Hacker News","siteHash":"37bb545430005dba450c1e40307450d8e4e791b434e83f3d38915ebad510fd50","entryHash":"0953823e3442a66732392dc8f3c7780918305cec08a9645125ed1ebdd274317d","category":"Tech"}