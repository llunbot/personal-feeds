{"title":"Apple Releases Open Source AI Models That Run On-Device","link":"https://www.macrumors.com/2024/04/24/apple-ai-open-source-models/","date":1713998390000,"content":"Apple today released several open source large language models (LLMs) that are designed to run on-device rather than through cloud servers. Called OpenELM (Open-source Efficient Language Models), the LLMs are available on <a href=\"https://huggingface.co/apple/OpenELM\">the Hugging Face Hub</a>, a community for sharing AI code.\r<br />\n\r<br />\n<img src=\"https://images.macrumors.com/article-new/2024/04/Apple-Silicon-AI-Optimized-Feature-Siri.jpg\" width=\"2500\" height=\"1406\" />\r<br />\nAs outlined in a white paper [<a href=\"https://arxiv.org/pdf/2404.14619\">PDF</a>], there are eight total OpenELM models, four of which were pre-trained using the CoreNet library, and four instruction tuned models. Apple uses a layer-wise scaling strategy that is aimed at improving accuracy and efficiency.\r<br />\n\r<br />\nApple provided code, training logs, and multiple versions rather than just the final trained model, and the researchers behind the project hope that it will lead to faster progress and \"more trustworthy results\" in the natural language AI field.\r<br />\n<blockquote>OpenELM, a state-of-the-art open language model. OpenELM uses a layer-wise scaling strategy to efficiently allocate parameters within each layer of the transformer model, leading to enhanced accuracy. For example, with a parameter budget of approximately one billion parameters, OpenELM exhibits a 2.36% improvement in accuracy compared to OLMo while requiring 2x fewer pre-training tokens.\r<br />\n\r<br />\nDiverging from prior practices that only provide model weights and inference code, and pre-train on private datasets, our release includes the complete framework for training and evaluation of the language model on publicly available datasets, including training logs, multiple checkpoints, and pre-training configurations.</blockquote>\r<br />\nApple says that it is releasing the OpenELM models to \"empower and enrich the open research community\" with stage-of-the-art language models. Sharing open source models gives researchers a way to investigate risks and data and model biases. Developers and companies are able to use the models as-is or make modifications.\r<br />\n\r<br />\nThe open sharing of information has become an important tool for Apple to recruit top engineers, scientists, and experts because it provides opportunities for research papers that would not normally have been able to be published under Apple's secretive policies.\r<br />\n\r<br />\nApple has not yet brought these kinds of AI capabilities to its devices, but <a href=\"https://www.macrumors.com/roundup/ios-18/\">iOS 18</a> is expected to include a number of new AI features, and rumors suggest that Apple is planning to run its large language models on-device for privacy purposes.<div>Tag: <a href=\"https://www.macrumors.com/guide/artificial-intelligence/\">Artificial Intelligence</a></div><br />This article, \"<a href=\"https://www.macrumors.com/2024/04/24/apple-ai-open-source-models/\">Apple Releases Open Source AI Models That Run On-Device</a>\" first appeared on <a href=\"https://www.macrumors.com\">MacRumors.com</a><br /><br /><a href=\"https://forums.macrumors.com/threads/apple-releases-open-source-ai-models-that-run-on-device.2424846/\">Discuss this article</a> in our forums<br /><br />","author":"Juli Clover","siteTitle":"MacRumors: Mac News and Rumors - All Stories","siteHash":"4c0f1b1ecc2ed084c9f5be50f1058e33a55cdf9b904dadc33a2071fc2d63e8c1","entryHash":"22afc29a0bddb2d24e321634206c1cec310f1303a030168acb518590905db4c8","category":"Apple"}