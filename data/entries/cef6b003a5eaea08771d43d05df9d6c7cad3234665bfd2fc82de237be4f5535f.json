{"title":"งานวิจัยพบ ChatGPT ตอบคำถามโค้ดดิ้ง มีโอกาสผิดถึง 52% แต่คนชอบเพราะสุภาพกว่า Stack Overflow","link":"https://www.blognone.com/node/135327","date":1692280467000,"content":"<div><div><div><p>ทีมวิจัยจาก Purdue University ลองสำรวจการใช้ ChatGPT ตอบคำถามด้านโค้ดดิ้ง โดยเทียบคำถามเดียวกันกับที่ถามบน Stack Overflow จำนวน 517 คำถาม แล้วนำคำตอบมาเปรียบเทียบกับคำตอบของมนุษย์ว่าถูกต้อง แม่นยำ ครบถ้วนแค่ไหน อีกทั้งให้อาสาสมัครจำนวนหนึ่งเลือกว่าชอบคำตอบอันไหนมากกว่า</p>\n<p>ผลคือคำตอบ 52% ของ ChatGPT ตอบผิด (incorrect) ส่วนอาสาสมัครเลือกคำตอบจาก ChatGPT จำนวน 39.34% เนื่องจากใช้ภาษาดี แสดงเหตุผลดูน่าเชื่อถือ ซึ่ง 77% ของคำตอบเหล่านี้ผิดซะด้วย</p>\n<p>คณะวิจัยบอกว่า ในกรณีที่ ChatGPT ตอบผิดแบบจะแจ้ง ผู้ใช้จะแยกแยะได้ง่าย แต่ถ้าคำตอบไม่สามารถยืนยันได้ง่ายว่าผิดถูกอย่างไร จำเป็นต้องนำโค้ดไปลองรันใน IDE หรือเปิดจากเอกสาร ผู้ใช้มักแยกแยะความถูกต้องของคำตอบไม่ได้เลย อีกทั้งวิธีการใช้ภาษาของ ChatGPT ที่ดูเป็นทางการ เขียนอธิบายแนวคิด ไม่มีอารมณ์เชิงลบ ทำให้ผู้ใช้มีโอกาสโน้มเอียงไปทางคำตอบของ ChatGPT (ที่มีโอกาสผิดสูง) ด้วย</p>\n<p>อีกประเด็นที่น่าสนใจคือ ChatGPT มักตอบผิดในเชิงคอนเซปต์ผิด (conceptual) มากกว่าข้อมูลผิด (factual) ซึ่งแสดงให้เห็นว่า ChatGPT ยังไม่เข้าใจบริบทของคำถามดีพอ</p>\n<p>ที่มา - <a href=\"https://www.theregister.com/2023/08/07/chatgpt_stack_overflow_ai/\">The Register</a></p>\n<p><img src=\"https://www.blognone.com/sites/default/files/externals/1e82a6cf1ea2f582592f4a3eeae5c82e.jpg\" alt /></p>\n</div></div></div><div><div>Topics: </div><div><div><a href=\"/topics/chatgpt\">ChatGPT</a></div><div><a href=\"/topics/artificial-intelligence\">Artificial Intelligence</a></div><div><a href=\"/topics/stack-overflow\">Stack Overflow</a></div><div><a href=\"/topics/programming\">Programming</a></div></div></div>","author":"mk","siteTitle":"Blognone","siteHash":"ededadcf18490b3937e7dd89ebe8c00dc129addbdf1ebe4aff1f458146693da0","entryHash":"cef6b003a5eaea08771d43d05df9d6c7cad3234665bfd2fc82de237be4f5535f","category":"Thai"}