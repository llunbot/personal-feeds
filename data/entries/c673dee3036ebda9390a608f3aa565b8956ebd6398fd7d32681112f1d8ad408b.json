{"title":"สิ่งที่น่าสนใจจากเรื่องการ scale PostgreSQL database ของระบบ ChatGPT และ OpenAI API","link":"https://www.somkiat.cc/note-scale-postgresql-at-openai/","date":1769704995000,"content":"<p><img width=\"150\" height=\"150\" src=\"https://www.somkiat.cc/wp-content/uploads/2026/01/openai-postgresql-150x150.png\" alt=\"\" loading=\"lazy\" srcset=\"https://www.somkiat.cc/wp-content/uploads/2026/01/openai-postgresql-150x150.png 150w, https://www.somkiat.cc/wp-content/uploads/2026/01/openai-postgresql-75x75.png 75w\" /></p>\n<p>จากบทความเรื่อง <strong><a href=\"https://openai.com/index/scaling-postgresql/\" target=\"_blank\">Scaling PostgreSQL to power 800 million ChatGPT users</a></strong><br />ซึ่งเป็น session หนึ่งในงาน <a href=\"https://www.pgevents.ca/events/pgconfdev2025/schedule/session/433-scaling-postgres-to-the-next-level-at-openai/\" target=\"_blank\">PostgreSQL development conference 2025</a><br />เป็นการเล่าถึงการ scale PostgreSQL database เพื่อรองรับ workload ที่สูงขึ้น<br />สิ่งที่น่าสนใจมาก ๆ คือ ที่มาที่ไปของปัญหา และ แนวทางการแก้ไขปัญหา<br />มาดูกันว่าเป็นอย่างไรบ้าง ?<br />เอาที่ผมรู้เรื่องนะครับ !!</p>\n\n\n\n<span></span>\n\n\n\n<p>ระบบหลักของ OpenAI นั้นจะใช้ PostgreSQL database เป็นหลัก<br />ดังนั้นถ้า database มีปัญหาแล้ว ระบบล่ม และ ใช้งานไม่ได้<br />และแน่นอนว่ามีปัญหามาตลอดเวลา</p>\n\n\n\n<p><strong>แนวทางในการแก้ไขปัญหาคอขวดนี้</strong></p>\n\n\n\n<p>ทางทีมจึงเลือกใช้งาน database บน Azure (Geo-distributed) ซึ่งเป็น managed service<br />โดยใช้ database topology เป็น master-slave (Primary-Replicas)<br />ใช้งาน 1 primary database เท่านั้น <strong>และไม่ทำการ sharding อีกด้วย</strong><br />ในส่วนของ replica database ประมาณ 50 เครื่องกระจายในแต่ละ zone ทั้งโลก<br />เหตุผลคือ สามารถขยายระบบเพื่อรองรับการ read และ read ได้อย่างดี<br />อีกอย่างถ้าทำ shardding แล้ว จะทำให้ระบบซับซ้อนขึ้น และกระทบต่อระบบอื่น ๆ อีก<br />ดังนั้นตอนนี้จึงยังไม่ทำ แต่ในอนาคตก็เป็นอีกหนึ่งทางเลือกเช่นกัน</p>\n\n\n\n<figure><a href=\"https://www.somkiat.cc/wp-content/uploads/2026/01/openai-postgresql.png\"><img src=\"https://www.somkiat.cc/wp-content/uploads/2026/01/openai-postgresql-1024x592.png\" alt=\"\" width=\"611\" height=\"353\" /></a></figure>\n\n\n\n<p><strong>แต่เมื่อใช้งานไปสักระยะหนึ่งก็เจอปัญหาใหม่คือ </strong><br />ระบบมีการ write ข้อมูลที่สูงขึ้น<br />ซึ่งส่งผลให้ระบบที่ใช้งานอยู่นั้น ไม่สามารถรองรับได้ !!<br />เพราะว่า การทำงานของระบบงานนั้นมีปัญหาคอขวดเพียบ</p>\n\n\n\n<p><strong>หนึ่งในนั้นมันคือ PostgreSQL ที่มีปัญหาในการรองรับการ write ข้อมูลจำนวนมาก ๆ</strong><br />ซึ่งมาจากการออกแบบ <a href=\"https://bohanzhang.me/assets/blogs/hate_the_most/hate_the_most.html\" target=\"_blank\">MVVC ของ database </a>นั่นเอง เช่น</p>\n\n\n\n<ul>\n<li>เมื่อ table มีขนาดใหญ่ขึ้น ก็ทำ index มากขึ้น</li>\n\n\n\n<li>การ tuning autovacuum ก็ยากและซับซ้อนมาก</li>\n\n\n\n<li>การจัดการและดูแลพวก index ต่าง ๆ ก็ใช้เวลานาน</li>\n\n\n\n<li>ไม่พอ ในการ replica ข้อมูลไปยังเครื่องอื่นก็ช้าอีกด้วย (replica lag)</li>\n\n\n\n<li>การใช้งาน bandwidth ของ network ก็สูงขึ้น จนเต็มอีก !!</li>\n</ul>\n\n\n\n<p><strong>แนวทางการลดปัญหาคือ ลดการใช้งานบน Primary database</strong></p>\n\n\n\n<p>ยกตัวอย่างเช่น</p>\n\n\n\n<ul>\n<li>ย้ายการ write data ไปยังระบบอื่น ซึ่งเป็น Shard system ภายใน ที่คล้าย ๆ กับ <a href=\"https://cosmos.azure.com/\" target=\"_blank\">Azure Cosmos DB</a></li>\n\n\n\n<li>ลดจำนวนการ write ในฝั่ง application ลง แถมยังเจอ bug ว่ามีการ write ที่ไม่จำเป็นจำนวนมาก</li>\n\n\n\n<li>ใช้เทคนิด Lazy write และใช้งาน rate limit เข้ามาช่วยเหลือ</li>\n\n\n\n<li>ส่วนการ read ให้ไปเครื่อง Replica ให้มากที่สุด</li>\n\n\n\n<li>ต้อง monitor การทำงานให้ดี เช่น การดูว่า index ที่สร้างนั้นถูกใช้งานหรือไม่ ถ้าไม่หรือน้อยแล้ว ให้ทำการ disable ก่อนเพื่อดูผล จากนั้นถ้าไม่ส่งผล ก็ทำการลบมันซะ</li>\n</ul>\n\n\n\n<p><strong>ต่อมาปรับปรุงการ read อีกด้วย เพื่อลดการใช้งานลงไป</strong></p>\n\n\n\n<p>ยกตัวอย่างเช่น</p>\n\n\n\n<ul>\n<li>ใช้ rate limit ในทุก ๆ ระดับ ทั้ง application ทั้งการสร้าง database connection ก็จัดการที่ connection pool ด้วย <a href=\"https://www.pgbouncer.org/\" target=\"_blank\">pgbouuncer</a></li>\n\n\n\n<li>กำหนด timeout ในการ run query ด้วยเสมอทั้ง transaction, statement และ client timeout</li>\n\n\n\n<li>ลดการ run query ที่ join table กันเยอะ ๆ ซึ่งเจอเยอะสุดคือ 12 tables  (ลูกอีช่าง join มาก ๆ) </li>\n\n\n\n<li>ในการใช้งาน ORM (Object Relation Mapping) ต้องระวังให้มาก ๆ เพราะว่า ถ้าใช้ไม่ดี มักจะสร้าง query ที่แย่ ๆ ออกมา</li>\n\n\n\n<li>มีการทำ caching ด้วย <a href=\"https://redis.io/\" target=\"_blank\">Redis</a> แต่ก็มีปัญหาตามมาเมื่อไม่เจอข้อมูลใน cache ก็จะวิ่งไป database แต่ถ้า query นาน ๆ จนเกิน timeout ก็จะ retry อีก !!! นี่มันปัญหาที่น่ากลัวมาก ๆ (เพื่อนล้มแล้สเราต้องกระทืบซ้ำ !!)</li>\n</ul>\n\n\n\n<p>และแน่นอนว่ายังคงปรับปรุงระบบงาน<br />เพื่อรองรับจำนวนข้อมูลและผู้ใช้งานที่สูงขึ้นอย่างต่อเนื่อง</p>\n\n\n\n<p><br /></p>\n","author":"somkiat","siteTitle":"cc :: somkiat","siteHash":"3a23a5a4389e1e40c6fbb16520a8cc20df5b3591c25145ce72aaa18b19e48201","entryHash":"c673dee3036ebda9390a608f3aa565b8956ebd6398fd7d32681112f1d8ad408b","category":"Thai"}