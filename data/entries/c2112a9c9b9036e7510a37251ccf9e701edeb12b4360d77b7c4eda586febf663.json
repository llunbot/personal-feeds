{"title":"Googleâ€™s Bard AI can now write and execute code to answer a question","link":"https://arstechnica.com/?p=1946727","date":1686334059000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2017/05/google-800x523.jpg\" alt=\"A large Google logo is displayed amidst foliage.\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2017/05/google.jpg\">Enlarge</a> (credit: <a href=\"https://www.gettyimages.com/search/photographer?family=editorial&amp;photographer=Sean+Gallup\">Sean Gallup | Getty Images</a>)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>Large language models (LLMs) like ChatGPT and Google Bard can provide <em>some</em> decent answers to certain types of questions, but these computers are ironically pretty bad at computing stuff. Google has a new solution to try to get language models to do simple tasks, like math, correctly: have the AI <a href=\"https://blog.google/technology/ai/bard-improved-reasoning-google-sheets-export/\">write a program</a>. Google says that now when you ask Bard a \"computational\" task like math or string manipulation, instead of showing the output of the language model, that language model will instead write a program, execute that program, and then show the output of that program to the user as an answer.</p>\n<p>Google's blog post provides the example input of \"Reverse the word 'Lollipop' for me.\" ChatGPT flubs this question and provides the incorrect answer \"pillopoL,\" because language models see the world in chunks of words, or \"tokens,\" and they just aren't good at this. Here is Bard's example output:</p>\n<div><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2023/06/4-1.jpg\"><img src=\"https://cdn.arstechnica.net/wp-content/uploads/2023/06/4-1-980x789.jpg\" /></a><p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2023/06/4-1.jpg\"></a> (credit: Google)</p></div>\n<p>It gets the output correct as \"popilloL,\" but more interesting is that it also<em> includes the python code</em> it wrote to answer the question. That's neat for programming-minded people to see under the hood, but wow, is that probably the scariest output ever for regular people. It's also not particularly relevant. Imagine if Gmail showed you a block of code when you just asked it to fetch email. It's weird. Just do the job you were asked to do, Bard.</p></div><p><a href=\"https://arstechnica.com/?p=1946727#p3\">Read 3 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=1946727&amp;comments=1\">Comments</a></p>","author":"Ron Amadeo","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"c2112a9c9b9036e7510a37251ccf9e701edeb12b4360d77b7c4eda586febf663","category":"Tech"}