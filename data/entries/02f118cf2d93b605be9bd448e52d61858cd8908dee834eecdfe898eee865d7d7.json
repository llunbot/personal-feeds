{"title":"สิ่งที่น่าสนใจใน Technology Radar 2025 Volume 32","link":"https://www.somkiat.cc/technology-radar-2025-volume-32/","date":1743912970000,"content":"<p><img width=\"150\" height=\"150\" src=\"https://www.somkiat.cc/wp-content/uploads/2025/04/technology-radar-2025-150x150.jpg\" alt=\"\" loading=\"lazy\" srcset=\"https://www.somkiat.cc/wp-content/uploads/2025/04/technology-radar-2025-150x150.jpg 150w, https://www.somkiat.cc/wp-content/uploads/2025/04/technology-radar-2025-75x75.jpg 75w\" /></p>\n<figure><a href=\"https://www.somkiat.cc/wp-content/uploads/2025/04/technology-radar-2025.jpg\"><img src=\"https://www.somkiat.cc/wp-content/uploads/2025/04/technology-radar-2025-1024x566.jpg\" alt=\"\" width=\"637\" height=\"352\" /></a></figure>\n\n\n\n<p>เห็นทาง <a href=\"https://www.thoughtworks.com/radar\" target=\"_blank\">Thoughtworks ปล่อย Technology Radar 2025 Volume 32</a> ออกมา<br />เลยมาดูกันหน่อยว่ามีอะไรที่น่าสนใจบ้าง<br />จากที่อ่านคร่าว ๆ จะเป็นเรื่องของ Generative AI เยอะมาก ๆ เช่น</p>\n\n\n\n<span></span>\n\n\n\n<ul>\n<li>Supervisor Agent ในการเป็นตัวช่วยการเขียน code (Coding assistant) ซึ่ง integrate เข้ามาใน IDE ให้เลย แต่ก็ยังต้องปรับปรุง user interface ให้เป็นมิตร หรือ ใช้งานได้ง่ายยิ่งขึ้น เช่น Cline, Cursor, Aider และ Claude Code เป็นต้น</li>\n\n\n\n<li>เรื่องของ observability ที่ opentelemetry เข้ามาเป็นมาตรฐานหลัก ทั้งยังนำ LLM มาใช้ร่วมด้วย (AI-assisted observability) หรือพวก LLMOps ก็เข้ามาแล้วเช่นกัน</li>\n\n\n\n<li>การปรับปรุงการทำงานของ Retrieval-Augmented Generation (RAG) เพื่อให้ได้ผลที่ดีและถูกต้องมากยิ่งขึ้น เช่น corrective RAG, Fusion RAG, Graph RAG และ self-RAG</li>\n\n\n\n<li>พวก  AI library และ framework ที่แนะนำเช่น langchain/graph และ Llamaindex เป็นต้น</li>\n\n\n\n<li>เรื่องของ Data Product thinking โดยสามารถนำเอา AI เข้ามาช่วยทั้งการทำงานและ วิเคราะห์เรื่องต่าง ๆ</li>\n\n\n\n<li>การใช้งาน SLM (Small Language Model) เช่น DeepSeek R1 ช่วยให้ model มีขนาดที่เล็กลง ใช้งาน resource ที่น้อยลง แต่ยังคุณเรื่องของคุณภาพที่สูงไว้ เป็นอีกแนวคิดที่สำคัญมาก ๆ</li>\n\n\n\n<li>ในฝั่งของ UI testing ก็มีการนำ AI เข้ามาช่วย ทั้งการทดสอบให้เองแบบอัตโนมัติ ตาม prompt ที่สั่ง จากนั้น AI จะจัดการให้เอง ไม่ว่าจะทำการ snapshot หน้าจอ หรือ ทำการอ่าน DOM มาให้เอง เช่น <a href=\"https://github.com/browser-use/browser-use\" target=\"_blank\">Browser Use</a> เป็นต้น</li>\n</ul>\n\n\n\n<p>แต่ก็มีหลาย ๆ อย่างให้ Hold ไว้ เช่น</p>\n\n\n\n<ul>\n<li>Replacing pair programming with AI ซึ่งเริ่มต้นอาจจะดูดี แต่ผลที่ตามมาคือ มันไม่ใช้เป้าหมายของการ pair-programming เพราะว่ามันคือเรื่องของการทำงานเป็นทีม ไม่ใช่ใครคนใดคนหนึ่ง เป็น share ความรู้ของคนในทีม เข้าใจซึ่งกันและกัน รวมทั้งการเรียนรู็สิ่งใหม่ ๆ แต่เมื่อใช้ AI มาช่วยแล้วเรื่องเหล่านี้หายไปหมดเลย นั่นคือผลเสียที่ตามมา</li>\n\n\n\n<li>Local coding assistants เป็นการใช้งาน Local LLM นั่นเอง เป้าหมายเพื่อเรื่องของ privacy และ security ของ code ที่เขียนว่าจะออกไปข้างนอก แต่จากการใช้งานพบว่ model ก็ไม่ค่อย update และยังใช้งาน resource ที่เยอะ เรื่องของคนใช้งานต้องมี spec ที่สูง อีกทั้ง prompt ที่ซับซ้อน ได้ผลที่ไม่ค่อยดี หรือบาง model ก็ไม่สนับสนุน function call อีก ดังนั้นก็ต้องพิจารณาให้ดี</li>\n</ul>\n\n\n\n<p>อีก  2 เรื่องที่น่าสนใจ และไม่เกี่ยวกับ AI คือ</p>\n\n\n\n<ul>\n<li>API request collection as API product artifact</li>\n\n\n\n<li><a href=\"https://martinfowler.com/articles/scaling-architecture-conversationally.html\" target=\"_blank\">Architecture advice process</a> แทนที่จะทำงานแบบ centralize ให้เปลี่ยนมาทำงานแบบ decentralize สำหรับการตัดสินใจต่าง ๆ แต่ก็ยังมีการ review จากคนในส่วนต่าง ๆ  ได้เช่นกัน เนื่องจากการทำงานแบบ centralize ส่วนใหญ่พบว่าเป็นการทำงานเชิงรับมากกว่า และส่งผลให้ productivity แย่ลง หรือหนักกว่านั้นจะไม่มีใครกล้าทำในสิ่งที่แตกต่าง เพราะว่า กลัวกับการ review และปัญหาต่าง ๆ  นั่นเอง</li>\n</ul>\n\n\n\n<p>ลองอ่านเพิ่มเติมกันดูครับ</p>\n","author":"somkiat","siteTitle":"cc :: somkiat","siteHash":"3a23a5a4389e1e40c6fbb16520a8cc20df5b3591c25145ce72aaa18b19e48201","entryHash":"02f118cf2d93b605be9bd448e52d61858cd8908dee834eecdfe898eee865d7d7","category":"Thai"}