{"title":"บันทึกการ pre-processing ข้อมูลก่อนจัดเก็บใน Elasticsearch","link":"https://www.somkiat.cc/pre-processing-data-with-elasticsearch/","date":1689308265000,"content":"<p><img width=\"150\" height=\"150\" src=\"https://www.somkiat.cc/wp-content/uploads/2023/07/prune-tree-2-150x150.gif\" alt loading=\"lazy\" srcset=\"https://www.somkiat.cc/wp-content/uploads/2023/07/prune-tree-2-150x150.gif 150w, https://www.somkiat.cc/wp-content/uploads/2023/07/prune-tree-2-75x75.gif 75w\" /></p>\n<figure><a href=\"https://www.somkiat.cc/wp-content/uploads/2023/07/prune-tree-2.gif\"><img src=\"https://www.somkiat.cc/wp-content/uploads/2023/07/prune-tree-2-1024x535.gif\" alt width=\"660\" height=\"344\" /></a></figure>\n\n\n\n<p>จากบทความของ Elastic เรื่อง <a href=\"https://www.elastic.co/blog/pruning-incoming-log-volumes-with-elastic\" target=\"_blank\">Pruning incoming log volumes with Elastic</a><br />อธิบายถึงการเก็บข้อมูลใน Elastic stack ว่า<br />ข้อมูลที่จัดเก็บนั้นมีจำนวนที่เยอะ รูปแบบที่หลากหลาย<br />ส่งผลให้ระบบมีปัญหาในการจัดเก็บ การประมวลผล หรือ ใช้งาน<br />ดังนั้น สิ่งหนึ่งที่เราควรทำก่อนคือ<br />รู้ว่าข้อมูลอะไรบ้างที่ใช้ และ ไม่ใช้งานบ้าง<br />เพื่อที่จะเก็บเท่าที่ใช้งานเท่านั้น มิใช่เก็บไปเสียทุกอย่าง</p>\n\n\n\n<span></span>\n\n\n\n<p>ดังนั้นมาดูกับว่าในบทความข้างต้นแนะนำวิธีการอย่างไรบ้าง ?</p>\n\n\n\n<ul>\n<li>Beats</li>\n\n\n\n<li>Logstash</li>\n\n\n\n<li>Elastic Agent</li>\n\n\n\n<li>Ingest pipeline</li>\n\n\n\n<li>OpenTelemetry collector</li>\n</ul>\n\n\n\n<p><strong>ตัวอย่างที่ 1 Beats</strong></p>\n\n\n\n<p>ในส่วนของ processor สามารถทำการ drop หรือลบพวก event และ field/property ต่าง ๆ ได้<br />เช่น</p>\n\n\n\n[gist id=\"51071b528cb90d66595cd836aad13cba\" file=\"filebeat.yml\"]\n\n\n\n<p><strong>ตัวอย่างที่ 2 Logstash</strong></p>\n\n\n\n<p>ใน Logstash จะมีส่วนการทำงาน filter สำหรับกรองข้อมูลต่าง ๆ <br />ทั้งเพิ่ม เปลี่ยน และ ลบ รวมทั้งการ transform ข้อมูลไปยังรูปแบบต่าง ๆ ที่ต้องการ<br />หรือจำนวน % ข้อมูลที่จะจัดเก็บได้อีกด้วย<br />แต่ Logstash นั้นจะใช้ resource เช่น CPU และ Memory เยอะมาก ๆ ต้องใช้อย่างระมัดระวัง</p>\n\n\n\n[gist id=\"51071b528cb90d66595cd836aad13cba\" file=\"logstash.conf\"]\n\n\n\n<p><strong>ตัวอย่างที่ 3 Ingest Pipeline</strong></p>\n\n\n\n<p>เป็นอีก feature ของ Node ใน Elasticsearch<br />สามารถเขียน ingest pipeline ได้ หรือ เทียบง่าย ๆ คือ store procedure ใน database นั่นเอง<br />ซึ่งสามารถเขียนในส่วนของ processor โดยเขียนด้วย Painless script ดังนี้</p>\n\n\n\n[gist id=\"51071b528cb90d66595cd836aad13cba\" file=\"3.txt\"]\n\n\n\n<p>ดังนั้นแนะนำให้กลับมาดูข้อมูลว่าตอนนี้เป็นอย่างไร<br />ใช้อะไร ก็เก็บสิ่งนั้น<br />อะไรไม่ใช้งานก็ควรเอาออกไป<br />น่าจะเป็นอีกทางเลือกที่น่าสนใจ<br />เพื่อลดขนาดของข้อมูล<br />เพื่อลดการใช้ resource ต่าง ๆ ลงไป<br />ทำให้ดูแลและใช้งานดีขึ้นมาบ้าง</p>\n","author":"somkiat","siteTitle":"cc :: somkiat","siteHash":"3a23a5a4389e1e40c6fbb16520a8cc20df5b3591c25145ce72aaa18b19e48201","entryHash":"d7d7c79fa51803a6ebbcdabe6f4eba237729afb99cfe18e3c42381ce1642ed08","category":"Thai"}