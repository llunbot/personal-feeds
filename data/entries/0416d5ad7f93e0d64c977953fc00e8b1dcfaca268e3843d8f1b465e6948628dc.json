{"title":"Researchers claim breakthrough in fight against AI’s frustrating security hole","link":"https://arstechnica.com/information-technology/2025/04/researchers-claim-breakthrough-in-fight-against-ais-frustrating-security-hole/","date":1744802144000,"content":"<p>In the AI world, a vulnerability called \"prompt injection\" has haunted developers since chatbots went mainstream in 2022. Despite numerous attempts to solve this fundamental vulnerability—the digital equivalent of <a href=\"https://arstechnica.com/information-technology/2023/02/ai-powered-bing-chat-spills-its-secrets-via-prompt-injection-attack/\">whispering secret instructions</a> to override a system's intended behavior—no one has found a reliable solution. Until now, perhaps.</p>\n<p>Google DeepMind has <a href=\"https://arxiv.org/abs/2503.18813\">unveiled CaMeL</a> (CApabilities for MachinE Learning), a new approach to stopping prompt-injection attacks that abandons the failed strategy of having AI models police themselves. Instead, CaMeL treats language models as fundamentally untrusted components within a secure software framework, creating clear boundaries between user commands and potentially malicious content.</p>\n<p>Prompt injection has created a significant barrier to building trustworthy AI assistants, which may be why general-purpose big tech AI like Apple's Siri doesn't currently work like ChatGPT. As AI agents get integrated into email, calendar, banking, and document-editing processes, the consequences of prompt injection have shifted from hypothetical to existential. When agents can send emails, move money, or schedule appointments, a misinterpreted string isn't just an error—it's a dangerous exploit.</p><p><a href=\"https://arstechnica.com/information-technology/2025/04/researchers-claim-breakthrough-in-fight-against-ais-frustrating-security-hole/\">Read full article</a></p>\n<p><a href=\"https://arstechnica.com/information-technology/2025/04/researchers-claim-breakthrough-in-fight-against-ais-frustrating-security-hole/#comments\">Comments</a></p>","author":"Benj Edwards","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"0416d5ad7f93e0d64c977953fc00e8b1dcfaca268e3843d8f1b465e6948628dc","category":"Tech"}