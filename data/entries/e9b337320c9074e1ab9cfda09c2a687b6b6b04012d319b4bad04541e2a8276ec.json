{"title":"Google’s Careful AI","link":"https://markpeak.net/google-careful-ai/","date":1680421020000,"content":"<p>โลกช่วงปลายปี 2022 ต่อมาจนถึงต้นปี 2023 ถูกขับเคลื่อนโดยพลัง GPT ของ OpenAI บวกกับกระแส generative AI ด้านงานภาพ ซึ่งก่อตัวมาก่อนหน้านั้นสักระยะ (Dall-E, Stable Diffusion, Midjourney, etc.)</p>\n<p>บริษัทหนึ่งที่ดูเพลี่ยงพล้ำ เฉื่อยชา ตอบสนองต่อการเปลี่ยนแปลงอย่างช้ามากผิดสังเกตคือ Google</p>\n<p>Google เป็นบริษัทที่ทำเรื่อง AI มายาวนาน มีผลงาน AI จำนวนมากมาย ไล่ตั้งแต่ผู้ช่วยส่วนตัว Google Assistant, ระบบแยกแยะและจดจำภาพใน Google Photos/Google Lens, เป็นเจ้าของ DeepMind ทำศึก AlphaGo, รถไร้คนขับ Waymo ไปจนถึงตัวถอดเสียงเป็นข้อความใน YouTube</p>\n<p>แต่ทำไมพอถึงยุค Generative AI ที่เน้นการ “สร้าง” (generate/synthesis) มากกว่างานแยกแยะ (analysis) Google กลับสงวนท่าทีเป็นพิเศษ</p>\n<p>ทั้งที่จริงๆ แล้ว Google เองด้วยซ้ำที่<a href=\"https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html\">สร้างอัลกอริทึม Transformer เป็นคนแรกในปี 2017</a> แต่กลับกลายเป็น OpenAI ที่นำไปใช้ประโยชน์จนกลายเป็น GPT (Generative Pre-trained <strong>Transformer</strong>) ได้ก่อน</p>\n<p>และไม่ใช่ว่า Google ไม่ทำอะไรกับงานสาย Generative เลย ถ้าใครติดตามข่าวสาย AI จะทราบดีว่ามีโมเดลสารพัดออกใหม่ตลอดเวลา เช่น <a href=\"https://www.blognone.com/node/112753\">BERT</a> (2018), <a href=\"https://www.blognone.com/node/123498\">MUM</a> (2021), <a href=\"https://www.blognone.com/node/122737\">LaMDA</a> (2020-2021), <a href=\"https://www.blognone.com/node/127921\">PaLM</a> (2022) แต่แนวทางการใช้งานกลับยังสงวนไว้ในงานวิจัย หรือนำมาใช้รันงานอยู่เบื้องหลังโดยผู้ใช้ไม่ได้สัมผัสตรง</p>\n<p>ทำไมถึงเป็นเช่นนั้น?</p>\n<p>คนทั้งโลกก็สงสัยแบบนี้ และคงไม่มีใครตอบคำถามนี้ได้ดีกว่า Sundar Pichai ที่<a href=\"https://www.nytimes.com/2023/03/31/podcasts/hard-fork-sundar.html\">ล่าสุดไปออกรายการ podcast ของ The New York Times</a></p>\n<p></p>\n<p>คำตอบของ Pichai นั้นชัดเจนมากๆ ว่าต้องการ “ระมัดระวัง” (careful) ในการปล่อยผลิตภัณฑ์ด้าน AI chatbot ออกสู่สาธารณะ แผนการปล่อยฟีเจอร์ของ Bard นั้นถูกออกแบบอย่างตั้งใจ ให้ตอนแรกยังไม่เก่งนัก เพื่อทดสอบปฏิกิริยาของผู้ใช้งาน ก่อนที่จะ<a href=\"https://www.blognone.com/node/133261\">ค่อยๆ นำโมเดลใหม่ที่เก่งขึ้นมาใช้ทีละส่วน</a></p>\n<blockquote><p>We knew when we were putting Bard out <strong>we wanted to be careful.</strong> It’s the beginning of a journey for us. There are a few things you have to get right when you put these models out.</p>\n<p>We did say we are using <strong>a lightweight and efficient version of LaMDA.</strong> So in some ways, we put out one of our smaller models out there, what’s powering Bard. And <strong>we were careful.</strong></p>\n<p>And to me, it was important to not put a more capable model before we can fully <strong>make sure we can handle it well. </strong></p></blockquote>\n<p>Pichai ย้ำมากว่า ไม่สนใจที่จะเป็นคนแรก (แบบ OpenAI) แต่ขอทำให้ถูกต้องเหมาะสมเป็นสำคัญ</p>\n<blockquote><p>I don’t want it to be just <strong>who’s there first</strong>, but <strong>getting it right</strong> is very important to us.</p>\n<p>I do think sometimes I get concerned when people use the word, race, and <strong>being first</strong>, thought about AI for a long time, and we are definitely working with technology, which is going to be incredibly beneficial, but clearly has <strong>the potential to cause harm in a deep way.</strong> And so I think it’s very important that we are all responsible in how we approach it.</p></blockquote>\n<p>ประเด็นที่ Google สนใจมีทั้งเรื่องความปลอดภัย (safe/security) และความเป็นส่วนตัว (privacy) โดยยกประเด็นเรื่องการใช้งานในองค์กร (enterprise) ที่ระวังเรื่องข้อมูลขององค์กรรั่วไหล</p>\n<blockquote><p>We want to figure out in a<strong> safe, privacy-preserving</strong> way, to fine tune this on your data. The enterprise use case is obvious. You can fine tune it on an enterprise’s data so it makes it much more powerful, again with all the right <strong>privacy and security</strong> protections in place.</p></blockquote>\n<p>เขาตอบคำถามเรื่องจุดสมดุลระหว่างความเร็วกับความรอบคอบ (balancing that innovation and safety) ว่าในเคสนี้ ความปลอดภัยสำคัญกว่าชัดเจน</p>\n<p>หมายเหตุ: Google มีประกาศหลักการที่เรียกว่า <a href=\"https://ai.google/responsibilities/responsible-ai-practices/\">Responsible AI</a> มาได้นานพอสมควรแล้ว</p>\n<blockquote><p>But the work we do around <strong>privacy, safety, responsible AI,</strong> I think, if anything, <strong>is more important.</strong> And so our commitment there is going to be unwavering, to <strong>get all of this right.</strong></p></blockquote>\n<p>Pichai บอกว่ามีคนถามเยอะว่าทำไมไม่ทำงานเร็วๆ ปล่อยของโดยไม่ต้องแคร์ใคร (move fast and break things) คำตอบคือมันต้องมีจังหวะทั้งช้าและเร็วผสมกันไป ซึ่งเคสของ Bard คือตั้งใจช้า</p>\n<blockquote><p>Right it’s like asking, hey, <strong>why aren’t you moving fast and breaking things again?</strong></p>\n<p>So there will be <strong>times when we will hold back things.</strong> I think what we are doing in Bard, for us, is an example of it.</p></blockquote>\n<p>อีกคำที่ Pichai ย้ำหลายรอบมากคือคำว่า early บอกว่าพวกเรายังอยู่ในช่วงเริ่มต้นมากๆ ของเส้นทาง AI (ดังนั้นเป็นเหตุผลว่าทำไมต้องระวัง)</p>\n<blockquote><p>it’s such early stages of a new technology.</p></blockquote>\n<p>เหตุผลหนึ่งที่ Google ระวังมาก เป็นเพราะมีประสบการณ์กับ Google Assistant มาเยอะระดับหนึ่งแล้ว (น่าจะเห็นคำถามของผู้ใช้ว่ามีอะไรบ้าง) และตรงนี้ Pichai ก็ให้ข้อมูลว่า LaMDA ถูกสร้างขึ้นมาเพราะเอนจินเดิมของ Assistant ยังไม่ดีพอ</p>\n<blockquote><p>Because the reason we built LaMDA — to be a conversational dialogue thing — LaMDA was trained to be a conversational dialogue agent, right? So <strong>because we were working on Google Assistant, and we realized the limitations</strong> of, like, approaching the assistant with the underlying technology approach we had, so it wasn’t an accident that what we worked on LaMDA to be a conversational dialogue.</p>\n<p><strong>So we understood the power of — because people are talking to the Google Assistant back and forth.</strong></p></blockquote>\n<p>Pichai ยอมรับว่าปัญหาเรื่องความปลอดภัย AI เป็นเรื่องใหญ่ ที่ยังไม่มีใครรู้แน่ชัดว่าคำตอบที่ถูกต้องคืออะไร</p>\n<blockquote><p>This is going to need a lot of debate. No one knows all the answers. No one company can get it right.</p></blockquote>\n<p>เขายังพูดเรื่องการกำกับดูแล AI ว่า มันอยู่ตรงกลางระหว่างไม่กำกับดูแลใดๆ กับการกำกับดูแล (แต่ไม่ดี) ซึ่งเขาเทียบกรณีกับกระแสเทคโนโลยีด้าน genetic ในยุค 70 ที่ก่อให้เกิดการถกเถียงแบบเดียวกัน</p>\n<blockquote><p><strong>AI is too important an area not to regulate. It’s also too important an area not to regulate well.</strong> So I’m glad these conversations are underway. If you look at an area like genetics in the ‘70s, when the power of DNA and recombinant DNA came into being, there were things like the Asilomar Conference.</p></blockquote>\n<p>เขายังบอกว่า AI เป็นเทคโนโลยีที่เขาเห็นดีเบทมากที่สุด (ทั้งในแง่บวกและลบ) ในช่วงเริ่มต้นของเทคโนโลยี มากกว่าเทคโนโลยีตัวอื่นๆ ที่เคยเห็นมา</p>\n<blockquote><p>The thing that gives me <strong>hope</strong> is I’ve never seen a technology in its <strong>earliest days</strong> with as much <strong>concern</strong> as AI.</p></blockquote>\n<p><img loading=\"lazy\" src=\"https://markpeak.net/wp-content/uploads/2023/04/google-ai.jpg\" alt width=\"900\" height=\"507\" srcset=\"https://markpeak.net/wp-content/uploads/2023/04/google-ai.jpg 900w, https://markpeak.net/wp-content/uploads/2023/04/google-ai-300x169.jpg 300w, https://markpeak.net/wp-content/uploads/2023/04/google-ai-768x433.jpg 768w, https://markpeak.net/wp-content/uploads/2023/04/google-ai-700x394.jpg 700w\" /></p>\n<p>Pichai พูดถึง OpenAI ว่าไม่ได้ “เซอร์ไพร์ส” มากนัก เพราะทีมงานหลายคนเคยทำงานกับกูเกิลมาก่อน แต่ก็ยกย่อง OpenAI ที่สามารถหา product market fit เจอ และช่วยบุกเบิกวงการผู้ใช้งานให้กูเกิลด้วย</p>\n<blockquote><p>And so we knew the caliber of the team. So I think OpenAI’s progress and surprises — I think ChatGPT — you know, credit to them for<strong> finding something with a product market fit.</strong> The reception from users, I think, was a pleasant surprise for — maybe even for them, and for a lot of us.</p></blockquote>\n<p>แต่เขาเทียบสถานะของ Google กับ OpenAI ว่าต้องระมัดระวังแตกต่างกัน บริษัทใหญ่แบบ Google ต้องมองให้รอบด้านมากๆ ซึ่งเขาค่อนข้างเซอร์ไพร์สที่ปฏิกิริยาเชิงบวกจากผู้ใช้ GPT ออกมาดีกว่าที่คาด (แสดงว่า Google ต้องคาดการณ์ในแง่ลบไว้เยอะอยู่)</p>\n<blockquote><p>maybe <strong>from a Google vantage standpoint, we looked at in all the areas where it goes wrong</strong>, maybe, a bit more. But users are kind of seeing <strong>the potential</strong> in these models a lot as well. So I would say that part — maybe <strong>more of a surprise. </strong></p></blockquote>\n<p>เขายังแยกแยะความแตกต่างระหว่าง search และ chat โดยบอกว่า search คือคนต้องการตามหาข้อมูลที่ “จริง” ในขณะที่ chat AI เหมาะกับงานที่สร้าง “แรงบันดาลใจ” มากกว่า</p>\n<blockquote><p>search is where people come because they trust it to <strong>get information right.</strong></p>\n<p>I think there are two categories where [LaMDA] works well, where it’s <strong>fun, creative, imaginative.</strong> You’re just kind of looking to spark some stuff. Hey, what movies can I watch on a Friday night?</p></blockquote>\n<p>บล็อกอื่นๆ ในซีรีส์ นักคิดเรื่อง AI</p>\n<ul>\n<li><a href=\"https://markpeak.net/yuval-harari-on-ai/\">Yuval Harari on AI</a></li>\n<li><a href=\"https://markpeak.net/yann-lecun-and-the-ai-gold-rush/\">Yann LeCun and the AI Gold Rush</a></li>\n</ul>The post <a href=\"https://markpeak.net/google-careful-ai/\">Google’s Careful AI</a> first appeared on <a href=\"https://markpeak.net\">markpeak.net</a>.","author":"Isriya Paireepairit","siteTitle":"markpeak.net","siteHash":"174209a41ef21fd794de2993285c799df6ec31048fd82206fb5c8fe38898acfe","entryHash":"e9b337320c9074e1ab9cfda09c2a687b6b6b04012d319b4bad04541e2a8276ec","category":"Thai"}