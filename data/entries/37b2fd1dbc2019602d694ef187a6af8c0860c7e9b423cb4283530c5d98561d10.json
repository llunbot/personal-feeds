{"title":"AWS ชี้แจงปัญหาคลาวด์ล่มสัปดาห์ที่แล้ว เตรียมยกเครื่องซัพพอร์ตและแดชบอร์ดใหม่ให้ลูกค้าตรวจสอบปัญหาได้ง่ายขึ้น","link":"https://www.blognone.com/node/126272","date":1639301257000,"content":"<div><div><div><p>เมื่อสัปดาห์ที่ผ่านมา <a href=\"https://www.blognone.com/node/126199\">AWS มีปัญหา</a>โดยเริ่มต้นจากโซน Northern Virginia หรือ US-EAST-1 ในวันที่ 7 ธันวาคม (เป็นช่วงรอยต่อระหว่างคืนวันที่ 7-8 ธันวาคมตามเวลาประเทศไทย) และวันนี้ Amazon ก็ได้ออกแถลงการณ์อย่างละเอียดเกี่ยวกับเรื่องนี้แล้ว</p>\n<p>AWS เล่าแบคกราวน์ว่า เซอร์วิสส่วนใหญ่ของ AWS และเวิร์คโหลดของลูกค้าทั้งหมดจะรันบนเครือข่ายหลักของ AWS (main AWS network) แต่ก็ยังมีบางส่วนที่ AWS ใช้เครือข่ายภายใน (internal network) เช่น ระบบ DNS ภายใน, ระบบมอนิเตอร์, ระบบควบคุมสิทธิ์ และ control plane บางส่วนของ EC2 ซึ่ง AWS ก็มีการสเกลเครือข่ายเหล่านี้ไปทั่วโลกเพื่อทำให้เซอร์วิสเหล่านี้มี HA มากพอ</p>\n<p>ปัญหาเริ่มเกิดเมื่อเวลา 7:30 นาฬิกาตามเวลาแปซิฟิก ระบบสเกลอัตโนมัติของเซอร์วิสที่โฮสต์อยู่ภายใต้เครือข่ายหลักเกิดพฤติกรรมที่ไม่คาดคิด (unexpected behaviour) เนื่องจากมีไคลเอนท์จำนวนมากในเครือข่าย ทำให้การเชื่อมต่อเพิ่มขึ้นมหาศาล เกิดความแออัดบนเครือข่ายมากเกินกว่าอุปกรณ์เครือข่ายระหว่างเครือข่ายภายในและเครือข่ายหลักของ AWS จะรับไหว จึงทำให้เกิดดีเลย์ในการสื่อสารระหว่างสองเครือข่ายนี้ ส่งผลให้ระบบช้าและเกิดข้อผิดพลาดขึ้นจำนวนมาก</p>\n<p>นอกจากลูกค้าจะได้รับผลกระทบแล้ว ปัญหานี้ยังกระทบไปถึงทีมงานภายใน AWS ด้วย คือระบบมอนิเตอร์เรียลไทม์สำหรับทีมโอเปอเรชั่นภายในก็ใช้ไม่ได้ ทำให้ AWS ต้องใช้เวลานานในการหาสาเหตุด้วยการตรวจสอบ log และพบว่าเป็นปัญหาจากระบบ DNS ภายใน จึงย้าย DNS ออกไปจากจุดที่เครือข่ายหนาแน่นก่อน ในเวลา 9:28 นาฬิกาตามเวลาแปซิฟิก AWS ย้ายระบบ DNS ภายในเสร็จสิ้น DNS จึงเริ่มกลับสู่สภาพปกติ เครือข่ายเริ่มกลับมาบางส่วนแต่ยังไม่สามารถแก้ปัญหาทั้งหมดได้ และระบบมอนิเตอร์หลักก็ยังใช้ไม่ได้ จึงต้องแก้ปัญหาแบบมอนิเตอร์ไม่ได้ไปก่อน</p>\n<p>หลังจากนั้น AWS จึงตรวจสอบหาว่าทราฟฟิกจำนวนมากมาจากไหนและแยกอุปกรณ์เน็ตเวิร์คนั้นออกไปก่อน ปิดเซอร์วิสที่ใช้ทราฟฟิกจำนวนมากเพื่อให้เครือข่ายกลับมา กระบวนการนี้ใช้เวลาค่อนข้างนานกว่าจะเข้าใจปัญหาเนื่องจากไม่มีมอนิเตอร์ และใช้เวลาแก้ปัญหานานกว่าปกติเนื่องจากระบบดีพลอยในเครือข่ายภายในก็มีปัญหาตามไปด้วย แต่ในช่วงนี้เซอร์วิสเกือบทั้งหมดบนเครือข่ายหลักของ AWS กลับมาปกติแล้ว และแอปของลูกค้าก็รันได้ AWS จึงต้องแก้ปัญหาด้วยความระมัดระวังไม่ให้ลูกค้าได้รับผลกระทบ สุดท้ายระบบจึงกลับมาทำงานได้เต็มรูปแบบตอนเวลา 14:22 นาฬิกาตามเวลาแปซิฟิก</p>\n<p>เพื่อป้องกันปัญหาในอนาคต AWS จึงสั่งปิดระบบสเกลที่สร้างอีเว้นท์นี้ขึ้นมาและจะยังไม่เปิดใช้งานจนกว่าจะดีพลอยเพื่อซ่อมปัญหาทั้งหมดก่อน ซึ่งปัจจุบันระบบ AWS ขนาดใหญ่พอแล้วจึงยังไม่จำเป็นต้องสเกลอีกในระยะเวลาอันใกล้ โดย AWS ระบุว่าไคลเอนท์ที่เชื่อมต่อกับเครือข่ายได้ทดสอบเพื่อกู้คืนตัวเองได้ในกรณีที่มีทราฟฟิกหนาแน่นในเครือข่ายอยู่แล้ว แต่ปัญหาบางอย่างทำให้ไคลเอนท์ไม่สามารถกู้คืนตัวเองได้ในอีเวนท์ครั้งนี้ ตัวโค้ดนี้อยู่ในโปรดักชั่นมาหลายปีแล้ว แต่ระบบสเกลอัตโนมัติสร้างพฤติกรรมที่ไม่ได้สังเกตมาก่อน ดังนั้น AWS จึงจะแก้ปัญหานี้และดีพลอยภายใน 2 สัปดาห์ข้างหน้า นอกจากนี้ AWS ได้ดีพลอยคอนฟิกเครือข่ายเพิ่มเติมเข้าไปเพื่อป้องกันอุปกรณ์เครือข่ายเกิดปัญหาหากพบเหตุการณ์ทราฟฟิกหนาแน่นอีก </p>\n<p>AWS ระบุว่าทางบริษัทเข้าใจดีว่าการเกิดเหตุการณ์แบบนี้ส่งผลกระทบต่อลูกค้าอย่างไรโดยเฉพาะตอนที่ไม่รู้ว่าเกิดอะไรขึ้น โดย AWS ยอมรับว่าเนื่องจากระบบมอนิเตอร์มีปัญหาจึงทำให้ AWS ไม่เข้าใจเหตุการณ์ได้ทันที และปัญหาเครือข่ายก็ทำให้ Service Health Dashboard ไม่สามารถ fail over ไปยัง standby ได้ ส่วน Support Contact Center ของ AWS ก็อยู่ที่เครือข่ายภายใน ทำให้ช่วงที่เกิดปัญหาก็ไม่สามารถเปิดเคสหาซัพพอร์ตได้เช่นกัน</p>\n<p>ดังนั้น ในอนาคต เพื่อแก้ไขปัญหาเหล่านี้ AWS ระบุว่า Service Health Dashboard จะเปิดเวอร์ชันใหม่ให้ใช้ภายในปีหน้า ซึ่งจะทำให้ผู้ใช้เข้าใจมากขึ้นว่าเซอร์วิสไหนจะได้รับผลกระทบบ้าง ส่วนระบบซัพพอร์ต ทาง AWS ก็จะปรับโครงสร้างใหม่ให้รันหลาย AWS regions เพื่อให้ลูกค้าสามารถติดต่อซัพพอร์ตได้ในช่วงที่มีปัญหา และขออภัยต่อเหตุการณ์ที่เกิดขึ้น ซึ่ง AWS จะนำเหตุการณ์นี้มาเรียนรู้และปรับปรุงทุกอย่างเท่าที่จะทำได้เพื่อเพิ่มประสิทธิภาพของระบบคลาวด์ต่อไปในอนาคต</p>\n<p>ที่มา - <a href=\"https://aws.amazon.com/message/12721/\">AWS</a>, <a href=\"https://www.engadget.com/amazon-aws-outage-explanation-214151710.html\">Engadget</a>, <a href=\"https://www.cnbc.com/2021/12/10/aws-explains-outage-and-will-make-it-easier-to-track-future-ones.html\">CNBC</a></p>\n<p><img src=\"https://www.blognone.com/sites/default/files/externals/a0016a234898cae09ab30eee099c3d75.png\" /></p>\n</div></div></div><div><div>Topics: </div><div><div><a href=\"/topics/aws\">AWS</a></div><div><a href=\"/topics/amazon\">Amazon</a></div><div><a href=\"/topics/cloud\">Cloud</a></div></div></div>","author":"nutmos","siteTitle":"Blognone","siteHash":"ededadcf18490b3937e7dd89ebe8c00dc129addbdf1ebe4aff1f458146693da0","entryHash":"37b2fd1dbc2019602d694ef187a6af8c0860c7e9b423cb4283530c5d98561d10","category":"Thai"}