{"title":"Speed of AI development is outpacing risk assessment","link":"https://arstechnica.com/?p=2016058","date":1712758224000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2024/04/ai-logos-800x450.jpg\" alt=\"Logo montage\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2024/04/ai-logos.jpg\">Enlarge</a> <span>/</span> Google, Anthropic, Cohere and Mistral have each released AI models over the past two months as they seek to unseat OpenAI from the top of public rankings. (credit: FT)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>The increasing power of the latest artificial intelligence systems is stretching traditional evaluation methods to breaking point, posing a challenge to businesses and public bodies over how best to work with the fast-evolving technology.</p>\n<p>Flaws in the evaluation criteria commonly used to gauge performance, accuracy and safety are being exposed as more models come to market, according to people who build, test and invest in AI tools. The traditional tools are easy to manipulate and too narrow for the complexity of the latest models, they said.</p>\n<p>The accelerating technology race sparked by the 2022 release of OpenAI’s chatbot ChatGPT and fed by tens of billions of dollars from venture capitalists and big tech companies, such as Microsoft, Google and Amazon, has obliterated many older yardsticks for assessing AI’s progress.</p></div><p><a href=\"https://arstechnica.com/?p=2016058#p3\">Read 23 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=2016058&amp;comments=1\">Comments</a></p>","author":"Financial Times","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"e56b24f6eb2efaf8a565e382d4018613fd176a55b55056db939b1d01c46fdb38","category":"Tech"}