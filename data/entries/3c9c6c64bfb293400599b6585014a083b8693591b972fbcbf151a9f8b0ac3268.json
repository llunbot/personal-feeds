{"title":"ChatGPT goes temporarily “insane” with unexpected outputs, spooking users","link":"https://arstechnica.com/?p=2004783","date":1708534659000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2024/02/robot_haywire_hero_2-800x450.jpg\" alt=\"Illustration of a broken toy robot.\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2024/02/robot_haywire_hero_2.jpg\">Enlarge</a> (credit: <a href=\"https://www.gettyimages.com/detail/photo/broken-toy-robot-royalty-free-image/78396205\">Benj Edwards / Getty Images</a>)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>On Tuesday, <a href=\"https://arstechnica.com/information-technology/2023/11/chatgpt-was-the-spark-that-lit-the-fire-under-generative-ai-one-year-ago-today/\">ChatGPT</a> users began reporting unexpected outputs from OpenAI's AI assistant, flooding the r/ChatGPT Reddit sub with reports of the AI assistant \"<a href=\"https://www.reddit.com/r/ChatGPT/comments/1avw1sv/its_not_just_you_gpt_is_having_a_stroke/\">having a stroke</a>,\" \"<a href=\"https://www.reddit.com/r/ChatGPT/comments/1avumfh/has_chatgpt_gone_temporarily_insane/\">going insane</a>,\" \"<a href=\"https://www.reddit.com/r/ChatGPT/comments/1avwqzh/very_strange_rambling_responses/\">rambling</a>,\" and \"<a href=\"https://www.reddit.com/r/ChatGPT/comments/1avydjd/anyone_else_experiencing_chatgpt_losing_it/\">losing it</a>.\" OpenAI has <a href=\"https://status.openai.com/incidents/ssg8fh7sfyz3\">acknowledged the problem</a> and is working on a fix, but the experience serves as a high-profile example of how some people perceive malfunctioning <a href=\"https://arstechnica.com/science/2023/07/a-jargon-free-explanation-of-how-ai-large-language-models-work/\">large language models</a>, which are designed to mimic humanlike output.</p>\n\n<p>ChatGPT is not alive and does not have a mind to lose, but tugging on human metaphors (called \"anthropomorphization\") seems to be the easiest way for most people to describe the unexpected outputs they have been seeing from the AI model. They're forced to use those terms because OpenAI <a href=\"https://arstechnica.com/information-technology/2023/07/is-chatgpt-getting-worse-over-time-study-claims-yes-but-others-arent-sure/\">doesn't share</a> exactly how ChatGPT works under the hood; the underlying large language models function like a <a href=\"https://arstechnica.com/information-technology/2023/05/openai-peeks-into-the-black-box-of-neural-networks-with-new-research/\">black box</a>.</p>\n<p>\"It gave me the exact same feeling—like watching someone slowly lose their mind either from psychosis or dementia,\" <a href=\"https://www.reddit.com/r/ChatGPT/comments/1avyp21/comment/krf70j3/\">wrote</a> a Reddit user named z3ldafitzgerald in response to a post about ChatGPT bugging out. \"It’s the first time anything AI related sincerely gave me the creeps.\"</p></div><p><a href=\"https://arstechnica.com/?p=2004783#p3\">Read 7 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=2004783&amp;comments=1\">Comments</a></p>","author":"Benj Edwards","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"3c9c6c64bfb293400599b6585014a083b8693591b972fbcbf151a9f8b0ac3268","category":"Tech"}