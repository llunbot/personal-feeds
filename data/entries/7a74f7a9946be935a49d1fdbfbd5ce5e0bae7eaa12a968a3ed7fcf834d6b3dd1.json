{"title":"Richard Sutton – The Bitter Lesson","link":"https://markpeak.net/richard-sutton-the-bitter-lesson/","date":1765696594000,"content":"<p>มีโอกาสได้อ่านโพสต์ของ <a href=\"https://en.wikipedia.org/wiki/Richard_S._Sutton\">Richard Sutton</a> นักวิจัยด้าน AI ชื่อดังจากแคนาดา หนึ่งในผู้บุกเบิกเทคนิค reinforcement learning (RL) ยุคหลังๆ ซึ่งกลายมาเป็นแกนหลักสำคัญของ AI ที่แบบเรียนรู้ด้วยตัวเองยุคใหม่ๆ อย่าง AlphaGo และ AlphaZero ด้วย</p>\n<p>โพสต์ของ Sutton เขียนในปี 2019 ชื่อว่า “บทเรียนอันขมขื่น” (<a href=\"http://www.incompleteideas.net/IncIdeas/BitterLesson.html\">The Bitter Lesson</a>) ถือเป็น “ข้อสังเกต” (observation) ของเขาที่กลายมาเป็นหลักการสำคัญของวงการ AI อย่างน้อยก็ของกลุ่มคนที่เชื่อมั่นในแนวทาง RL ว่าคือเส้นทางที่มุ่งไปสู่ AGI ในอนาคต</p>\n<p>Sutton บอกว่าวงการ AI มีอายุประมาณ 70 ปี นับตั้งแต่ยุคเริ่มต้นมาจนถึงวันนี้ จะเห็นว่าแนวทางสร้าง AI แบบทั่วไป (general methods) จะสามารถเอาชนะวิธีการสร้างโมเดลเฉพาะทาง (special methods) ได้เสมอ</p>\n<p>การสร้าง AI ทำงานหัวข้อใดๆ เป็นเรื่องยาก วิธีการของนักวิจัยในแต่ละยุคจึงเป็นการนำความรู้ของมนุษย์ (human knowledge) มาจำลองไว้ใน AI ด้วยวิธีการต่างๆ ซึ่งมักได้ผลในช่วงแรกๆ แต่สุดท้ายแล้วจะแพ้วิธีการสร้าง AI ที่ทำงานได้ทั่วไป ที่เทรนขึ้นมาโดยอาศัยแค่พลังประมวลผลล้วนๆ ไม่ต้องมีกรรมวิธีพิเศษใดๆ มาแทรกแซง</p>\n<p>เหตุผลเป็นเพราะ AI แบบทั่วไปที่อาศัยวิธีการถึกๆ อย่าง search/learning algorithm ที่ดูธรรมดาทั่วไป มันจะเก่งขึ้นเรื่อยๆ ตามพลังประมวลผลที่เพิ่มขึ้นตามกาลเวลา (Sutton อ้างอิงจาก Moore’s law) ทำให้ท้ายที่สุดแล้ว โมเดลทั่วไปจะสามารถเอาชนะโมเดลเฉพาะกิจได้</p>\n<p>Sutton ยกตัวอย่างในอดีตหลายเคส</p>\n<ul>\n<li>หมากรุก: อัลกอริทึมที่เอาชนะ Gary Kasparov ได้ในปี 1997 อาศัยแค่ deep search โดยที่ตัวโมเดลไม่ต้องรู้จักกลไกของหมากรุกพิเศษ แต่ชนะได้เพราะคอมแรงมากพอ</li>\n<li>โกะ: แบบเดียวกับหมากรุกเลย แต่มาช้ากว่ากัน 20 ปี เพราะโกะซับซ้อนกว่า ต้องรอนานกว่าคอมพิวเตอร์มีพลังประมวลผลมากพอ</li>\n<li>Speech Recognition: โมเดลที่อิงจากสถิติคำล้วนๆ (ใช้พลังประมวลผลเยอะกว่า) เอาชนะโมเดลที่มีโครงสร้างภาษาแบบมนุษย์ได้</li>\n<li>Computer Vision: โมเดลยุคหลังใช้แค่ convolution network ล้วนๆ ก็เอาชนะโมเดลในอดีตได้</li>\n</ul>\n<p>[Sutton ไม่ได้เขียนถึงเพราะมันมาทีหลัง แต่กรณีของ LLM ที่เป็น transformer-based มีกลไก attention mechanism ที่เป็น generalization ใช้กับข้อมูลประเภทใดๆ ก็ได้ ก็เข้าข่าย The Bitter Lesson เหมือนกัน เทียบกับโมเดลภาษายุคก่อน]</p>\n<p>Sutton เรียกปรากฏการณ์นี้ว่าเป็น “บทเรียนอันขมขื่นของนักวิจัย” ว่าวิธีเฉพาะทางมันไม่เวิร์คในระยะยาว การฝังความรู้ของมนุษย์ลงไปในโมเดลเป็นการเฉพาะทำงานได้ดีแค่ในระยะสั้น แต่ผ่านไปสักพักมันจะติดเพดาน แล้วจะมีโมเดลที่ breakthrough จากแนวทางที่อิงพลัง <a href=\"https://markpeak.net/scaling-laws/\">scaling</a> ของการประมวลผลเกิดขึ้นมาเสมอ</p>\n<p>ในปี 2025 Sutton ไปออกรายการของ Dwarkesh Patel และพูดเรื่องนี้ โดยใช้กรอบเรื่อง The Bitter Lesson มาวิจารณ์โมเดล LLM ในปัจจุบัน (ซึ่งมีความเป็น RL ในระดับนึงแล้ว) ว่ามันยังไม่ RL มากพอ</p>\n<p></p>\n<p>และมี <a href=\"https://karpathy.bearblog.dev/animals-vs-ghosts/\">บล็อกของ Andrej Karpathy</a> ที่เขียนถกถึงเรื่องนี้ต่อ ซึ่งจะเขียนถึงในโอกาสถัดไป</p>The post <a href=\"https://markpeak.net/richard-sutton-the-bitter-lesson/\">Richard Sutton – The Bitter Lesson</a> first appeared on <a href=\"https://markpeak.net\">markpeak.net</a>.","author":"Isriya Paireepairit","siteTitle":"markpeak.net","siteHash":"174209a41ef21fd794de2993285c799df6ec31048fd82206fb5c8fe38898acfe","entryHash":"7a74f7a9946be935a49d1fdbfbd5ce5e0bae7eaa12a968a3ed7fcf834d6b3dd1","category":"Thai"}