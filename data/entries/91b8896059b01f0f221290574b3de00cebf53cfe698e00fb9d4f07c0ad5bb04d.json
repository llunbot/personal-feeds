{"title":"กูเกิลเปิดให้ใช้งาน Gemini 1.5 Pro ขนาดอินพุต 2 ล้านโทเคน, เพิ่ม Context Caching ช่วยลดราคาอินพุต","link":"https://www.blognone.com/node/140635","date":1719541516000,"content":"<div><div><div><p>กูเกิลเปิดให้นักพัฒนาทั่วไปใช้งานโมเดล Gemini 1.5 Pro ความยาวอินพุต 2 ล้านโทเคน <a href=\"https://www.blognone.com/node/139746\">ที่เปิดตัวในงาน Google I/O 2024 เมื่อเดือนพฤษภาคม</a></p>\n<p>การที่ความยาวอินพุต (context window) ใหญ่ขึ้นมาก ทำให้เราสามารถป้อนข้อมูลที่ซับซ้อน เช่น หนังสือทั้งเล่ม หรือไฟล์เอกสารจำนวนมากขององค์กร เข้าไปให้โมเดลช่วยประมวลผลได้เยอะขึ้น (ตัวอย่างการใช้งานคือการสร้างฐานความรู้ขององค์กร เพื่อให้พนักงานเข้ามาสอบถามจากบ็อทได้) อย่างไรก็ตาม สิ่งที่ต้องแลกมาคือค่าใช้จ่ายที่เพิ่มขึ้นจากอินพุตที่ยาวขึ้น ทำให้กูเกิลเพิ่มตัวช่วยคือ <a href=\"https://ai.google.dev/gemini-api/docs/caching?lang=python\">context caching</a> เข้ามาใน Gemini API (รองรับทั้ง Gemini 1.5 Pro และ 1.5 Flash) เพื่อลดจำนวนอินพุตที่ซ้ำซ้อนลง อินพุตที่ถูกแคชไว้แล้วจะตั้งราคาถูกกว่าอินพุตใหม่ โดยนักพัฒนาสามารถตั้งค่าจำนวนโทเคนที่ต้องการแคช และระยะเวลาที่ต้องการแคชได้เอง</p>\n<p>ตัวอย่างราคาบนหน้าเว็บ Gemini API</p>\n<ul>\n<li>อินพุตปกติ = 3.5 ดอลลาร์ต่อ 1 ล้านโทเคน (พรอมต์ยาวไม่เกิน 128K)</li>\n<li>อินพุตแคช = 0.875 ดอลลาร์ต่อ 1 ล้านโทเคน (พรอมต์ยาวไม่เกิน 128K)</li>\n</ul>\n<p>ที่มา - <a href=\"https://developers.googleblog.com/en/new-features-for-the-gemini-api-and-google-ai-studio/\">Google</a></p>\n<p><img alt=\"No Description\" src=\"https://www.blognone.com/sites/default/files/externals/73041d55505171b0bc2ba2ec11324c30.png\" /></p>\n</div></div></div><div><div>Topics: </div><div><div><a href=\"/topics/gemini\">Gemini</a></div><div><a href=\"/topics/google\">Google</a></div><div><a href=\"/topics/llm\">LLM</a></div></div></div>","author":"mk","siteTitle":"Blognone","siteHash":"ededadcf18490b3937e7dd89ebe8c00dc129addbdf1ebe4aff1f458146693da0","entryHash":"91b8896059b01f0f221290574b3de00cebf53cfe698e00fb9d4f07c0ad5bb04d","category":"Thai"}