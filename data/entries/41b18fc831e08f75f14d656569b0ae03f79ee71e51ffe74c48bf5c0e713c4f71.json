{"title":"Announcing Amazon EC2 G7e instances accelerated by NVIDIA RTX PRO 6000 Blackwell Server Edition GPUs","link":"https://aws.amazon.com/blogs/aws/announcing-amazon-ec2-g7e-instances-accelerated-by-nvidia-rtx-pro-6000-blackwell-server-edition-gpus/","date":1768944176000,"content":"<p>Today, we’re announcing the general availability of <a href=\"https://aws.amazon.com/ec2/?trk=d8ec3b19-0f37-4f8c-8c12-189f913e205c&amp;sc_channel=el\">Amazon Elastic Compute Cloud (Amazon EC2)</a> G7e instances that deliver cost-effective performance for generative AI inference workloads and the highest performance for graphics workloads.</p> \n<p>G7e instances are accelerated by the NVIDIA RTX PRO 6000 Blackwell Server Edition GPUs and are well suited for a broad range of GPU-enabled workloads including spatial computing and scientific computing workloads. G7e instances deliver up to 2.3 times inference performance compared to <a href=\"https://aws.amazon.com/ec2/instance-types/g6e/?trk=d8ec3b19-0f37-4f8c-8c12-189f913e205c&amp;sc_channel=el\">G6e instances</a>.</p> \n<p>Improvements made compared to predecessors:</p> \n<ul> \n <li><strong>NVIDIA RTX PRO 6000 Blackwell GPUs</strong> — NVIDIA RTX PRO 6000 Blackwell Server Edition GPUs offer two times the GPU memory and 1.85 times the GPU memory bandwidth compared to G6e instances. By using the higher GPU memory offered by G7e instances, you can run medium-sized models of up to 70B parameters with FP8 precision on a single GPU.</li> \n <li><strong>NVIDIA GPUDirect P2P</strong> — For models that are too large to fit into the memory of a single GPU, you can split the model or computations across multiple GPUs. G7e instances reduce the latency of your multi-GPU workloads with support for NVIDIA GPUDirect P2P, which enables direct communication between GPUs over PCIe interconnect. These instances offer the lowest peer to peer latency for GPUs on the same PCIe switch. Additionally, G7e instances offer up to four times the inter-GPU bandwidth compared to L40s GPUs featured in G6e instances, boosting the performance of multi-GPU workloads. These improvements mean you can run inference for larger models across multiple GPUs offering up to 768 GB of GPU memory in a single node.</li> \n <li><strong>Networking</strong> — G7e instances offer four times the networking bandwidth compared to G6e instances, which means you can use the instance for small-scale multi-node workloads. Additionally, multi-GPU G7e instances support NVIDIA GPUDirect Remote Direct Memory Access (RDMA) with <a href=\"https://aws.amazon.com/hpc/efa/?trk=d8ec3b19-0f37-4f8c-8c12-189f913e205c&amp;sc_channel=el\">Elastic Fabric Adapter (EFA)</a>, which reduces the latency of remote GPU-to-GPU communication for multi-node workloads. These instance sizes also support NVIDIA GPUDirectStorage with <a href=\"https://aws.amazon.com/fsx/lustre/?trk=d8ec3b19-0f37-4f8c-8c12-189f913e205c&amp;sc_channel=el\">Amazon FSx for Lustre</a>, which increases throughput by up to 1.2 Tbps to the instances compared to G6e instances, which means you can quickly load your models.</li> \n</ul> \n<p><strong><u>EC2 G7e specifications</u></strong><br /> G7e instances feature up to 8 NVIDIA RTX PRO 6000 Blackwell Server Edition GPUs with up to 768 GB of total GPU memory (96 GB of memory per GPU) and Intel Emerald Rapids processors. They also support up to 192 vCPUs, up to 1,600 Gbps of network bandwidth, up to 2,048 GiB of system memory, and up to 15.2 TB of local NVMe SSD storage.</p> \n<p>Here are the specs:</p> \n<table> \n <tbody> \n  <tr> \n   <td><strong>Instance name<br /> </strong></td> \n   <td><strong> GPUs</strong></td> \n   <td><strong>GPU memory (GB)</strong></td> \n   <td><strong>vCPUs</strong></td> \n   <td><strong>Memory (GiB)</strong></td> \n   <td><strong>Storage (TB)</strong></td> \n   <td><strong>EBS bandwidth (Gbps)</strong></td> \n   <td><strong>Network bandwidth (Gbps)</strong></td> \n  </tr> \n  <tr> \n   <td><strong>g7e.2xlarge</strong></td> \n   <td>1</td> \n   <td>96</td> \n   <td>8</td> \n   <td>64</td> \n   <td>1.9 x 1</td> \n   <td>Up to 5</td> \n   <td>50</td> \n  </tr> \n  <tr> \n   <td><strong>g7e.4xlarge</strong></td> \n   <td>1</td> \n   <td>96</td> \n   <td>16</td> \n   <td>128</td> \n   <td>1.9 x 1</td> \n   <td>8</td> \n   <td>50</td> \n  </tr> \n  <tr> \n   <td><strong>g7e.8xlarge</strong></td> \n   <td>1</td> \n   <td>96</td> \n   <td>32</td> \n   <td>256</td> \n   <td>1.9 x 1</td> \n   <td>16</td> \n   <td>100</td> \n  </tr> \n  <tr> \n   <td><strong>g7e.12xlarge</strong></td> \n   <td>2</td> \n   <td>192</td> \n   <td>48</td> \n   <td>512</td> \n   <td>3.8 x 1</td> \n   <td>25</td> \n   <td>400</td> \n  </tr> \n  <tr> \n   <td><strong>g7e.24xlarge</strong></td> \n   <td>4</td> \n   <td>384</td> \n   <td>96</td> \n   <td>1024</td> \n   <td>3.8 x 2</td> \n   <td>50</td> \n   <td>800</td> \n  </tr> \n  <tr> \n   <td><strong>g7e.48xlarge</strong></td> \n   <td>8</td> \n   <td>768</td> \n   <td>192</td> \n   <td>2048</td> \n   <td>3.8 x 4</td> \n   <td>100</td> \n   <td>1600</td> \n  </tr> \n </tbody> \n</table> \n<p>To get started with G7e instances, you can use the <a href=\"https://aws.amazon.com/ai/machine-learning/amis/?trk=d8ec3b19-0f37-4f8c-8c12-189f913e205c&amp;sc_channel=el\">AWS Deep Learning AMIs (DLAMI)</a> for your machine learning (ML) workloads. To run instances, you can use <a href=\"https://console.aws.amazon.com/ec2?trk=d8ec3b19-0f37-4f8c-8c12-189f913e205c&amp;sc_channel=el\">AWS Management Console</a>, <a href=\"https://aws.amazon.com/cli/?trk=d8ec3b19-0f37-4f8c-8c12-189f913e205c&amp;sc_channel=el\">AWS Command Line Interface (AWS CLI)</a> or <a href=\"http://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/EC2.html?trk=d8ec3b19-0f37-4f8c-8c12-189f913e205c&amp;sc_channel=el\">AWS SDKs</a>. For a managed experience, you can use G7e instances with <a href=\"https://aws.amazon.com/ecs/?trk=d8ec3b19-0f37-4f8c-8c12-189f913e205c&amp;sc_channel=el\">Amazon Elastic Container Service (Amazon ECS)</a>, <a href=\"https://aws.amazon.com/eks/?trk=d8ec3b19-0f37-4f8c-8c12-189f913e205c&amp;sc_channel=el\">Amazon Elastic Kubernetes Service (Amazon EKS)</a>, and <a href=\"https://aws.amazon.com/pcs/?trk=d8ec3b19-0f37-4f8c-8c12-189f913e205c&amp;sc_channel=el\">AWS Parallel Computing Service (AWS PCS)</a>. Support for <a href=\"https://aws.amazon.com/sagemaker-ai/?trk=d8ec3b19-0f37-4f8c-8c12-189f913e205c&amp;sc_channel=el\">Amazon SageMaker AI</a> is also coming soon.</p> \n<p><strong><u>Now available</u></strong><br /> Amazon EC2 G7e instances are available today in the US East (N. Virginia) and US East (Ohio) <a href=\"https://docs.aws.amazon.com/glossary/latest/reference/glos-chap.html#region?trk=d8ec3b19-0f37-4f8c-8c12-189f913e205c&amp;sc_channel=el\">AWS Regions</a>. For Regional availability and a future roadmap, search the instance type in the <strong>CloudFormation</strong> resources tab of <a href=\"https://builder.aws.com/build/capabilities/explore?tab=cfn-resources&amp;trk=d8ec3b19-0f37-4f8c-8c12-189f913e205c&amp;sc_channel=el\">AWS Capabilities by Region</a>.</p> \n<p>The instances can be purchased as <a href=\"https://aws.amazon.com/ec2/pricing/on-demand/?trk=d8ec3b19-0f37-4f8c-8c12-189f913e205c&amp;sc_channel=el\">On-Demand Instances</a>, <a href=\"https://aws.amazon.com/savingsplans/?trk=cc9e0036-98c5-4fa8-8df0-5281f75284ca&amp;sc_channel=el\">Savings Plan</a>, and <a href=\"https://aws.amazon.com/ec2/spot/pricing/?trk=d8ec3b19-0f37-4f8c-8c12-189f913e205c&amp;sc_channel=el\">Spot Instances</a>. G7e instances are also available in <a href=\"https://aws.amazon.com/ec2/pricing/dedicated-instances/?trk=d8ec3b19-0f37-4f8c-8c12-189f913e205c&amp;sc_channel=el\">Dedicated Instances</a> and <a href=\"https://aws.amazon.com/ec2/dedicated-hosts/pricing/?trk=d8ec3b19-0f37-4f8c-8c12-189f913e205c&amp;sc_channel=el\">Dedicated Hosts</a>. To learn more, visit the <a href=\"https://aws.amazon.com/ec2/pricing\">Amazon EC2 Pricing page</a>.</p> \n<p>Give G7e instances a try in the <a href=\"https://console.aws.amazon.com/ec2/?trk=d8ec3b19-0f37-4f8c-8c12-189f913e205c&amp;sc_channel=el\">Amazon EC2 console</a>. To learn more, visit the <a href=\"https://aws.amazon.com/ec2/instance-types/g7e/?trk=d8ec3b19-0f37-4f8c-8c12-189f913e205c&amp;sc_channel=el\">Amazon EC2 G7e instances page</a> and send feedback to <a href=\"https://repost.aws/tags/TAO-wqN9fYRoyrpdULLa5y7g/amazon-ec-2?trk=d8ec3b19-0f37-4f8c-8c12-189f913e205c&amp;sc_channel=el\">AWS re:Post for EC2</a> or through your usual AWS Support contacts.</p> \n<p>— <a href=\"https://linkedin.com/in/channy/\">Channy</a></p>","author":"Channy Yun (윤석찬)","siteTitle":"AWS News Blog","siteHash":"6093e072e4117ec22616e844cb857d03ca62c57a411a8affc77cb5e8b6b15bf6","entryHash":"41b18fc831e08f75f14d656569b0ae03f79ee71e51ffe74c48bf5c0e713c4f71","category":"Tech"}