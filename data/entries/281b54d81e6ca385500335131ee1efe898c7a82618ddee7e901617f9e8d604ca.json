{"title":"White House challenges hackers to break top AI models at DEF CON 31","link":"https://arstechnica.com/?p=1937397","date":1683564140000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2023/05/cyber_whitehouse_hero_2-800x450.jpg\" alt=\"An AI-generated image of the White House in front of a cybernetic background.\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2023/05/cyber_whitehouse_hero_2.jpg\">Enlarge</a> <span>/</span> An AI-generated image of the White House in front of a cybernetic background. (credit: Midjourney)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>On Thursday, the White House <a href=\"https://www.whitehouse.gov/briefing-room/statements-releases/2023/05/04/fact-sheet-biden-harris-administration-announces-new-actions-to-promote-responsible-ai-innovation-that-protects-americans-rights-and-safety/\">announced</a> a surprising collaboration between top AI developers, including OpenAI, Google, Antrhopic, Hugging Face, Microsoft, Nvidia, and Stability AI, to participate in a public evaluation of their generative AI systems at <a href=\"https://defcon.org/\">DEF CON 31</a>, a hacker convention taking place in Las Vegas in August. The event will be hosted by <a href=\"https://aivillage.org/\">AI Village</a>, a community of AI hackers.</p>\n<p>Since last year, large language models (LLMs) such as <a href=\"https://arstechnica.com/information-technology/2022/12/openai-invites-everyone-to-test-new-ai-powered-chatbot-with-amusing-results/\">ChatGPT</a> have become a popular way to accelerate writing and communications tasks, but officials recognize that they also come with inherent risks. Issues such as <a href=\"https://arstechnica.com/information-technology/2023/04/why-ai-chatbots-are-the-ultimate-bs-machines-and-how-people-hope-to-fix-them/\">confabulations</a>, jailbreaks, and biases pose challenges for security professionals and the public. That's why the <a href=\"https://www.whitehouse.gov/ostp/\">White House Office of Science, Technology, and Policy</a> endorses pushing these new generative AI models to their limits.</p>\n\n<p>\"This independent exercise will provide critical information to researchers and the public about the impacts of these models and will enable AI companies and developers to take steps to fix issues found in those models,\" <a href=\"https://www.whitehouse.gov/briefing-room/statements-releases/2023/05/04/fact-sheet-biden-harris-administration-announces-new-actions-to-promote-responsible-ai-innovation-that-protects-americans-rights-and-safety/\">says a statement</a> from the White House, which says the event aligns with the Biden administration's <a href=\"https://arstechnica.com/information-technology/2022/10/biden-proposes-new-bill-of-rights-to-protect-americans-from-ai-snooping/\">AI Bill of Rights</a> and the National Institute of Standards and Technology's <a href=\"https://www.nist.gov/itl/ai-risk-management-framework\">AI Risk Management Framework</a>.</p></div><p><a href=\"https://arstechnica.com/?p=1937397#p3\">Read 7 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=1937397&amp;comments=1\">Comments</a></p>","author":"Benj Edwards","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"281b54d81e6ca385500335131ee1efe898c7a82618ddee7e901617f9e8d604ca","category":"Tech"}