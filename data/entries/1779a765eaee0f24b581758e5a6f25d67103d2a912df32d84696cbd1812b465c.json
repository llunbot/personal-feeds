{"title":"As 2024 election looms, OpenAI says it is taking steps to prevent AI abuse","link":"https://arstechnica.com/?p=1996606","date":1705513479000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2024/01/pixelated_trump_2-800x450.jpg\" alt=\"A pixelated photo of Donald Trump.\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2024/01/pixelated_trump_2.jpg\">Enlarge</a> (credit: <a href=\"https://www.gettyimages.com/detail/news-photo/republican-presidential-candidate-former-u-s-president-news-photo/1938757552\">Getty Images | Benj Edwards</a>)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>On Monday, ChatGPT maker OpenAI <a href=\"https://openai.com/blog/how-openai-is-approaching-2024-worldwide-elections\">detailed its plans</a> to prevent the misuse of its AI technologies during the upcoming elections in 2024, promising transparency in AI-generated content and enhancing access to reliable voting information. The AI developer says it is working on an approach that involves policy enforcement, collaboration with partners, and the development of new tools aimed at classifying AI-generated media.</p>\n\n<p>\"As we prepare for elections in 2024 across the world’s largest democracies, our approach is to continue our platform safety work by elevating accurate voting information, enforcing measured policies, and improving transparency,\" writes OpenAI in its blog post. \"Protecting the integrity of elections requires collaboration from every corner of the democratic process, and we want to make sure our technology is not used in a way that could undermine this process.\"</p>\n<p>Initiatives proposed by OpenAI include preventing abuse by means such as <a href=\"https://arstechnica.com/information-technology/2022/12/thanks-to-ai-its-probably-time-to-take-your-photos-off-the-internet/\">deepfakes</a> or bots imitating candidates, refining usage policies, and launching a reporting system for the public to flag potential abuses. For example, OpenAI's image generation tool, <a href=\"https://arstechnica.com/information-technology/2023/09/openai-announces-dall-e-3-a-next-gen-ai-image-generator-based-on-chatgpt/\">DALL-E 3</a>, includes built-in filters that reject requests to create images of real people, including politicians. \"For years, we’ve been iterating on tools to improve factual accuracy, reduce bias, and decline certain requests,\" the company stated.</p></div><p><a href=\"https://arstechnica.com/?p=1996606#p3\">Read 5 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=1996606&amp;comments=1\">Comments</a></p>","author":"Benj Edwards","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"1779a765eaee0f24b581758e5a6f25d67103d2a912df32d84696cbd1812b465c","category":"Tech"}