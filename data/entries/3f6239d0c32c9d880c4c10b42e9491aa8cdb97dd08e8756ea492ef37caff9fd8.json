{"title":"แนวทางในการสร้าง Local LLMs server มีอะไรบ้าง ?","link":"https://www.somkiat.cc/qa-local-llms/","date":1739270119000,"content":"<p><img width=\"150\" height=\"150\" src=\"https://www.somkiat.cc/wp-content/uploads/2025/02/local-llm-150x150.jpg\" alt=\"\" loading=\"lazy\" srcset=\"https://www.somkiat.cc/wp-content/uploads/2025/02/local-llm-150x150.jpg 150w, https://www.somkiat.cc/wp-content/uploads/2025/02/local-llm-75x75.jpg 75w\" /></p>\n<figure><a href=\"https://www.somkiat.cc/wp-content/uploads/2025/02/local-llm.jpg\"><img src=\"https://www.somkiat.cc/wp-content/uploads/2025/02/local-llm.jpg\" alt=\"\" width=\"492\" height=\"303\" /></a></figure>\n\n\n\n<p>คำถามจากการแบ่งปันเรื่อง AI for software development นั้น<br />สอบถามเกี่ยวกับการสร้าง Local LLMs server เพื่อใช้งานในองค์กร<br />เพื่อจัดการในแง่ของ privacy และ การทดสอบ<br />ว่ามีแนวทางอย่างไรบ้าง ?</p>\n\n\n\n<span></span>\n\n\n\n<p><strong>โดยสิ่งที่แนะนำไปประกอบไปด้วย</strong></p>\n\n\n\n<ul>\n<li><a href=\"https://ollama.com/\" target=\"_blank\">Ollama</a></li>\n\n\n\n<li><a href=\"https://lmstudio.ai/\" target=\"_blank\">LMStudio</a></li>\n\n\n\n<li><a href=\"https://github.com/ggerganov/llama.cpp\" target=\"_blank\">LlamaCPP</a></li>\n\n\n\n<li><a href=\"https://github.com/vllm-project/vllm\" target=\"_blank\">vLLM</a></li>\n\n\n\n<li><a href=\"https://jan.ai/\" target=\"_blank\">Jan.AI</a></li>\n\n\n\n<li><a href=\"https://github.com/Mozilla-Ocho/llamafile\" target=\"_blank\">LLamaFile</a></li>\n</ul>\n\n\n\n<p>ลองใช้งานกันดูครับ</p>\n","author":"somkiat","siteTitle":"cc :: somkiat","siteHash":"3a23a5a4389e1e40c6fbb16520a8cc20df5b3591c25145ce72aaa18b19e48201","entryHash":"3f6239d0c32c9d880c4c10b42e9491aa8cdb97dd08e8756ea492ef37caff9fd8","category":"Thai"}