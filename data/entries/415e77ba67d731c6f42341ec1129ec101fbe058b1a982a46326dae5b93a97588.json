{"title":"Chrome will support the WebGPU API by default—here’s why that’s important","link":"https://arstechnica.com/?p=1929889","date":1680890216000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2023/04/chrome-gpu-800x533.jpeg\" alt=\"Chrome will support the WebGPU API by default—here’s why that’s important\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2023/04/chrome-gpu.jpeg\">Enlarge</a> (credit: Andrew Cunningham/Google)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>Google <a href=\"https://developer.chrome.com/blog/webgpu-release/\">announced today</a> that it would enable WebGPU support in its Chrome browser by default starting in version 113, currently in beta. In development since 2017, WebGPU is a next-generation graphics API that aims to bring the benefits of low-overhead APIs like Microsoft's Direct3D 12, Apple's Metal, and Vulkan to web browsers and other apps.</p>\n<p>WebGPU support has been available but off by default in Chrome for a while now, because the API wasn't finalized and things could break from update to update. Google says that Mozilla and Apple will eventually support WebGPU in Firefox and Safari, and browsers like Microsoft Edge and Opera that rely on the Chromium browser engine can presumably choose to switch it on just as Google has.</p>\n<p>Chrome 113 supports WebGPU on Windows, macOS, and ChromeOS to start, with \"support for other platforms\" like Linux and Android \"coming later this year.\" This browser version should roll out to all Chrome users sometime in May.</p></div><p><a href=\"https://arstechnica.com/?p=1929889#p3\">Read 8 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=1929889&amp;comments=1\">Comments</a></p>","author":"Andrew Cunningham","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"415e77ba67d731c6f42341ec1129ec101fbe058b1a982a46326dae5b93a97588","category":"Tech"}