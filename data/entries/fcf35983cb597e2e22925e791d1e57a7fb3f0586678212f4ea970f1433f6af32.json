{"title":"แอปเปิลชี้แจงระบบสแกนภาพ ต้องยืนยันว่าเป็นภาพโป๊เด็กจากหลายชาติ, ให้ผู้ตรวจยืนยันว่าไม่ตรวจข้อมูลอื่น","link":"https://www.blognone.com/node/124231","date":1628950177000,"content":"<div><div><div><p>แอปเปิลเพิ่มเอกสารชี้แจงจุดที่อาจจะถูกโจมตีได้ของระบบสแกนภาพอนาจารเด็กหรือ CSAM หลังจาก <a href=\"https://www.blognone.com/node/124220\">Craig Federighi เดินสายให้สัมภาษณ์</a>และยอมรับว่ามีกระแสตีกลับ โดยเอกสารระบุถึงเงื่อนไขการออกแบบของแอปเปิล</p>\n<p>เงื่อนไขที่แอปเปิลพูดถึงในเอกสารฉบับใหม่ ระบุว่าค่าแฮชที่แอปเปิลจะยอมรับ ต้องเป็นค่าแฮชที่ตรงกันจากองค์กรคุ้มครองเด็กสององค์กรที่อยู่ภายใต้คนละรัฐบาลกัน (separate sovereign jurisdictions) เงื่อนไขนี้ไม่ปรากฎอยู่ใน<a href=\"https://www.apple.com/child-safety/pdf/CSAM_Detection_Technical_Summary.pdf\">เอกสารด้านเทคนิคฉบับแรก</a>ที่แอปเปิลเปิดเผยออกมาที่ระบุเพียงว่าค่าแฮชจะมาจาก NCMEC และองค์กรคุ้มครองเด็กอื่นๆ</p>\n<p>กระบวนการอัพเดตฐานข้อมูลค่าแฮชนี้จะต้องอัพเดตผ่านการอัพเดตระบบปฎิบัติการที่ตรงกันทั้งโลก จะไม่มีการอัพเดตเฉพาะตัวฐานข้อมูลเปล่าๆ และไม่สามารถอัพเดตฐานข้อมูลบนเครื่องผู้ใช้รายคน แอปเปิลจะแสดงค่า root hash ของฐานข้อมูลบนเว็บไซต์ และแสดงในเครื่องของผู้ใช้เอง</p>\n<p>สำหรับประสิทธิภาพของตัวสแกน NeuralHash แอปเปิลสแกนภาพทั้งจากฐานข้อมูลของ NCMEC กับภาพที่ไม่เกี่ยวข้อง 100 ล้านภาพ พบภาพถูกแจ้งเตือนอย่างผิดๆ เพียง 3 ภาพ และเมื่อทดสอบกับภาพโป๊อื่นๆ อีก 500,000 ภาพก็ไม่พบภาพถูกแจ้งเตือนเลย โดยแอปเปิลยืนยันว่า NeuralHash ไม่ได้พยายามจับลักษณะภาพใดเป็นพิเศษ เช่น ลักษณะใบหน้า นอกจากนี้แอปเปิลยังป้องกันการแจ้งเตือนอย่างผิดๆ ด้วยการตั้งค่าว่าต้องพบภาพในฐานข้อมูลถึง 30 ภาพจึงแจ้งเตือน (ข้อมูลนี้เปิดเผยครั้งแรกหลัง Craig Federighi พบสื่อ โดยตอนให้สัมภาษณ์เขาพูดเพียงว่า \"ประมาณ 30 ภาพ\" แต่เอกสารยืนยันภายหลังว่าฐานข้อมูลแรกจะใช้เกณฑ์ 30 ภาพ) เกณฑ์นี้จะเปลี่ยนไปได้ในอนาคต และแอปเปิลจะแสดงข้อมูลคู่กับค่า root hash</p>\n<p>แอปเปิลจะไม่มีฐานข้อมูลภาพ CSAM ที่องค์กรคุ้มครองเด็กส่งมาให้ อย่างไรก็ตามเมื่อผู้ใช้มีภาพที่ถูกแจ้งเตือนครบเกณฑ์ เจ้าหน้าที่ของแอปเปิลจะเห็นภาพที่ถูกแจ้งเตือนและตรวจสอบอีกครั้งว่าเป็นภาพที่เข้าข่าย CSAM จริง แนวทางนี้ป้องกันการสอดไส้ค่าแฮชของข้อมูลที่ไม่เกี่ยวข้องเข้าไปในฐานข้อมูล และแอปเปิลจะให้ผู้ตรวจภายนอก (third party auditor) ยืนยันว่าทำตามกระบวนการที่วางไว้ทั้งหมดจริง</p>\n<p>ที่มา - <a href=\"https://www.apple.com/child-safety/pdf/Security_Threat_Model_Review_of_Apple_Child_Safety_Features.pdf\">Apple</a></p>\n<p><img src=\"https://www.blognone.com/sites/default/files/externals/ba7ce76bd4e1ffeb074eaf03a4158a6a.jpg\" /></p>\n</div></div></div><div><div>Topics: </div><div><div><a href=\"/topics/apple\">Apple</a></div><div><a href=\"/topics/privacy\">Privacy</a></div></div></div>","author":"lew","siteTitle":"Blognone","siteHash":"ededadcf18490b3937e7dd89ebe8c00dc129addbdf1ebe4aff1f458146693da0","entryHash":"fcf35983cb597e2e22925e791d1e57a7fb3f0586678212f4ea970f1433f6af32","category":"Thai"}