{"title":"Microsoft launches AI chatbot for spies","link":"https://arstechnica.com/?p=2022611","date":1715109730000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2024/05/secret_agent_computer_1-800x450.jpg\" alt=\"A person using a computer with a computer screen reflected in their glasses.\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2024/05/secret_agent_computer_1.jpg\">Enlarge</a> (credit: <a href=\"https://www.gettyimages.com/detail/photo/cyber-attacks-royalty-free-image/874781132\">Getty Images</a>)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>Microsoft has introduced a GPT-4-based generative AI model designed specifically for US intelligence agencies that operates disconnected from the Internet, according to a <a href=\"https://www.bloomberg.com/news/articles/2024-05-07/microsoft-creates-top-secret-generative-ai-service-for-us-spies\">Bloomberg report</a>. This reportedly marks the first time Microsoft has deployed a major language model in a secure setting, designed to allow spy agencies to analyze top-secret information without connectivity risks—and to allow secure conversations with a chatbot similar to <a href=\"https://arstechnica.com/information-technology/2023/11/chatgpt-was-the-spark-that-lit-the-fire-under-generative-ai-one-year-ago-today/\">ChatGPT</a> and <a href=\"https://arstechnica.com/information-technology/2023/11/bing-chat-is-now-microsoft-copilot-in-potentially-confusing-rebranding-move/\">Microsoft Copilot</a>. But it may also mislead officials if not used properly due to inherent design limitations of AI language models.</p>\n\n<p><a href=\"https://arstechnica.com/information-technology/2023/11/openai-introduces-gpt-4-turbo-larger-memory-lower-cost-new-knowledge/\">GPT-4</a> is a large language model (LLM) created by OpenAI that attempts to predict the most likely tokens (fragments of encoded data) in a sequence. It can be used to craft computer code and analyze information. When configured as a chatbot (like ChatGPT), GPT-4 can power AI assistants that converse in a human-like manner. Microsoft has a license to use the technology as part of a deal in exchange for <a href=\"https://arstechnica.com/information-technology/2023/01/openai-and-microsoft-reaffirm-shared-quest-for-powerful-ai-with-new-investment/\">large investments</a> it has made in OpenAI.</p>\n<p>According to the report, the new AI service (which does not yet publicly have a name) addresses a growing interest among intelligence agencies to use generative AI for processing classified data, while mitigating risks of data breaches or hacking attempts. ChatGPT normally  runs on cloud servers provided by Microsoft, which can introduce data leak and interception risks. Along those lines, the CIA <a href=\"https://www.bloomberg.com/news/articles/2023-09-26/cia-builds-its-own-artificial-intelligence-tool-in-rivalry-with-china\">announced</a> its plan to create a ChatGPT-like service last year, but this Microsoft effort is reportedly a separate project.</p></div><p><a href=\"https://arstechnica.com/?p=2022611#p3\">Read 4 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=2022611&amp;comments=1\">Comments</a></p>","author":"Benj Edwards","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"d8a8dd8f931f18f575e665ae6c2ec2701e96d700927036ebe6b1df106662b8a5","category":"Tech"}