{"title":"Lazy use of AI leads to Amazon products called “I cannot fulfill that request”","link":"https://arstechnica.com/?p=1995750","date":1705092999000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2024/01/amazonai5.png\" alt=\"I know naming new products can be hard, but these Amazon sellers made some particularly odd naming choices.\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2024/01/amazonai5.png\">Enlarge</a> <span>/</span> I know naming new products can be hard, but these Amazon sellers made some particularly odd naming choices. (credit: Amazon)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>Amazon users are at this point used to search results filled with products that are <a href=\"https://arstechnica.com/tech-policy/2020/09/doj-amazon-workers-took-bribes-to-reinstate-sellers-of-dangerous-products/\">fraudulent</a>, <a href=\"https://arstechnica.com/gadgets/2023/01/64gb-microsd-cards-are-posing-as-16tb-portable-ssds-on-amazon/\">scams</a>, or <a href=\"https://arstechnica.com/tech-policy/2019/12/some-junk-for-sale-on-amazon-is-very-literally-garbage-report-finds/\">quite literally garbage</a>. These days, though, they also may have to pick through obviously shady products, with names like \"I'm sorry but I cannot fulfill this request it goes against OpenAI use policy.\"</p>\n<p>As of press time, some version of that telltale OpenAI error message appears in Amazon products ranging from <a href=\"https://archive.is/ZnPdj\">lawn chairs</a> to <a href=\"https://archive.is/9HjYd\">office furniture</a> to <a href=\"https://archive.is/cFsK4\">Chinese religious tracts</a> (Update: Links now go to archived copies, as the original were taken down shortly after publication). A few similarly named products that were available as of this morning have been taken down as word of the listings spreads across social media (one such example <a href=\"https://archive.is/ia5Ro#selection-3993.55-3993.93\">is archived here</a>).</p>\n<div><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2024/01/amazonai3.png\"><img alt=\"ProTip: Don't ask OpenAI to integrate a trademarked brand name when generating a name for your weird length of rubber tubing.\" src=\"https://cdn.arstechnica.net/wp-content/uploads/2024/01/amazonai3-640x470.png\" srcset=\"https://cdn.arstechnica.net/wp-content/uploads/2024/01/amazonai3.png 2x\" /></a><p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2024/01/amazonai3.png\">ProTip: Don't ask OpenAI to integrate a trademarked brand name when generating a name for your weird length of rubber tubing.</a> </p></div>\n<p>Other Amazon product names don't mention OpenAI specifically but feature <a href=\"https://github.com/Azure-Samples/azure-search-openai-demo/issues/965\">apparent AI-related error messages,</a> such as \"<a href=\"https://www.amazon.com/dp/B0CM7DHSFC/?tag=arstech20-20\">Sorry but I can't generate a response to that request</a>\" or \"<a href=\"https://www.amazon.com/dp/B0CNMZXWV2/?tag=arstech20-20\">Sorry but I can't provide the information you're looking for</a>,\" (available in a <a href=\"https://www.amazon.com/dp/B0CNMZXWV2/?tag=arstech20-20\">variety</a> of <a href=\"https://www.amazon.com/dp/B0CNN3L1Y7/?tag=arstech20-20\">colors</a>). Sometimes, the product names even highlight the specific reason why the apparent AI-generation request failed, noting that OpenAI can't provide content that \"requires using trademarked brand names\" or \"promotes a specific religious institution\" or, in one case, \"encourage unethical behavior.\"</p></div><p><a href=\"https://arstechnica.com/?p=1995750#p3\">Read 5 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=1995750&amp;comments=1\">Comments</a></p>","author":"Kyle Orland","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"eec2cebd558eaa63fd38201ff3073064f2e1867b9eec944a12ed76c0aa4cf3cf","category":"Tech"}