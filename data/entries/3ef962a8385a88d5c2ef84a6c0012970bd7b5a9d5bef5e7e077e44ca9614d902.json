{"title":"อย่าคิดมาก เปลือง, ทีมวิจัย Zoom พบการบอกให้ AI คิดก่อนตอบ แต่คิดแค่สั้นๆ พอ ได้ผลเหมือนกันแถมประหยัดกว่า","link":"https://www.blognone.com/node/145159","date":1741527721000,"content":"<div><div><div><p>ทีมวิจัยจาก Zoom Communications รายงานถึงเทคนิค Chain of Draft (CoD) ที่ล้อมาจาก Chain of Thought (CoT) หรือกระบวนการคิดก่อนตอบ ที่มักทำให้ผลการทดสอบต่างๆ ของปัญญาประดิษฐ์กลุ่ม LLM ดีขึ้น โดยพบว่ากระบวนการ CoD ได้ผลใกล้เคียงหรือดีกว่า CoT แต่กลับประหยัดค่า token อย่างมาก</p>\n<p>หลักการของ CoD นั้นเรียบง่าย คือการใส่ system prompt ระบุว่าให้คิดเป็นขั้นเป็นตอนก่อนตอบ (เหมือน CoT) แต่ระบุว่าให้คิดให้สั้นที่สุดเท่าที่เป็นไปได้ แต่ละขั้นตอนก็คิดสั้นๆ พอ</p>\n<p>ความน่าสนใจของแนวทางนี้คือเมื่อรันกับชุดทดสอบต่างๆ แล้วพบว่า CoD ทำคะแนนได้ดีกว่าโมเดลพื้นฐานอย่างมาก ขึ้นไประดับเดียวกับ CoT แต่กลับใช้โทเค็นรวมเพียง 7.6% ของ CoT เท่านั้น</p>\n<p>โมเดล LLM ที่คิดก่อนตอบมีค่าใช้จ่ายในการรันที่แพงมาก เพราะหลายโมเดลคิดยาวส่งผลให้ค่ารันสูงขึ้นอย่างมาก แถมการตอบสนองกับผู้ใช้ก็ไม่ดีในงานที่ต้องการคำตอบทันที เช่น call center, หรือการเติมโค้ด</p>\n<p>ข้อเสนอ CoD นี้ทำให้เป็นไปได้ว่า ในอนาคตเราจะเห็นโมเดลคิดก่อนตอบประสิทธิภาพสูง แต่ค่าใช้จ่ายไม่ต่างจากโมเดลธรรมดานัก</p>\n<p>ที่มา - <a href=\"https://arxiv.org/pdf/2502.18600\">ArXiV</a></p>\n<p><img alt=\"No Description\" src=\"https://www.blognone.com/sites/default/files/externals/c4f17f39897fe8831254ee08072b0ab8.png\" /></p>\n</div></div></div><div><div>Topics: </div><div><div><a href=\"/topics/llm\">LLM</a></div><div><a href=\"/topics/zoom\">Zoom</a></div><div><a href=\"/topics/research\">Research</a></div><div><a href=\"/topics/artificial-intelligence\">Artificial Intelligence</a></div></div></div>","author":"lew","siteTitle":"Blognone","siteHash":"ededadcf18490b3937e7dd89ebe8c00dc129addbdf1ebe4aff1f458146693da0","entryHash":"3ef962a8385a88d5c2ef84a6c0012970bd7b5a9d5bef5e7e077e44ca9614d902","category":"Thai"}