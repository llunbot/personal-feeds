{"title":"Round 2: We test the new Gemini-powered Bard against ChatGPT","link":"https://arstechnica.com/?p=1989639","date":1702062014000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2023/12/chatgpt-vs-bard-round2-800x450.jpg\" alt=\"Round 2: We test the new Gemini-powered Bard against ChatGPT\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2023/12/chatgpt-vs-bard-round2.jpg\">Enlarge</a> (credit: Aurich Lawson)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p><a href=\"https://arstechnica.com/information-technology/2023/04/clash-of-the-ai-titans-chatgpt-vs-bard-in-a-showdown-of-wits-and-wisdom/\">Back in April</a>, we ran a series of useful and/or somewhat goofy prompts through Google's (<a href=\"https://arstechnica.com/gadgets/2023/03/google-says-its-bard-generative-chat-ai-is-out-launches-waitlist/\">then-new</a>) <a href=\"https://blog.research.google/2022/04/pathways-language-model-palm-scaling-to.html\">PaLM-powered</a> Bard chatbot and OpenAI's (slightly older) ChatGPT-4 to see which AI chatbot reigned supreme. At the time, <a href=\"https://arstechnica.com/information-technology/2023/04/clash-of-the-ai-titans-chatgpt-vs-bard-in-a-showdown-of-wits-and-wisdom/\">we gave the edge to ChatGPT</a> on five of seven trials, while noting that \"it's still early days in the generative AI business.\"</p>\n<p>Now, the AI days are a bit less “early,\" and this week's launch of a new version of Bard <a href=\"https://arstechnica.com/information-technology/2023/12/google-launches-gemini-a-powerful-ai-model-it-says-can-surpass-gpt-4/\">powered by Google's new Gemini language model</a> seemed like a good excuse to revisit that chatbot battle with the same set of carefully designed prompts. That's especially true since <a href=\"https://arstechnica.com/information-technology/2023/12/google-launches-gemini-a-powerful-ai-model-it-says-can-surpass-gpt-4/\">Google's promotional materials</a> emphasize that Gemini Ultra beats GPT-4 in \"30 of the 32 widely used academic benchmarks\" (though the more limited “Gemini Pro\" currently powering Bard <a href=\"https://arstechnica.com/civis/threads/google-launches-gemini%E2%80%94a-powerful-ai-model-it-says-can-surpass-gpt-4.1497547/#post-42413300\">fares significantly worse</a> in those <a href=\"https://x.com/emilymbender/status/1732763085440774565?s=20\">not-completely-foolproof</a> benchmark tests).</p>\n<p>This time around, we decided to compare the new Gemini-powered Bard to both ChatGPT-3.5—for an apples-to-apples comparison of both companies’ current “free\" AI assistant products—and ChatGPT-4 Turbo—for a look at OpenAI’s current “top of the line\" <a href=\"https://www.reddit.com/r/ChatGPT/comments/185oi6e/how_long_is_the_waitlist_for_chatgpt_plus_right/\">waitlisted</a> paid subscription product (Google’s top-level “Gemini Ultra\" model won’t be publicly available until next year). We also looked at the April results generated by the pre-Gemini Bard model to gauge how much progress Google’s efforts have made in recent months.</p></div><p><a href=\"https://arstechnica.com/?p=1989639#p3\">Read 36 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=1989639&amp;comments=1\">Comments</a></p>","author":"Kyle Orland","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"abc4cce885bd88206ca948e8139ee22c99738a60890895075a4208c9ca2a07bb","category":"Tech"}