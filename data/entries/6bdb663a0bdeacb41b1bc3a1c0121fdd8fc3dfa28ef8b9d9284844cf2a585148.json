{"title":"Kolmogorov-Arnold Networks สถาปัตยกรรมใหม่ที่อาจบุกโลก Deep Learning ใช้พารามิเตอร์น้อยกว่า ทำความเข้าใจง่ายกว่า","link":"https://www.blognone.com/node/141253","date":1722877993000,"content":"<div><div><div><p>เมื่อเดือนเมษายนที่ผ่านมาทีมวิจัยรวมระหว่าง Massachusetts Institute of Technology, California Institute of Technology, และ Northeastern University <a href=\"https://arxiv.org/pdf/2404.19756\">นำเสนอรายงานถึงสถาปัตยกรรม Kolmogorov Arnold Networks (KANs)</a> ที่ได้รับแรงบันดาลใจจาก <a href=\"https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Arnold_representation_theorem\">Kolmogorov–Arnold representation theorem</a> โดย KAN อาจจะเป็นแนวทางใหม่ในการสร้าง neural network ที่ขนาดเล็กลงแต่ประสิทธิภาพคงเดิม และทำความเข้าใจโมเดลปัญญาประดิษฐ์ได้ง่ายขึ้นเทียบกับโมเดลที่พารามิเตอร์มหาศาลทุกวันนี้</p>\n<p>KAN เปลี่ยนแนวทางการออกแบบ neural network จากเดิมที่มอง activation function อยู่บน node และได้รับอินพุตจาก node ในชั้นก่อนหน้าขึ้นมาเป็นชั้นๆ เรียกว่า MLP (Multi-Layer Perceptrons) มาเป็นการวาง activation function บน edge ของกราฟแทน และ node ต่างๆ จะกลายเป็นการรวมค่าตรงๆ (sum)</p>\n<p>ทีมงานสาธิตระบุว่า KAN ช่วยให้สามารถออกแบบโมเดลทำนายค่าต่างๆ ได้ความแม่นยำใกล้เคียงโมเดลเดิมๆ แต่ขนาดโมเดลเล็กลงมาก เช่น โมเดลทำนายตัวเลข MNIST โมเดล KAN สามารถทำนายได้ 98.90% ด้วยพารามิเตอร์ 94,875 พารามิเตอร์เท่านั้น เทียบกับ CNN เดิมที่ใช้ 157,000 พารามิเตอร์แล้วได้ความแม่นยำ 99.12%</p>\n<p>ตอนนี้เริ่มมีงานวิจัยทดลองสถาปัตยกรรม KAN ออกมาเรื่อยๆ บางโมเดลสามารถทำความแม่นยำเทียบเท่าโมเดล deep learning แบบเดิมๆ ได้โดยใช้พารามิเตอร์น้อยกว่าเดิมนับพันเท่า แต่บางปัญหาก็ลดพารามิเตอร์ได้ประมาณครึ่งเดียวเท่านั้น แต่โดยรวมแล้วยังมีรายงานใหม่ๆ ถึงสถาปัตยกรรม KAN แสดงประสิทธิภาพสูงกว่าได้เรื่อยๆ</p>\n<p>งานเหล่านี้ยังอยู่ในระดับวิจัยเท่านั้น ในความเป็นจริงการฝึกและรันโมเดล KAN จริงๆ นั้นช้ากว่าโมเดล deep learning เดิมๆ มากเพราะซอฟต์แวร์ต่างๆ ไม่ได้ออปติไมซ์สำหรับการรันบนชิปกราฟิก แต่หากในอนาคตสถาปัตยกรรมแสดงให้เห็นว่าทำงานได้เหนือกว่าจริงๆ เราก็น่าจะได้เห็นซอฟต์แวร์ต่างๆ ออปติไมซ์รองรับกันมากขึ้น</p>\n<p>ที่มา - <a href=\"https://spectrum.ieee.org/kan-neural-network\">IEEE Spectrum</a></p>\n<p><img alt=\"No Description\" src=\"https://www.blognone.com/sites/default/files/externals/3c1d5659e0737ee04e36f84f01c45e2e.jpeg\" /></p>\n</div></div></div><div><div>Topics: </div><div><div><a href=\"/topics/deep-learning\">Deep Learning</a></div><div><a href=\"/topics/artificial-intelligence\">Artificial Intelligence</a></div></div></div>","author":"lew","siteTitle":"Blognone","siteHash":"ededadcf18490b3937e7dd89ebe8c00dc129addbdf1ebe4aff1f458146693da0","entryHash":"6bdb663a0bdeacb41b1bc3a1c0121fdd8fc3dfa28ef8b9d9284844cf2a585148","category":"Thai"}