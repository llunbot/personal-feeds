{"title":"Mixtral 8x7B: A Sparse Mixture of Experts language model","link":"https://arxiv.org/abs/2401.04088","date":1704768786000,"content":"<a href=\"https://news.ycombinator.com/item?id=38921668\">Comments</a>","author":"","siteTitle":"Hacker News","siteHash":"37bb545430005dba450c1e40307450d8e4e791b434e83f3d38915ebad510fd50","entryHash":"26508507bacf79d000bbd753efba0bc21ed9be28deac9ecb67e4f76e39d2df7f","category":"Tech"}