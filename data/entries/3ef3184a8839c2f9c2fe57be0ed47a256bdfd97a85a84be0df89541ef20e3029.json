{"title":"“CSAM generated by AI is still CSAM,” DOJ says after rare arrest","link":"https://arstechnica.com/?p=2025952","date":1716312038000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2024/05/GettyImages-1242740781-800x533.jpg\" alt=\"“CSAM generated by AI is still CSAM,” DOJ says after rare arrest\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2024/05/GettyImages-1242740781.jpg\">Enlarge</a> (credit: <a href=\"https://www.gettyimages.com/detail/photo/young-asian-preteen-teenager-boy-holding-a-royalty-free-image/1242740781?phrase=teen+boy+phone+anxious&amp;adppopup=true\">SewcreamStudio | iStock / Getty Images Plus</a>)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>The US Department of Justice has started cracking down on the use of AI image generators to produce child sexual abuse materials (CSAM).</p>\n<p>On Monday, the DOJ <a href=\"https://www.justice.gov/opa/pr/man-arrested-producing-distributing-and-possessing-ai-generated-images-minors-engaged\">arrested</a> Steven Anderegg, a 42-year-old \"extremely technologically savvy\" Wisconsin man who allegedly used Stable Diffusion to create \"thousands of realistic images of prepubescent minors,\" which were then distributed on Instagram and Telegram.</p>\n<p>The cops were tipped off to Anderegg's alleged activities after Instagram flagged direct messages that were sent on Anderegg's Instagram account to a 15-year-old boy. Instagram reported the messages to the National Center for Missing and Exploited Children (NCMEC), which subsequently alerted law enforcement.</p></div><p><a href=\"https://arstechnica.com/?p=2025952#p3\">Read 31 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=2025952&amp;comments=1\">Comments</a></p>","author":"Ashley Belanger","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"3ef3184a8839c2f9c2fe57be0ed47a256bdfd97a85a84be0df89541ef20e3029","category":"Tech"}