{"title":"Meta เปิดตัว MITA ชิป AI ตัวแรกที่บริษัทออกแบบเอง, สถาปัตยกรรม RISC-V คัสตอม","link":"https://www.blognone.com/node/133905","date":1684466534000,"content":"<div><div><div><p>Meta เปิดตัวชิปเร่งการประมวลผล AI รุ่นแรกของบริษัท ใช้ชื่อว่า <strong>MITA v1</strong> ย่อมาจาก <strong>Meta Training and Inference Accelerator</strong></p>\n<p>Meta ให้เหตุผลว่างานประมวลผล AI ของบริษัทในปัจจุบัน โดยเฉพาะงานกลุ่ม recommendation ในบริการโซเชียลต่างๆ ไม่ได้เหมาะกับ GPU มากนัก จึงออกแบบชิป ASIC ขึ้นมาใหม่ให้สอดคล้องกับโมเดล recommendation ของบริษัทเอง และเน้นการปรับแต่งมาเพื่อ PyTorch ซึ่งเป็นไลบรารีประมวลผล AI ที่เกิดจาก Meta ด้วย</p>\n<p><img alt=\"No Description\" src=\"https://www.blognone.com/sites/default/files/externals/c9602f5a9bced7ae8d4d485b24223be2.jpg\" /></p>\n<p>MITA เป็นชิป ASICS แบบคัสตอมที่ Meta ออกแบบเองมาตั้งแต่ปี 2020 (แต่เพิ่งเปิดตัวต่อสาธารณะวันนี้) ใช้กระบวนการผลิต 7nm TSMC, สัญญาณนาฬิกา 800Hz, สมรรถนะ 102.4 TOPS (INT8) หรือ 51.2 TFLOPS (FP16) มีอัตราการใช้พลังงาน TDP 25W</p>\n<p>ชิป MITA ประกอบด้วยหน่วยย่อยเรียกว่า processing element (PE) จำนวนรวม 64 ตัว วางแบบตาราง 8x8 เชื่อมกันแบบ mesh network ยืดหยุ่นต่อการจัดกลุ่ม PE ต่องานแต่ละขนาด, PE แต่ละตัวมี 2 คอร์ เป็นชิปสถาปัตยกรรม RISC-V แบบคัสตอม โดย 1 คอร์จะมีส่วนขยายประมวลผลแบบเวกเตอร์ด้วย, PE แต่ละตัวมี SRAM ขนาดเล็ก 128KB สำหรับเก็บข้อมูลเรียกใช้งานรวดเร็ว</p>\n<p>ในชิปยังมีแรม SRAM ขนาด 128MB แชร์กันระหว่าง PE ทุกตัว, แรมนอกชิปเป็น LPDDR5 ขนาดรวม 128GB</p>\n<p><img alt=\"No Description\" src=\"https://www.blognone.com/sites/default/files/externals/6ba8bc48c940d0d95667f446de0be069.png\" /></p>\n<p>ชิป MITA แต่ละตัวจะถูกนำมาติดตั้งบนบอร์ด M.2 เพื่อเสียบเข้ากับเซิร์ฟเวอร์ที่มีซีพียูหลักผ่าน PCIe Gen4 โดยตัวบอร์ด MITA ใช้พลังงานเพียง 35W, เซิร์ฟเวอร์หนึ่งตัวมีชิป MITA รวม 12 ตัว โดยเชื่อมต่อ MITA ของแต่ละเครื่องโดยตรงได้ผ่านสวิตช์ PCIe เพื่อไม่ให้ทราฟฟิกต้องวิ่งผ่านซีพียูเสมอไป</p>\n<p><img alt=\"No Description\" src=\"https://www.blognone.com/sites/default/files/externals/abfc7ae0a5beb5393677b6b93788a2e0.jpg\" /></p>\n<p>ซอฟต์แวร์ของ MITA ปรับแต่งมาเพื่อ PyTorch โดยเฉพาะ ทีมพัฒนาซอฟต์แวร์ได้สร้างตัวรันไทม์ของ PyTorch ที่รันบน MITA เพื่อปรับแต่งประสิทธิภาพให้เหมาะสม และตอนนี้กำลังพัฒนาซอฟต์แวร์ของ MITA ให้ทำงานร่วมกับ <a href=\"https://www.blognone.com/node/133038\">PyTorch 2.0</a> ที่เป็นการปรับปรุงครั้งใหญ่ด้วย</p>\n<p>ผลการทดสอบชิป MITA เทียบกับหน่วยประมวลผลแบบอื่นคือ NNPI accelerator และ GPU พบว่า MITA มีประสิทธิภาพต่อพลังงาน (efficiency) ดีกว่าชิปทั้งสองแบบในโมเดลขนาดเล็กและขนาดกลาง แต่ถ้าเป็นโมเดลขนาดใหญ่ยังแพ้ GPU แบบดั้งเดิมอยู่ ซึ่งทีม MITA บอกว่ารับทราบเรื่องนี้และจะหาวิธีปรับปรุงต่อไป</p>\n<p><img alt=\"No Description\" src=\"https://www.blognone.com/sites/default/files/externals/b81c6cf1b51c213f4987d1c522befa7e.png\" /></p>\n<p>ที่มา - <a href=\"https://ai.facebook.com/blog/meta-training-inference-accelerator-AI-MTIA/\">Meta AI Blog</a></p>\n</div></div></div><div><div>Topics: </div><div><div><a href=\"/topics/meta\">Meta</a></div><div><a href=\"/topics/asics\">ASICS</a></div><div><a href=\"/topics/artificial-intelligence\">Artificial Intelligence</a></div><div><a href=\"/topics/risc-v\">RISC-V</a></div><div><a href=\"/topics/pytorch\">PyTorch</a></div><div><a href=\"/topics/processor\">Processor</a></div></div></div>","author":"mk","siteTitle":"Blognone","siteHash":"ededadcf18490b3937e7dd89ebe8c00dc129addbdf1ebe4aff1f458146693da0","entryHash":"0c0009695c3437f33d27c122aa078e57130e55448c3d9cb26a4a486f6a2bb6d2","category":"Thai"}