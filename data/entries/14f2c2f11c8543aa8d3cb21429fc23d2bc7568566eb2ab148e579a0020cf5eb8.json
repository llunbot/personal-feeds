{"title":"Senators propose “Digital replication right” for likeness, extending 70 years after death","link":"https://arstechnica.com/?p=2040488","date":1722534317000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2024/08/deepfake_illustration-800x450.jpg\" alt=\"A stock photo illustration of a person's face lit with pink light.\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2024/08/deepfake_illustration.jpg\">Enlarge</a> (credit: <a href=\"https://www.gettyimages.com/detail/photo/biometric-identification-metaverse-technology-royalty-free-image/1819824175\">Maria Korneeva via Getty Images</a>)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>On Wednesday, US Sens. Chris Coons (D-Del.), Marsha Blackburn (R.-Tenn.), Amy Klobuchar (D-Minn.), and Thom Tillis (R-NC) <a href=\"https://www.coons.senate.gov/news/press-releases/senators-coons-blackburn-klobuchar-tillis-introduce-bill-to-protect-individuals-voices-and-likenesses-from-ai-generated-replicas\">introduced</a> the Nurture Originals, Foster Art, and Keep Entertainment Safe (<a href=\"https://www.coons.senate.gov/imo/media/doc/no_fakes_act_bill_text.pdf\">NO FAKES</a>) Act of 2024. The bipartisan legislation, up for consideration in the US Senate, aims to protect individuals from unauthorized AI-generated replicas of their voice or likeness.</p>\n\n<p>The NO FAKES Act would create legal recourse for people whose digital representations are created without consent. It would hold both individuals and companies liable for producing, hosting, or sharing these unauthorized digital replicas, including those created by generative AI. Due to generative AI technology that has become mainstream in the past two years, creating <a href=\"https://arstechnica.com/information-technology/2023/11/unauthorized-david-attenborough-ai-clone-narrates-developers-life-goes-viral/\">audio</a> or <a href=\"https://arstechnica.com/information-technology/2022/12/thanks-to-ai-its-probably-time-to-take-your-photos-off-the-internet/\">image</a> media fakes of people has become fairly trivial, with easy photorealistic video replicas likely next to arrive.</p>\n<p>In a press statement, Coons emphasized the importance of protecting individual rights in the age of AI. \"Everyone deserves the right to own and protect their voice and likeness, no matter if you're Taylor Swift or anyone else,\" he said, referring to a <a href=\"https://arstechnica.com/tech-policy/2024/01/fake-ai-taylor-swift-images-flood-x-amid-calls-to-criminalize-deepfake-porn/\">widely publicized deepfake incident</a> involving the musical artist in January. \"Generative AI can be used as a tool to foster creativity, but that can't come at the expense of the unauthorized exploitation of anyone's voice or likeness.\"</p></div><p><a href=\"https://arstechnica.com/?p=2040488#p3\">Read 11 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=2040488&amp;comments=1\">Comments</a></p>","author":"Benj Edwards","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"14f2c2f11c8543aa8d3cb21429fc23d2bc7568566eb2ab148e579a0020cf5eb8","category":"Tech"}