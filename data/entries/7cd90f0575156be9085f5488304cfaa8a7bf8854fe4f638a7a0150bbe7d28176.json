{"title":"Google’s latest AI video generator renders implausible situations for cute animals","link":"https://arstechnica.com/?p=1998725","date":1706136309000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2024/01/lumiere_hero_1-800x398.jpg\" alt=\"Still images of AI-generated video examples provided by Google for its Lumiere video synthesis model.\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2024/01/lumiere_hero_1.jpg\">Enlarge</a> <span>/</span> Still images of AI-generated video examples provided by Google for its Lumiere video synthesis model. (credit: <a href=\"https://lumiere-video.github.io/\">Google</a>)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>On Tuesday, Google announced <a href=\"https://lumiere-video.github.io/\">Lumiere</a>, an AI video generator that it calls \"a space-time diffusion model for realistic video generation\" in the <a href=\"https://arxiv.org/abs/2401.12945\">accompanying preprint paper</a>. But let's not kid ourselves: It does a great job at creating videos of cute animals in ridiculous scenarios, such as using roller skates, driving a car, or playing a piano. Sure, it can do more, but it is perhaps the most advanced text-to-animal AI video generator yet demonstrated.</p>\n\n<p>According to Google, Lumiere utilizes unique architecture to generate a video's entire temporal duration in one go. Or, as the company put it, \"We introduce a Space-Time U-Net architecture that generates the entire temporal duration of the video at once, through a single pass in the model. This is in contrast to existing video models which synthesize distant keyframes followed by temporal super-resolution—an approach that inherently makes global temporal consistency difficult to achieve.\"</p>\n<p>In layperson terms, Google's tech is designed to handle both the space (where things are in the video) and time (how things move and change throughout the video) aspects simultaneously. So, instead of making a video by putting together many small parts or frames, it can create the entire video, from start to finish, in one smooth process.</p></div><p><a href=\"https://arstechnica.com/?p=1998725#p3\">Read 8 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=1998725&amp;comments=1\">Comments</a></p>","author":"Benj Edwards","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"7cd90f0575156be9085f5488304cfaa8a7bf8854fe4f638a7a0150bbe7d28176","category":"Tech"}