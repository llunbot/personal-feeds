{"title":"AI chatbots can infer an alarming amount of info about you from your responses","link":"https://arstechnica.com/?p=1976786","date":1697636119000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2023/10/ai-eyes-800x560.jpg\" alt=\"eyes\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2023/10/ai-eyes.jpg\">Enlarge</a> (credit: atakan/Getty Images)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>The way you talk can reveal a lot about you—especially if you're talking to a chatbot. New research reveals that chatbots like ChatGPT can infer a lot of sensitive information about the people they chat with, even if the conversation is utterly mundane.</p>\n<p>The phenomenon appears to stem from the way the models’ algorithms are trained with broad swathes of web content, a key part of what makes them work, likely making it hard to prevent. “It's not even clear how you fix this problem,” says <a href=\"https://www.sri.inf.ethz.ch/people/martin\">Martin Vechev</a>, a computer science professor at ETH Zürich in Switzerland who led the research. “This is very, very problematic.”</p>\n<p></p></div><p><a href=\"https://arstechnica.com/?p=1976786#p3\">Read 21 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=1976786&amp;comments=1\">Comments</a></p>","author":"WIRED","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"350f2369e13cc9827b2db68b19ca4acc7db53c77f1c79394f0c870ad2a942010","category":"Tech"}