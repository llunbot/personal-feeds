{"title":"DeepSeek-R1 models now available on AWS","link":"https://aws.amazon.com/blogs/aws/deepseek-r1-models-now-available-on-aws/","date":1738281640000,"content":"<p><em><strong>Updated on February 5, 2025</strong> — DeepSeek-R1 Distill Llama and Qwen models are now available in Amazon Bedrock Marketplace and Amazon SageMaker JumpStart.</em></p> \n<p>During this past AWS re:Invent, Amazon CEO Andy Jassy <a href=\"https://youtu.be/LY7m5LQliAo?feature=shared&amp;t=6291\">shared valuable lessons learned</a> from Amazon’s own experience developing nearly 1,000 <a href=\"https://aws.amazon.com/ai/generative-ai/\">generative AI</a> applications across the company. Drawing from this extensive scale of AI deployment, Jassy offered three key observations that have shaped Amazon’s approach to enterprise AI implementation.</p> \n<blockquote>\n <p>First is that as you get to scale in generative AI applications, the cost of compute really matters. People are very hungry for better price performance. The second is actually quite difficult to build a really good generative AI application. The third is the diversity of the models being used when we gave our builders freedom to pick what they want to do. It doesn’t surprise us, because we keep learning the same lesson over and over and over again, which is that there is never going to be one tool to rule the world.</p>\n</blockquote> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/01/30/2025-deepseek-r1-on-aws-1-andy-keynote.png\" alt=\"\" width=\"1080\" height=\"496\" /></p> \n<p>As Andy emphasized, a broad and deep range of models provided by Amazon empowers customers to choose the precise capabilities that best serve their unique needs. By closely monitoring both customer needs and technological advancements, AWS regularly expands our curated selection of models to include promising new models alongside established industry favorites. This ongoing expansion of high-performing and differentiated model offerings helps customers stay at the forefront of AI innovation.</p> \n<p>This leads us to Chinese AI startup <a href=\"https://www.deepseek.com/\">DeepSeek</a>. DeepSeek launched <a href=\"https://github.com/deepseek-ai/DeepSeek-V3\">DeepSeek-V3</a> on December 2024 and subsequently released <a href=\"https://github.com/deepseek-ai/DeepSeek-R1\">DeepSeek-R1</a>, DeepSeek-R1-Zero with 671 billion parameters, and DeepSeek-R1-Distill models ranging from 1.5–70 billion parameters on January 20, 2025. They added their vision-based <a href=\"https://github.com/deepseek-ai/Janus\">Janus-Pro-7B</a> model on January 27, 2025. The models are publicly available and are <a href=\"https://venturebeat.com/ai/open-source-deepseek-r1-uses-pure-reinforcement-learning-to-match-openai-o1-at-95-less-cost/\">reportedly 90-95% more affordable and cost-effective than comparable models</a>. Per Deepseek, their model stands out for its reasoning capabilities, achieved through innovative training techniques such as reinforcement learning.</p> \n<p><strong>Today, you can now deploy DeepSeek-R1 models in <a href=\"https://aws.amazon.com/bedrock/\">Amazon Bedrock</a> and <a href=\"https://aws.amazon.com/sagemaker-ai/\">Amazon SageMaker AI</a></strong>. Amazon Bedrock is best for teams seeking to quickly integrate pre-trained foundation models through APIs. Amazon SageMaker AI is ideal for organizations that want advanced customization, training, and deployment, with access to the underlying infrastructure. Additionally, you can also use <a href=\"https://aws.amazon.com/ai/machine-learning/trainium/\">AWS Trainium</a> and <a href=\"https://aws.amazon.com/ai/machine-learning/inferentia/\">AWS Inferentia</a> to deploy DeepSeek-R1-Distill models cost-effectively via <a href=\"https://aws.amazon.com/ec2/\">Amazon Elastic Compute Cloud (Amazon EC2)</a> or Amazon SageMaker AI.</p> \n<p>With AWS, you can use DeepSeek-R1 models to build, experiment, and responsibly scale your generative AI ideas by using this powerful, cost-efficient model with minimal infrastructure investment. You can also confidently drive generative AI innovation by building on AWS services that are uniquely designed for security. We highly recommend integrating your deployments of the DeepSeek-R1 models with <a href=\"https://aws.amazon.com/bedrock/guardrails/\">Amazon Bedrock Guardrails</a> to add a layer of protection for your generative AI applications, which can be used by both Amazon Bedrock and Amazon SageMaker AI customers.</p> \n<p>You can choose how to deploy DeepSeek-R1 models on AWS today in a few ways: <strong>1/ <a href=\"https://aws.amazon.com/bedrock/marketplace/\">Amazon Bedrock Marketplace</a> for the DeepSeek-R1 model</strong>, <strong>2/ <a href=\"https://aws.amazon.com/sagemaker/jumpstart/\">Amazon SageMaker JumpStart</a> for the DeepSeek-R1 model</strong>, <strong>3/ <a href=\"https://aws.amazon.com/bedrock/custom-model-import/\">Amazon Bedrock Cust</a><a href=\"https://aws.amazon.com/bedrock/custom-model-import/\">om Model Import</a> for the DeepSeek-R1-Distill models</strong>, and <strong>4/ <a href=\"https://aws.amazon.com/ec2/instance-types/trn1/\">Amazon EC2 Trn1 instances</a> for the DeepSeek-R1-Distill models</strong>.</p> \n<p>Let me walk you through the various paths for getting started with DeepSeek-R1 models on AWS. Whether you’re building your first AI application or scaling existing solutions, these methods provide flexible starting points based on your team’s expertise and requirements.</p> \n<p><b><u>1. The DeepSeek-R1 model in Amazon Bedrock Marketplace</u></b><br /> <a href=\"https://aws.amazon.com/bedrock/marketplace/\">Amazon Bedrock Marketplace</a> offers over 100 popular, emerging, and specialized FMs alongside the current selection of industry-leading models in Amazon Bedrock. You can easily discover models in a single catalog, subscribe to the model, and then deploy the model on managed endpoints.</p> \n<p>To access the DeepSeek-R1 model in Amazon Bedrock Marketplace, go to the <a href=\"https://console.aws.amazon.com/bedrock/home?#/model-catalog\">Amazon Bedrock console</a> and select <b>Model catalog</b> under the <b>Foundation models </b>section. You can quickly find DeepSeek by searching or filtering by model providers.</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/01/30/2025-deepseek-r1-on-aws-3-bedrock-marketplace.png\" alt=\"\" width=\"2365\" height=\"1022\" /></p> \n<p>After checking out the model detail page including the model’s capabilities, and implementation guidelines, you can directly deploy the model by providing an endpoint name, choosing the number of instances, and selecting an instance type.</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/01/30/2025-deepseek-r1-on-aws-3-bedrock-marketplace-deploy.png\" alt=\"\" width=\"2154\" height=\"1201\" /></p> \n<p>You can also configure advanced options that let you customize the security and infrastructure settings for the DeepSeek-R1 model including VPC networking, service role permissions, and encryption settings. For production deployments, you should review these settings to align with your organization’s security and compliance requirements.</p> \n<p>With Amazon Bedrock Guardrails, you can independently evaluate user inputs and model outputs. You can control the interaction between users and DeepSeek-R1 with your defined set of policies by filtering undesirable and harmful content in generative AI applications. The DeepSeek-R1 model in Amazon Bedrock Marketplace can only be used with Bedrock’s <a href=\"https://aws.amazon.com/blogs/aws/guardrails-for-amazon-bedrock-can-now-detect-hallucinations-and-safeguard-apps-built-using-custom-or-third-party-fms/\" target=\"_blank\">ApplyGuardrail API</a> to evaluate user inputs and model responses for custom and third-party FMs available outside of Amazon Bedrock. To learn more, read <a href=\"https://aws.amazon.com/blogs/machine-learning/implement-model-independent-safety-measures-with-amazon-bedrock-guardrails/\">Implement model-independent safety measures with Amazon Bedrock Guardrails</a>.</p> \n<p>Amazon Bedrock Guardrails can also be integrated with other Bedrock tools including <a href=\"https://aws.amazon.com/bedrock/agents/\">Amazon Bedrock Agents</a> and <a href=\"https://aws.amazon.com/bedrock/knowledge-bases/\">Amazon Bedrock Knowledge Bases</a> to build safer and more secure generative AI applications aligned with responsible AI policies. To learn more, visit the <a href=\"https://aws.amazon.com/ai/responsible-ai/\">AWS Responsible AI</a> page.</p> \n<p><strong>Updated on 1st February</strong> – You can use the Bedrock playground for understanding how the model responds to various inputs and letting you fine-tune your prompts for optimal results.</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/02/02/bedrock-marketplace-playground-1.png\" alt=\"\" width=\"2034\" height=\"1375\" /></p> \n<p>When using DeepSeek-R1 model with the Bedrock’s playground or <code>InvokeModel</code> API, please use DeepSeek’s chat template for optimal results. For example, <code>&lt;｜begin_of_sentence｜&gt;&lt;｜User｜&gt;content for inference&lt;｜Assistant｜&gt;</code>.</p> \n<p>Refer to this <a href=\"https://aws.amazon.com/blogs/machine-learning/deepseek-r1-model-now-available-in-amazon-bedrock-marketplace-and-amazon-sagemaker-jumpstart/\">step-by-step guide</a> on how to deploy the DeepSeek-R1 model in Amazon Bedrock Marketplace. To learn more, visit <a href=\"https://docs.aws.amazon.com/bedrock/latest/userguide/amazon-bedrock-marketplace.html\">Deploy models in Amazon Bedrock Marketplace</a>.</p> \n<p><b><u>2. The DeepSeek-R1 model in Amazon SageMaker JumpStart</u></b><br /> <a href=\"https://aws.amazon.com/sagemaker-ai/jumpstart/\">Amazon SageMaker JumpStart</a> is a machine learning (ML) hub with FMs, built-in algorithms, and prebuilt ML solutions that you can deploy with just a few clicks. To deploy DeepSeek-R1 in SageMaker JumpStart, you can discover the DeepSeek-R1 model in <a href=\"https://aws.amazon.com/sagemaker/unified-studio/\">SageMaker Unified Studio</a>, <a href=\"https://aws.amazon.com/sagemaker-ai/studio/\">SageMaker Studio</a>, <a href=\"https://us-east-1.console.aws.amazon.com/sagemaker/home?#/foundation-models\">SageMaker AI console</a>, or programmatically through the <a href=\"https://sagemaker.readthedocs.io/en/stable/overview.html\">SageMaker Python SDK</a>.</p> \n<p>In the <a href=\"https://console.aws.amazon.com/sagemaker/\">Amazon SageMaker AI console</a>, open SageMaker Studio and choose <b>JumpStart</b> and search for “<code>DeepSeek-R1</code>” in the <b>All public models</b> page.</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/01/30/2025-deepseek-r1-on-aws-5-sagemaker-jumpstart.png\" alt=\"\" width=\"2585\" height=\"1735\" /></p> \n<p>You can select the model and choose deploy to create an endpoint with default settings. When the endpoint comes <b>InService</b>, you can make inferences by sending requests to its endpoint.</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/01/30/2025-deepseek-r1-on-aws-6-sagemaker-jumpstart-deploy.png\" alt=\"\" width=\"2441\" height=\"1736\" /></p> \n<p>You can derive model performance and ML operations controls with <a href=\"https://aws.amazon.com/sagemaker/\">Amazon SageMaker AI</a> features such as <a href=\"https://aws.amazon.com/sagemaker/pipelines/\">Amazon SageMaker Pipelines</a>, <a href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/train-debugger.html\">Amazon SageMaker Debugger</a>, or container logs. The model is deployed in an AWS secure environment and under your virtual private cloud (VPC) controls, helping to support data security.</p> \n<p>As like Bedrock Marketpalce, you can use the <code>ApplyGuardrail</code> API in the SageMaker JumpStart to decouple safeguards for your generative AI applications from the DeepSeek-R1 model. You can now use guardrails without invoking FMs, which opens the door to more integration of standardized and thoroughly tested enterprise safeguards to your application flow regardless of the models used.</p> \n<p>Refer to this <a href=\"https://aws.amazon.com/blogs/machine-learning/deepseek-r1-model-now-available-in-amazon-bedrock-marketplace-and-amazon-sagemaker-jumpstart/\">step-by-step guide</a> on how to deploy the DeepSeek-R1 model in Amazon SageMaker JumpStart. To learn more, visit <a href=\"https://docs.aws.amazon.com/sagemaker-unified-studio/latest/userguide/sagemaker-discover-models.html\">Discover SageMaker JumpStart models in SageMaker Unified Studio</a> or <a href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/jumpstart-foundation-models-use-studio-updated-deploy.html\">Deploy SageMaker JumpStart models in SageMaker Studio</a>.</p> \n<p><b><u>3. DeepSeek-R1-Distill models using Amazon Bedrock Custom Model Import</u></b><br /> <a href=\"https://aws.amazon.com/bedrock/custom-model-import/\">Amazon Bedrock Custom Model Import</a> provides the ability to import and use your customized models alongside existing FMs through a single serverless, unified API without the need to manage underlying infrastructure. With Amazon Bedrock Custom Model Import, you can import <a href=\"https://huggingface.co/collections/deepseek-ai/deepseek-r1-678e1e131c0169c0bc89728d\">DeepSeek-R1-Distill models</a> ranging from 1.5–70 billion parameters. As I highlighted in <a href=\"https://aws.amazon.com/blogs/aws/build-faster-more-cost-efficient-highly-accurate-models-with-amazon-bedrock-model-distillation-preview/\">my blog post about Amazon Bedrock Model Distillation</a>, the distillation process involves training smaller, more efficient models to mimic the behavior and reasoning patterns of the larger DeepSeek-R1 model with 671 billion parameters by using it as a teacher model.</p> \n<p>After storing these publicly available models in an <a href=\"https://aws.amazon.com/s3/\">Amazon Simple Storage Service (Amazon S3)</a> bucket or an <a href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry.html\">Amazon SageMaker Model Registry</a>, go to <b>Imported models</b> under <b>Foundation models</b> in the <a href=\"https://console.aws.amazon.com/bedrock/home?#/model-catalog\">Amazon Bedrock console</a> and import and deploy them in a fully managed and serverless environment through Amazon Bedrock. This serverless approach eliminates the need for infrastructure management while providing enterprise-grade security and scalability.</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/01/30/2025-deepseek-r1-on-aws-4-bedrock-custom-model-import.png\" alt=\"\" width=\"2424\" height=\"887\" /></p> \n<p><strong>Updated on 1st February</strong> – After importing the distilled model, you can use the Bedrock playground for understanding distilled model responses for your inputs.</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/02/02/bedrock-customer-model-import-playground-1.jpg\" alt=\"\" width=\"1887\" height=\"1182\" /></p> \n<p>Watch a <a href=\"https://www.youtube.com/watch?v=1aq_ju70qHQ\">demo video</a> made by my colleague <a href=\"https://www.linkedin.com/in/duanlightfoot/\">Du’An Lightfoot</a> for importing the model and inference in the Bedrock playground.</p> \n<p></p> \n<p>Refer to this <a href=\"https://aws.amazon.com/blogs/machine-learning/deploy-deepseek-r1-distilled-llama-models-with-amazon-bedrock-custom-model-import/\">step-by-step guide</a> on how to deploy DeepSeek-R1-Distill models using Amazon Bedrock Custom Model Import. To learn more, visit <a href=\"https://docs.aws.amazon.com/bedrock/latest/userguide/model-customization-import-model.html\">Import a customized model into Amazon Bedrock</a>.</p> \n<p><b><u>4. DeepSeek-R1-Distill models using AWS Trainium and AWS Inferentia</u></b><br /> <a href=\"https://docs.aws.amazon.com/dlami/latest/devguide/getting-started.html\">AWS Deep Learning AMIs (DLAMI)</a> provides customized machine images that you can use for deep learning in a variety of Amazon EC2 instances, from a small CPU-only instance to the latest high-powered multi-GPU instances. You can deploy the DeepSeek-R1-Distill models on AWS Trainuim1 or AWS Inferentia2 instances to get the best price-performance.</p> \n<p>To get started, go to <a href=\"https://quip-amazon.com/atboAwqWK1fT/console.aws.amazon.com/ec2\">Amazon EC2 console</a> and launch a <code>trn1.32xlarge</code> EC2 instance with the <a href=\"https://awsdocs-neuron.readthedocs-hosted.com/en/latest/dlami/index.html\">Neuron Multi Framework DLAMI </a>called Deep Learning AMI Neuron (Ubuntu 22.04).</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/01/30/2025-deepseek-r1-on-aws-7-ec2-instance.png\" alt=\"\" width=\"2394\" height=\"1504\" /></p> \n<p>Once you have connected to your launched ec2 instance, install vLLM, an open-source tool to serve <a href=\"https://aws.amazon.com/what-is/large-language-model/\">Large Language Models (LLMs)</a> and download the DeepSeek-R1-Distill model from Hugging Face. You can deploy the model using vLLM and invoke the model server.</p> \n<p>To learn more, refer to this <a href=\"https://repost.aws/articles/ARDaRTyEVQR9iWfVdek2CQwg/get-started-with-deepseek-r1-on-aws-inferentia-and-trainium\">step-by-step guide</a> on how to deploy DeepSeek-R1-Distill Llama models on AWS Inferentia and Trainium.</p> \n<p>You can also visit <a href=\"https://huggingface.co/collections/deepseek-ai/deepseek-r1-678e1e131c0169c0bc89728d\">DeepSeek-R1-Distill models cards</a> on Hugging Face, such as <a href=\"https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B\">DeepSeek-R1-Distill-Llama-8B</a> or <a href=\"https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-70B\">deepseek-ai/DeepSeek-R1-Distill-Llama-70B</a>. Choose <b>Deploy</b> and then <b>Amazon SageMaker</b>. From the <b>AWS Inferentia and Trainium</b> tab, copy the example code for deploy DeepSeek-R1-Distill models.</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/01/30/2025-deepseek-r1-on-aws-8-hugging-face.png\" alt=\"\" width=\"1974\" height=\"1354\" /></p> \n<p>Since the release of DeepSeek-R1, various guides of its deployment for Amazon EC2 and <a href=\"https://aws.amazon.com/eks/\">Amazon Elastic Kubernetes Service (Amazon EKS)</a> have been posted. Here is some additional material for you to check out:</p> \n<ul> \n <li><a href=\"https://community.aws/content/2Z6DlAohx12yuNoEAs7qb5YTH0q/leveraging-deepseek-r1-on-aws\">Leveraging DeepSeek-R1 with CPU and GPU options on AWS </a>by <a href=\"https://community.aws/@wirjo\">Daniel Wirjo</a></li> \n <li><a href=\"https://community.aws/content/2sHGS4Eqeekz32OOzn7am5lnGEX/benefits-of-installing-deepseek-on-an-aws-ec2-instance\">Benefits of installing DeepSeek on an Amazon EC2 instance</a> by <a href=\"https://community.aws/@kikitos\">Enrique Aguilar Martinez</a></li> \n <li><a href=\"https://community.aws/content/2sKnCT05v1WiD0Dw8QB5wfAf1Cm/deploying-deepseek-llama-model-on-amazon-ec2-inferentia-instance\">Deploying DeepSeek Llama models on Amazon EC2 inferentia instance</a> by <a href=\"https://community.aws/@irshadc\">Irshad Chohan</a></li> \n <li><a href=\"https://huggingface.co/blog/deepseek-r1-aws\">How to deploy and fine-tune DeepSeek models on AWS</a> by <a href=\"https://huggingface.co/\">Hugging Face</a></li> \n <li><a href=\"https://community.aws/content/2sJofoAecl6jVdDwVqglbZwKz2E/hosting-deepseek-r1-on-amazon-eks\">Hosting DeepSeek-R1 on Amazon EKS Auto Mode</a> by <a href=\"https://community.aws/@tiagoreichert\">Tiago Reichert</a></li> \n</ul> \n<p><b><u>Things to know</u></b><br /> Here are a few important things to know.</p> \n<ul> \n <li><b>Pricing</b> – For publicly available models like DeepSeek-R1, you are charged only the infrastructure price based on inference instance hours you select for Amazon Bedrock Markeplace, Amazon SageMaker JumpStart, and Amazon EC2. For the Bedrock Custom Model Import, you are only charged for model inference, based on the number of copies of your custom model is active, billed in 5-minute windows. To learn more, check out the <a href=\"https://aws.amazon.com/bedrock/pricing/\">Amazon Bedrock Pricing</a>, <a href=\"https://aws.amazon.com/sagemaker-ai/pricing/\">Amazon SageMaker AI Pricing</a>, and <a href=\"https://aws.amazon.com/ec2/pricing/\">Amazon EC2 Pricing</a> pages.</li> \n <li><b>Data security</b><b> </b>– You can use enterprise-grade security features in Amazon Bedrock and Amazon SageMaker to help you make your data and applications secure and private. This means your data is not shared with model providers, and is not used to improve the models. This applies to all models—proprietary and publicly available—like DeepSeek-R1 models on Amazon Bedrock and Amazon SageMaker. To learn more, visit <a href=\"https://aws.amazon.com/bedrock/security-compliance/\">Amazon Bedrock Security and Privacy</a> and <a href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/security.html\">Security in Amazon SageMaker AI</a>.</li> \n</ul> \n<p><b><u>Now available</u></b><br /> DeepSeek-R1 is generally available today in Amazon Bedrock Marketplace and Amazon SageMaker JumpStart in US East (Ohio) and US West (Oregon) AWS Regions. You can also use DeepSeek-R1-Distill models using Amazon Bedrock Custom Model Import and Amazon EC2 instances with AWS Trainum and Inferentia chips.</p> \n<p>Give DeepSeek-R1 models a try today in the <a href=\"https://console.aws.amazon.com/bedrock\">Amazon Bedrock console</a>, <a href=\"https://console.aws.amazon.com/sagemaker\">Amazon SageMaker AI console</a>, and <a href=\"https://console.aws.amazon.com/ec2\">Amazon EC2 console</a>, and send feedback to <a href=\"https://repost.aws/tags/TAQeKlaPaNRQ2tWB6P7KrMag/amazon-bedrock\">AWS re:Post for Amazon Bedrock</a> and <a href=\"https://repost.aws/tags/TAT80swPyVRPKPcA0rsJYPuA/amazon-sagemaker\">AWS re:Post for SageMaker AI</a> or through your usual AWS Support contacts.</p> \n<p>— <a href=\"https://twitter.com/channyun\">Channy</a></p> \n<p><em><strong>Updated on 1st February</strong> — Added more screenshots and demo video of Amazon Bedrock Playground.</em></p> \n<p><em><strong>Updated on 3rd February</strong> — Fixed unclear message for DeepSeek-R1 Distill model names and SageMaker Studio interface.</em></p>","author":"Channy Yun (윤석찬)","siteTitle":"AWS News Blog","siteHash":"6093e072e4117ec22616e844cb857d03ca62c57a411a8affc77cb5e8b6b15bf6","entryHash":"3c5682ef4de477582ee3dae394895a5d13c576760b7e8ba0bb78c93104f8df6d","category":"Tech"}