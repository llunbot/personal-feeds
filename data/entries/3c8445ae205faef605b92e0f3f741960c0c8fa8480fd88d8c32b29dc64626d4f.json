{"title":"กูเกิลปล่อย Gemma 3 QAT ฝึกแบบย่อเพื่อการรันบนพีซีโดยเฉพาะ","link":"https://www.blognone.com/node/145935","date":1744983725000,"content":"<div><div><div><p>กูเกิลปล่อยโมเดลปัญญาประดิษฐ์ Gemma 3 รุ่นย่อแบบ Quantization Aware Training (QAT) เป็นโมเดลที่ถูกฝึกระหว่างการย่อโมเดลเหลือ Q4_O เล็กพอที่จะรัน Gemma 3 27B ในการ์ดจอแรม 14.1GB</p>\n<p>โมเดล QAT อาศัยโมเดลเต็มแบบ BF16 เป็นต้นแบบแล้วฝึกโมเดลที่กำลังย่อให้จำลองตัวเองว่าถูกย่อไปแล้ว แต่ให้หาทางสร้างคำตอบให้ใกล้เคียงโมเดลเต็มให้ได้ การฝึกนี้ทำซ้ำประมาณ 5,000 รอบ กระบวนการนี้ทำให้เมื่อได้โมเดลสุดท้ายและย่อฟอร์แมตพารามิเตอร์ออกมาแล้วคุณภาพตกลงไปจากโมเดลต้นแบบไม่มาก</p>\n<p>Gemma 3 QAT รองรับทั้ง Ollama, LM Studio, MLX, Gemma.cpp, และ llama.cpp โมเดลมี 4 รุ่นเท่ากับ Gemma 3 ตัวเต็ม ทำให้รุ่นเล็กที่สุดขนาดเพียง 0.5GB รันในโทรศัพท์มือถือได้</p>\n<p>ที่มา - <a href=\"https://developers.googleblog.com/en/gemma-3-quantized-aware-trained-state-of-the-art-ai-to-consumer-gpus/\">Google</a></p>\n<p><img src=\"https://www.blognone.com/sites/default/files/externals/fcf43fe5b53d13b1c52e9d36db089597.png\" alt=\"\" /></p>\n</div></div></div><div><div>Topics: </div><div><div><a href=\"/topics/gemini\">Gemini</a></div><div><a href=\"/topics/google\">Google</a></div><div><a href=\"/topics/llm\">LLM</a></div></div></div>","author":"lew","siteTitle":"Blognone","siteHash":"ededadcf18490b3937e7dd89ebe8c00dc129addbdf1ebe4aff1f458146693da0","entryHash":"3c8445ae205faef605b92e0f3f741960c0c8fa8480fd88d8c32b29dc64626d4f","category":"Thai"}