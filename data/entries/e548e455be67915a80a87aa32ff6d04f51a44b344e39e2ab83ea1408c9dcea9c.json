{"title":"Quantum computing startup says it will beat IBM to error correction","link":"https://arstechnica.com/?p=1994815","date":1704836984000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2024/01/QuEras-Aquila-neutral-atom-quantum-computer-800x600.jpeg\" alt=\"The current generation of hardware, which will see rapid iteration over the next several years.\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2024/01/QuEras-Aquila-neutral-atom-quantum-computer.jpeg\">Enlarge</a> <span>/</span> The current generation of hardware, which will see rapid iteration over the next several years. (credit: QuEra)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>On Tuesday, the quantum computing startup Quera laid out a road map that will bring error correction to quantum computing in only two years and enable useful computations using it by 2026, years ahead of when <a href=\"https://arstechnica.com/science/2023/12/ibm-adds-error-correction-to-updated-quantum-computing-roadmap/\">IBM plans to offer the equivalent</a>. Normally, this sort of thing should be dismissed as hype. Except the company is Quera, which is a spinoff of the Harvard Universeity lab that demonstrated the <a href=\"https://arstechnica.com/science/2023/12/quantum-computer-performs-error-resistant-operations-with-logical-qubits/\">ability to identify and manage errors</a> using hardware that's similar in design to what Quera is building.</p>\n<p>Also notable: Quera uses the same type of qubit that a rival startup, Atom Computing, has <a href=\"https://arstechnica.com/science/2023/10/atom-computing-is-the-first-to-announce-a-1000-qubit-quantum-computer/\">already scaled up to over 1,000 qubits</a>. So, while the announcement should be viewed cautiously—several companies have promised rapid scaling and then failed to deliver—there are some reasons it should be viewed seriously as well.</p>\n<h2>It’s a trap!</h2>\n<p>Current qubits, regardless of their design, are prone to errors during measurements, operations, or even when simply sitting there. While it's possible to improve these error rates so that simple calculations can be done, most people in the field are skeptical it will ever be possible to drop these rates enough to do the elaborate calculations that would fulfill the promise of quantum computing. The consensus seems to be that, outside of a few edge cases, useful computation will require error-corrected qubits.</p></div><p><a href=\"https://arstechnica.com/?p=1994815#p3\">Read 16 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=1994815&amp;comments=1\">Comments</a></p>","author":"John Timmer","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"e548e455be67915a80a87aa32ff6d04f51a44b344e39e2ab83ea1408c9dcea9c","category":"Tech"}