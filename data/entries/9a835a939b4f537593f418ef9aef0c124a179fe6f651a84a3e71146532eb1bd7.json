{"title":"Research Suggests Facebook’s Algorithm Is ‘Influential’ but Doesn’t Necessarily Change Beliefs","link":"https://www.nytimes.com/2023/07/27/technology/facebook-instagram-algorithms.html","date":1690833582000,"content":"\n<p>Mike Isaac and Sheera Frenkel, reporting last week for The New York Times:</p>\n\n<blockquote>\n  <p>In the papers, researchers from the University of Texas, New York\nUniversity, Princeton and other institutions found that removing\nsome key functions of the social platforms’ algorithms had “no\nmeasurable effects” on people’s political beliefs. In <a href=\"https://www.science.org/doi/10.1126/science.add8424?adobe_mc=MCMID%3D61761082717445531361376140889916401782%7CMCORGID%3D242B6472541199F70A4C98A6%2540AdobeOrg%7CTS%3D1690482061\">one\nexperiment</a> on Facebook’s algorithm, people’s knowledge of\npolitical news declined when their ability to reshare posts was\nremoved, the researchers said.</p>\n\n<p>At the same time, the consumption of political news on Facebook\nand Instagram was highly segregated by ideology, according to\n<a href=\"https://www.science.org/doi/10.1126/science.ade7138?adobe_mc=MCMID%3D61761082717445531361376140889916401782%7CMCORGID%3D242B6472541199F70A4C98A6%2540AdobeOrg%7CTS%3D1690482061\">another study</a>. More than 97 percent of the links to news\nstories rated as false by fact checkers on the apps during the\n2020 election drew more conservative readers than liberal readers,\nthe research found. [...] Still, the proportion of false news\narticles that Facebook users read was low compared with all news\narticles viewed, researchers said.</p>\n</blockquote>\n\n<p>False news articles were low overall, but the articles deemed false were overwhelming consumed by conservatives. That’s no surprise, but to me, gets to the heart of the controversy. A hypothetical social media algorithm that promotes true stories and suppresses false ones, with perfect accuracy, is going to be accused by conservatives of being biased against conservatives, because conservatives are drawn to false stories.</p>\n\n<p>Jeff Horwitz, <a href=\"https://www.wsj.com/articles/does-facebook-polarize-users-meta-disagrees-with-partners-over-research-conclusions-24fde67a\">reporting for The Wall Street Journal</a> (<a href=\"https://apple.news/AZgaujY9rTG2a3TFHtLQryw\">News+ link</a>), on Facebook overstating the degree to which these new studies exonerate its platforms’ influence:</p>\n\n<blockquote>\n  <p>Science warned Meta earlier this week that it would publicly\ndispute an assertion that the published studies should be read as\nlargely exonerating Meta of a contributing role in societal\ndivisions, said Meagan Phelan, who oversees the communication of\nScience’s findings.</p>\n\n<p>“The findings of the research suggest Meta algorithms are an\nimportant part of what is keeping people divided,” Phelan told\nMeta’s communications team on Monday, according to an excerpt of\nher message she shared with The Wall Street Journal. She added\nthat one of the studies found that “compared to liberals,\npolitically conservative users were far more siloed in their news\nsources, driven in part by algorithmic processes, and especially\napparent on Facebook’s Pages and Groups.”</p>\n</blockquote>\n\n<div>\n<a href=\"https://daringfireball.net/linked/2023/07/31/facebook-research\"> ★ </a>\n</div>\n\n\t","author":"John Gruber","siteTitle":"Daring Fireball","siteHash":"fc569638025dadf22a867470f8215f38855cf50e975782a6c989909474292a36","entryHash":"9a835a939b4f537593f418ef9aef0c124a179fe6f651a84a3e71146532eb1bd7","category":"Tech"}