{"title":"FlashAttention: Fast Transformer training with long sequences","link":"https://www.adept.ai/blog/flashier-attention","date":1696159380000,"content":"<a href=\"https://news.ycombinator.com/item?id=37724861\">Comments</a>","author":"","siteTitle":"Hacker News","siteHash":"37bb545430005dba450c1e40307450d8e4e791b434e83f3d38915ebad510fd50","entryHash":"9077c7ca90fabcbf1eec667476510031db16a373395ecd149f9401263b67cbd4","category":"Tech"}