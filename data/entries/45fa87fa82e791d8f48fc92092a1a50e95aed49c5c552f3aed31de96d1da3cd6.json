{"title":"ไมโครซอฟท์โชว์ ONNX Runtime รันโมเดล AI ภายในเครื่องพีซีวินโดวส์ เปิดให้แอพอื่นใช้ได้ด้วย","link":"https://www.blognone.com/node/134015","date":1685005109000,"content":"<div><div><div><p>เก็บตกของใหม่จากงาน Microsoft Build 2023 ที่สำคัญต่อการรันโมเดล AI บนพีซีวินโดวส์ โดยไมโครซอฟท์ประกาศรองรับ ONNX Runtime บนวินโดวส์ และเปิดให้แอพตัวอื่นๆ ใช้งาน</p>\n<p>Open Neural Network Exchange (ONNX) เป็นโครงการฟอร์แมตกลางของโมเดล AI <a href=\"https://www.blognone.com/node/95343\">ที่ไมโครซอฟท์กับเฟซบุ๊กร่วมกันทำในปี 2017</a> และ<a href=\"https://www.blognone.com/node/101989\">มีสมาชิกเข้าร่วมมากขึ้นเรื่อยๆ แม้แต่แอปเปิลยังเข้าร่วม</a> (แต่กูเกิลไม่เข้า เพราะ ONNX อิงกับ PyTorch เป็นหลัก) ส่วน <a href=\"https://onnxruntime.ai/\">ONNX Runtime</a> คือซอฟต์แวร์ที่ช่วยให้รันโมเดลในฟอร์แมต ONNX บนแพลตฟอร์มต่างๆ ได้</p>\n<p>ที่ผ่านมาไมโครซอฟท์เน้นการรันโมเดล AI ที่ฝั่งเซิร์ฟเวอร์คือเครื่องของ Azure เป็นหลัก ข่าวนี้คือฝั่งไคลเอนต์วินโดวส์รองรับการรันโมเดล ONNX ผ่าน ONNX Runtime แล้ว, <a href=\"https://onnxruntime.ai/docs/performance/olive.html\">ออกเครื่องมือชื่อ Olive คอยบีบอัดโมเดลมารันบนพีซี</a> และแอพค่ายอื่นที่ไม่ใช่ไมโครซอฟท์สามารถสั่งรันโมเดล AI ภายในเครื่องพีซี (on-device) ได้ด้วย โดยใช้ API ตัวเดียวกับฝั่งเซิร์ฟเวอร์เลย</p>\n<p><img alt=\"No Description\" src=\"https://www.blognone.com/sites/default/files/externals/90c931f154e3055001e5ea65fa5ce222.png\" /></p>\n<p>การรันโมเดลบนวินโดวส์ ยังสามารถใช้ประโยชน์จากฟีเจอร์เร่งการประมวลผล AI ในซีพียู จีพียู หรือ NPU ได้ด้วย ซึ่งไมโครซอฟท์ก็ประกาศความร่วมมือกับผู้ผลิตฮาร์ดแวร์ 3 รายคือ <a href=\"https://community.amd.com/t5/corporate/amd-accelerates-ai-adoption-on-windows-11-with-new-developer/ba-p/607847\">AMD</a> (ซีพียู Ryzen บางรุ่น), <a href=\"https://blogs.nvidia.com/blog/2023/05/23/microsoft-build-nvidia-ai-windows-rtx/\">NVIDIA</a> (Tensor Core ในการ์ด RTX), <a href=\"https://www.qualcomm.com/news/releases/2023/05/qualcomm-and-microsoft-align-efforts-to-scale-on-device-ai-at-bu\">Qualcomm</a> (NPU ใน Snapdragon 8cx Gen 3) ให้รองรับฟีเจอร์นี้แล้ว</p>\n<p>กรณีของ Qualcomm โชว์การรันโมเดลสร้างภาพ Stable Diffusion ขนาด 1 พันล้านพารามิเตอร์บน Snapdragon ล้วนๆ ได้แล้ว และบอกว่าจะสามารถรันโมเดลขนาด 10 พันล้านพารามิเตอร์ได้ด้วยเช่นกัน</p>\n<p>ไมโครซอฟท์ยังบอกว่าแอพดังๆ อย่าง WhatsApp, Luminar Neo, Camo เริ่มใช้งานฟีเจอร์ ONNX Runtime เพื่อรันโมเดลในแอพของตัวเองแล้ว และจะมีแอพอื่นๆ ตามมาในภายหลัง</p>\n<p><img alt=\"No Description\" src=\"https://www.blognone.com/sites/default/files/externals/2164298a7b556a6fe89e6d3587ad072f.png\" /></p>\n<p>ที่มา - <a href=\"https://blogs.windows.com/windowsdeveloper/2023/05/23/unlocking-the-end-to-end-windows-ai-developer-experience-using-onnx-runtime-and-olive/\">Microsoft (1)</a>, <a href=\"https://blogs.windows.com/windowsdeveloper/2023/05/23/bringing-the-power-of-ai-to-windows-11-unlocking-a-new-era-of-productivity-for-customers-and-developers-with-windows-copilot-and-dev-home/\">Microsoft (2)</a></p>\n</div></div></div><div><div>Topics: </div><div><div><a href=\"/topics/onnx\">ONNX</a></div><div><a href=\"/topics/windows-11\">Windows 11</a></div><div><a href=\"/topics/artificial-intelligence\">Artificial Intelligence</a></div><div><a href=\"/topics/microsoft\">Microsoft</a></div><div><a href=\"/topics/operating-system\">Operating System</a></div></div></div>","author":"mk","siteTitle":"Blognone","siteHash":"ededadcf18490b3937e7dd89ebe8c00dc129addbdf1ebe4aff1f458146693da0","entryHash":"45fa87fa82e791d8f48fc92092a1a50e95aed49c5c552f3aed31de96d1da3cd6","category":"Thai"}