{"title":"Open-R1 ได้ผลผลิตแรก OlympicCoder-7B โมเดลขนาดเล็กสำหรับเขียนโปรแกรม เอาชนะ DeepSeek-R1 เฉพาะหัวข้อได้แล้ว","link":"https://www.blognone.com/node/145216","date":1741749485000,"content":"<div><div><div><p>หลังจาก <a href=\"https://www.blognone.com/node/144365\">HuggingFace พยายามทำซ้ำ DeepSeek-R1 แบบเปิดทั้งหมด</a> ตอนนี้ก็มีผลผลิตแรกแล้วเป็นโมเดล OlympicCoder-7B ที่พัฒนาต่อมาจาก Qwen2.5-Coder</p>\n<p>OlympicCoder-7B อาศัยชุดข้อมูลคิดก่อนตอบจาก CodeForces-CoTs ที่ใส่โจทย์เขียนโปรแกรมภาษา C++ และ Python ลง DeepSeek-R1 กว่าแสนข้อ โดยนำโมเดล Qwen2.5-Coder ขนาด 7B และ 32B มาใช้งาน ตอนนี้ทดสอบเฉพาะชุดข้อสอบโอลิมปิก ผลทดสอบที่ได้ OlympicCoder-32B สามารถเอาชนะ QwQ-32B และ DeepSeek-R1 ไปได้ โดยยังเป็นรอง o1 และ o3-mini อยู่</p>\n<p>บทเรียนจากการฝึก OlympicCoder ทำให้ทีมงานได้บทเรียนหลายอย่าง เช่น เทคนิคการฝึก sample packing ทำให้ประสิทธิภาพโมเดลลดลง, learning rate สามามารถปรับให้สูงขึ้นได้, พบปัญหาโมเดลไม่ยอมคิดในปัญหาอื่นๆ ที่ไม่ได้ฝึกไว้ก่อน, ปัญหาหน่วยความจำจากการฝึกกับข้อความส่วนคิดในใจที่ยาวมาก</p>\n<p>ที่มา - <a href=\"https://huggingface.co/blog/open-r1/update-3\">HuggingFace</a></p>\n<p><img alt=\"No Description\" src=\"https://www.blognone.com/sites/default/files/externals/b8778c641b564eeefa012b839df6eb93.png\" /></p>\n</div></div></div><div><div>Topics: </div><div><div><a href=\"/topics/hugging-face\">Hugging Face</a></div><div><a href=\"/topics/llm\">LLM</a></div></div></div>","author":"lew","siteTitle":"Blognone","siteHash":"ededadcf18490b3937e7dd89ebe8c00dc129addbdf1ebe4aff1f458146693da0","entryHash":"6c5973580e51b1b83cf2134304f1e7740f7f17645b55ec0d93319ffd134a5c81","category":"Thai"}