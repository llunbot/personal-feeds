{"title":"Lamini ร่วมมือ AMD ขายเซิร์ฟเวอร์รัน AI แบบ LLM ระบุประสิทธิภาพเทียบเท่า CUDA แล้ว","link":"https://www.blognone.com/node/135939","date":1695749932000,"content":"<div><div><div><p>Lamini บริษัทขายแพลตฟอร์มฝึกและรันโมเดลปัญญาประดิษฐ์ รวมมือถือกับ AMD เปิดตัว LLM Superstation เซิร์ฟเวอร์สำหรับรันปัญญาประดิษฐ์ LLM โดยเฉพาะ เปิดเครื่องมามี Llama 2-70B ให้ใช้งานทันที</p>\n<p>ความพิเศษของ LLM Superstation คือใช้การ์ด AMD Instinct MI250 แทนที่จะเป็นการ์ด NVIDIA ที่อุตสาหกรรมนิยมกัน ความได้เปรียบของ MI250 คือมันใส่แรมมาถึง 128GB ทำให้รันโมเดลขนาดใหญ่ได้ง่ายกว่าการ์ด A100 (NVIDIA เริ่ม<a href=\"https://www.blognone.com/node/133109\">ใส่แรมเยอะขึ้นในการ์ดรุ่นหลังๆ</a>) และข้อดีสำคัญอีกอย่างคือรอสั่งเครื่องเร็วกว่าเซิร์ฟเวอร์ที่ใช้การ์ด NVIDIA</p>\n<p>ทาง Lamini ระบุว่าบริการของบริษัทเองก็ใช้การ์ด MI210 และ MI250 มาตลอด และ AMD เองก็ใช้แพลตฟอร์ใ Lamini สำหรับ LLM ภายในบริษัทเองเพื่อให้บริการนักพัฒนาด้วย</p>\n<p>Lamini เปิดแบบฟอร์มให้ผู้แสดงความสนใจสั่งซื้อ LLM Superstation แต่ยังไม่บอกราคาหรือสเปคโดยรวม</p>\n<p>ที่มา - <a href=\"https://www.lamini.ai/blog/lamini-amd-paving-the-road-to-gpu-rich-enterprise-llms\">Lamini</a></p>\n<p><img alt=\"No Description\" src=\"https://www.blognone.com/sites/default/files/externals/28a0dd7e1d645e9aa9486837094576b3.png\" /></p>\n</div></div></div><div><div>Topics: </div><div><div><a href=\"/topics/amd\">AMD</a></div><div><a href=\"/topics/llm\">LLM</a></div><div><a href=\"/topics/artificial-intelligence\">Artificial Intelligence</a></div></div></div>","author":"lew","siteTitle":"Blognone","siteHash":"ededadcf18490b3937e7dd89ebe8c00dc129addbdf1ebe4aff1f458146693da0","entryHash":"9fb2a2ce0d788089995386e26bf098a82ea45891967cba45e7b118a31d40d414","category":"Thai"}