{"title":"Intel, Microsoft discuss plans to run Copilot locally on PCs instead of in the cloud","link":"https://arstechnica.com/?p=2012793","date":1711565155000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2024/03/intel-ai-pc-2-800x450.jpeg\" alt=\"The basic requirements for an AI PC, at least when it's running Windows.\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2024/03/intel-ai-pc-2.jpeg\">Enlarge</a> <span>/</span> The basic requirements for an AI PC, at least when it's running Windows. (credit: Intel)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>Microsoft <a href=\"https://arstechnica.com/gadgets/2024/01/ai-comes-for-your-pcs-keyboard-as-microsoft-adds-dedicated-copilot-key/\">said in January</a> that 2024 would be the year of the \"AI PC,\" and we know that AI PCs will include a few hardware components that most Windows systems currently do not includeâ€”namely, <a href=\"https://arstechnica.com/ai/2024/02/your-current-pc-probably-doesnt-have-an-ai-processor-but-your-next-one-might/\">a built-in neural processing unit</a> (NPU) and Microsoft's new Copilot key for keyboards. But so far we haven't heard a whole lot about what a so-called AI PC will actually do for users.</p>\n\n<p>Microsoft and Intel are starting to talk about a few details as part of an announcement from Intel about a new AI PC developer program that will encourage software developers to leverage local hardware to build AI features into their apps.</p>\n<p>The main news <a href=\"https://www.tomshardware.com/pc-components/cpus/intel-confirms-microsoft-copilot-will-soon-run-locally-on-pcs-next-gen-ai-pcs-require-40-tops-of-npu-performance\">comes from Tom's Hardware</a>, confirming that AI PCs would be able to run \"more elements of Copilot,\" Microsoft's AI chatbot assistant, \"locally on the client.\" Currently, Copilot relies on server-side processing even for small requests, introducing lag that is tolerable if you're making a broad request for information but less so if all you want to do is change a setting or get basic answers. Running generative AI models locally could also improve user privacy, making it possible to take advantage of AI-infused software without automatically sending information to a company that will use it for further model training.</p></div><p><a href=\"https://arstechnica.com/?p=2012793#p3\">Read 5 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=2012793&amp;comments=1\">Comments</a></p>","author":"Andrew Cunningham","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"7ca042a6e66bbb03871e31e6ebc57ff4bc807730baaf3e4dd89ec3c55fe9c2a9","category":"Tech"}