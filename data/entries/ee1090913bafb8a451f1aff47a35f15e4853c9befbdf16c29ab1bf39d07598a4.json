{"title":"Sam Altman accused of being shady about OpenAIâ€™s safety efforts","link":"https://arstechnica.com/?p=2040870","date":1722622134000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2024/08/GettyImages-1930535859-800x523.jpg\" alt=\"Sam Altman, chief executive officer of OpenAI, during an interview at Bloomberg House on the opening day of the World Economic Forum (WEF) in Davos, Switzerland, on Tuesday, Jan. 16, 2024.\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2024/08/GettyImages-1930535859.jpg\">Enlarge</a> <span>/</span> Sam Altman, chief executive officer of OpenAI, during an interview at Bloomberg House on the opening day of the World Economic Forum (WEF) in Davos, Switzerland, on Tuesday, Jan. 16, 2024. (credit: <a href=\"https://www.gettyimages.com/detail/news-photo/sam-altman-chief-executive-officer-of-openai-during-an-news-photo/1930535859?adppopup=true\">Bloomberg / Contributor | Bloomberg</a>)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>OpenAI is facing increasing pressure to prove it's not hiding AI risks after whistleblowers alleged to the US Securities and Exchange Commission (SEC) that the AI company's <a href=\"https://arstechnica.com/tech-policy/2024/05/openai-ends-harsh-non-disparagement-agreements-that-could-claw-back-millions/\">non-disclosure agreements had illegally silenced employees</a> from disclosing major safety concerns to lawmakers.</p>\n<p>In a <a href=\"https://www.washingtonpost.com/documents/8bf076a6-663b-4552-be52-079b79274f9c.pdf\">letter</a> to OpenAI yesterday, Senator Chuck Grassley (R-Iowa) demanded evidence that OpenAI is no longer requiring agreements that could be \"stifling\" its \"employees from making protected disclosures to government regulators.\"</p>\n<p>Specifically, Grassley asked OpenAI to produce current employment, severance, non-disparagement, and non-disclosure agreements to reassure Congress that contracts don't discourage disclosures. That's critical, Grassley said, so that it will be possible to rely on whistleblowers exposing emerging threats to help shape effective AI policies safeguarding against existential AI risks as technologies advance.</p></div><p><a href=\"https://arstechnica.com/?p=2040870#p3\">Read 27 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=2040870&amp;comments=1\">Comments</a></p>","author":"Ashley Belanger","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"ee1090913bafb8a451f1aff47a35f15e4853c9befbdf16c29ab1bf39d07598a4","category":"Tech"}