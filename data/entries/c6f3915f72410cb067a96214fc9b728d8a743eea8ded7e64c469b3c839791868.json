{"title":"Chasing defamatory hallucinations, FTC opens investigation into OpenAI","link":"https://arstechnica.com/?p=1953636","date":1689274387000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2023/05/getty-sam-altman-800x534.jpg\" alt=\"OpenAI CEO Sam Altman sits at a table and speaks into a microphone while testifying in a Senate hearing.\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2023/05/getty-sam-altman.jpg\">Enlarge</a> <span>/</span> OpenAI CEO Sam Altman testifies about AI rules before the Senate Judiciary Subcommittee on Privacy, Technology, and the Law on May 16, 2023, in Washington, DC.  (credit: Getty Images | Win McNamee )</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>OpenAI, best known for its <a href=\"https://arstechnica.com/information-technology/2022/12/openai-invites-everyone-to-test-new-ai-powered-chatbot-with-amusing-results/\">ChatGPT</a> AI assistant, has come under scrutiny by the US Federal Trade Commission (FTC) over allegations that it violated consumer protection laws, potentially putting personal data and reputations at risk, according to <a href=\"https://www.washingtonpost.com/technology/2023/07/13/ftc-openai-chatgpt-sam-altman-lina-khan/?utm_campaign=wp_main&amp;utm_medium=social&amp;utm_source=twitter\">The Washington Post</a> and <a href=\"https://www.reuters.com/technology/us-ftc-opens-investigation-into-openai-washington-post-2023-07-13/\">Reuters</a>.</p>\n\n<p>As part of the investigation, the FTC sent a 20-page <a href=\"https://www.washingtonpost.com/documents/67a7081c-c770-4f05-a39e-9d02117e50e8.pdf?itid=lk_inline_manual_4\">record request</a> to OpenAI that focuses on the company's risk management strategies surrounding its AI models. The agency is investigating whether the company has engaged in deceptive or unfair practices, resulting in reputational harm to consumers.</p>\n<p>The inquiry is also seeking to understand how OpenAI has addressed the potential of its products to generate false, misleading, or disparaging statements about real individuals. In the AI industry, these false generations are sometimes called \"hallucinations\" or \"<a href=\"https://arstechnica.com/information-technology/2023/04/why-ai-chatbots-are-the-ultimate-bs-machines-and-how-people-hope-to-fix-them/\">confabulations</a>.\"</p></div><p><a href=\"https://arstechnica.com/?p=1953636#p3\">Read 5 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=1953636&amp;comments=1\">Comments</a></p>","author":"Benj Edwards","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"c6f3915f72410cb067a96214fc9b728d8a743eea8ded7e64c469b3c839791868","category":"Tech"}