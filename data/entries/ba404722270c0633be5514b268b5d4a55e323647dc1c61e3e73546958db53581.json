{"title":"Over half of LLM-written news summaries have “significant issues”—BBC analysis","link":"https://arstechnica.com/ai/2025/02/bbc-finds-significant-inaccuracies-in-over-30-of-ai-produced-news-summaries/","date":1739467826000,"content":"<p>Here at Ars, we've done <a href=\"https://arstechnica.com/science/2024/02/scientists-aghast-at-bizarre-ai-rat-with-huge-genitals-in-peer-reviewed-article/\">plenty</a> of <a href=\"https://arstechnica.com/information-technology/2022/11/after-controversy-meta-pulls-demo-of-ai-model-that-writes-scientific-papers/\">coverage</a> of the <a href=\"https://arstechnica.com/ai/2024/10/hospitals-adopt-error-prone-ai-transcription-tools-despite-warnings/\">errors</a> and <a href=\"https://arstechnica.com/information-technology/2024/05/googles-ai-overview-can-give-false-misleading-and-dangerous-answers/\">inaccuracies</a> that <a href=\"https://arstechnica.com/gadgets/2025/01/apple-plans-software-update-after-ai-summaries-get-news-headlines-wrong/\">LLMs</a> often <a href=\"https://arstechnica.com/science/2023/12/humana-also-using-ai-tool-with-90-error-rate-to-deny-care-lawsuit-claims/\">introduce</a> into their responses. Now, the BBC is trying to quantify the scale of this <a href=\"https://arstechnica.com/information-technology/2023/04/why-ai-chatbots-are-the-ultimate-bs-machines-and-how-people-hope-to-fix-them/\">confabulation</a> problem, at least when it comes to summaries of its own news content.</p>\n<p>In <a href=\"https://www.bbc.co.uk/aboutthebbc/documents/bbc-research-into-ai-assistants.pdf\">an extensive report published this week</a>, the BBC analyzed how four popular large language models used or abused information from BBC articles when answering questions about the news. The results found inaccuracies, misquotes, and/or misrepresentations of BBC content in a significant proportion of the tests, supporting the news organization's conclusion that \"AI assistants cannot currently be relied upon to provide accurate news, and they risk misleading the audience.\"</p>\n<h2>Where did you come up with <em>that</em>?</h2>\n<p>To assess the state of AI news summaries, BBC's Responsible AI team gathered 100 news questions related to trending Google search topics from the last year (e.g., \"How many Russians have died in Ukraine?\" or \"What is the latest on the independence referendum debate in Scotland?\"). These questions were then put to ChatGPT-4o, Microsoft Copilot Pro, Google Gemini Standard, and Perplexity, with the added instruction to \"use BBC News sources where possible.\"</p><p><a href=\"https://arstechnica.com/ai/2025/02/bbc-finds-significant-inaccuracies-in-over-30-of-ai-produced-news-summaries/\">Read full article</a></p>\n<p><a href=\"https://arstechnica.com/ai/2025/02/bbc-finds-significant-inaccuracies-in-over-30-of-ai-produced-news-summaries/#comments\">Comments</a></p>","author":"Kyle Orland","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"ba404722270c0633be5514b268b5d4a55e323647dc1c61e3e73546958db53581","category":"Tech"}