{"title":"Amazon Aurora PostgreSQL and Amazon DynamoDB zero-ETL integrations with Amazon Redshift now generally available","link":"https://aws.amazon.com/blogs/aws/amazon-aurora-postgresql-and-amazon-dynamodb-zero-etl-integrations-with-amazon-redshift-now-generally-available/","date":1729022383000,"content":"<p>Today, I am excited to announce the general availability of <a href=\"https://aws.amazon.com/rds/aurora/zero-etl/\">Amazon Aurora PostgreSQL-Compatible Edition</a> and <a href=\"https://aws.amazon.com/dynamodb/integrations/\">Amazon DynamoDB</a> zero-ETL integrations with <a href=\"https://aws.amazon.com/redshift/\">Amazon Redshift</a>. Zero-ETL integration seamlessly makes transactional or operational data available in Amazon Redshift, removing the need to build and manage complex data pipelines that perform extract, transform, and load (ETL) operations. It automates the replication of source data to Amazon Redshift, simultaneously updating source data for you to use in Amazon Redshift for analytics and machine learning (ML) capabilities to derive timely insights and respond effectively to critical, time-sensitive events.</p> \n<p>Using these new zero-ETL integrations, you can run unified analytics on your data from different applications without having to build and manage different data pipelines to write data from multiple relational and non-relational data sources into a single data warehouse. In this post, I provide two step-by-step walkthroughs on how to get started with both Amazon Aurora PostgreSQL and Amazon DynamoDB zero-ETL integrations with Amazon Redshift.</p> \n<p>To create a zero-ETL integration, you specify a source and Amazon Redshift as the target. The integration replicates data from the source to the target data warehouse, making it available in Amazon Redshift seamlessly, and monitors the pipeline’s health.</p> \n<p>Let’s explore how these new integrations work. In this post, you will learn how to create zero-ETL integrations to replicate data from different source databases (Aurora PostgreSQL and DynamoDB) to the same Amazon Redshift cluster. You will also learn how to select multiple tables or databases from Aurora PostgreSQL source databases to replicate data to the same Amazon Redshift cluster. You will observe how zero-ETL integrations provide flexibility without the operational burden of building and managing multiple ETL pipelines.</p> \n<p><span><strong>Getting started with Aurora PostgreSQL zero-ETL integration with Amazon Redshift</strong></span><br /> Before creating a database, I create a custom cluster parameter group because Aurora PostgreSQL zero-ETL integration with Amazon Redshift requires specific values for the <a href=\"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/zero-etl.setting-up.html#zero-etl.parameters\">Aurora DB cluster parameters</a>. In the <a href=\"https://console.aws.amazon.com/rds\">Amazon RDS console</a>, I go to <strong>Parameter groups</strong> in the navigation pane. I choose <strong>Create parameter group</strong>.</p> \n<p>I enter <code>custom-pg-aurora-postgres-zero-etl</code> for <strong>Parameter group name</strong> and <strong>Description</strong>. I choose <strong>Aurora PostgreSQL</strong> for <strong>Engine type</strong> and <strong>aurora-postgresql16 </strong>for <strong>Parameter group family</strong> (zero-ETL integration works with PostgreSQL 16.4 or above versions). Finally, I choose <strong>DB Cluster Parameter Group</strong> for <strong>Type </strong>and choose <strong>Create</strong>.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/17/01a-create-custom-pg-LaunchMarketingIntake-1191.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/17/01a-create-custom-pg-LaunchMarketingIntake-1191.png\" width=\"1696\" height=\"1482\" /></a></p> \n<p>Next, I edit the newly created cluster parameter group by choosing it on the <strong>Parameter groups</strong> page. I choose <strong>Actions</strong> and then choose <strong>Edit</strong>. I set the following cluster parameter settings:</p> \n<ul> \n <li><code>rds.logical_replication=1</code></li> \n <li><code>aurora.enhanced_logical_replication=1</code></li> \n <li><code>aurora.logical_replication_backup=0</code></li> \n <li><code>aurora.logical_replication_globaldb=0</code></li> \n</ul> \n<p>I choose <strong>Save Changes</strong>.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/17/02-edit-custom-pg-LaunchMarketingIntake-1191.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/17/02-edit-custom-pg-LaunchMarketingIntake-1191.png\" width=\"2222\" height=\"1042\" /></a></p> \n<p>Next, I create an <a href=\"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/CHAP_GettingStartedAurora.CreatingConnecting.AuroraPostgreSQL.html\">Aurora PostgreSQL database</a>. When creating the database, you can set the configurations according to your needs. Remember to choose <strong>Aurora PostgreSQL (compatible with PostgreSQL 16.4 or above) </strong>from <strong>Available versions </strong>and the custom cluster parameter group (<code>custom-pg-aurora-postgres-zero-etl</code> in this case) for <strong>DB cluster parameter group</strong> in the <strong>Additional configuration</strong> section.</p> \n<p>After the database becomes available, I connect to the Aurora PostgreSQL cluster, create a database named <strong>books,</strong> create a table named <strong>book_catalog</strong> in the default schema for this database and insert sample data to use with zero-ETL integration.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/22/03e-postgresdb-LaunchMarketingIntake-1191.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/22/03e-postgresdb-LaunchMarketingIntake-1191.png\" width=\"2506\" height=\"290\" /></a></p> \n<p>To get started with zero-ETL integration, I use an existing Amazon Redshift data warehouse. To create and manage Amazon Redshift resources, visit the <a href=\"https://docs.aws.amazon.com/redshift/latest/gsg/new-user-serverless.html\">Amazon Redshift Getting Started Guide</a>.</p> \n<p>In the Amazon RDS console, I go to the <strong>Zero-ETL integrations</strong> tab in the navigation pane and choose <strong>Create zero-ETL integration</strong>. I enter <code>postgres-redshift-zero-etl</code> for <strong>Integration identifier </strong>and <code>Amazon Aurora zero-ETL integration with Amazon Redshift</code> for <strong>Integration description</strong>. I choose <strong>Next</strong>.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/17/04-postgres-zetl-LaunchMarketingIntake-1191.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/17/04-postgres-zetl-LaunchMarketingIntake-1191.png\" width=\"2740\" height=\"1332\" /></a></p> \n<p>On the next page, I choose <strong>Browse RDS databases</strong> to select the source database. For the <strong>Data filtering options</strong>, I use <code>database.schema.table</code> pattern. I include my table called <strong>book_catalog</strong> in Aurora PostgreSQL <strong>books</strong> database. The <code>*</code> in filters will replicate all <strong>book_catalog</strong> tables in all schemas within <strong>books</strong> database. I choose <strong>Include</strong> as filter type and enter <code>books.*.book_catalog</code> into the <strong>Filter expression</strong> field. I choose <strong>Next</strong>.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/22/05b-postgres-zetl-LaunchMarketingIntake-1191.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/22/05b-postgres-zetl-LaunchMarketingIntake-1191.png\" width=\"2032\" height=\"1540\" /></a></p> \n<p>On the next page, I choose <strong>Browse Redshift data warehouses</strong> and select the existing Amazon Redshift data warehouse as the target. I must specify authorized principals and integration source on the target to enable Amazon Aurora to replicate into the data warehouse and enable case sensitivity. Amazon RDS can complete these steps for me during setup, or I can configure them manually in Amazon Redshift. For this demo, I choose <strong>Fix it for me</strong> and choose <strong>Next</strong>.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/17/06-postgres-zetl-LaunchMarketingIntake-1191.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/17/06-postgres-zetl-LaunchMarketingIntake-1191.png\" width=\"1124\" height=\"867\" /></a></p> \n<p>After the case sensitivity parameter and the resource policy for data warehouse are fixed, I choose <strong>Next</strong> on the next <strong>Add tags and encryption</strong> page. After I review the configuration, I choose <strong>Create zero-ETL integration</strong>.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/17/07-postgres-zetl-LaunchMarketingIntake-1191.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/17/07-postgres-zetl-LaunchMarketingIntake-1191.png\" width=\"1845\" height=\"882\" /></a></p> \n<p>After the integration succeeded, I choose the integration name to check the details.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/22/08e-postgres-zetl-LaunchMarketingIntake-1191.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/22/08e-postgres-zetl-LaunchMarketingIntake-1191.png\" width=\"2882\" height=\"1582\" /></a></p> \n<p>Now, I need to create a database from integration to finish setting up. I go to the <a href=\"https://console.aws.amazon.com/redshiftv2/home\">Amazon Redshift console</a>, choose <strong>Zero-ETL integrations</strong> in the navigation pane and select the Aurora PostgreSQL integration I just created. I choose <strong>Create database from integration</strong>.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/28/08ab-postgres-zetl-LaunchMarketingIntake-1191.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/28/08ab-postgres-zetl-LaunchMarketingIntake-1191.png\" width=\"2838\" height=\"1558\" /></a></p> \n<p>I choose <strong>books</strong> as <strong>Source named database</strong> and I enter <code>zeroetl_aurorapg</code> as the <strong>Destination database name</strong>. I choose <strong>Create database</strong>.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/22/09f-postgres-zetl-LaunchMarketingIntake-1191.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/22/09f-postgres-zetl-LaunchMarketingIntake-1191.png\" width=\"1206\" height=\"1098\" /></a></p> \n<p>After the database is created, I return to the Aurora PostgreSQL integration page. On this page, I choose <strong>Query data</strong> to connect to the Amazon Redshift data warehouse to observe if the data is replicated. When I run a select query in the <strong>zeroetl_aurorapg</strong> database, I see that the data in <strong>book_catalog</strong> table is replicated to Amazon Redshift successfully.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/22/10a-postgres-zetl-LaunchMarketingIntake-1191.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/22/10a-postgres-zetl-LaunchMarketingIntake-1191.png\" width=\"3032\" height=\"968\" /></a></p> \n<p>As I said in the beginning, you can select multiple tables or databases from the Aurora PostgreSQL source database to replicate the data to the same Amazon Redshift cluster. To add another database to the same zero-ETL integration, all I have to do is to add another filter to the <strong>Data filtering options</strong> in the form of <code>database.schema.table</code>, replacing the database part with the database name I want to replicate. For this demo, I will select multiple tables to be replicated to the same data warehouse. I create another table named <strong>publisher </strong>in the Aurora PostgreSQL cluster and insert sample data to it.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/22/11-postgresdb-LaunchMarketingIntake-1191.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/22/11-postgresdb-LaunchMarketingIntake-1191.png\" width=\"1054\" height=\"280\" /></a></p> \n<p>I edit the <strong>Data filtering options </strong>to include publisher table for replication. To do this, I go to the <strong>postgres-redshift-zero-etl </strong>details page and choose <strong>Modify</strong>. I append <code>books.*.publisher</code> using comma in the <strong>Filter expression</strong> field. I choose <strong>Continue</strong>. I review the changes and choose <strong>Save changes</strong>. I observe that the <strong>Filtered data tables</strong> section on the integration details page has now 2 tables included for replication.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/22/13-postgresdb-LaunchMarketingIntake-1191.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/22/13-postgresdb-LaunchMarketingIntake-1191.png\" width=\"2758\" height=\"866\" /></a></p> \n<p>When I switch to the Amazon Redshift Query editor and refresh the tables, I can see that the new <strong>publisher</strong> table and its records are replicated to the data warehouse.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/22/14-postgresdb-LaunchMarketingIntake-1191.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/22/14-postgresdb-LaunchMarketingIntake-1191.png\" width=\"3032\" height=\"1010\" /></a></p> \n<p>Now that I completed the Aurora PostgreSQL zero-ETL integration with Amazon Redshift, let’s create a DynamoDB zero-ETL integration with the same data warehouse.</p> \n<p><span><strong>Getting started with DynamoDB zero-ETL integration with Amazon Redshift<br /> </strong></span>In this part, I proceed to create an Amazon DynamoDB zero-ETL integration using an existing Amazon DynamoDB table named <strong>Book_Catalog</strong>. The table has 2 items in it:</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/19/20a-dynamodb-zetl-LaunchMarketingIntake-1191.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/19/20a-dynamodb-zetl-LaunchMarketingIntake-1191.png\" width=\"2356\" height=\"942\" /></a></p> \n<p>I go to the <a href=\"https://console.aws.amazon.com/redshiftv2/home\">Amazon Redshift console</a> and choose <strong>Zero-ETL integrations</strong> in the navigation pane. Then, I choose the arrow next to the <strong>Create zero-ETL integration </strong>and choose <strong>Create DynamoDB integration</strong>. I enter <code>dynamodb-redshift-zero-etl</code> for <strong>Integration name</strong> and <code>Amazon DynamoDB zero-ETL integration with Amazon Redshift</code> for <strong>Description</strong>. I choose <strong>Next</strong>.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/17/20-dynamodb-zetl-LaunchMarketingIntake-1191.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/17/20-dynamodb-zetl-LaunchMarketingIntake-1191.png\" width=\"1385\" height=\"587\" /></a></p> \n<p>On the next page, I choose <strong>Browse DynamoDB tables</strong> and select the <strong>Book_Catalog</strong> table. I must specify a resource policy with authorized principals and integration sources, and enable point-in-time recovery (PITR) on the source table before I create an integration. Amazon DynamoDB can do it for me, or I can change the configuration manually. I choose <strong>Fix it for me</strong> to automatically apply the required resource policies for the integration and enable PITR on the DynamoDB table. I choose <strong>Next</strong>.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/18/21a-dynamodb-zetl-LaunchMarketingIntake-1191.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/18/21a-dynamodb-zetl-LaunchMarketingIntake-1191.png\" width=\"1633\" height=\"629\" /></a></p> \n<p>Then, I choose my existing <a href=\"https://aws.amazon.com/redshift/redshift-serverless/\">Amazon Redshift Serverless</a> data warehouse as the target and choose <strong>Next</strong>.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/18/22a-dynamodb-zetl-LaunchMarketingIntake-1191.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/18/22a-dynamodb-zetl-LaunchMarketingIntake-1191.png\" width=\"1638\" height=\"759\" /></a></p> \n<p>I choose <strong>Next</strong> again in the <strong>Add tags and encryption</strong> page and choose <strong>Create DynamoDB integration</strong> in the <strong>Review and create page</strong>.</p> \n<p>Now, I need to create a database from integration to finish setting up just like I did with Aurora PostgreSQL zero-ETL integration. In the Amazon Redshift console, I choose the DynamoDB integration and I choose <strong>Create database from integration</strong>. In the popup screen, I enter <code>zeroetl_dynamodb</code> as the <strong>Destination database name</strong> and choose <strong>Create database</strong>.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/18/24-dynamodb-zetl-LaunchMarketingIntake-1191.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/18/24-dynamodb-zetl-LaunchMarketingIntake-1191.png\" width=\"661\" height=\"478\" /></a></p> \n<p>After the database is created, I go to the Amazon Redshift <strong>Zero-ETL integrations</strong> page and choose the DynamoDB integration I created. On this page, I choose <strong>Query data</strong> to connect to the Amazon Redshift data warehouse to observe if the data from DynamoDB <strong>Book_Catalog</strong> table is replicated. When I run a select query in the <strong>zeroetl_dynamodb</strong> database, I see that the data is replicated to Amazon Redshift successfully. Note that the data from DynamoDB is replicated in <a href=\"https://docs.aws.amazon.com/redshift/latest/dg/r_SUPER_type.html\">SUPER datatype</a> column and can be accessed using <a href=\"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/ql-reference.html\">PartiQL sql</a>.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/19/26a-dynamodb-zetl-LaunchMarketingIntake-1191.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/19/26a-dynamodb-zetl-LaunchMarketingIntake-1191.png\" width=\"1337\" height=\"523\" /></a></p> \n<p>I insert another entry to the DynamoDB <strong>Book_Catalog</strong> table.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/19/27-dynamodb-zetl-LaunchMarketingIntake-1191.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/19/27-dynamodb-zetl-LaunchMarketingIntake-1191.png\" width=\"2346\" height=\"1026\" /></a></p> \n<p>When I switch to the Amazon Redshift Query editor and refresh the select query, I can see that the new record is replicated to the data warehouse.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/20/28-dynamodb-zetl-LaunchMarketingIntake-1191.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/20/28-dynamodb-zetl-LaunchMarketingIntake-1191.png\" width=\"3012\" height=\"988\" /></a></p> \n<p>Zero-ETL integrations between Aurora PostgreSQL and DynamoDB with Amazon Redshift help you unify data from multiple database clusters and unlock insights in your data warehouse. Amazon Redshift allows cross-database queries and materialized views based off the multiple tables, giving you the opportunity to consolidate and simplify your analytics assets, improve operational efficiency, and optimize cost. You no longer have to worry about setting up and managing complex ETL pipelines.</p> \n<p><span><strong>Now available<br /> </strong></span>Aurora PostgreSQL zero-ETL integration with Amazon Redshift is now available in US East (N. Virginia), US East (Ohio), US West (Oregon), Asia Pacific (Hong Kong), Asia Pacific (Mumbai), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Europe (Frankfurt), Europe (Ireland), and Europe (Stockholm) AWS Regions.</p> \n<p>Amazon DynamoDB zero-ETL integration with Amazon Redshift is now available in all commercial, China and GovCloud AWS Regions.</p> \n<p>For pricing information, visit the <a href=\"https://aws.amazon.com/rds/aurora/pricing/#Zero-ETL_integration_costs\">Amazon Aurora</a> and <a href=\"https://aws.amazon.com/dynamodb/pricing/\">Amazon DynamoDB</a> pricing pages.</p> \n<p>To get started with this feature, visit <a href=\"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/zero-etl.html\">Working with Aurora zero-ETL integrations with Amazon Redshift</a> and <a href=\"https://docs.aws.amazon.com/redshift/latest/mgmt/zero-etl-using.html\">Amazon Redshift Zero-ETL integrations</a> documentation.</p> \n<a href=\"https://www.linkedin.com/in/esrakayabali/\">— Esra</a>","author":"Esra Kayabali","siteTitle":"AWS News Blog","siteHash":"6093e072e4117ec22616e844cb857d03ca62c57a411a8affc77cb5e8b6b15bf6","entryHash":"f7befc6462ff247e7029207c9e21787098678faaa32caf19fa58e7023d331cb9","category":"Tech"}