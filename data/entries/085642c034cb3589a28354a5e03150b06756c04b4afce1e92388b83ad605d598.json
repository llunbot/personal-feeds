{"title":"กูเกิลเปิดตัว Gemma 3n รุ่นย่อสำหรับรันบนโทรศัพท์ ปรับจนใช้แรมน้อยลงครึ่งหนึ่ง","link":"https://www.blognone.com/node/146534","date":1747818252000,"content":"<span>กูเกิลเปิดตัว Gemma 3n รุ่นย่อสำหรับรันบนโทรศัพท์ ปรับจนใช้แรมน้อยลงครึ่งหนึ่ง</span>\n\n  <div>\n    <div>Body</div>\n              <div><p>กูเกิลเปิดตัวโมเดลปัญญาประดิษฐ์ Gemma 3n ที่ใช้เทคนิคต่างๆ ในการย่อขนาดโมเดลจนเล็กลงเพียงพอที่จะรันในโทรศัพท์หรือแทบเล็ตได้ โดยยังมีความฉลาดสูง</p>\n<p>เทคนิคย่อโมเดลสำคัญคือที่สุดคือ Per-Layer Embeddings (PLE) ที่แยกข้อมูลออกไปเก็บไว้ในสตอเรจ แล้วค่อยนำข้อมูลกลับมาใช้เมื่อรันแต่ละส่วน ทำให้โดยรวมสามารถรันโมเดลโดยใช้แรมไม่ถึงครึ่งของโมเดลเต็มๆ</p>\n<p>สถาปัตยกรรมของ Gemma 3n ใช้ MatFormer ที่เปิดให้คอนฟิกโมเดลเป็นหลายขนาดได้ตามการใช้งานจริง เช่น โมเดลรุ่นใหญ่สุด คือ Gemma 3n E4B (E มาจาก effective แปลว่าใช้พื้นที่แรมเท่ากับโมเดลขนาด 4B) ก็จะเลือกคอนฟิกตอนรันให้โหลดโมเดล E2B ขึ้นมาใช้งานได้</p>\n<p>ตัวโมเดลรองรับอินพุตทั้งข้อความ, ภาพ, และเสียง สามารถดาวน์โหลดได้แล้วผ่าน <a href=\"https://huggingface.co/google/gemma-3n-E4B-it-litert-preview\">HuggingFace</a> หรือทดลองใช้งานผ่าน Google AI Studio</p>\n<p>ที่มา - <a href=\"https://developers.googleblog.com/en/introducing-gemma-3n/\">Google Developers Blog</a></p>\n</div>\n          </div>\n<span><a href=\"https://www.blognone.com/user/lew\">lew</a></span>\n<span><time>Wed, 05/21/2025 - 16:04</time>\n</span>","author":"lew","siteTitle":"Blognone","siteHash":"ededadcf18490b3937e7dd89ebe8c00dc129addbdf1ebe4aff1f458146693da0","entryHash":"085642c034cb3589a28354a5e03150b06756c04b4afce1e92388b83ad605d598","category":"Thai"}