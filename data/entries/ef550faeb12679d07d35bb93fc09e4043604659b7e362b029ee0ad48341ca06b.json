{"title":"Google ชี้แจงสาเหตุที่โมเดล AI เจนรูปภาพบุคคลออกมาผิดจากความจริง","link":"https://www.blognone.com/node/138376","date":1708733605000,"content":"<div><div><div><p>กูเกิลออกคำชี้แจง หลังจากมีรายงานพบว่า Gemini AI สร้างรูปภาพ ทำงานไม่ถูกต้องเมื่อได้รับคำสั่งให้สร้างรูปภาพบุคคลที่มีจริงในประวัติศาสตร์ ผิดเพี้ยนออกไปจากความจริง เช่น ภาพโป๊ปเป็นคนดำ หรือผู้ก่อตั้งกูเกิลเป็นคนเอเชีย ซึ่งทำให้กูเกิลต้องประกาศ<a href=\"https://www.blognone.com/node/138347\">ปิดการทำงาน</a>คำสั่งสร้างรูปภาพบุคคลชั่วคราว</p>\n<p>ฟีเจอร์สร้างรูปภาพใน Gemini มีออกมา<a href=\"https://www.blognone.com/node/137997\">ตั้งแต่ต้นเดือนกุมภาพันธ์</a>ที่ผ่านมา โดยใช้ Imagen 2 โมเดลสำหรับการสร้างรูปภาพ</p>\n<p>กูเกิลบอกว่าสิ่งที่บริษัทระมัดระวังมากในการพัฒนาเครื่องมือสร้างรูปภาพบน Gemini คือการป้องกันไม่ให้โปรแกรมไปสร้างรูปที่รุนแรง มีเนื้อหาทางเพศ หรือโจมตีบุคคลที่มีตัวตนจริง ซึ่งมีกรณีแบบนี้เกิดขึ้นมาแล้วในเครื่องมือประเภทเดียวกัน และเนื่องจากเครื่องมือนี้เปิดให้คนทั่วโลกใช้งาน กูเกิลจึงต้องการให้มันรองรับความต้องการของทุกคนด้วย ผลลัพธ์ที่ได้จึงควรมีความหลากหลาย ไม่ใช่แค่บุคคล หรือชาติพันธุ์เดียว</p>\n<p>อย่างไรก็ตามหากเป็น prompt ที่ระบุลักษณะบุคคลชัดเจน เช่น \"a Black teacher in a classroom\" กูเกิลยอมรับว่าผลลัพธ์ที่ได้ก็ควรออกมาเจาะจงตรงตามที่ระบุ แต่ตอนนี้มันไม่เป็นเช่นนั้น ซึ่งมาจากสองสาเหตุ หนึ่งคือ Gemini ทำงานผิดพลาดเองเมื่อต้องแสดงผลลัพธ์ที่เจาะจง แต่กลับเลือกแสดงผลลัพธ์ที่หลากหลาย และสอง โมเดลมีปัญหาเองที่ระวังตัวมากไป โดยปฏิเสธที่จะสร้างรูปภาพ หากมีการเจาะจงลักษณะเฉพาะ แล้วไปเหมารวมว่าเป็นคำสั่งที่อ่อนไหว จากสองปัญหาที่กล่าวมาจึงทำให้ Gemini ทำงานผิดพลาดอย่างที่ปรากฏ</p>\n<p>สิ่งที่กูเกิลจะทำต่อไปคือปรับการทำงานให้โมเดลทำงานถูกต้องมากกว่านี้ ทำการทดสอบในรายละเอียดมากขึ้น ก่อนจะเปิดให้ใช้งานอีกครั้ง อย่างไรก็ตามกูเกิลย้ำว่า Gemini เป็นเครื่องมือช่วยด้านความคิดสร้างสรรค์ และอาจไม่ได้ให้ผลลัพธ์ที่แม่นยำทุกครั้ง โดยเฉพาะถ้าเป็นคำถามเกี่ยวกับเหตุการณ์ปัจจุบัน ซึ่งกูเกิลก็ปรับปรุงส่วนนี้อย่างต่อเนื่อง</p>\n<p>ที่มา: <a href=\"https://blog.google/products/gemini/gemini-image-generation-issue/\">กูเกิล</a></p>\n<p><img alt=\"No Description\" src=\"https://www.blognone.com/sites/default/files/externals/39280fca2e43c251e711cc016b1a4802.jpeg\" /></p>\n</div></div></div><div><div>Topics: </div><div><div><a href=\"/topics/google\">Google</a></div><div><a href=\"/topics/gemini\">Gemini</a></div><div><a href=\"/topics/artificial-intelligence\">Artificial Intelligence</a></div><div><a href=\"/topics/diversity\">Diversity</a></div></div></div>","author":"arjin","siteTitle":"Blognone","siteHash":"ededadcf18490b3937e7dd89ebe8c00dc129addbdf1ebe4aff1f458146693da0","entryHash":"ef550faeb12679d07d35bb93fc09e4043604659b7e362b029ee0ad48341ca06b","category":"Thai"}