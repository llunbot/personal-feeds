{"title":"กูเกิลเปิดตัว Gemini 2.5 Flash โมเดลรุ่นเล็ก ตอบเร็ว ต้นทุนต่ำ มี Reasoning","link":"https://www.blognone.com/node/145764","date":1744210353000,"content":"<div><div><div><p>เพียงไม่กี่สัปดาห์หลัง <a href=\"https://www.blognone.com/node/145470\">Gemini 2.5 Pro รุ่นใหญ่</a> กูเกิลเดินหน้าเปิดตัว Gemini 2.5 Flash โมเดลรุ่นเล็กต่อทันที</p>\n<p>กูเกิลเรียกโมเดล Gemini 2.5 Flash ว่าเป็นโมเดลที่ใช้ทำงานจริงๆ (workhorse model) ปรับแต่งมาให้ตอบเร็ว (low latency) ต้นทุนต่ำ แต่ยังมีฟีเจอร์การให้เหตุผล (reasoning) โดยสามารถปรับแต่งระยะเวลาในการคิดตามงบประมาณ (thinking budget) จึงเหมาะสำหรับงานที่ต้องเรียกโมเดลเป็นจำนวนครั้งมากๆ และต้องการความเร็วแบบเรียลไทม์ เช่น การตอบคำถามลูกค้า หรือ การประมวลผลเอกสาร</p>\n<p>ตอนนี้กูเกิลยังไม่ประกาศราคาของ Gemini 2.5 Flash ออกมา รวมถึงคะแนนเบนช์มาร์คของ 2.5 Flash ด้วย</p>\n<p>ฝั่งของ Gemini 2.5 Pro จะได้ฟีเจอร์ supervised tuning (for unique data specialization) และ context caching (for efficient long context processing) ของแพลตฟอร์ม Vertex AI ในอีกไม่กี่สัปดาห์ข้างหน้า ซึ่งจะช่วยเพิ่มประสิทธิภาพของคำตอบและลดต้นทุนลงได้ด้วย</p>\n<p>ที่มา - <a href=\"https://cloud.google.com/blog/products/ai-machine-learning/gemini-2-5-pro-flash-on-vertex-ai\">Google</a></p>\n<p><img alt=\"No Description\" src=\"https://www.blognone.com/sites/default/files/externals/26d1bcec9096afa06dd8e764c9e5dc48.jpeg\" /></p>\n</div></div></div><div><div>Topics: </div><div><div><a href=\"/topics/gemini\">Gemini</a></div><div><a href=\"/topics/google\">Google</a></div><div><a href=\"/topics/llm\">LLM</a></div></div></div>","author":"mk","siteTitle":"Blognone","siteHash":"ededadcf18490b3937e7dd89ebe8c00dc129addbdf1ebe4aff1f458146693da0","entryHash":"0cdf753476f5c4e79ac3812370a718f93c6751c88042b76c08795eb71bdf13c2","category":"Thai"}