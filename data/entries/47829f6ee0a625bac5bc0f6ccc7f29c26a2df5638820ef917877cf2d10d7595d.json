{"title":"Deepfakes in the courtroom: US judicial panel debates new AI evidence rules","link":"https://arstechnica.com/?p=2019174","date":1713989674000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2024/04/juding_fake_evidence-800x450.jpg\" alt=\"An illustration of a man with a very long nose holding up the scales of justice.\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2024/04/juding_fake_evidence.jpg\">Enlarge</a> (credit: <a href=\"https://www.gettyimages.com/detail/illustration/vector-of-a-man-head-silhouette-and-a-law-royalty-free-illustration/1191877745\">Getty Images</a>)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>On Friday, a federal judicial panel convened in Washington, DC, to discuss the challenges of policing AI-generated evidence in court trials, according to a <a href=\"https://www.reuters.com/legal/transactional/us-judicial-panel-wrestles-with-how-police-ai-generated-evidence-2024-04-19/\">Reuters report</a>. The US Judicial Conference's <a href=\"https://www.uscourts.gov/rules-policies/archives/agenda-books/advisory-committee-evidence-rules-april-2024\">Advisory Committee on Evidence Rules</a>, an eight-member panel responsible for drafting evidence-related amendments to the <a href=\"https://www.law.cornell.edu/rules/fre\">Federal Rules of Evidence</a>, heard from computer scientists and academics about the potential risks of AI being used to <a href=\"https://arstechnica.com/information-technology/2022/09/with-stable-diffusion-you-may-never-believe-what-you-see-online-again/\">manipulate images and videos</a> or create deepfakes that could disrupt a trial.</p>\n\n<p>The meeting took place amid <a href=\"https://www.reuters.com/legal/transactional/wary-courts-confront-ai-pitfalls-2024-promises-2023-12-27/\">broader efforts</a> by federal and state courts nationwide to address the rise of generative AI models (such as those that power OpenAI's <a href=\"https://arstechnica.com/information-technology/2023/11/chatgpt-was-the-spark-that-lit-the-fire-under-generative-ai-one-year-ago-today/\">ChatGPT</a> or Stability AI's <a href=\"https://arstechnica.com/information-technology/2024/02/stability-announces-stable-diffusion-3-a-next-gen-ai-image-generator/\">Stable Diffusion</a>), which can be trained on large datasets with the aim of producing realistic text, images, audio, or videos.</p>\n<p>In the published <a href=\"https://www.uscourts.gov/sites/default/files/2024-04_agenda_book_for_evidence_rules_meeting_final.pdf\">358-page agenda</a> for the meeting, the committee offers up this definition of a deepfake and the problems AI-generated media may pose in legal trials:</p></div><p><a href=\"https://arstechnica.com/?p=2019174#p3\">Read 9 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=2019174&amp;comments=1\">Comments</a></p>","author":"Benj Edwards","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"47829f6ee0a625bac5bc0f6ccc7f29c26a2df5638820ef917877cf2d10d7595d","category":"Tech"}