{"title":"The iPhone 16 could be Apple’s first AI device","link":"https://www.macworld.com/article/2133525/iphone-16-large-language-model-ai-chatgpt.html","date":1699604492000,"content":"<p><a href=\"https://www.macworld.com\">Macworld</a></p>\n\n<div>\n<section><div></div></section>\n\n\n\n<p>It’s no secret that Apple is <a href=\"https://www.macworld.com/article/2022627/apple-artificial-intelligence-pace-of-development.html\">way behind on AI</a>. While Google, Microsoft, and Samsung are all showcasing new technology around ChatGPT-style models, Apple still hasn’t announced anything beyond Siri’s rudimentary commands. But according to a new rumor, that’s going to change next year.</p>\n\n\n\n<p>Over on X, occasional leaker Revegnus reports that Apple is using its own LLM (large language model) deep-learning algorithm to “completely revamp Siri into the ultimate virtual assistant” and is “preparing to develop it into Apple’s most powerful killer AI app.” It’s not the first time we’ve heard that Apple is working on its own GPT-style AI chatbot. Back in July, <a href=\"https://www.macworld.com/article/2000557/apple-gpt-chatbot-genreative-ai-siri-2024.html\" target=\"_blank\">Bloomberg’s Mark Gurman</a> reported that generative AI was “a major effort for Apple” but hadn’t led to any consumer-facing products.</p>\n\n\n\n<figure><div>\n<blockquote><p>Good news:<br /><br />Apple is currently using LLM to completely revamp Siri into the ultimate virtual assistant and is preparing to develop it into Apple's most powerful killer AI app. <br /><br />This integrated development effort is actively underway, and the first product is expected to be… <a href=\"https://go.redirectingat.com/?id=111346X1569486&amp;url=https://t.co/rN3Fh3sw7L&amp;xcust=1-1-2133525-1-0-0&amp;sref=https://www.macworld.com/feed\">pic.twitter.com/rN3Fh3sw7L</a></p>— Revegnus (@Tech_Reve) <a href=\"https://go.redirectingat.com/?id=111346X1569486&amp;url=https://twitter.com/Tech_Reve/status/1722418466647625999?ref_src=twsrc%5Etfw&amp;xcust=1-1-2133525-1-0-0&amp;sref=https://www.macworld.com/feed\">November 9, 2023</a></blockquote>\n</div></figure>\n\n\n\n<p>According to Revegnus, the “integrated development effort is actively underway,” and Apple is targeting an unveiling at WWDC 2024. However, the new service might not be available to every Apple device. As it’s dependent on the Neural Engine and likely to include some serious privacy guardrails and operate on-device rather than in the cloud, Revegnus says Apple plans to make the service “standard on the iPhone 16 models and onwards.” </p>\n\n\n\n<p>In a change from the two-chip policy favored for the iPhone 15 generation, all <a href=\"https://www.macworld.com/article/2007943/iphone-16-release-date-specs-features-rumors.html\">iPhone 16 models</a> are expected to have the A18 processor—with the Pro models getting the higher-end A18 Pro. It’s likely that the AI model is dependent on new features in the chip that mean it can’t be used on older devices. That could also mean that the service will only be available on Macs with M4 chips, which will likely arrive in 2025.</p>\n\niPhone</div>","author":"","siteTitle":"Macworld","siteHash":"37e84dd5a21fa961d6d6630e269546024dbb7741b2e2fadbe74f47383c70dfbb","entryHash":"a9009529c300f38470ebeb18b8369d22ba1bd7979a629ebbee6b2b03219324f7","category":"Apple"}