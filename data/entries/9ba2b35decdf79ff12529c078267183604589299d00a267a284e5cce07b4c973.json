{"title":"DeepSeek เปิดตัวโมเดลคิดก่อนตอบ R1 ผลทดสอบบางชุดเอาชนะ OpenAI o1","link":"https://www.blognone.com/node/144230","date":1737425712000,"content":"<div><div><div><p>DeepSeek บริษัทปัญญาประดิษฐ์จากจีนเปิดตัวโมเดล DeepSeek-R1 โมเดล LLM แบบคิดหาเหตุผลก่อนตอบ (reasoning model) โดยแบ่งเป็นสองรุ่นย่อย คือ</p>\n<ul>\n<li>DeepSeek-R1-Zero รุ่นฝึกแบบ reinforcement learning (RL) หรือการฝึกแบบวางเป้าหมายให้แล้วให้โมเดลพยายามไปถึงเป้าหมาย แม้ว่าจะทำได้ดีแต่ก็มีปัญหาบางอย่าง เช่น พูดซ้ำๆ ไม่หยุด, ข้อความเหตุผลอ่านได้ยาก, หรือคิดหลายภาษาผสมกัน</li>\n<li>DeepSeek-R1 ฝึกแบบ supervised fine-tuning (SFT) ด้วยชุดข้อมูลการคิดเป็นเหตุเป็นผลก่อน จากนั้นจึงค่อนมาฝึกแบบ RL เพื่อมุ่งสู่เป้าหมาย ผลที่ได้ใกล้เคียงกับ OpenAI o1</li>\n</ul>\n<p>นอกจากนี้โมเดลตระกูล R1 ยังมีโมเดลขนาดเล็กที่ย่อมาจาก Qwen และ Llama ทำให้ได้โมเดลขนาดเล็กแต่ประสิทธิภาพสูง ขึ้นไปถึงระดับ OpenAI o1-mini โมเดลขนาดเล็กสุดมีขนาดเพียง 1.5B เท่านั้น แต่ตัวที่นำมาโชว์ผลทดสอบคือ DeepSeek-R1-32B</p>\n<p>โมเดล DeepSeek-R1 ตัวเต็มมีขนาด 671B พารามิเตอร์ผสมกันทั้ง BF16, F32, และ F8_E4M3 ขนาดไฟล์รวม 700GB</p>\n<p>ที่มา - <a href=\"https://huggingface.co/deepseek-ai/DeepSeek-R1\">HuggingFace</a></p>\n<p><img alt=\"No Description\" src=\"https://www.blognone.com/sites/default/files/externals/2627931f687e8bde892b5a07c4c602f3.jpg\" /></p>\n</div></div></div><div><div>Topics: </div><div><div><a href=\"/topics/deepseek\">DeepSeek</a></div><div><a href=\"/topics/llm\">LLM</a></div><div><a href=\"/topics/artificial-intelligence\">Artificial Intelligence</a></div><div><a href=\"/topics/china\">China</a></div></div></div>","author":"lew","siteTitle":"Blognone","siteHash":"ededadcf18490b3937e7dd89ebe8c00dc129addbdf1ebe4aff1f458146693da0","entryHash":"9ba2b35decdf79ff12529c078267183604589299d00a267a284e5cce07b4c973","category":"Thai"}