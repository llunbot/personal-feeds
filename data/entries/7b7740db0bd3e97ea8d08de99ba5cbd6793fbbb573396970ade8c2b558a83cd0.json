{"title":"OpenAI ระบุรัฐควรเข้าควบคุมการพัฒนา AI ฉลาดเหนือมนุษย์","link":"https://www.blognone.com/node/133976","date":1684862600000,"content":"<div><div><div><p>กลุ่มผู้ร่วมก่อตั้ง OpenAI ได้แก่ Sam Altman, Greg Brockman, และ Ilya Sutskever เขียนบล็อกเรียกร้องว่ารัฐต้องเข้ามากำกับการพัฒนาปัญญาประดิษฐ์ฉลาดเหนือมนุษย์ (superintelligence) รูปแบบเดียวกับที่รัฐบาลต้องเข้ามาควบคุมการพัฒนาเทคโนโลยีนิวเคลียร์</p>\n<p>ข้อเสนอนี้ระบุชัดว่าควรจำกัดเฉพาะระดับ superintelligence เท่านั้นไม่ควรไปสร้างเงื่อนไขกับปัญญาประดิษฐ์ที่ความสามารถต่ำกว่านี้มากเกินไป</p>\n<p>ข้อเสนอระบุ 3 แนวทาง ได้แก่</p>\n<ol>\n<li>สร้างความร่วมมือขนาดใหญ่เพื่อพัฒนาปัญญาประดิษฐ์ระดับเหนือมนุษย์อย่างระมัดระวัง ทำข้อตกลงร่วมกันว่าจะเพิ่มความสามารถมันในอัตราที่กำหนดไว้</li>\n<li>มีองค์กรควบคุมการพัฒนา สามารถเข้าตรวจสอบการพัฒนาได้แบบเดียวกับที่ IAEA ตรวจสอบหน่วยงานด้านนิวเคลียร์ทั่วโลก หน่วยงานนี้สามารถกำหนดเงื่อนไขการพัฒนาหรือใช้งานเพิ่มเติมได้</li>\n<li>พัฒนาความสามารถในการตรวจสอบเพื่อให้แน่ใจว่าปัญญาประดิษฐ์เหนือมนุษย์จะปลอดภัย</li>\n</ol>\n<p>บทความระบุว่าปัญญาประดิษฐ์เหนือมนุษย์นั้นมีทั้งข้อดีและข้อเสีย หากพัฒนาสำเร็จเราน่าจะแก้ปัญหาต่างๆ ในโลกได้จำนวนมาก และคุณภาพชีวิตมนุษย์ก็จะดีขึ้นมาก และการห้ามพัฒนาไปทั้งหมดก็ทำได้ยากมากเพราะหน่วยงานที่มีความสามารถจะพัฒนาก็มากขึ้นเรื่อยๆ ตามการพัฒนาของเทคโนโลยี</p>\n<p>ที่มา - <a href=\"https://openai.com/blog/governance-of-superintelligence\">OpenAI</a></p>\n<p><img src=\"https://www.blognone.com/sites/default/files/externals/7c0941090d852a50c70616ce768a8d3f.jpg\" alt /></p>\n</div></div></div><div><div>Topics: </div><div><div><a href=\"/topics/openai\">OpenAI</a></div><div><a href=\"/topics/artificial-intelligence\">Artificial Intelligence</a></div></div></div>","author":"lew","siteTitle":"Blognone","siteHash":"ededadcf18490b3937e7dd89ebe8c00dc129addbdf1ebe4aff1f458146693da0","entryHash":"7b7740db0bd3e97ea8d08de99ba5cbd6793fbbb573396970ade8c2b558a83cd0","category":"Thai"}