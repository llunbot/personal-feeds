{"title":"NYCâ€™s government chatbot is lying about city laws and regulations","link":"https://arstechnica.com/?p=2013719","date":1711743741000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2024/03/GettyImages-2047200563-800x533.jpg\" alt=\"Has a government employee checked all those zeroes and ones floating above the skyline?\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2024/03/GettyImages-2047200563.jpg\">Enlarge</a> <span>/</span> Has a government employee checked all those zeroes and ones floating above the skyline? (credit: <a href=\"https://www.gettyimages.com/detail/photo/cybersecurity-in-the-usa-digital-code-and-new-york-royalty-free-image/2047200563?phrase=new+york+ai&amp;adppopup=true\">Getty Images</a>)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>If you follow generative AI news at all, you're probably familiar with LLM chatbots' tendency to <a href=\"https://arstechnica.com/information-technology/2023/11/thanks-to-ai-hallucinate-is-cambridge-dictionarys-word-of-the-year-for-2023/\">\"confabulate\" incorrect information</a> while presenting that information as authoritatively true. That tendency seems poised to cause some serious problems now that a chatbot run by the New York City government is making up incorrect answers to some important questions of local law and municipal policy.</p>\n<p>NYC's \"MyCity\" ChatBot launched as a \"pilot\" program <a href=\"https://www.nyc.gov/office-of-the-mayor/news/777-23/mayor-adams-releases-first-of-its-kind-plan-responsible-artificial-intelligence-use-nyc#/0\">last October</a>. The announcement touted the ChatBot as a way for business owners to \"save ... time and money by instantly providing them with actionable and trusted information from more than 2,000 NYC Business webpages and articles on topics such as compliance with codes and regulations, available business incentives, and best practices to avoid violations and fines.\"</p>\n<p>But <a href=\"https://www.thecity.nyc/2024/03/29/ai-chat-false-information-small-business/\">a new report</a> from The Markup and local nonprofit news site The City found the MyCity chatbot giving dangerously wrong information about some pretty basic city policies. To cite just one example, the bot said that NYC buildings \"are not required to accept Section 8 vouchers,\" when <a href=\"https://www.nyc.gov/site/cchr/media/source-of-income.page\">an NYC government info page</a> says clearly that <a href=\"https://www.nyc.gov/site/nycha/section-8/about-section-8.page\">Section 8 housing subsidies</a> are one of many lawful sources of income that landlords are required to accept without discrimination. The Markup also received incorrect information in response to chatbot queries regarding worker pay and work hour regulations, as well as industry-specific information like funeral home pricing.</p></div><p><a href=\"https://arstechnica.com/?p=2013719#p3\">Read 7 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=2013719&amp;comments=1\">Comments</a></p>","author":"Kyle Orland","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"dfe768b33698c3d5a02becda037c832e253ebcdd6fb372a2f1f9ce8caa9b4cbd","category":"Tech"}