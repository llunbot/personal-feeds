{"title":"Apple’s upcoming Personal Voice feature can clone your voice in 15 minutes using AI","link":"https://www.macworld.com/article/1919264/ios-17-macos-14-accessibility-live-speech-personal-voice.html","date":1684297083000,"content":"<p><a href=\"https://www.macworld.com\">Macworld</a></p>\n\n<div>\n<section><div></div></section>\n\n\n\n<p>With WWDC just weeks away, Apple on Tuesday offered a preview of a wide range of new accessibility software features for the iPhone, iPad, and Mac. The features, intended to make Apple’s devices easier to use for those with or at risk of cognitive, vision, hearing, speaking, and mobility disabilities, will roll out later in 2023, but the company made the announcement to tie in with <a href=\"https://go.redirectingat.com/?id=111346X1569486&amp;url=https://accessibility.day/&amp;xcust=1-1-1919264-1-0-0&amp;sref=https://www.macworld.com/feed\" target=\"_blank\">Global Accessibility Awareness Day</a>, which falls this year on Thursday, May 18.</p>\n\n\n\n<p>“Today, we’re excited to share incredible new features that build on our long history of making technology accessible,” said Tim Cook, “so that everyone has the opportunity to create, communicate, and do what they love.”</p>\n\n\n\n<h2>Assistive Access</h2>\n\n\n\n<p>The first new feature is designed to make it easier for those with cognitive disabilities to use the iPhone and iPad. Assistive Access works on the level of individual apps, offering a simplified or slimmed-down experience to lower its cognitive requirements. Apple refers to this process as “us[ing] innovations in design to distill apps and experiences to their essential features.”</p>\n\n\n\n<p>The Phone and FaceTime apps, for example, have been boiled down to a single Calls app designed to be easier to use, while Messages offers a video message feature and the option of an emoji-only keyboard. Similarly, there are “distilled” versions of the Camera, Photos, and Music apps. Apple doesn’t indicate if third-party developers will be able to create Assistive Access versions of their apps, but it seems likely they will be encouraged to do so.</p>\n\n\n\n<p>Finally, Assistive Access offers the ability to customize your device’s interface at the level of the OS, with the choice of a traditional grid-based layout or one based on rows. This sounds similar to the choices of the home screen view on the Apple Watch, which can show apps either as a honeycomb grid or as an alphabetical list, which many of us find easier to use.</p>\n\n\n\n<h2>Live Speech</h2>\n\n\n\n<p>Live Speech is a text-to-speech function for those without the ability to speak, or difficulties in doing so. It can be used during in-person conversations if you’ve got the device to hand, but it can also enable iPhone, iPad, and Mac users to type responses during phone and FaceTime calls and have them spoken out loud.</p>\n\n\n\n<p>This might sound like it could slow down conversations for those who aren’t speedy typists, but Apple says the user will be able to save commonly used phrases for rapid responses.</p>\n\n\n\n<h2>Personal Voice</h2>\n\n\n\n<p>Related to Live Speech, Personal Voice is designed for those who don’t currently face prohibitive difficulties with speech, but are at risk of doing so in the future. The idea is that you spend 15 minutes reading text prompts aloud to your iPhone or iPad, which will then use this audio data and machine learning to create a digital voice that matches your own. Then, if speech becomes impossible in the future for whatever reason, you will be able to use the Live Speech function to make calls and send messages in a voice similar to your own. Apple assures us that the data will be kept private and secure to prevent the possibility of audio impersonation.</p>\n\n\n\n<h2>Other new features and related announcements</h2>\n\n\n\n<p>Those strike us as the three biggest announcements in today’s press release, but there are lots of smaller announcements worth mentioning.</p>\n\n\n\n<p>Detection Mode in Magnifier, for instance, gets a new Point and Speak feature. This means that a user with low vision could move their finger across the buttons on a domestic appliance and the iPhone will read their labels out loud.</p>\n\n\n\n<p>Text Size will be easier to adjust across Mac apps. Those who are sensitive to rapid animations will be able to automatically pause GIFs in Messages and Safari. And it will be possible for deaf or hard-of-hearing people to directly pair hearing devices certified as Made for iPhone with their Macs.</p>\n\n\n\n<p>Some of the announcements, however, fall outside the realm of software features. Apple is expanding its SignTime service, which offers sign language interpreters for Apple Store customers and those contacting Apple support, to more countries. There will be sessions in Apple Stores to introduce customers to accessibility features, while curated collections of shows, movies, and series related to issues of accessibility or created by people from the disabled community will be showcased on Podcasts and the Apple TV app.</p>\n\nApple</div>","author":"","siteTitle":"Macworld","siteHash":"37e84dd5a21fa961d6d6630e269546024dbb7741b2e2fadbe74f47383c70dfbb","entryHash":"d28a5eced457d7d06c84bf72033281a4aaaeaa627b1ec213889835c9475ddf30","category":"Apple"}