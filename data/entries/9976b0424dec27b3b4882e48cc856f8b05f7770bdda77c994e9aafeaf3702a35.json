{"title":"Apple Researchers Reveal New AI System That Can Beat GPT-4","link":"https://www.macrumors.com/2024/04/02/apple-reveals-new-ai-system/","date":1712062350000,"content":"Apple researchers have developed an artificial intelligence system named ReALM (Reference Resolution as Language Modeling) that aims to radically enhance how voice assistants understand and respond to commands.\r<br />\n\r<br />\n<img src=\"https://images.macrumors.com/article-new/2022/03/hey-siri-banner-apple.jpg\" width=\"1200\" height=\"630\" />\r<br />\nIn a <a href=\"https://arxiv.org/abs/2403.20329\">research paper</a> (via <em><a href=\"https://venturebeat.com/ai/apple-researchers-develop-ai-that-can-see-and-understand-screen-context/\">VentureBeat</a></em>), Apple outlines a new system for how large language models tackle reference resolution, which involves deciphering ambiguous references to on-screen entities, as well as understanding conversational and background context. As a result, ReALM could lead to more intuitive and natural interactions with devices.\r<br />\n\r<br />\nReference resolution is an important part of natural language understanding, enabling users to use pronouns and other indirect references in conversation without confusion. For digital assistants, this capability has historically been a significant challenge, limited by the need to interpret a wide range of verbal cues and visual information. Apple's ReALM system seeks to address this by converting the complex process of reference resolution into a pure language modeling problem. In doing so, it can comprehend references to visual elements displayed on a screen and integrate this understanding into the conversational flow.\r<br />\n\r<br />\nReALM reconstructs the visual layout of a screen using textual representations. This involves parsing on-screen entities and their locations to generate a textual format that captures the screen's content and structure. Apple researchers found that this strategy, combined with specific fine-tuning of language models for reference resolution tasks, significantly outperforms traditional methods, including the capabilities of OpenAI's GPT-4.\r<br />\n\r<br />\nReALM could enable users to interact with digital assistants much more efficiently with reference to what is currently displayed on their screen without the need for precise, detailed instructions. This has the potential to make voice assistants much more useful in a variety of settings, such as helping drivers navigate infotainment systems while driving or assisting users with disabilities by providing an easier and more accurate means of indirect interaction.\r<br />\n\r<br />\nApple has now published several AI research papers. Last month, the company <a href=\"https://www.macrumors.com/2024/03/18/apple-mm1-ai-model-details/\">revealed a new method</a> for training large language models that seamlessly integrates both text and visual information. Apple is widely expected to unveil an array of AI features at WWDC in June.<div>Tag: <a href=\"https://www.macrumors.com/guide/artificial-intelligence/\">Artificial Intelligence</a></div><br />This article, \"<a href=\"https://www.macrumors.com/2024/04/02/apple-reveals-new-ai-system/\">Apple Researchers Reveal New AI System That Can Beat GPT-4</a>\" first appeared on <a href=\"https://www.macrumors.com\">MacRumors.com</a><br /><br /><a href=\"https://forums.macrumors.com/threads/apple-researchers-reveal-new-ai-system-that-can-beat-gpt-4.2423356/\">Discuss this article</a> in our forums<br /><br />","author":"Hartley Charlton","siteTitle":"MacRumors: Mac News and Rumors - All Stories","siteHash":"4c0f1b1ecc2ed084c9f5be50f1058e33a55cdf9b904dadc33a2071fc2d63e8c1","entryHash":"9976b0424dec27b3b4882e48cc856f8b05f7770bdda77c994e9aafeaf3702a35","category":"Apple"}