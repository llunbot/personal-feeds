{"title":"Now THAT&#8217;S What I Call Service Worker!","link":"https://alistapart.com/article/now-thats-what-i-call-service-worker/","date":1616076000000,"content":"\n<p>The <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/Service_Worker_API\">Service Worker</a> API is the <a href=\"https://en.wikipedia.org/wiki/Dremel\">Dremel</a> of the web platform. It offers incredibly broad utility while also yielding resiliency and better performance. If you’ve not used Service Worker yet—and you couldn’t be blamed if so, as <a href=\"https://almanac.httparchive.org/en/2020/pwa#service-workers\">it hasn’t seen wide adoption as of 2020</a>—it goes something like this:</p>\n\n\n\n<ol><li>On the initial visit to a website, the browser <a href=\"https://developers.google.com/web/fundamentals/primers/service-workers#register_a_service_worker\">registers</a> what amounts to a client-side proxy powered by <a href=\"https://www.weeklytimber.com/sw.js\">a comparably paltry amount of JavaScript</a> that—like a Web Worker—runs on its own thread.</li><li>After the Service Worker’s registration, you can intercept requests and decide how to respond to them in the <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/FetchEvent\">Service Worker’s <code>fetch()</code> event</a>.</li></ol>\n\n\n\n<p>What you decide to do with requests you intercept is a) your call and b) depends on your website. You can <a href=\"https://alistapart.com/article/request-with-intent-caching-strategies-in-the-age-of-pwas/#section8\">rewrite requests</a>, <a href=\"https://web.dev/offline-cookbook/#on-install-as-dependency\">precache static assets</a> during install, <a href=\"https://www.madebymike.com.au/writing/service-workers/#a-better-offline-page-deeper-down-the-rabbit-hole\">provide offline functionality</a>, and—as will be our eventual focus—<a href=\"https://philipwalton.com/articles/smaller-html-payloads-with-service-workers/\">deliver smaller HTML payloads and better performance</a> for repeat visitors.</p>\n\n\n\n<h2>Getting out of the woods</h2>\n\n\n\n<p>Weekly Timber is a client of mine that provides logging services in central Wisconsin. For them, a fast website is vital. Their business is located in <a href=\"https://en.wikipedia.org/wiki/Waushara_County,_Wisconsin\">Waushara County</a>, and like many rural stretches in the United States, <a href=\"https://maps.psc.wi.gov/apps/WisconsinBroadbandMap/\">network quality and reliability isn’t great</a>.</p>\n\n\n\n<div><figure><img src=\"https://149572954.v2.pressablecdn.com/wp-content/uploads/2021/03/fig-1.png?resize=1024,533\" /><figcaption><em><strong>Figure 1. </strong>A wireless coverage map of Waushara County, Wisconsin. The tan areas of the map indicate downlink speeds between 3 and 9.99 Mbps. Red areas are even slower, while the pale and dark blue areas are faster.</em></figcaption></figure></div>\n\n\n\n<p>Wisconsin has farmland for <em>days</em>, but it also has plenty of forests. When you need a company that cuts logs, Google is probably your first stop. How fast a given logging company’s website is might be enough to get you looking elsewhere if you’re left waiting too long on a crappy network connection.</p>\n\n\n\n<p>I initially didn’t believe a Service Worker was necessary for Weekly Timber’s website. After all, if things were plenty fast to start with, why complicate things? On the other hand, knowing that my client services not just Waushara County, but much of central Wisconsin, even a barebones Service Worker could be the kind of progressive enhancement that adds resilience in the places it might be needed most.</p>\n\n\n\n<p>The first Service Worker I wrote for my client’s website—which I’ll refer to henceforth as the “standard” Service Worker—used three <a href=\"https://web.dev/offline-cookbook/\">well-documented caching strategies</a>:</p>\n\n\n\n<ol><li>Precache CSS and JavaScript assets for all pages when the Service Worker is installed when the window’s load event fires.</li><li>Serve static assets out of <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/CacheStorage\"><code>CacheStorage</code></a> if available. If a static asset isn’t in <code>CacheStorage</code>, retrieve it from the network, then cache it for future visits.</li><li>For HTML assets, hit the network first and place the HTML response into <code>CacheStorage</code>. If the network is unavailable the next time the visitor arrives, serve the cached markup from <code>CacheStorage</code>.</li></ol>\n\n\n\n<p>These are neither new nor special strategies, but they provide two benefits:</p>\n\n\n\n<ul><li>Offline capability, which is handy when network conditions are spotty.</li><li>A performance boost for loading static assets.</li></ul>\n\n\n\n<p>That performance boost translated to a 42% and 48% decrease in the median time to <a href=\"https://web.dev/fcp/\">First Contentful Paint (FCP)</a> and <a href=\"https://web.dev/lcp/\">Largest Contentful Paint (LCP)</a>, respectively. Better yet, these insights are based on <a href=\"https://en.wikipedia.org/wiki/Real_user_monitoring\">Real User Monitoring (RUM)</a>. That means these gains aren’t just theoretical, but a real improvement for real people.</p>\n\n\n\n<div><figure><img src=\"https://149572954.v2.pressablecdn.com/wp-content/uploads/2021/03/fig-2.png?resize=1024,301\" /><figcaption><em><strong>Figure 2.</strong> A breakdown of request/response timings depicted in Chrome’s developer tools. The request is for a static asset from <code>CacheStorage</code>. Because the Service Worker doesn’t need to access the network, it takes about 23 milliseconds to “download” the asset from <code>CacheStorage</code>.</em></figcaption></figure></div>\n\n\n\n<p>This performance boost is from bypassing the network entirely for static assets already in <code>CacheStorage</code>—particularly render-blocking stylesheets. A similar benefit is realized when we rely on the HTTP cache, only the FCP and LCP improvements I just described are in comparison to pages with a primed HTTP cache without an installed Service Worker.</p>\n\n\n\n<p>If you’re wondering why <a href=\"https://blog.yoav.ws/tale-of-four-caches/\"><code>CacheStorage</code> and the HTTP cache aren’t equal</a>, it’s because the HTTP cache—at least in <a href=\"https://jakearchibald.com/2016/caching-best-practices/#pattern-2-mutable-content-always-server-revalidated\">some cases</a>—may still involve a trip to the server to verify asset freshness. <a href=\"https://hacks.mozilla.org/2017/01/using-immutable-caching-to-speed-up-the-web/\">Cache-Control’s <code>immutable</code> flag gets around this</a>, but <a href=\"https://caniuse.com/mdn-http_headers_cache-control_immutable\"><code>immutable</code> doesn’t have great support</a> yet. A long max-age value works, too, but the combination of Service Worker API and <code>CacheStorage</code> gives you a lot more flexibility.</p>\n\n\n\n<p>Details aside, the takeaway is that the simplest and most well-established Service Worker caching practices can improve performance. Potentially more than what well-configured <code>Cache-Control</code> headers can provide. Even so, Service Worker is an incredible technology with far more possibilities. It’s possible to go farther, and I’ll show you how.</p>\n\n\n\n<h2>A better, faster Service Worker</h2>\n\n\n\n<p>The web <em>loves</em> itself some “innovation,” which is a word we equally love to throw around. To me, true innovation isn’t when we create new frameworks or patterns solely for the benefit of developers, but whether those inventions benefit people who end up using whatever it is we slap up on the web. <a href=\"https://www.w3.org/TR/html-design-principles/#priority-of-constituencies\">The priority of constituencies</a> is a thing we ought to respect. Users above all else, always.</p>\n\n\n\n<p>The Service Worker API’s innovation space is considerable. How you work within that space can have a big effect on how the web is experienced. Things like <a href=\"https://developers.google.com/web/updates/2017/02/navigation-preload\">navigation preload</a> and <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/ReadableStream#examples\"><code>ReadableStream</code></a> have taken Service Worker from great to killer. We can do the following with these new capabilities, respectively:</p>\n\n\n\n<ul><li>Reduce Service Worker latency by parallelizing Service Worker startup time and <a href=\"https://fetch.spec.whatwg.org/#navigation-request\">navigation requests</a>.</li><li>Stream content in from <code>CacheStorage</code> and the network.</li></ul>\n\n\n\n<p>Moreover, we’re going to combine these capabilities and pull out one more trick: precache header and footer partials, then combine them with content partials from the network. This not only reduces how much data we download from the network, but it also improves perceptual performance for repeat visits. That’s innovation that helps everyone.</p>\n\n\n\n<p>Grizzled, I turn to you and say <em>“let’s do this.”</em></p>\n\n\n\n<h3>Laying the groundwork</h3>\n\n\n\n<p>If the idea of combining precached header and footer partials with network content on the fly seems like a Single Page Application (SPA), you’re not far off. Like an SPA, you’ll need to apply the “app shell” model to your website. Only instead of a client-side router plowing content into one piece of minimal markup, you have to think of your website as three separate parts:</p>\n\n\n\n<ul><li>The header.</li><li>The content.</li><li>The footer.</li></ul>\n\n\n\n<p>For my client’s website, that looks like this:</p>\n\n\n\n<div><figure><img src=\"https://149572954.v2.pressablecdn.com/wp-content/uploads/2021/03/fig-3.png?resize=490,1024\" /><figcaption><em><strong>Figure 3.</strong> A color coding of the Weekly Timber website’s different partials. The Footer and Header partials are stored in <code>CacheStorage</code>, while the Content partial is retrieved from the network unless the user is offline.</em></figcaption></figure></div>\n\n\n\n<p>The thing to remember here is that the individual partials don’t have to be valid markup in the sense that all tags need to be closed within each partial. The only thing that counts in the final sense is that the combination of these partials must be valid markup.</p>\n\n\n\n<p>To start, you’ll need to precache separate header and footer partials when the Service Worker is installed. For my client’s website, these partials are served from the <code>/partial-header</code> and <code>/partial-footer</code> pathnames:</p>\n\n\n\n<pre><code>self.addEventListener(\"install\", event =&gt; {\n  const cacheName = \"fancy_cache_name_here\";\n  const precachedAssets = [\n    \"/partial-header\",  // The header partial\n    \"/partial-footer\",  // The footer partial\n    // Other assets worth precaching\n  ];\n\n  event.waitUntil(caches.open(cacheName).then(cache =&gt; {\n    return cache.addAll(precachedAssets);\n  }).then(() =&gt; {\n    return self.skipWaiting();\n  }));\n});</code></pre>\n\n\n\n<p>Every page must be fetchable as a content partial minus the header and footer, as well as a full page with the header and footer. This is key because the initial visit to a page won’t be controlled by a Service Worker. Once the Service Worker takes over, then you serve content partials and assemble them into complete responses with the header and footer partials from <code>CacheStorage</code>.</p>\n\n\n\n<p>If your site is static, this means generating a whole other mess of markup partials that you can rewrite requests to in the Service Worker’s <code>fetch()</code> event. If your website has a back end—as is the case with my client—you can use an HTTP request header to instruct the server to deliver full pages or content partials.</p>\n\n\n\n<p>The hard part is putting all the pieces together—but we’ll do just that.</p>\n\n\n\n<h3>Putting it all together</h3>\n\n\n\n<p>Writing even a basic Service Worker can be challenging, but things get real complicated real fast when assembling multiple responses into one. One reason for this is that in order to avoid the Service Worker startup penalty, we’ll need to set up navigation preload.</p>\n\n\n\n<h4>Implementing navigation preload</h4>\n\n\n\n<p>Navigation preload addresses the problem of Service Worker startup time, which delays navigation requests to the network. The last thing you want to do with a Service Worker is hold up the show.</p>\n\n\n\n<p>Navigation preload must be explicitly enabled. Once enabled, the Service Worker won’t hold up navigation requests during startup. Navigation preload is enabled in the Service Worker’s <code>activate</code> event:</p>\n\n\n\n<pre><code>self.addEventListener(\"activate\", event =&gt; {\n  const cacheName = \"fancy_cache_name_here\";\n  const preloadAvailable = \"navigationPreload\" in self.registration;\n\n  event.waitUntil(caches.keys().then(keys =&gt; {\n    return Promise.all([\n      keys.filter(key =&gt; {\n        return key !== cacheName;\n      }).map(key =&gt; {\n        return caches.delete(key);\n      }),\n      self.clients.claim(),\n      preloadAvailable ? self.registration.navigationPreload.enable() : true\n    ]);\n  }));\n});</code></pre>\n\n\n\n<p><a href=\"https://caniuse.com/mdn-api_navigationpreloadmanager\">Because navigation preload isn’t supported everywhere</a>, we have to do the usual feature check, which we store in the above example in the <code>preloadAvailable</code> variable.</p>\n\n\n\n<p>Additionally, we need to use <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise/all\"><code>Promise.all()</code></a> to resolve multiple asynchronous operations before the Service Worker activates. This includes pruning those old caches, as well as waiting for both <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/Clients/claim\"><code>clients.claim()</code></a> (which tells the Service Worker to assert control immediately rather than waiting until the next navigation) and navigation preload to be enabled.</p>\n\n\n\n<p>A ternary operator is used to enable navigation preload in supporting browsers and avoid throwing errors in browsers that don’t. If <code>preloadAvailable</code> is <code>true</code>, we enable navigation preload. If it isn’t, we pass a Boolean that won’t affect how <code>Promise.all()</code> resolves.</p>\n\n\n\n<p>With navigation preload enabled, we need to write code in our Service Worker’s <code>fetch()</code> event handler to make use of the preloaded response:</p>\n\n\n\n<pre><code>self.addEventListener(\"fetch\", event =&gt; {\n  const { request } = event;\n\n  // Static asset handling code omitted for brevity\n  // ...\n\n  // Check if this is a request for a document\n  if (request.mode === \"navigate\") {\n    const networkContent = Promise.resolve(event.preloadResponse).then(response =&gt; {\n      if (response) {\n        addResponseToCache(request, response.clone());\n\n        return response;\n      }\n\n      return fetch(request.url, {\n        headers: {\n          \"X-Content-Mode\": \"partial\"\n        }\n      }).then(response =&gt; {\n        addResponseToCache(request, response.clone());\n\n        return response;\n      });\n    }).catch(() =&gt; {\n      return caches.match(request.url);\n    });\n\n    // More to come...\n  }\n});</code></pre>\n\n\n\n<p>Though this isn’t the entirety of the Service Worker’s <code>fetch()</code> event code, there’s a lot that needs explaining:</p>\n\n\n\n<ol><li>The preloaded response is available in <code>event.preloadResponse</code>. However, <a href=\"https://developers.google.com/web/updates/2017/02/navigation-preload\">as Jake Archibald notes</a>, the value of <code>event.preloadResponse</code> will be <code>undefined</code> in browsers that don’t support navigation preload. Therefore, we must pass <code>event.preloadResponse</code> to <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise/resolve\"><code>Promise.resolve()</code></a> to avoid compatibility issues.</li><li>We adapt in the resulting <code>then</code> callback. If event.<code>preloadResponse</code> is supported, we use the preloaded response and add it to <code>CacheStorage</code> via an <code>addResponseToCache()</code> helper function. If not, we send a <code>fetch()</code> request to the network to get the content partial using a custom <code>X-Content-Mode</code> header with a value of <code>partial</code>.</li><li>Should the network be unavailable, we fall back to the most recently accessed content partial in <code>CacheStorage</code>.</li><li>The response—regardless of where it was procured from—is then returned to a variable named <code>networkContent</code> that we use later.</li></ol>\n\n\n\n<p>How the content partial is retrieved is tricky. With navigation preload enabled, a special <code>Service-Worker-Navigation-Preload</code> header with a value of <code>true</code> is added to navigation requests. We then work with that header on the back end to ensure the response is a content partial rather than the full page markup.</p>\n\n\n\n<p>However, because navigation preload isn’t available in all browsers, we send a different header in those scenarios. In Weekly Timber’s case, we fall back to a custom <code>X-Content-Mode</code> header. In my client’s PHP back end, I’ve created some handy constants:</p>\n\n\n\n<pre><code>&lt;?php\n\n// Is this a navigation preload request?\ndefine(\"NAVIGATION_PRELOAD\", isset($_SERVER[\"HTTP_SERVICE_WORKER_NAVIGATION_PRELOAD\"]) &amp;&amp; stristr($_SERVER[\"HTTP_SERVICE_WORKER_NAVIGATION_PRELOAD\"], \"true\") !== false);\n\n// Is this an explicit request for a content partial?\ndefine(\"PARTIAL_MODE\", isset($_SERVER[\"HTTP_X_CONTENT_MODE\"]) &amp;&amp; stristr($_SERVER[\"HTTP_X_CONTENT_MODE\"], \"partial\") !== false);\n\n// If either is true, this is a request for a content partial\ndefine(\"USE_PARTIAL\", NAVIGATION_PRELOAD === true || PARTIAL_MODE === true);\n\n?&gt;</code></pre>\n\n\n\n<p>From there, the <code>USE_PARTIAL</code> constant is used to adapt the response:</p>\n\n\n\n<pre><code>&lt;?php\n\nif (USE_PARTIAL === false) {\n  require_once(\"partial-header.php\");\n}\n\nrequire_once(\"includes/home.php\");\n\nif (USE_PARTIAL === false) {\n  require_once(\"partial-footer.php\");\n}\n\n?&gt;</code></pre>\n\n\n\n<p>The thing to be hip to here is that you should specify <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Vary\">a <code>Vary</code> header</a> for HTML responses to take the <code>Service-Worker-Navigation-Preload</code> (and in this case, the <code>X-Content-Mode</code> header) into account for HTTP caching purposes—assuming you’re caching HTML at all, which may not be the case for you.</p>\n\n\n\n<p>With our handling of navigation preloads complete, we can then move onto the work of streaming content partials from the network and stitching them together with the header and footer partials from <code>CacheStorage</code> into a single response that the Service Worker will provide.</p>\n\n\n\n<h4>Streaming partial content and stitching together responses</h4>\n\n\n\n<p>While the header and footer partials will be available almost instantaneously because they’ve been in <code>CacheStorage</code> since the Service Worker’s installation, it’s the content partial we retrieve from the network that will be the bottleneck. It’s therefore vital that we <a href=\"https://developers.google.com/web/updates/2016/06/sw-readablestreams\">stream responses</a> so we can start pushing markup to the browser as quickly as possible. <code>ReadableStream</code> can do this for us.</p>\n\n\n\n<p>This <code>ReadableStream</code> business is a mind-bender. Anyone who tells you it’s “easy” is whispering sweet nothings to you. It’s <em>hard</em>. After I wrote my own function to merge streamed responses and messed up a critical step—which ended up not improving page performance, mind you—I modified <a href=\"https://gist.github.com/jakearchibald/d0b7e65496a8ec362f10739c3e28da6e\">Jake Archibald’s <code>mergeResponses()</code> function</a> to suit my needs:</p>\n\n\n\n<pre><code>async function mergeResponses (responsePromises) {\n  const readers = responsePromises.map(responsePromise =&gt; {\n    return Promise.resolve(responsePromise).then(response =&gt; {\n      return response.body.getReader();\n    });\n  });\n\n  let doneResolve,\n      doneReject;\n\n  const done = new Promise((resolve, reject) =&gt; {\n    doneResolve = resolve;\n    doneReject = reject;\n  });\n\n  const readable = new ReadableStream({\n    async pull (controller) {\n      const reader = await readers[0];\n\n      try {\n        const { done, value } = await reader.read();\n\n        if (done) {\n          readers.shift();\n\n          if (!readers[0]) {\n            controller.close();\n            doneResolve();\n\n            return;\n          }\n\n          return this.pull(controller);\n        }\n\n        controller.enqueue(value);\n      } catch (err) {\n        doneReject(err);\n        throw err;\n      }\n    },\n    cancel () {\n      doneResolve();\n    }\n  });\n\n  const headers = new Headers();\n  headers.append(\"Content-Type\", \"text/html\");\n\n  return {\n    done,\n    response: new Response(readable, {\n      headers\n    })\n  };\n}</code></pre>\n\n\n\n<p>As usual, there’s a lot going on:</p>\n\n\n\n<ol><li><code>mergeResponses()</code> accepts an argument named <code>responsePromises</code>, which is an array of <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/Response\"><code>Response</code></a> objects returned from either a navigation preload, <code>fetch()</code>, or <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/CacheStorage/match\"><code>caches.match()</code></a>. Assuming the network is available, this will always contain three responses: two from <code>caches.match()</code> and (hopefully) one from the network.</li><li>Before we can stream the responses in the <code>responsePromises</code> array, we must map <code>responsePromises</code> to an array containing one reader for each response. Each reader is used later in a <code>ReadableStream()</code> constructor to stream each response’s contents.</li><li>A promise named <code>done</code> is created. In it, we assign the promise’s <code>resolve()</code> and <code>reject()</code> functions to the external variables <code>doneResolve</code> and <code>doneReject</code>, respectively. These will be used in the <code>ReadableStream()</code> to signal whether the stream is finished or has hit a snag.</li><li>The new <code>ReadableStream()</code> instance is created with a name of <code>readable</code>. As responses stream in from <code>CacheStorage</code> and the network, their contents will be appended to <code>readable</code>.</li><li>The stream’s <code>pull()</code> method streams the contents of the first response in the array. If the stream isn’t canceled somehow, the reader for each response is discarded by calling the readers array’s <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/shift\"><code>shift()</code> method</a> when the response is fully streamed. This repeats until there are no more readers to process.</li><li>When all is done, the merged stream of responses is returned as a single response, and we return it with a <code>Content-Type</code> header value of <code>text/html</code>.</li></ol>\n\n\n\n<p>This is <a href=\"https://gist.github.com/jakearchibald/32b2155708a665e9c8e06642b7c09d86\">much simpler</a> if you use <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/TransformStream\"><code>TransformStream</code></a>, but depending on when you read this, that may not be an option for every browser. For now, we’ll have to stick with this approach.</p>\n\n\n\n<p>Now let’s revisit the Service Worker’s <code>fetch()</code> event from earlier, and apply the <code>mergeResponses()</code> function:</p>\n\n\n\n<pre><code>self.addEventListener(\"fetch\", event =&gt; {\n  const { request } = event;\n\n  // Static asset handling code omitted for brevity\n  // ...\n\n  // Check if this is a request for a document\n  if (request.mode === \"navigate\") {\n    // Navigation preload/fetch() fallback code omitted.\n    // ...\n\n    const { done, response } = await mergeResponses([\n      caches.match(\"/partial-header\"),\n      networkContent,\n      caches.match(\"/partial-footer\")\n    ]);\n\n    event.waitUntil(done);\n    event.respondWith(response);\n  }\n});</code></pre>\n\n\n\n<p>At the end of the <code>fetch()</code> event handler, we pass the header and footer partials from <code>CacheStorage</code> to the <code>mergeResponses()</code> function, and pass the result to the <code>fetch()</code> event’s <a href=\"https://developer.mozilla.org/en-us/docs/Web/API/FetchEvent/respondWith\"><code>respondWith()</code> method</a>, which serves the merged response on behalf of the Service Worker.</p>\n\n\n\n<h2>Are the results worth the hassle?</h2>\n\n\n\n<p>This is a lot of stuff to do, and it’s complicated! You might mess something up, or maybe your website’s architecture isn’t well-suited to this exact approach. So it’s important to ask: are the performance benefits worth the work? In my view? Yes! The synthetic performance gains aren’t bad at all:</p>\n\n\n\n<div><figure><img src=\"https://149572954.v2.pressablecdn.com/wp-content/uploads/2021/03/fig-4.png?resize=1024,565\" /><figcaption><em><strong>Figure 4.</strong> A bar chart of median FCP and LCP synthetic performance data across various Service Worker types for the Weekly Timber website.</em></figcaption></figure></div>\n\n\n\n<p>Synthetic tests don’t measure performance for anything except the specific device and internet connection they’re performed on. Even so, these tests were conducted on a staging version of my client’s website with a low-end <a href=\"https://www.gsmarena.com/nokia_2-8513.php\">Nokia 2 Android phone</a> on a throttled “Fast 3G” connection in Chrome’s developer tools. Each category was tested ten times on the homepage. The takeaways here are:</p>\n\n\n\n<ul><li>No Service Worker at all is slightly faster than the “standard” Service Worker with simpler caching patterns than the streaming variant. Like, ever so slightly faster. This may be due to the delay introduced by Service Worker startup, however, the RUM data I’ll go over shows a different case.</li><li>Both LCP and FCP are tightly coupled in scenarios where there’s no Service Worker or when the “standard” Service Worker is used. This is because the content of the page is pretty simple and the CSS is fairly small. The Largest Contentful Paint is usually the opening paragraph on a page.</li><li>However, the streaming Service Worker decouples FCP and LCP because the header content partial streams in right away from <code>CacheStorage</code>.</li><li>Both FCP and LCP are lower in the streaming Service Worker than in other cases.</li></ul>\n\n\n\n<div><figure><img src=\"https://149572954.v2.pressablecdn.com/wp-content/uploads/2021/03/fig-5.png?resize=1024,577\" /><figcaption><em><strong>Figure 5.</strong> A bar chart of median FCP and LCP RUM performance data across various Service Worker types for the Weekly Timber website.</em></figcaption></figure></div>\n\n\n\n<p>The benefits of the streaming Service Worker for real users is pronounced. For FCP, we receive an 79% improvement over no Service Worker at all, and a 63% improvement over the “standard” Service Worker. The benefits for LCP are more subtle. Compared to no Service Worker at all, we realize a 41% improvement in LCP—which is incredible! However, compared to the “standard” Service Worker, LCP is a touch slower.</p>\n\n\n\n<p>Because <a href=\"https://timkadlec.com/remembers/2018-06-07-prioritizing-the-long-tail-of-performance/\">the long tail of performance</a> is important, let’s look at the 95th percentile of FCP and LCP performance:</p>\n\n\n\n<div><figure><img src=\"https://149572954.v2.pressablecdn.com/wp-content/uploads/2021/03/fig-6.png?resize=1024,569\" /><figcaption><em><strong>Figure 6.</strong> A bar chart of 95th percentile FCP and LCP RUM performance data across various Service Worker types for the Weekly Timber website.</em></figcaption></figure></div>\n\n\n\n<p>The 95th percentile of RUM data is a great place to assess the slowest experiences. In this case, we see that the streaming Service Worker confers a 40% and 51% improvement in FCP and LCP, respectively, over no Service Worker at all. Compared to the “standard” Service Worker, we see a reduction in FCP and LCP by 19% and 43%, respectively. If these results seem a bit squirrely compared to synthetic metrics, remember: that’s RUM data for you! You never know who’s going to visit your website on which device on what network.</p>\n\n\n\n<p>While both FCP and LCP are boosted by the myriad benefits of streaming, navigation preload (in Chrome’s case), and sending less markup by stitching together partials from both <code>CacheStorage</code> and the network, FCP is the clear winner. Perceptually speaking, the benefit is pronounced, as this video would suggest:</p>\n\n\n\n<figure><figcaption><em><strong>Figure 7.</strong> Three WebPageTest videos of a repeat view of the Weekly Timber homepage. On the left is the page not controlled by a Service Worker, with a primed HTTP cache. On the right is the same page controlled by a streaming Service Worker, with CacheStorage primed.</em></figcaption></figure>\n\n\n\n<p>Now ask yourself this: If this is the kind of improvement we can expect on such a small and simple website, what might we expect on a website with larger header and footer markup payloads?</p>\n\n\n\n<h2>Caveats and conclusions</h2>\n\n\n\n<p>Are there trade-offs with this on the development side? <em>Oh</em> yeah.</p>\n\n\n\n<p><a href=\"https://philipwalton.com/articles/smaller-html-payloads-with-service-workers/#5)-set-the-correct-title\">As Philip Walton has noted</a>, a cached header partial means the document title must be updated in JavaScript on each navigation by changing the value of <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/Document/title\"><code>document.title</code></a>. It also means you’ll need to update the navigation state in JavaScript to reflect the current page if that’s something you do on your website. Note that this shouldn’t cause indexing issues, as Googlebot crawls pages with an unprimed cache.</p>\n\n\n\n<p>There may also be some challenges on sites with authentication. For example, if your site’s header displays the current authenticated user on log in, you may have to update the header partial markup provided by <code>CacheStorage</code> in JavaScript on each navigation to reflect who is authenticated. You may be able to do this by storing basic user data in <code>localStorage</code> and updating the UI from there.</p>\n\n\n\n<p>There are certainly other challenges, but it’ll be up to you to weigh the user-facing benefits versus the development costs. In my opinion, this approach has broad applicability in applications such as blogs, marketing websites, news websites, ecommerce, and other typical use cases.</p>\n\n\n\n<p>All in all, though, it’s akin to the performance improvements and efficiency gains that you’d get from an SPA. Only the difference is that you’re not replacing time-tested navigation mechanisms and grappling with all the messiness that entails, but <em>enhancing </em>them. That’s the part I think is really important to consider in a world where client-side routing is all the rage.</p>\n\n\n\n<p>“What about <a href=\"https://developers.google.com/web/tools/workbox\">Workbox</a>?,” you might ask—and you’d be right to. Workbox simplifies a lot when it comes to using the Service Worker API, and you’re not wrong to reach for it. Personally, I prefer to work as close to the metal as I can so I can gain a better understanding of what lies beneath abstractions like Workbox. Even so, Service Worker is hard. Use Workbox if it suits you. As far as frameworks go, its abstraction cost is very low.</p>\n\n\n\n<p>Regardless of this approach, I think there’s incredible utility and power in using the Service Worker API to reduce the amount of markup you send. It benefits my client and all the people that use their website. Because of Service Worker and the innovation around its use, my client’s website is faster in the far-flung parts of Wisconsin. That’s something I feel good about.</p>\n\n\n\n<p><em>Special thanks to </em><a href=\"https://jakearchibald.com/\"><em>Jake Archibald</em></a><em> for his valuable editorial advice, which, to put it mildly, considerably improved the quality of this article.</em></p>\n","author":"","siteTitle":"A List Apart: The Full Feed","siteHash":"09b09f389b84b264a6ebab120b6208479961d3fe7df4850a75b103b2b9c8a950","entryHash":"4c27b7e48dca47c64a3e536c600d44ec1919fef5caab18c1f9923b09049f3aa5","category":"Tech"}