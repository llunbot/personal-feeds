{"title":"Meta ปล่อยโมเดล SAM 2 จับวัตถุอะไรก็ได้ในวิดีโอ","link":"https://www.blognone.com/node/141135","date":1722319927000,"content":"<div><div><div><p>Meta ปล่อยโมเดล Segment Anything Model (SAM) เวอร์ชั่นที่สองที่สามารถแยกส่วนวัตถุใดๆ ก็ได้ในภาพ โดยมีความสามารถเพิ่มขึ้นระดับที่สามารถจับวัตถุที่ไม่มีในชุดข้อมูลฝึกมาก่อน</p>\n<p>แนวทางการใช้งานโมเดล SAM เช่น การจับการเคลื่อนไหววัตถุ, การสร้างเอฟเฟควิดีโอ, ตลอดจนการลบฉากหลังเมื่อประชุม โดยโมเดลต้องการอินพุตเป็น จุด, กล่อง, หรือพื้นที่ ของเฟรมเริ่มต้น ทั้งแบบ positive พื้นที่แสดงวัตถุกที่ต้องการ, และ negative พื้นที่แสดงว่าไม่ใช่วัตถุที่ต้องการ จากนั้นโมเดลสามารถวาดหาพื้นที่ของวัตถุทั้งหมดได้อัตโนมัติ และสามารถจดจำได้ว่ากำลังจับวัตถุอะไรอยู่</p>\n<p>นอกจากตัวโมเดลแล้ว ทาง Meta ยังปล่อยชุดข้อมูล SA-V ที่ใช้ฝึก SAM 2 ออกมาด้วย โดยรวมเป็นการแยกวัตถุกว่า 600,000 รายการ บนวิดีโอ 51,000 รายการ ชุดข้อมูลมีความหลากหลายสูงครอบคลุม 47 ประเทศ และวัตถุที่ระบายไว้ในชุดข้อมูลก็มีความหลากหลาย อาจจะหายไประหว่างทาง หรือเข้าออกจากเฟรมได้ด้วย</p>\n<p>โดยทั่วไปแล้ว SAM 2 แสดงประสิทธิภาพได้ดีมาก แต่ยังมีข้อจำกัด เช่น การติดตามวัตถุเมื่อมีวัตถุแบบเดียวกันจำนวนมาก (crowded scene) ทำให้มีบางจังหวะจับวัตถุผิดชิ้นได้</p>\n<p>โมเดลเปิดให้ใช้งานได้ฟรีในสัญญาอนุญาตแบบ Apache 2.0 ส่วนชุดข้อมูล SA-V เปิดให้ใช้งานแบบ CC BY 4.0</p>\n<p>ที่มา - <a href=\"https://ai.meta.com/blog/segment-anything-2/\">AI at Meta</a></p>\n<p><img alt=\"No Description\" src=\"https://www.blognone.com/sites/default/files/externals/cc4b63672ee7fc207229c006a771c8ee.jpg\" /></p>\n</div></div></div><div><div>Topics: </div><div><div><a href=\"/topics/meta\">Meta</a></div><div><a href=\"/topics/artificial-intelligence\">Artificial Intelligence</a></div></div></div>","author":"lew","siteTitle":"Blognone","siteHash":"ededadcf18490b3937e7dd89ebe8c00dc129addbdf1ebe4aff1f458146693da0","entryHash":"b752eddc7e1e4876c7ebcfdd6d40a49a1e052cc438ed0e7622aba283f903ad10","category":"Thai"}