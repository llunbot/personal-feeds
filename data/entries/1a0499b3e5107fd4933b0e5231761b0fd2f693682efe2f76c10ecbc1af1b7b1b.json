{"title":"Producing more but understanding less: The risks of AI for scientific research","link":"https://arstechnica.com/?p=2007526","date":1709748534000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2022/10/ai-brain-800x534.jpg\" alt=\"3d illustration of brain with wires\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2022/10/ai-brain.jpg\">Enlarge</a> <span>/</span> Current concerns about AI tend to focus on its obvious errors. But psychologist Molly Crockett and anthropologist Lisa Messeri argue that AI also poses potential long-term epistemic risks to the practice of science. (credit: Just_Super/E+ via Getty)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>Last month, we witnessed <a href=\"https://arstechnica.com/science/2024/02/scientists-aghast-at-bizarre-ai-rat-with-huge-genitals-in-peer-reviewed-article/\">the viral sensation</a> of several egregiously bad AI-generated figures published in a <a href=\"https://cdn.arstechnica.net/wp-content/uploads/2024/02/fcell-11-1339390-1.pdf\">peer-reviewed article</a> in Frontiers, a reputable scientific journal. Scientists on social media expressed equal parts shock and ridicule at the images, one of which featured a rat with grotesquely large and bizarre genitals.</p>\n<p>As Ars Senior Health Reporter Beth Mole <a href=\"https://arstechnica.com/science/2024/02/scientists-aghast-at-bizarre-ai-rat-with-huge-genitals-in-peer-reviewed-article/\">reported</a>, looking closer only revealed more flaws, including the labels \"dissilced,\" \"Stemm cells,\" \"iollotte sserotgomar,\" and \"dck.\" Figure 2 was less graphic but equally mangled, rife with nonsense text and baffling images. Ditto for Figure 3, a collage of small circular images densely annotated with gibberish.</p>\n<p>The paper has since been retracted, but that eye-popping rat penis image will remain indelibly imprinted on our collective consciousness. The incident reinforces a growing concern that the increasing use of AI will make published scientific research less trustworthy, even as it increases productivity. While the proliferation of errors is a valid concern, especially in the early days of AI tools like ChatGPT, two researchers argue in <a href=\"https://www.nature.com/articles/s41586-024-07146-0\">a new perspective</a> published in the journal Nature that AI also poses potential long-term epistemic risks to the practice of science.</p></div><p><a href=\"https://arstechnica.com/?p=2007526#p3\">Read 47 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=2007526&amp;comments=1\">Comments</a></p>","author":"Jennifer Ouellette","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"1a0499b3e5107fd4933b0e5231761b0fd2f693682efe2f76c10ecbc1af1b7b1b","category":"Tech"}