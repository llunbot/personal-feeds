{"title":"Rewarding accuracy gets people to spot more misinformation","link":"https://arstechnica.com/?p=1923411","date":1678490541000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2023/03/GettyImages-1367849545-800x539.jpg\" alt=\"a gavel hammers on a chat text bubble\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2023/03/GettyImages-1367849545-scaled.jpg\">Enlarge</a> (credit: <a href=\"https://www.gettyimages.com/detail/photo/speech-laws-royalty-free-image/1367849545\">Getty</a>)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>Piecing together why so many people are willing to share misinformation online is a major focus among behavioral scientists. It's easy to think partisanship is driving it allâ€”people will simply share things that make their side look good or their opponents look bad. But the reality is a bit more complicated. Studies have indicated that many people don't seem to <a href=\"https://arstechnica.com/science/2021/03/distraction-not-partisanship-drives-sharing-of-misinformation/\">carefully evaluate links</a> for accuracy, and that partisanship may be secondary to the rush of <a href=\"https://arstechnica.com/science/2023/01/for-facebook-addicts-clicking-is-more-important-than-facts-or-ideology/\">getting a lot of likes on social media</a>. Given that, it's not clear what induces users to stop sharing things that a small bit of checking would show to be untrue.</p>\n<p>So, a team of researchers tried the obvious: We'll give you money if you stop and evaluate a story's accuracy. The work shows that small payments and even minimal rewards boost the accuracy of people's evaluation of stories. Nearly all that effect comes from people recognizing stories that don't favor their political stance as factually accurate. While the cash boosted the accuracy of conservatives more, they were so far behind liberals in judging accuracy that the gap remains substantial.</p>\n<h2>Money for accuracy</h2>\n<p>The basic outline of the new experiments is pretty simple: get a bunch of people, ask them about their political leanings, and then show them a bunch of headlines as they would appear on a social media site such as Facebook. The headlines were rated based on their accuracy (i.e., whether they were true or misinformation) and whether they would be more favorable to liberals or conservatives.</p></div><p><a href=\"https://arstechnica.com/?p=1923411#p3\">Read 11 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=1923411&amp;comments=1\">Comments</a></p>","author":"John Timmer","siteTitle":"Ars Technica","siteHash":"23e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"ad7100a3f07902d65565ec3a3011e9787e24144718631e630de684","category":"Tech"}