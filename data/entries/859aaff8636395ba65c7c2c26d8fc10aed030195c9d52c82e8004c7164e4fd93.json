{"title":"Reddit cracked down on revenge porn, creepshots with twofold spike in permabans","link":"https://arstechnica.com/?p=1927657","date":1680114051000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2023/03/GettyImages-1244516743-800x534.jpg\" alt=\"Reddit cracked down on revenge porn, creepshots with twofold spike in permabans\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2023/03/GettyImages-1244516743.jpg\">Enlarge</a> (credit: <a href=\"https://www.gettyimages.com/detail/news-photo/reddit-logo-displayed-on-a-phone-screen-and-reddit-website-news-photo/1244516743\">NurPhoto / Contributor | NurPhoto</a>)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>A year after Reddit updated its <a href=\"https://www.reddithelp.com/hc/en-us/articles/360043513411\">policy</a> on non-consensual intimate image (NCII) sharing—a category that includes everything from revenge porn to voyeurism and accidental nip slips—the social media platform has announced that it has gotten much better at detecting and removing this kind of content. Reddit has also launched a <a href=\"https://www.redditinc.com/transparency\">transparency center</a> where users can more easily assess Reddit's ongoing efforts to make the platform safer.</p>\n<p>According to <a href=\"https://www.redditinc.com/policies/2022-transparency-report\">Reddit’s 2022 Transparency Report</a>—which tracks various “ongoing efforts to keep Reddit safe, healthy, and real”—last year Reddit removed much more NCII than it did in 2021. The latest report shows that Reddit removed 473 percent more subreddits and permanently suspended 244 percent more user accounts found to be violating community guidelines by sharing non-consensual intimate media. Previously, Reddit labeled NCII as \"involuntary pornography,\" and the 2022 report still uses that label, reporting that the total number of posts removed was 187,258. That <a href=\"https://www.reddithelp.com/hc/en-us/articles/360043513951-What-should-I-do-if-someone-has-shared-or-threatened-to-share-intimate-images-of-me-or-somebody-I-know-\">includes non-consensual AI-generated deepfakes</a>, also known as “lookalike” pornography.</p>\n<p>“It’s likely this increase is primarily reflective of our updated policies and increased effectiveness in detecting and removing non-consensual intimate media from Reddit,” the transparency report said.</p></div><p><a href=\"https://arstechnica.com/?p=1927657#p3\">Read 13 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=1927657&amp;comments=1\">Comments</a></p>","author":"Ashley Belanger","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"859aaff8636395ba65c7c2c26d8fc10aed030195c9d52c82e8004c7164e4fd93","category":"Tech"}