{"title":"Eureka: With GPT-4 overseeing training, robots can learn much faster","link":"https://arstechnica.com/?p=1977747","date":1698068276000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2023/10/eureka_hands-800x447.jpg\" alt=\"In this still captured from a video provided by Nvidia, a simulated robot hand learns pen tricks, trained by Eureka, using simultaneous trials.\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2023/10/eureka_hands-scaled.jpg\">Enlarge</a> <span>/</span> In this still captured from a video provided by Nvidia, a simulated robot hand learns pen tricks, trained by Eureka, using simultaneous trials. (credit: <a href=\"https://eureka-research.github.io/\">Nvidia</a>)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>On Friday, researchers from Nvidia, UPenn, Caltech, and the University of Texas at Austin announced Eureka, an algorithm that uses OpenAI's <a href=\"https://arstechnica.com/information-technology/2023/03/openai-announces-gpt-4-its-next-generation-ai-language-model/\">GPT-4</a> language model for designing training goals (called \"reward functions\") to enhance robot dexterity. The work aims to bridge the gap between high-level reasoning and low-level motor control, allowing robots to learn complex tasks rapidly using massively parallel simulations that run through trials simultaneously. According to the team, Eureka outperforms human-written reward functions by a substantial margin.</p>\n\n<p>Before robots can interact with the real world successfully, they need to learn how to move their robot bodies to achieve goalsâ€”like picking up objects or moving. Instead of making a physical robot try and fail one task at a time to learn in a lab, researchers at Nvidia have been experimenting with using video game-like computer worlds (thanks to platforms called <a href=\"https://developer.nvidia.com/isaac-sim\">Isaac Sim</a> and <a href=\"https://developer.nvidia.com/isaac-gym\">Isaac Gym</a>) that simulate three-dimensional physics. These allow for massively parallel training sessions to take place in many virtual worlds at once, dramatically speeding up training time.</p>\n<p>\"Leveraging state-of-the-art GPU-accelerated simulation in Nvidia Isaac Gym,\" writes Nvidia on its <a href=\"https://eureka-research.github.io/\">demonstration page</a>, \"Eureka is able to quickly evaluate the quality of a large batch of reward candidates, enabling scalable search in the reward function space.\" They call it \"rapid reward evaluation via massively parallel <a href=\"https://en.wikipedia.org/wiki/Reinforcement_learning\">reinforcement learning</a>.\"</p></div><p><a href=\"https://arstechnica.com/?p=1977747#p3\">Read 6 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=1977747&amp;comments=1\">Comments</a></p>","author":"Benj Edwards","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"fd1ebfe74bfb0e8b6f2bf67f42b2daf9b1830fdbec673361dd0e634d9bab9d35","category":"Tech"}