{"title":"New report illuminates why OpenAI board said Altman “was not consistently candid”","link":"https://arstechnica.com/?p=1988890","date":1701811892000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2017/05/GettyImages-545523518-800x533.jpg\" alt=\"Sam Altman, president of Y Combinator and co-chairman of OpenAI, seen here in July 2016.\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2017/05/GettyImages-545523518.jpg\">Enlarge</a> <span>/</span> Sam Altman, president of Y Combinator and co-chairman of OpenAI, seen here in July 2016. (credit: Drew Angerer / Getty Images News)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>When Sam Altman was <a href=\"https://arstechnica.com/ai/2023/11/openai-fires-ceo-sam-altman-citing-less-than-candid-communications/\">suddenly removed as CEO of OpenAI</a>—before being <a href=\"https://arstechnica.com/tech-policy/2023/11/sam-altman-wins-power-struggle-returns-to-openai-with-new-board/\">reinstated days later</a>—the company's board publicly justified the move by saying Altman \"was not consistently candid in his communications with the board, hindering its ability to exercise its responsibilities.\" In the days since, there has been <a href=\"https://arstechnica.com/information-technology/2023/11/report-sutskever-led-board-coup-at-openai-that-ousted-altman-over-ai-safety-concerns/\">some reporting</a> on potential reasons for the attempted board coup, but not much in the way of follow-up on what specific information Altman was allegedly less than \"candid\" about.</p>\n<p>Now, in <a href=\"https://www.newyorker.com/magazine/2023/12/11/the-inside-story-of-microsofts-partnership-with-openai\">an in-depth piece for The New Yorker</a>, writer Charles Duhigg—who was <a href=\"https://twitter.com/cduhigg/status/1730590030496960517\">embedded inside OpenAI for months</a> on a separate story—suggests that some board members found Altman \"manipulative and conniving\" and took particular issue with the way Altman allegedly tried to manipulate the board into firing fellow board member Helen Toner.</p>\n<h2>Board “manipulation” or “ham-fisted” maneuvering?</h2>\n<p>Toner, who <a href=\"https://cset.georgetown.edu/staff/helen-toner/\">serves as</a> director of strategy and foundational research grants at Georgetown University’s Center for Security and Emerging Technology, allegedly drew Altman's negative attention by co-writing <a href=\"https://cset.georgetown.edu/publication/decoding-intentions/\">a paper</a> on different ways AI companies can \"signal\" their commitment to safety through \"costly\" words and actions. In the paper, Toner contrasts <a href=\"https://arstechnica.com/information-technology/2023/11/chatgpt-was-the-spark-that-lit-the-fire-under-generative-ai-one-year-ago-today/\">OpenAI's public launch of ChatGPT</a> last year with Anthropic's \"deliberate deci[sion] not to productize its technology in order to avoid stoking the flames of AI hype.\"</p></div><p><a href=\"https://arstechnica.com/?p=1988890#p3\">Read 6 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=1988890&amp;comments=1\">Comments</a></p>","author":"Kyle Orland","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"cdc0098d1b95316479693bd5b17fa7354b2d0b007169f5934db7ec9d9dc3c2e3","category":"Tech"}