{"title":"Fearing “loss of control,” AI critics call for 6-month pause in AI development","link":"https://arstechnica.com/?p=1927560","date":1680120301000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2023/03/AI_pause_hero_1-800x450.jpg\" alt=\"An AI-generated image of a globe that has stopped spinning.\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2023/03/AI_pause_hero_1.jpg\">Enlarge</a> <span>/</span> An AI-generated image of a globe that has stopped spinning. (credit: Stable Diffusion)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>On Wednesday, the Future of Life Institute published an <a href=\"https://futureoflife.org/open-letter/pause-giant-ai-experiments/\">open letter</a> on its website calling on AI labs to \"immediately pause for at least 6 months the training of AI systems more powerful than <a href=\"https://arstechnica.com/information-technology/2023/03/openai-announces-gpt-4-its-next-generation-ai-language-model/\">GPT-4</a>.\" Signed by Elon Musk and several prominent AI researchers, the letter quickly began to <a href=\"https://www.reuters.com/technology/musk-experts-urge-pause-training-ai-systems-that-can-outperform-gpt-4-2023-03-29/\">draw attention</a> in the press—and some <a href=\"https://twitter.com/timnitGebru/status/1640924853493714944?s=20\">criticism</a> on social media.</p>\n\n<p>Earlier this month, OpenAI released <a href=\"https://arstechnica.com/information-technology/2023/03/openai-announces-gpt-4-its-next-generation-ai-language-model/\">GPT-4</a>, an AI model that can perform compositional tasks and allegedly pass standardized tests at a human level, although those claims are still being evaluated by research. Regardless, GPT-4 and <a href=\"https://arstechnica.com/information-technology/2023/02/ai-powered-bing-chat-loses-its-mind-when-fed-ars-technica-article/\">Bing Chat's</a> advancement in capabilities over previous AI models <a href=\"https://arstechnica.com/information-technology/2023/03/openai-checked-to-see-whether-gpt-4-could-take-over-the-world/\">spooked some experts</a> who believe we are heading toward super-intelligent AI systems faster than previously expected.</p>\n<p>Along these lines, the Future of Life Institute argues that recent advancements in AI have led to an \"out-of-control race\" to develop and deploy AI models that are difficult to predict or control. They believe that the lack of planning and management of these AI systems is concerning and that powerful AI systems should only be developed once their effects are well-understood and manageable. As they write in the letter:</p></div><p><a href=\"https://arstechnica.com/?p=1927560#p3\">Read 15 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=1927560&amp;comments=1\">Comments</a></p>","author":"Benj Edwards","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"dbe4bbb851c494747128e9171b156b40ac50418e5022bedc9d049e266a42a1cd","category":"Tech"}