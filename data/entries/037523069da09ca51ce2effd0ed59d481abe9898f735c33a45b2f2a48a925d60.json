{"title":"Now that machines can learn, can they unlearn?","link":"https://arstechnica.com/?p=1788910","date":1629543311000,"content":"<div>\n<figure><img src=\"https://cdn.arstechnica.net/wp-content/uploads/2021/08/ai-brain-800x560.jpg\" /><p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2021/08/ai-brain.jpg\">Enlarge</a> (credit: <a href=\"https://www.gettyimages.com/search/photographer?family=editorial&amp;photographer=Andriy+Onufriyenko\">Andriy Onufriyenko | Getty Images</a>)</p>  </figure><div><a name=\"page-1\"></a></div>\n<p>Companies of all kinds use <a href=\"https://www.wired.com/tag/machine-learning/\">machine learning</a> to analyze people’s desires, dislikes, or faces. Some researchers are now asking a different question: How can we make machines forget?</p>\n<p>A nascent area of computer science dubbed machine <em>unlearning</em> seeks ways to induce selective amnesia in <a href=\"https://www.wired.com/tag/artificial-intelligence/\">artificial intelligence</a> software. The goal is to remove all trace of a particular person or data point from a machine-learning system, without affecting its performance.</p>\n<p>If made practical, the concept could give people more control over their data and the value derived from it. Although users can already ask some companies to delete personal data, they are generally in the dark about what algorithms their information helped tune or train. Machine unlearning could make it possible for a person to withdraw both their data and a company’s ability to profit from it.</p></div><p><a href=\"https://arstechnica.com/?p=1788910#p3\">Read 13 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=1788910&amp;comments=1\">Comments</a></p>","author":"WIRED","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"037523069da09ca51ce2effd0ed59d481abe9898f735c33a45b2f2a48a925d60","category":"Tech"}