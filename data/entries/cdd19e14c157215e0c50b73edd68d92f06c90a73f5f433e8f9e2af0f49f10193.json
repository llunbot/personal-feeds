{"title":"New – Enhanced Dead-letter Queue Management Experience for Amazon SQS Standard Queues","link":"https://aws.amazon.com/blogs/aws/enhanced-dlq-management-sqs/","date":1638401348000,"content":"<p>Hundreds of thousands of customers use <a href=\"https://aws.amazon.com/sqs/\">Amazon Simple Queue Service (SQS)</a> to build message-based applications to decouple and scale microservices, distributed systems, and serverless apps. When a message cannot be successfully processed by the queue consumer, you can configure SQS to store it in a dead-letter queue (DLQ).</p> \n<p>As a software developer or architect, you’d like to examine and review unconsumed messages in your DLQs to figure out why they couldn’t be processed, identify patterns, resolve code errors, and ultimately reprocess these messages in the original queue. The life cycle of these unconsumed messages is part of your error-handling workflow, which is often manual and time consuming.</p> \n<p>Today, I’m happy to announce the general availability of a new enhanced DLQ management experience for SQS standard queues that lets you easily redrive unconsumed messages from your DLQ to the source queue.</p> \n<p>This new functionality is available in the SQS console and helps you focus on the important phase of your error handling workflow, which consists of identifying and resolving processing errors. With this new development experience, you can easily inspect a sample of the unconsumed messages and move them back to the original queue with a click, and without writing, maintaining, and securing any custom code. This new experience also takes care of redriving messages in batches, reducing overall costs.</p> \n<p><img src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/11/22/sqs-dlq-redrive-flow-1024x340.png\" /></p> \n<p><span><strong>DLQ and Lambda Processor Setup<br /> </strong></span>If you’re already comfortable with the DLQ setup, then <a href=\"#dlq-redrive-experience\">skip the setup and jump into the new DLQ redrive experience</a>.</p> \n<p>First, I create two queues: the source queue and the dead-letter queue.</p> \n<p>I edit the source queue and configure the <strong>Dead-letter queue</strong> section. Here, I pick the DLQ and configure the <strong>Maximum receives</strong>, which is the number of times after which a message is reprocessed before being sent to the DLQ. For this demonstration, I’ve set it to one. This means that every failed message goes to the DLQ immediately. In a real-world environment, you might want to set a higher number depending on your requirements and based on what a failure means with respect to your application.</p> \n<p><img src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/11/09/sqs-dlq-init-1024x589.png\" /></p> \n<p>I also edit the DLQ to make sure that only my source queue is allowed to use this DLQ. This configuration is optional: when this <strong>Redrive allow policy</strong> is disabled, any SQS queue can use this DLQ. There are cases where you want to reuse a single DLQ for multiple queues. But usually it’s considered best practices to setup independent DLQs per source queue to simplify the redrive phase without affecting cost. Keep in mind that you’re charged based on the number of API calls, not the number of queues.</p> \n<p><img src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/11/09/sqs-dlq-redrive-allow-policy-1024x631.png\" /></p> \n<p>Once the DLQ is correctly set up, I need a processor. Let’s implement a simple message consumer using <a href=\"https://aws.amazon.com/lambda/\">AWS Lambda</a>.</p> \n<p>The Lambda function written in Python will iterate over the batch of incoming messages, fetch two values from the message body, and print the sum of these two values.</p> \n<pre><code>import json\n\ndef lambda_handler(event, context):\n    for record in event['Records']:\n        payload = json.loads(record['body'])\n\n        value1 = payload['value1']\n        value2 = payload['value2']\n\n        value_sum = value1 + value2\n        print(\"the sum is %s\" % value_sum)\n        \n    return \"OK\"\n</code></pre> \n<p>The code above assumes that each message’s body contains two integer values that can be summed, without dealing with any validation or error handling. As you can imagine, this will lead to trouble later on.</p> \n<p>Before processing any messages, you must grant this Lambda function enough permissions to read messages from SQS and configure its trigger. For the IAM permissions, I use the managed policy named <code>AWSLambdaSQSQueueExecutionRole</code>, which grants permissions to invoke <code>sqs:ReceiveMessage</code>, <code>sqs:DeleteMessage</code>, and <code>sqs:GetQueueAttributes</code>.</p> \n<p>I use the Lambda console to set up the SQS trigger. I could achieve the same from the SQS console too.</p> \n<p><img src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/11/09/sqs-lambda-trigger-1024x907.png\" /></p> \n<p>Now I’m ready to process new messages using <strong>Send and receive messages</strong> for my source queue in the SQS console. I write <code>{\"value1\": 10, \"value2\": 5}</code> in the message body, and select <strong>Send message</strong>.</p> \n<p><img src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/11/09/sqs-send-message-1024x730.png\" /></p> \n<p>When I look at the CloudWatch logs of my Lambda function, I see a successful invocation.</p> \n<pre><code>START RequestId: 637888a3-c98b-5c20-8113-d2a74fd9edd1 Version: $LATEST\nthe sum is 15\nEND RequestId: 637888a3-c98b-5c20-8113-d2a74fd9edd1\nREPORT RequestId: 637888a3-c98b-5c20-8113-d2a74fd9edd1\tDuration: 1.31 ms\tBilled Duration: 2 ms\tMemory Size: 128 MB\tMax Memory Used: 39 MB\tInit Duration: 116.90 ms\t</code></pre> \n<p><strong><span>Troubleshooting powered by DLQ Redrive</span></strong><br /> Now what if a different producer starts publishing messages with the wrong format? For example, <code>{\"value1\": \"10\", \"value2\": 5}</code>. The first number is a string and this is quite likely to become a problem in my processor.</p> \n<p>In fact, this is what I find in the CloudWatch logs:</p> \n<div> \n <pre><code>START RequestId: 542ac2ca-1db3-5575-a1fb-98ce9b30f4b3 Version: $LATEST\n[ERROR] TypeError: can only concatenate str (not \"int\") to str\nTraceback (most recent call last):\n  File \"/var/task/lambda_function.py\", line 8, in lambda_handler\n    value_sum = value1 + value2\nEND RequestId: 542ac2ca-1db3-5575-a1fb-98ce9b30f4b3\nREPORT RequestId: 542ac2ca-1db3-5575-a1fb-98ce9b30f4b3\tDuration: 1.69 ms\tBilled Duration: 2 ms\tMemory Size: 128 MB\tMax Memory Used: 39 MB\t</code></pre> \n</div> \n<p>To figure out what’s wrong in the offending message, I use the new SQS redrive functionality, selecting <strong>DLQ redrive</strong> in my dead-letter queue.</p> \n<p><img src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/11/22/sqs-dlq-redrive-button-1-1024x436.png\" /></p> \n<p>I use <strong>Poll for messages</strong> and fetch all unconsumed messages from the DLQ.</p> \n<p><img src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/11/22/sqs-debug-unconsumed-message-1-1024x336.png\" /></p> \n<p>And then I inspect the unconsumed message by selecting it.</p> \n<p><img src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/11/09/sqs-dlq-message-1024x409.png\" /></p> \n<p>The problem is clear, and I decide to update my processing code to handle this case properly. In the ideal world, this is an upstream issue that should be fixed in the message producer. But let’s assume that I can’t control that system and it’s critically important for the business that I process this new type of messages.</p> \n<p>Therefore, I update the processing logic as follows:</p> \n<pre><code>import json\n\ndef lambda_handler(event, context):\n    for record in event['Records']:\n        payload = json.loads(record['body'])\n        value1 = int(payload['value1'])\n        value2 = int(payload['value2'])\n        value_sum = value1 + value2\n        print(\"the sum is %s\" % value_sum)\n        # do some more stuff\n        \n    return \"OK\"\n</code></pre> \n<p>Now that my code is ready to process the unconsumed message, I start a new redrive task from the DLQ to the source queue.</p> \n<p>By default, SQS will redrive unconsumed messages to the source queue. But you could also specify a different destination and provide a custom velocity to set the maximum number of messages per second.</p> \n<p><img src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/11/22/sqs-dlq-redrive-task-1-1024x613.png\" /></p> \n<p>I wait for the redrive task to complete by monitoring the redrive status in the console. This new section always shows the status of most recent redrive task.</p> \n<p><img src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/11/19/sqs-redrive-task-status-1024x331.png\" /></p> \n<p>The message has been moved back to the source queue and successfully processed by my Lambda function. Everything looks fine in my CloudWatch logs.</p> \n<pre><code>START RequestId: 637888a3-c98b-5c20-8113-d2a74fd9edd1 Version: $LATEST\nthe sum is 15\nEND RequestId: 637888a3-c98b-5c20-8113-d2a74fd9edd1\nREPORT RequestId: 637888a3-c98b-5c20-8113-d2a74fd9edd1\tDuration: 1.31 ms\tBilled Duration: 2 ms\tMemory Size: 128 MB\tMax Memory Used: 39 MB\tInit Duration: 116.90 ms\t</code></pre> \n<p><span><strong>Available Today at No Additional Cost</strong></span><br /> Today you can start leveraging the new DLQ redrive experience to simplify your development and troubleshooting workflows, without any additional cost. This new console experience is available in all AWS Regions where SQS is available, and we’re looking forward to hearing your feedback.</p> \n<p>— <a href=\"https://twitter.com/alex_casalboni\">Alex</a></p>","author":"Alex Casalboni","siteTitle":"AWS News Blog","siteHash":"6093e072e4117ec22616e844cb857d03ca62c57a411a8affc77cb5e8b6b15bf6","entryHash":"cdd19e14c157215e0c50b73edd68d92f06c90a73f5f433e8f9e2af0f49f10193","category":"Tech"}