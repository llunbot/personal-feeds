{"title":"★ Training Large Language Models on the Public Web","link":"https://daringfireball.net/2024/06/training_large_language_models_on_the_public_web","date":1719016864000,"content":"\n<p>Yesterday, quoting Anthropic’s announcement of their impressive new model, Claude 3.5 Sonnet, <a href=\"https://daringfireball.net/linked/2024/06/20/claude-3-5-sonnet\">I wrote</a>:</p>\n\n<blockquote>\n  <p>Also, from the bottom of the post, this interesting nugget:</p>\n\n<blockquote>\n  <p>One of the core constitutional principles that guides our AI model\ndevelopment is privacy. We do not train our generative models on\nuser-submitted data unless a user gives us explicit permission to\ndo so. To date we have not used any customer or user-submitted\ndata to train our generative models.</p>\n</blockquote>\n\n<p><a href=\"https://www.macstories.net/linked/apple-details-its-ai-foundation-models-and-applebot-web-scraping/\">Even Apple can’t say that</a>.</p>\n</blockquote>\n\n<p>It now seems clear that I misread Anthropic’s statement. I wrongly interpreted this as implying that Claude was not trained on public web data. <a href=\"https://support.anthropic.com/en/articles/7996885-how-do-you-use-personal-data-in-model-training\">Here is Anthropic’s FAQ on training data</a>:</p>\n\n<blockquote>\n  <p>Large language models such as Claude need to be “trained” on text\nso that they can learn the patterns and connections between words.\nThis training is important so that the model performs effectively\nand safely.</p>\n\n<p>While it is not our intention to “train” our models on personal\ndata specifically, training data for our large language models,\nlike others, can include web-based data that may contain publicly\navailable personal data. We train our models using data from three\nsources:</p>\n\n<ol>\n<li>Publicly available information via the Internet</li>\n<li>Datasets that we license from third party businesses</li>\n<li>Data that our users or crowd workers provide</li>\n</ol>\n\n<p>We take steps to minimize the privacy impact on individuals\nthrough the training process. We operate under strict policies and\nguidelines for instance that we do not access password protected\npages or bypass CAPTCHA controls. We undertake due diligence on\nthe data that we license. And we encourage our users not to use\nour products and services to process personal data. Additionally,\nour <a href=\"https://www.anthropic.com/index/claudes-constitution\">models are trained to respect privacy</a>: one of our\nconstitutional “principles” at the heart of Claude, based on the\nUniversal Declaration of Human Rights, is to choose the response\nthat is most respectful of everyone’s privacy, independence,\nreputation, family, property rights, and rights of association.</p>\n</blockquote>\n\n<p><a href=\"https://machinelearning.apple.com/research/introducing-apple-foundation-models\">Here is Apple, from its announcement last week of their on-device and server foundation models</a>:</p>\n\n<blockquote>\n  <p>We train our foundation models on licensed data, including data\nselected to enhance specific features, as well as publicly\navailable data collected by our web-crawler, AppleBot. Web\npublishers have <a href=\"https://support.apple.com/en-us/119829\">the option to opt out</a> of the use of their\nweb content for Apple Intelligence training with a data usage\ncontrol.</p>\n\n<p>We never use our users’ private personal data or user interactions\nwhen training our foundation models, and we apply filters to\nremove personally identifiable information like social security\nand credit card numbers that are publicly available on the\nInternet. We also filter profanity and other low-quality content\nto prevent its inclusion in the training corpus. In addition to\nfiltering, we perform data extraction, deduplication, and the\napplication of a model-based classifier to identify high quality\ndocuments.</p>\n</blockquote>\n\n<p>This puts Apple in the same boat as Anthropic in terms of using public pages on the web as training sources. Some writers and creators object to this — <a href=\"https://machinelearning.apple.com/research/introducing-apple-foundation-models\">including Federico Viticci</a>, whose piece on MacStories I linked to with my “Even Apple can’t say that” comment yesterday. <a href=\"https://sixcolors.com/post/2024/06/excluding-your-website-from-apples-ai-crawler/\">Dan Moren wrote a good introduction to blocking these crawling bots</a> with robots.txt directives.</p>\n\n<p>The best argument against Apple’s use of public web pages for model training is that they trained first, but only after announcing Apple Intelligence last week issued the instructions for blocking Applebot for AI training purposes. Apple should clarify whether they plan to re-index the public data they used for training before Apple Intelligence ships in beta this summer. Clearly, a website that bans Applebot-Extended shouldn’t have its data in Apple’s training corpus simply because Applebot crawled it before Apple Intelligence was even announced. It’s fair for public data to be excluded on an opt-out basis, rather than included on an opt-in one, but Apple trained its models on the public web before they allowed for opting out.</p>\n\n<p>But other than that chicken/egg opt-out issue, I don’t object to this. The whole point of the public web is that it’s there to learn from — even if the learner isn’t human. Is there a single LLM that was <em>not</em> trained on the public web? To my knowledge there is not, and a model that is ignorant of all information available on the public web would be, well, pretty ignorant of the world. To me the standards for LLMs should be similar to those we hold people to. You’re free to learn from anything I publish, but not free <a href=\"https://daringfireball.net/linked/2024/06/19/robb-knight-perplexity\">to plagiarize it</a>. If you quote it, attribute and link to the source. That’s my standard for AI bots as well. So at the moment, <a href=\"https://daringfireball.net/robots.txt\">my robots.txt file</a> bans just one: Perplexity.</p>\n\n<p>(I’d block a second, <a href=\"https://www.threads.net/@gruber/post/C8Zoz4jR-EB\">the hypocrites at Arc</a>, if I could figure out how.)</p>\n\n\n\n    ","author":"John Gruber","siteTitle":"Daring Fireball","siteHash":"fc569638025dadf22a867470f8215f38855cf50e975782a6c989909474292a36","entryHash":"16fcd0f8b6f8e235d50543cf6e5d35123b74a863da03b30015abaddd9ca091ee","category":"Tech"}