{"title":"Lamini เสนอเทคนิค Memory Tuning ใส่ความรู้ให้ LLM โดยแทบไม่เหลืออาการหลอน","link":"https://www.blognone.com/node/140437","date":1718640726000,"content":"<div><div><div><p>Lamini บริษัทแพลตฟอร์มปัญญาประดิษฐ์แบบ LLM นำเสนอเทคนิคการปรับแต่งโมเดลปัญญาประดิษฐ์ที่ชื่อว่า Lamini Memory Tuning (LMT) โดยระบุว่าลดอาการหลอน (hallucinate) ของปัญญาประดิษฐ์แบบ LLM ได้ถึง 95%</p>\n<p>ก่อนหน้านี้การลดอาการหลอนของ LLM นั้นอาศัยการวางข้อมูลอ้างอิงจากแหล่งที่น่าเชื่อถือต่างๆ เช่น องค์กรอาจจะมีชุดข้อมูลของตัวเองก็สามารถนำข้อมูลที่เกี่ยวข้องกับคำถามมาวางในพรอมพ์ เรียกว่า Retrieval Augmented Generation (RAG) เทคนิคนี้เพิ่มความแม่นยำได้จริง แต่ก็มีข้อจำกัดเพราะกระบวนการดึงข้อมูลไม่สมบูรณ์</p>\n<p>แนวทาง LMT เสนอให้ใส่ความรู้เข้าไปยัง LLM ด้วยการ finetune โมเดลแบบ LoRA ซึ่งไม่ใช่เรื่องใหม่ แต่ที่พิเศษคือ LMT จะฝึกโมเดลจำนวนมหาศาลนับล้านโมเดลที่มีความเชี่ยวชาญและความรู้เฉพาะแต่ละเรื่อง เรียกว่า memory expert และเมื่อผู้ใช้ถามคำถามจริงก็จะดึง expert ที่เกี่ยวข้องกับคำถามมาสร้างคำตอบสุดท้าย เรียกสถาปัตยกรรมนี้ว่า Mixture of Memory Experts (MoME)</p>\n<p>รายงานของ Lamini ไม่ได้เปิดเผยวิธีการทดสอบชัดเจนนัก โดยรายงาน 3 ตัวอย่างที่ทำให้กับลูกค้า ได้แก่</p>\n<ol>\n<li><strong>ตัวแปลงข้อความเป็น SQL</strong>: ลูกค้ามีฐานข้อมูลภายในจำนวนมาก มีชื่อเฉพาะแต่ละระบบ สามารถฝึกโมเดลจนตอบได้ 95% จากเดิมใช้ RAG ทำได้สูงสุด 50%</li>\n<li><strong>ระบบจัดหมวดหมู่เอกสาร</strong>: จัดหมวดหมู่เอกสารจำนวนมากเข้าหมวดประมาณ 900 หมวด ทำได้เต็ม 100%</li>\n<li><strong>ระบบแนะนำสินค้า</strong>: ระบบที่ต้องแนะนำตามสินค้าในฐานข้อมูลจริง ระบบสามารถแนะนำได้ถูกต้อง 88% จากสินค้า 50,000 รายการ</li>\n</ol>\n<p>แม้ผลของ Lamini จะน่าตื่นเต้นแต่บริษัทก็ยังไม่ได้เปิดเผยโค้ดทดลองให้ภายนอกสามารถทำซ้ำว่าสถาปัตยกรรม MoME นั้นได้ผลดีเช่นนั้นจริงหรือไม่ อาจจะต้องรอการอิมพลีเมนต์จากภายนอกว่าแนวทางเช่นนี้ทำงานนอกเหนือจากรูปแบบการใช้งานที่ Lamini เสนอมาได้กว้างเพียงใด</p>\n<p>ที่มา - <a href=\"https://www.lamini.ai/blog/lamini-memory-tuning\">Lamini</a></p>\n<p><img alt=\"No Description\" src=\"https://www.blognone.com/sites/default/files/externals/9da0c4f4fff47c74f3bb7a190423099a.png\" /></p>\n</div></div></div><div><div>Topics: </div><div><div><a href=\"/topics/llm\">LLM</a></div><div><a href=\"/topics/artificial-intelligence\">Artificial Intelligence</a></div></div></div>","author":"lew","siteTitle":"Blognone","siteHash":"ededadcf18490b3937e7dd89ebe8c00dc129addbdf1ebe4aff1f458146693da0","entryHash":"fbdaae96ae68a183b11e21575ad540576f96188cfbe210eaaa9b553154b87fd6","category":"Thai"}