{"title":"กูเกิลโชว์ USM โมเดลแยกแยะเสียงพูดที่รองรับมากกว่า 300 ภาษา มีภาษายาวีด้วย","link":"https://www.blognone.com/node/132932","date":1678284628000,"content":"<div><div><div><p>ทีมวิจัย Google Research เผยแพร่ข้อมูลของโมเดลแยกแยะเสียงพูดตัวใหม่ชื่อ Universal Speech Model (USM) ที่รองรับภาษามากกว่า 300 ภาษา ซึ่งครอบคลุมถึงภาษาที่อาจไม่ได้มีผู้ใช้งานเยอะนัก (จากภาพของกูเกิลจะเห็นคำว่า \"ภาษายาวี\" อยู่ด้วย)</p>\n<p>โมเดล USM เป็นก้าวแรกสู่เป้าหมาย <a href=\"https://www.blognone.com/node/131324\">โมเดลเดียวรองรับ 1,000 ภาษา (1,000 Languages Intitiative) ที่กูเกิลเคยประกาศไว้ช่วงปลายปี 2022</a> โดยตอนนี้ USM ถูกนำไปใช้แล้วกับ YouTube ในการฟังเสียงจากวิดีโอแล้วสร้างเป็นซับไตเติลในภาษาต่างๆ</p>\n<p><img alt=\"No Description\" src=\"https://www.blognone.com/sites/default/files/externals/67453f516573f97f5b7a1a1c67e85839.png\" /></p>\n<p>USM เลือกใช้แนวทาง self-supervised learning เรียนรู้จากการฟังเสียงพูดในภาษาต่างๆ โดยไม่จำเป็นต้องมีป้ายกำกับ (labeled) ซึ่งมีข้อจำกัดเรื่องปริมาณข้อมูลตัวอย่างเสียงที่มีป้ายกำกับ โดยเฉพาะภาษาที่มีผู้ใช้น้อย ในอีกทาง โมเดลจำเป็นต้องใช้ทรัพยากรประมวลผลให้มีประสิทธิภาพ เพราะต้องขยายจำนวนภาษาที่รองรับให้มากขึ้นเรื่อยๆ ด้วย</p>\n<p>เทคนิคที่ USM ใช้งานคือ self-supervised learning with fine-tuning เพิ่มขั้นตอนการปรับแต่ง เพื่อให้ประสิทธิภาพของโมเดลออกมาดีขึ้น กระบวนการเทรนแบ่งเป็น 3 ขั้นตอนคือ</p>\n<ol>\n<li>self-supervised learning จากเสียงพูด ใช้อัลกอริทึม <a href=\"https://proceedings.mlr.press/v162/chiu22a.html\">BERT-based Speech pre-Training<br />\nwith Random-projection Quantizer (BEST-RQ)</a> ปี 2022 ที่อิงจากอัลกอริทึม BERT ของกูเกิลเมื่อปี 2018 ขั้นตอนนี้กินพลังประมวลผลราว 80% ของทั้งกระบวนการ</li>\n<li>multi-objective supervised pre-training เพิ่มข้อมูลประเภทข้อความ (text data) ให้โมเดลมีความรู้เพิ่มขึ้น กูเกิลบอกว่าขั้นที่สองนี่จะทำหรือไม่ก็ได้ (optional) แต่ทำแล้วได้ผลลัพธ์ที่ดีขึ้น</li>\n<li>fine-tune ปรับแต่งงานบางส่วนโดยใช้ข้อมูล supervised data อีกเล็กน้อย</li>\n</ol>\n<p><img alt=\"No Description\" src=\"https://www.blognone.com/sites/default/files/externals/5500241ab6424424f28c8da2769d167d.png\" /></p>\n<p>ผลที่ได้คือโมเดล USM สามารถทำคะแนนผ่านชุดทดสอบ YouTube Captions ได้ดีกว่าโมเดลอื่น เช่น Whisper-v2 ที่เทรนด้วย labeled data โดยใช้ข้อมูลการเทรนน้อยกว่า และมีอัตราการผิดพลาดน้อยกว่า</p>\n<p>กูเกิลบอกว่าสถาปัตยกรรมของ USM น่าจะถูกนำมาใช้เป็นพื้นฐานของโมเดลรุ่นถัดๆ ไปที่จะสามารถพิชิตเป้าหมายแยกแยะ 1,000 ภาษาได้สำเร็จ</p>\n<p><img alt=\"No Description\" src=\"https://www.blognone.com/sites/default/files/externals/f28592b6c43756ef1a5e23ace7f30e2d.png\" /></p>\n<p>ที่มา - <a href=\"https://ai.googleblog.com/2023/03/universal-speech-model-usm-state-of-art.html?m=1\">Google AI Blog</a></p>\n</div></div></div><div><div>Topics: </div><div><div><a href=\"/topics/google\">Google</a></div><div><a href=\"/topics/speech-recognition\">Speech Recognition</a></div><div><a href=\"/topics/artificial-intelligence\">Artificial Intelligence</a></div></div></div>","author":"mk","siteTitle":"Blognone","siteHash":"490b3937e7dd89ebe8c00dc129addbdf1ebe4aff1f458146693da0","entryHash":"d9641fc1ae2b60c8f065df7cae30db8917065deee5fc48644303fd","category":"Thai"}