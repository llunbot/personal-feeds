{"title":"Elon Muskâ€™s xAI releases Grok source and weights, taunting OpenAI","link":"https://arstechnica.com/?p=2010763","date":1710780958000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2024/03/grok_1_hero-800x450.jpg\" alt=\"An AI-generated image released by xAI during the launch of Grok\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2024/03/grok_1_hero.jpg\">Enlarge</a> <span>/</span> An AI-generated image released by xAI during the open-weights launch of Grok-1. (credit: <a href=\"https://x.ai/blog/grok-os\">xAI</a>)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>On Sunday, Elon Musk's AI firm <a href=\"https://arstechnica.com/information-technology/2023/07/musk-announces-new-ai-company-that-seeks-to-understand-the-universe/\">xAI</a> released the base model weights and network architecture of <a href=\"https://x.ai/blog/grok-os\">Grok-1</a>, a large language model designed to compete with the models that power OpenAI's ChatGPT. The open-weights release through GitHub and BitTorrent comes as Musk continues to criticize (and <a href=\"https://arstechnica.com/ai/2024/03/elon-musk-sues-openai-and-sam-altman-accusing-them-of-chasing-profits/\">sue</a>) rival OpenAI for not releasing its AI models in an open way.</p>\n\n<p><a href=\"https://arstechnica.com/information-technology/2023/11/elon-musks-new-ai-model-doesnt-shy-from-questions-about-cocaine-and-orgies/\">Announced</a> in November, Grok is an AI assistant similar to <a href=\"https://arstechnica.com/information-technology/2023/11/chatgpt-was-the-spark-that-lit-the-fire-under-generative-ai-one-year-ago-today/\">ChatGPT</a> that is available to X Premium+ subscribers who pay $16 a month to the social media platform formerly known as Twitter. At its heart is a <a href=\"https://huggingface.co/blog/moe\">mixture-of-experts</a> LLM called \"Grok-1,\" clocking in at 314 billion parameters. As a reference, GPT-3 included 175 billion parameters. Parameter count is a rough measure of an AI model's complexity, reflecting its potential for generating more useful responses.</p>\n<p>xAI is releasing the base model of Grok-1, which is not fine-tuned for a specific task, so it is likely not the same model that X uses to power its Grok AI assistant. \"This is the raw base model checkpoint from the Grok-1 pre-training phase, which concluded in October 2023,\" writes xAI on its release page. \"This means that the model is not fine-tuned for any specific application, such as dialogue,\" meaning it's not necessarily shipping as a chatbot.</p></div><p><a href=\"https://arstechnica.com/?p=2010763#p3\">Read 9 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=2010763&amp;comments=1\">Comments</a></p>","author":"Benj Edwards","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"6307200d3e17d2fcc9aac5512b7b51b8aef7a6780ed5bd14a7c486bba5f54e70","category":"Tech"}