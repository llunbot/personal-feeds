{"title":"กูเกิลเพิ่มฟีเจอร์แคชอัตโนมัติให้ Gemini คุยต่อเนื่องได้ลดค่าใช้งานสูงสุด 75%","link":"https://www.blognone.com/node/146362","date":1746991570000,"content":"<span>กูเกิลเพิ่มฟีเจอร์แคชอัตโนมัติให้ Gemini คุยต่อเนื่องได้ลดค่าใช้งานสูงสุด 75%</span>\n\n  <div>\n    <div>Body</div>\n              <div><p>กูเกิลเพิ่มฟีเจอร์ Implicit Caching ให้กับลูกค้าที่ซื้อ Gemini ใช้งานผ่าน API โดยหลังจากนี้ไม่จำเป็นต้องระบุให้กูเกิลเก็บแคชไว้เอง</p>\n<p>แนวทางการทำ caching ใน LLM นั้นอาศัยแนวทางการใช้งานที่หลายครั้งผู้ใช้มักเริ่มต้นบทสนทนากับปัญญาประดิษฐ์เหมือนๆ กัน เช่น การใส่ system prompt หรือการคุยกับเอกสารชุดเดิมๆ แต่เปลี่ยนคำถามใหม่ทำให้มีข้อความเดิมๆ ไปทุกครั้ง ผู้ให้บริการ LLM นั้นสามารถเก็บสถานะที่ประมวลผลข้อความเริ่มต้นแล้วเอาไว้ ทำให้สามารถตอบคำถามต่อไปได้ทันที ก่อนหน้านี้กูเกิลรองรับการทำ caching อยู่แล้ว แต่ผู้ใช้ต้องประกาศใช้งานเอง และเสียค่าสตอเรจเก็บแคช</p>\n<p>ฟีเจอร์ใหม่นี้ทำให้ผู้ใช้ที่เรียกใช้ Gemini ด้วยข้อความเริ่มต้นซ้ำๆ ประหยัดค่าอินพุตไป 75%  แต่เนื่องจากไม่มีการประกาศระยะเวลาใช้งานแคช กูเกิลก็ไม่รับประกันว่าจะเก็บแคชให้ผู้ใช้นานแค่ไหน แต่ถ้าใครได้แคชก็จะเห็นค่า <code>cached_content_token_count</code> ส่งกลับมาเอง</p>\n<p>ฟีเจอร์แคชอัตโนมัติเป็นฟีเจอร์หนึ่งที่ <a href=\"https://api-docs.deepseek.com/news/news0802\">DeepSeek โชว์มานาน</a> โดยระบุว่ามีเทคโนโลยีการแคช์บนดิสก์ทำให้สามารถแคชข้อมูลได้จำนวนมากโดยผู้ใช้ไม่ต้องประกาศขอใช้งาน และแคชก็อยู่บนระบบของ DeepSeek นานหลายชั่วโมง</p>\n<p>ที่มา - <a href=\"https://developers.googleblog.com/en/gemini-2-5-models-now-support-implicit-caching/\">Google Developers Blog</a></p>\n</div>\n          </div>\n<span><a href=\"https://www.blognone.com/user/lew\">lew</a></span>\n<span><time>Mon, 05/12/2025 - 02:26</time>\n</span>","author":"lew","siteTitle":"Blognone","siteHash":"ededadcf18490b3937e7dd89ebe8c00dc129addbdf1ebe4aff1f458146693da0","entryHash":"f6335821f82f605a0340547eb144fc1146a9be8d37650b0761ab9acef12f46a3","category":"Thai"}