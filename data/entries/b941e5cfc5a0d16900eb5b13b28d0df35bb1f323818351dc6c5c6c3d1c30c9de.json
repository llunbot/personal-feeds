{"title":"[Sponsor] Kolide: ‘Voice Clones Have Crossed the Uncanny Valley’","link":"https://l.kolide.co/43vcTaN","date":1714441813000,"content":"\n\n\n<p><img src=\"https://daringfireball.net/martini/images/kolide/kolide-art-H12024-D.jpeg\" width=\"600\" alt=\"Illustration of two playing cards: the jack of spades and ace of spades, with the ace labeled “MGM”.\" /></p>\n\n<p>Now, don’t get offended, but — you aren’t as good at clocking deepfakes as you think you are.</p>\n\n<p>And it’s not just you — nobody’s that good at it. Not <a href=\"https://slate.com/technology/2023/04/descript-playht-ai-voice-copy.html\">your mom</a>, or your boss, or anyone in your IT department.</p>\n\n<p>To make matters worse, you probably think you can spot a fake. After all, you see weird AI-generated videos of celebrities on social media and they give you that uncanny valley tingle. But it’s a different ballgame when all you’ve got to go on is a voice.</p>\n\n<p>In real life, people only catch voice clones about <a href=\"https://slate.com/technology/2023/04/descript-playht-ai-voice-copy.html\">50% of the time</a>. You might as well flip a coin.</p>\n\n<p>And that makes us extremely vulnerable to attacks.</p>\n\n<p>In the “classic” voice clone scam, the caller is after an immediate payout (“Hi it’s me, your boss. <a href=\"https://www.forbes.com/sites/jessedamiani/2019/09/03/a-voice-deepfake-was-used-to-scam-a-ceo-out-of-243000/\">Wire a bunch of company money</a> to this account ASAP”). Then there are the more complex social engineering attacks, where a phone call is just the entryway to break into a company’s systems and steal data or plant malware (that’s what happened in the <a href=\"https://l.kolide.co/3TB3FF8\">MGM attack</a>, albeit without the use of AI).</p>\n\n<p>As <a href=\"https://decrypt.co/143479/fbi-warning-ai-extortion-sextortion-deepfake-scams\">more and more</a> hackers use voice cloning in social engineering attacks, deepfakes are becoming such a hot-button issue that it’s hard to tell the fear-mongering (for instance, it definitely takes more than three seconds of audio to clone a voice) from the actual risk.   </p>\n\n<p>To disentangle the true risks from the exaggerations, we need to answer some basic questions:  </p>\n\n<ol>\n<li>How hard is it to deepfake someone’s voice?</li>\n<li>How do hackers use voice clones to attack companies?</li>\n<li>And how do we guard ourselves against this… attack of the clones?</li>\n</ol>\n\n<p>Like a lot of modern technologies, deepfake attacks actually exploit some deep-seated fears. Fears like, “your boss is mad at you.” These anxieties have been used by social engineers since the dawn of the scam, and voice clones add a shiny new boost to their tactics.</p>\n\n<p>But the good news is that we can be trained to look past those fears and recognize a suspicious phone call — even if the voice sounds just like someone we trust. </p>\n\n<p>If you want to learn more about our findings, <a href=\"https://l.kolide.co/4cKaI7B\">read our piece on the Kolide blog</a>. It’s a frank and thorough exploration of what we should be worried about when it comes to audio deepfakes.</p>\n\n<div>\n<a href=\"https://daringfireball.net/feeds/sponsors/2024/04/kolide_voice_clones_have_cross\"> ★ </a>\n</div>\n\n\t","author":"Daring Fireball Department of Commerce","siteTitle":"Daring Fireball","siteHash":"fc569638025dadf22a867470f8215f38855cf50e975782a6c989909474292a36","entryHash":"b941e5cfc5a0d16900eb5b13b28d0df35bb1f323818351dc6c5c6c3d1c30c9de","category":"Tech"}