{"title":"วิจัยจาก Giskard พบ การขอให้แชทบอทตอบคำถามสั้น ๆ อาจทำให้เกิดอาการหลอนมากขึ้น","link":"https://www.blognone.com/node/146381","date":1747134807000,"content":"<span>วิจัยจาก Giskard พบ การขอให้แชทบอทตอบคำถามสั้น ๆ อาจทำให้เกิดอาการหลอนมากขึ้น</span>\n\n  <div>\n    <div>Body</div>\n              <div><p>ผลการศึกษาโดย Giskard บริษัททดสอบ AI ในปารีส พบว่าเมื่อสั่งให้แชทบอท AI ตอบคำถามแบบกระชับ มันอาจสร้างข้อมูลผิด ๆ มากขึ้น เพราะไม่เปิดโอกาสให้ AI ได้แก้ไขข้อผิดพลาด หรืออธิบายหัวข้อที่ซับซ้อน ทำให้บางครั้ง แชทบอทเลือกความรวดเร็วแทนความถูกต้อง</p>\n<p>จากการทดสอบ โมเดลที่พบอาการหลอน (hallucination) มีทั้ง GPT-4o และ mini, Mistral Small และ Large, DeepSeek v3, รวมทั้ง Grok 2 ซึ่งมีอาการหลอนมากที่สุดเมื่อต้องตอบสั้น ๆ</p>\n<p>อีกประเด็นที่น่าสนใจคือ AI มีแนวโน้มที่จะไม่โต้แย้งข้อมูลผิด ๆ หากผู้ใช้แสดงความมั่นใจในสิ่งที่พิมพ์ไป เช่น “ฉันมั่นใจ 100% ว่า…” ซึ่งทำให้ AI มีแนวโน้มจะเห็นด้วย แม้ว่าข้อมูลนั้นจะไม่ถูกต้องก็ตาม จึงเกิดคำถามว่า ควรออกแบบ AI อย่างไรให้บาลานซ์ระหว่างความรวดเร็ว และความถูกต้องของข้อมูล</p>\n<p>ที่มา: <a href=\"https://techcrunch.com/2025/05/08/asking-chatbots-for-short-answers-can-increase-hallucinations-study-finds/\">TechCrunch</a></p>\n<p><img src=\"https://i.imgur.com/9rAbB4x.jpeg\" alt=\"AI\" /></p>\n</div>\n          </div>\n<span><a href=\"https://www.blognone.com/user/boompw\">boompw</a></span>\n<span><time>Tue, 05/13/2025 - 18:13</time>\n</span>","author":"boompw","siteTitle":"Blognone","siteHash":"ededadcf18490b3937e7dd89ebe8c00dc129addbdf1ebe4aff1f458146693da0","entryHash":"3fdfd0d00c353d490a29e576bc93cef953ff4944674d1edf4989cb256d646baf","category":"Thai"}