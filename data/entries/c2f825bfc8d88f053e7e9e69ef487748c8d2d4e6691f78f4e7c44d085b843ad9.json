{"title":"Nvidia’s new AI audio model can synthesize sounds that have never existed","link":"https://arstechnica.com/ai/2024/11/nvidias-new-ai-audio-model-can-synthesize-sounds-that-have-never-existed/","date":1732570800000,"content":"<p>At this point, anyone who has been following AI research is <a href=\"https://arstechnica.com/information-technology/2023/09/ai-can-now-generate-cd-quality-music-from-text-and-its-only-getting-better/\">long familiar</a> with <a href=\"https://arstechnica.com/information-technology/2023/01/googles-new-ai-model-creates-songs-from-text-descriptions-of-moods-sounds/\">generative models</a> that can <a href=\"https://arstechnica.com/information-technology/2023/01/microsofts-new-ai-can-simulate-anyones-voice-with-3-seconds-of-audio/\">synthesize speech</a> or <a href=\"https://arstechnica.com/information-technology/2024/04/new-ai-music-generator-udio-synthesizes-realistic-music-on-demand/\">melodic music</a> from <a href=\"https://arstechnica.com/information-technology/2024/04/mit-license-text-becomes-viral-sad-girl-piano-ballad-generated-by-ai/\">nothing but text prompting</a>. Nvidia's <a href=\"https://d1qx31qr3h6wln.cloudfront.net/publications/FUGATTO.pdf\">newly revealed \"Fugatto\" model</a> looks to go a step further, using new synthetic training methods and inference-level combination techniques to \"transform any mix of music, voices, and sounds,\" including the synthesis of sounds that have never existed.</p>\n<p>While Fugatto isn't available for public testing yet, <a href=\"https://fugatto.github.io/\">a sample-filled website</a> showcases how Fugatto can be used to dial a number of distinct audio traits and descriptions up or down, resulting in everything from the sound of saxophones barking to people speaking underwater to ambulance sirens singing in a kind of choir. While the results on display can be a bit hit or miss, the vast array of capabilities on display here helps support Nvidia's description of Fugatto as \"a Swiss Army knife for sound.\"</p>\n<h2>You’re only as good as your data</h2>\n<p>In <a href=\"https://d1qx31qr3h6wln.cloudfront.net/publications/FUGATTO.pdf\">an explanatory research paper</a>, over a dozen Nvidia researchers explain the difficulty in crafting a training dataset that can \"reveal meaningful relationships between audio and language.\" While standard language models can often infer how to handle various instructions from the text-based data itself, it can be hard to generalize descriptions and traits from audio without more explicit guidance.</p><p><a href=\"https://arstechnica.com/ai/2024/11/nvidias-new-ai-audio-model-can-synthesize-sounds-that-have-never-existed/\">Read full article</a></p>\n<p><a href=\"https://arstechnica.com/ai/2024/11/nvidias-new-ai-audio-model-can-synthesize-sounds-that-have-never-existed/#comments\">Comments</a></p>","author":"Kyle Orland","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"c2f825bfc8d88f053e7e9e69ef487748c8d2d4e6691f78f4e7c44d085b843ad9","category":"Tech"}