{"title":"New Mexico Sues Meta Over CSAM Content on Facebook and Instagram","link":"https://www.cnbc.com/2023/12/06/facebook-content-enabled-child-sexual-abuse-new-mexico-lawsuit.html","date":1701980151000,"content":"\n<p>Rohan Goswami, reporting for CNBC:</p>\n\n<blockquote>\n  <p>Facebook and Instagram created “prime locations” for sexual \npredators that enabled child sexual abuse, solicitation, and \ntrafficking, New Mexico’s attorney general alleged in a <a href=\"https://www.nmag.gov/wp-content/uploads/2023/12/2023-12-05-NM-v.-Meta-et-al.-COMPLAINT_Redacted.pdf\">civil \nsuit filed Wednesday</a> against Meta and CEO Mark \nZuckerberg. </p>\n\n<p>The suit was brought after an “undercover investigation” allegedly \nrevealed myriad instances of sexually explicit content being \nserved to minors, child sexual coercion, or the sale of child \nsexual abuse material, or CSAM, New Mexico attorney general Raúl \nTorrez said in a press release. </p>\n\n<p>The suit alleges that “certain child exploitative content” is ten \ntimes “more prevalent” on Facebook and Instagram as compared to \npornography site PornHub and adult content platform OnlyFans, \naccording to the release. </p>\n</blockquote>\n\n<p>This follows the recent and ongoing <a href=\"https://daringfireball.net/linked/2023/11/28/instagram-wsj-footage-of-children\">investigative reporting by The Wall Street Journal</a> into child porn rings on Instagram, and the ways in which their content algorithms send these deviants further down their perverted rabbit holes.</p>\n\n<p>Which in turn leads the Muskateers paying for Twitter/X <a href=\"https://twitter.com/stillgray/status/1732616176247934980\">to ask questions like</a> “Why are advertisers still on Facebook and Instagram but have such a massive problem with X, which bans such content?”</p>\n\n<p>No content is more electrifyingly objectionable than CSAM. No bones about it, Meta has both a content moderation problem <em>and</em> PR fiasco on its hands. They have got to stamp this out, or advertisers will start abandoning their platform. But there are huge differences between Meta and X. Meta does not want CSAM or even CSAM-adjacent content on its platforms. Their current content moderation infrastructure quashes a shocking amount of it already. They need to do better, and I think most people believe they want to. The objectionable material on Twitter/X, on the other hand — <a href=\"https://daringfireball.net/linked/2023/11/17/apple-ibm-twitter\">the racism, the antisemitism, the outright Nazism</a> — is explicitly permitted in the name of “free speech”. And in terms of <em>perception</em>, which is what advertisers care most about, Twitter/X is defined now by its number-one user, Elon Musk.</p>\n\n<p>Also, more cynically, ads on Instagram work — advertisers gain more in sales than they spend on the ads. That’s less true — and perhaps not true at all — on Twitter/X.</p>\n\n<p>Meta’s big legal problem isn’t that they’ve looked the other way at CSAM, but that <a href=\"https://www.nytimes.com/2023/11/25/technology/instagram-meta-children-privacy.html\">they’ve deliberately looked the other way at under-13 users signing up for Instagram accounts</a>, and purposely optimized their algorithms to engage teens. It doesn’t pass the sniff test that they’d want CSAM on Instagram; it easily passes the sniff test that they’d want to hook kids on the platform as young as possible.</p>\n\n<div>\n<a href=\"https://daringfireball.net/linked/2023/12/07/new-mexico-meta-csam\"> ★ </a>\n</div>\n\n\t","author":"John Gruber","siteTitle":"Daring Fireball","siteHash":"fc569638025dadf22a867470f8215f38855cf50e975782a6c989909474292a36","entryHash":"39e9b4cc86f2c51eedb20b0e4baa06adbd21e46c605337da65f85240b0b8e1cb","category":"Tech"}