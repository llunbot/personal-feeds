{"title":"GPT-4 poses too many risks and releases should be halted, AI group tells FTC","link":"https://arstechnica.com/?p=1927971","date":1680202908000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2023/03/getty-chatgpt-800x534.jpg\" alt=\"The ChatGPT website is displayed on a smartphone screen next to two blocks displaying the letters \" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2023/03/getty-chatgpt.jpg\">Enlarge</a> (credit: Getty Images | VCG)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>A nonprofit AI research group wants the Federal Trade Commission to investigate OpenAI, Inc. and halt releases of GPT-4.</p>\n<p>OpenAI \"has released a product GPT-4 for the consumer market that is biased, deceptive, and a risk to privacy and public safety. The outputs cannot be proven or replicated. No independent assessment was undertaken prior to deployment,\" said a <a href=\"https://cdn.arstechnica.net/wp-content/uploads/2023/03/CAIDP-FTC-Complaint-OpenAI-GPT-033023.pdf\">complaint to the FTC</a> submitted today by the <a href=\"https://www.caidp.org/\">Center for Artificial Intelligence and Digital Policy</a> (CAIDP).</p>\n<p>Calling for \"independent oversight and evaluation of commercial AI products offered in the United States,\" CAIDP asked the FTC to \"open an investigation into OpenAI, enjoin further commercial releases of GPT-4, and ensure the establishment of necessary guardrails to protect consumers, businesses, and the commercial marketplace.\"</p></div><p><a href=\"https://arstechnica.com/?p=1927971#p3\">Read 21 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=1927971&amp;comments=1\">Comments</a></p>","author":"Jon Brodkin","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"48c9ffb34f0c399e840af0ca60bb2de8f8866792f53f45dcff4c5418f461f0b8","category":"Tech"}