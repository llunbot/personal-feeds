{"title":"Apple releases visionOS SDK to developers and details testing process","link":"https://arstechnica.com/?p=1949343","date":1687381777000,"content":"<div>\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n  <ul>\n          <li>\n        <div>\n          <div><img src=\"https://cdn.arstechnica.net/wp-content/uploads/2023/06/IMG_4028-980x735.jpeg\" alt /></div>\n          <p>\n            This is Apple’s Vision Pro headset. It looks a bit like a particularly bulky pair of ski goggles, with the materials and design language of Apple’s AirPods Max headphones.                          [credit:\n                              Samuel Axon                            ]\n                      </p>\n        </div>\n      </li>\n      </ul>\n\n<p>Today, Apple <a href=\"https://www.apple.com/newsroom/2023/06/developer-tools-to-create-spatial-experiences-for-apple-vision-pro-now-available/\">announced</a> the imminent availability of the visionOS software development kit, which will allow app developers to begin working on apps for the company's upcoming Vision Pro mixed reality headset.</p>\n<p>Developers will use frameworks like SwiftUI, RealityKit, and ARKit to make augmented or mixed reality apps while working with tools previously used in Mac and iOS development, like Apple's Xcode IDE, Simulator, and TestFlight.</p>\n<p>Tools like these can be used either to develop new spatial apps for Vision Pro or to adapt iPhone or iPad apps to be used as windows within the Vision Pro's interface.</p></div><p><a href=\"https://arstechnica.com/?p=1949343#p3\">Read 6 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=1949343&amp;comments=1\">Comments</a></p>","author":"Samuel Axon","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"443f3b1e496ea11640530e6daa3464ed2c26e74027e3f582b42c3e5d22628d2e","category":"Tech"}