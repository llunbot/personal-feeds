{"title":"Import custom models in Amazon Bedrock (preview)","link":"https://aws.amazon.com/blogs/aws/import-custom-models-in-amazon-bedrock-preview/","date":1713871540000,"content":"<p>With <a href=\"https://aws.amazon.com/bedrock/\">Amazon Bedrock</a>, you have access to a choice of high-performing foundation models (FMs) from leading artificial intelligence (AI) companies that make it easier to build and scale generative AI applications. Some of these models provide publicly available weights that can be fine-tuned and customized for specific use cases. However, deploying customized FMs in a secure and scalable way is not an easy task.</p> \n<p>Starting today, Amazon Bedrock adds in preview the capability to import custom weights for supported model architectures (such as <a href=\"https://aws.amazon.com/bedrock/llama/\">Meta Llama 2, Llama 3</a>, and <a href=\"https://aws.amazon.com/bedrock/mistral/\">Mistral</a>) and serve the custom model using On-Demand mode. You can import models with weights in <a href=\"https://huggingface.co/docs/safetensors\">Hugging Face safetensors</a> format from <a href=\"https://aws.amazon.com/sagemaker/\">Amazon SageMaker</a> and <a href=\"https://aws.amazon.com/s3/\">Amazon Simple Storage Service (Amazon S3)</a>.</p> \n<p>In this way, you can use Amazon Bedrock with existing customized models such as <a href=\"https://ai.meta.com/blog/code-llama-large-language-model-coding/\">Code Llama</a>, a code-specialized version of Llama 2 that was created by further training Llama 2 on code-specific datasets, or use your data to fine-tune models for your own unique business case and import the resulting model in Amazon Bedrock.</p> \n<p>Let’s see how this works in practice.</p> \n<p><span><strong>Bringing a custom model to Amazon Bedrock<br /> </strong></span>In the <a href=\"https://console.aws.amazon.com/bedrock\">Amazon Bedrock console</a>, I choose <strong>Imported models</strong> from the <strong>Foundation models</strong> section of the navigation pane. Now, I can create a custom model by importing model weights from an <a href=\"https://aws.amazon.com/s3/\">Amazon Simple Storage Service (Amazon S3)</a> bucket or from an Amazon SageMaker model.</p> \n<p>I choose to import model weights from an S3 bucket. In another browser tab, I download the <a href=\"https://github.com/awslabs/extending-the-context-length-of-open-source-llms/tree/main/MistralLite\">MistralLite</a> model from the <a href=\"https://huggingface.co/\">Hugging Face</a> website using <a href=\"https://huggingface.co/amazon/MistralLite/tree/refs%2Fpr%2F20\">this pull request (PR)</a> that provides weights in safetensors format. The <a href=\"https://huggingface.co/amazon/MistralLite/discussions/20\">pull request</a> is currently <strong>Ready to merge</strong>, so it might be part of the main branch when you read this. MistralLite is a fine-tuned <a href=\"https://huggingface.co/mistralai/Mistral-7B-v0.1\">Mistral-7B-v0.1</a> language model with enhanced capabilities of processing long context up to 32K tokens.</p> \n<p>When the download is complete, I upload the files to an S3 bucket in the same <a href=\"https://aws.amazon.com/about-aws/global-infrastructure/regions_az/\">AWS Region</a> where I will import the model. Here are the MistralLite model files in the Amazon S3 console:</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/04/17/bedrock-import-model-s3-files.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/04/17/bedrock-import-model-s3-files.png\" alt=\"Console screenshot.\" width=\"1748\" height=\"770\" /></a></p> \n<p>Back at the Amazon Bedrock console, I enter a name for the model and keep the proposed import job name.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/04/17/bedrock-import-model-name.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/04/17/bedrock-import-model-name.png\" alt=\"Console screenshot.\" width=\"1750\" height=\"1114\" /></a></p> \n<p>I select <strong>Model weights</strong> in the <strong>Model import settings</strong> and browse S3 to choose the location where I uploaded the model weights.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/04/17/bedrock-import-model-settings.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/04/17/bedrock-import-model-settings.png\" alt=\"Console screenshot.\" width=\"1756\" height=\"580\" /></a></p> \n<p>To authorize Amazon Bedrock to access the files on the S3 bucket, I select the option to create and use a new <a href=\"https://aws.amazon.com/iam/\">AWS Identity and Access Management (IAM)</a> service role. I use the <strong>View permissions details</strong> link to check what will be in the role. Then, I submit the job.</p> \n<p>About ten minutes later, the import job is completed.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/04/17/bedrock-import-model-job.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/04/17/bedrock-import-model-job.png\" alt=\"Console screenshot.\" width=\"1756\" height=\"562\" /></a></p> \n<p>Now, I see the imported model in the console. The list also shows the model <a href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/reference-arns.html\">Amazon Resource Name (ARN)</a> and the creation date.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/04/17/bedrock-import-model-list.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/04/17/bedrock-import-model-list.png\" alt=\"Console screenshot.\" width=\"1754\" height=\"1270\" /></a></p> \n<p>I choose the model to get more information, such as the S3 location of the model files.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/04/17/bedrock-import-model-detail.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/04/17/bedrock-import-model-detail.png\" alt=\"Console screenshot.\" width=\"1752\" height=\"1270\" /></a></p> \n<p>In the model detail page, I choose <strong>Open in playground</strong> to test the model in the console. In the text playground, I type a question using the prompt template of the model:</p> \n<p><code>&lt;|prompter|&gt;What are the main challenges to support a long context for LLM?&lt;/s&gt;&lt;|assistant|&gt;</code></p> \n<p>The MistralLite imported model is quick to reply and describe some of those challenges.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/04/17/bedrock-import-model-playground.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/04/17/bedrock-import-model-playground.png\" alt=\"Console screenshot.\" width=\"1752\" height=\"1534\" /></a></p> \n<p>In the playground, I can tune responses for my use case using configurations such as temperature and maximum length or add stop sequences specific to the imported model.</p> \n<p>To see the syntax of the API request, I choose the three small vertical dots at the top right of the playground.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/04/17/bedrock-import-model-api-request.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/04/17/bedrock-import-model-api-request.png\" alt=\"Console screenshot.\" width=\"1758\" height=\"464\" /></a></p> \n<p>I choose <strong>View API syntax</strong> and run the command using the <a href=\"https://aws.amazon.com/cli/\">AWS Command Line Interface (AWS CLI)</a>:</p> \n<div> \n <pre><code>aws bedrock-runtime invoke-model \\\n--model-id arn:aws:bedrock:us-east-1:123412341234:imported-model/a82bkefgp20f \\\n--body \"{\\\"prompt\\\":\\\"&lt;|prompter|&gt;What are the main challenges to support a long context for LLM?&lt;/s&gt;&lt;|assistant|&gt;\\\",\\\"max_tokens\\\":512,\\\"top_k\\\":200,\\\"top_p\\\":0.9,\\\"stop\\\":[],\\\"temperature\\\":0.5}\" \\\n--cli-binary-format raw-in-base64-out \\\n--region us-east-1 \\\ninvoke-model-output.txt</code></pre> \n</div> \n<p>The output is similar to what I got in the playground. As you can see, for imported models, the model ID is the ARN of the imported model. I can use the model ID to invoke the imported model with the AWS CLI and <a href=\"https://aws.amazon.com/tools/\">AWS SDKs</a>.</p> \n<p><span><strong>Things to know<br /> </strong></span>You can bring your own weights for supported model architectures to <a href=\"https://aws.amazon.com/bedrock/\">Amazon Bedrock</a> in the US East (N. Virginia) <a href=\"https://aws.amazon.com/about-aws/global-infrastructure/regions_az/\">AWS Region</a>. The model import capability is currently available in preview.</p> \n<p>When using custom weights, Amazon Bedrock serves the model with On-Demand mode, and you only pay for what you use with no time-based term commitments. For detailed information, see <a href=\"https://aws.amazon.com/bedrock/pricing/\">Amazon Bedrock pricing</a>.</p> \n<p>The ability to import models is managed using <a href=\"https://aws.amazon.com/iam/\">AWS Identity and Access Management (IAM)</a>, and you can allow this capability only to the roles in your organization that need to have it.</p> \n<p>With this launch, it’s now easier to build and scale generative AI applications using custom models with security and privacy built in.</p> \n<p>To learn more:</p> \n<ul> \n <li>See the <a href=\"https://docs.aws.amazon.com/bedrock/latest/userguide/what-is-bedrock.html\">Amazon Bedrock User Guide</a>.</li> \n <li>Visit our <a href=\"https://community.aws/generative-ai?trk=e8665609-785f-4bbe-86e8-750a3d3e9e61&amp;sc_channel=el\">community.aws site</a> to find deep-dive technical content and discover how others are using Amazon Bedrock in their solutions.</li> \n</ul> \n<p>— <a href=\"https://twitter.com/danilop\">Danilo</a></p>","author":"Danilo Poccia","siteTitle":"AWS News Blog","siteHash":"6093e072e4117ec22616e844cb857d03ca62c57a411a8affc77cb5e8b6b15bf6","entryHash":"8094de47cf8c19f2a0c25ab91bc8b3a47427812035b19a69e6ec3124b41a23d3","category":"Tech"}