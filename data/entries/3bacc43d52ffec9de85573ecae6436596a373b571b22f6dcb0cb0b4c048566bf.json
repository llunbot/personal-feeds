{"title":"Fast LLM Inference From Scratch (using CUDA)","link":"https://andrewkchan.dev/posts/yalm.html","date":1734192168000,"content":"<a href=\"https://news.ycombinator.com/item?id=42417857\">Comments</a>","author":"","siteTitle":"Hacker News","siteHash":"37bb545430005dba450c1e40307450d8e4e791b434e83f3d38915ebad510fd50","entryHash":"3bacc43d52ffec9de85573ecae6436596a373b571b22f6dcb0cb0b4c048566bf","category":"Tech"}