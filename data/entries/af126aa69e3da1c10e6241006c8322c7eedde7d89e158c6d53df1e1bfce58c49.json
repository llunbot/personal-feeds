{"title":"Adobe Photoshop’s new “Generative Fill” AI tool lets you manipulate photos with text","link":"https://arstechnica.com/?p=1941261","date":1684868839000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2023/05/generative_fill_hero_3-800x450.jpg\" alt=\"An example of a 1983 file photo of the Apple Lisa computer that has been significantly enhanced by Generative Fill in the Adobe Photoshop beta.\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2023/05/generative_fill_hero_3.jpg\">Enlarge</a> <span>/</span> An example of a 1983 file photo of the Apple Lisa computer that has been significantly enhanced by the new \"Generative Fill\" AI tool in the Adobe Photoshop beta. (credit: Apple / Benj Edwards / Adobe)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>On Tuesday, Adobe <a href=\"https://blog.adobe.com/en/publish/2023/05/23/photoshop-new-features-ai-contextual-presets\">added</a> a new tool to its Photoshop beta called \"Generative Fill,\" which uses cloud-based image synthesis to fill selected areas of an image with new AI-generated content based on a text description. Powered by Adobe Firefly, Generative Fill works similarly to a technique called \"inpainting\" used in <a href=\"https://arstechnica.com/information-technology/2022/09/openai-image-generator-dall-e-now-available-without-waitlist/\">DALL-E</a> and <a href=\"https://arstechnica.com/information-technology/2022/09/with-stable-diffusion-you-may-never-believe-what-you-see-online-again/\">Stable Diffusion</a> releases since last year.</p>\n\n<p>At the core of Generative Fill is <a href=\"https://arstechnica.com/information-technology/2023/03/ethical-ai-art-generation-adobe-firefly-may-be-the-answer/\">Adobe Firefly</a>, which is Adobe's custom image-synthesis model. As a deep learning AI model, Firefly has been trained on millions of images in Adobe's stock library to associate certain imagery with text descriptions of them. Now part of Photoshop, people can type in what they want to see (i.e., \"a clown on a computer monitor\"), and Firefly will synthesize several options for the user to choose from. Generative Fill uses a well-known AI technique called \"<a href=\"https://www.nvidia.com/research/inpainting/index.html\">inpainting</a>\" to create a context-aware generation that can seamlessly blend synthesized imagery into an existing image.</p>\n<p>To use Generative Fill, users select an area of an existing image they want to modify. After selecting it, a \"Contextual Task Bar\" pops up that allows users to type in a description of what they want to see generated in the selected area. Photoshop sends this data to Adobe's servers for processing, then returns results in the app. After generating, the user has the option to select between several options of generations or to create more options to browse through.</p></div><p><a href=\"https://arstechnica.com/?p=1941261#p3\">Read 7 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=1941261&amp;comments=1\">Comments</a></p>","author":"Benj Edwards","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"af126aa69e3da1c10e6241006c8322c7eedde7d89e158c6d53df1e1bfce58c49","category":"Tech"}