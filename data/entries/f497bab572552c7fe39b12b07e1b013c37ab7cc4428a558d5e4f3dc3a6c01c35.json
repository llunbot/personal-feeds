{"title":"UK targets “despicable individuals” who create AI sex deepfakes with new law","link":"https://arstechnica.com/?p=2017401","date":1713279098000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2024/04/deepfake_illustration_1-800x450.jpg\" alt=\"An illustrator's concept of a deepfake.\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2024/04/deepfake_illustration_1.jpg\">Enlarge</a> (credit: <a href=\"https://www.gettyimages.com/detail/photo/deepfake-concept-royalty-free-image/1470340715\">Getty Images</a>)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>On Tuesday, the UK government <a href=\"https://www.gov.uk/government/news/government-cracks-down-on-deepfakes-creation\">announced</a> a new law targeting the creation of AI-generated sexually explicit deepfake images. Under the legislation, which has not yet been passed, offenders would face prosecution and an unlimited fine, even if they do not widely share the images but create them with the intent to distress the victim. The government positions the law as part of a broader effort to enhance legal protections for women.</p>\n\n<p>Over the past decade, the rise of deep learning image synthesis technology has made it increasingly easy for people with a consumer PC to create misleading pornography by swapping out the faces of the performers with someone else who has not consented to the act. That practice spawned the term \"deepfake\" around 2017, named after a Reddit user named \"deepfakes\" that <a href=\"https://www.vice.com/en/article/gydydm/gal-gadot-fake-ai-porn\">shared AI-faked porn</a> on the service. Since then, the term has grown to encompass completely new images and video <a href=\"https://arstechnica.com/information-technology/2022/12/thanks-to-ai-its-probably-time-to-take-your-photos-off-the-internet/\">synthesized entirely from scratch,</a> created from neural networks that have been trained on images of the victim.</p>\n<p>The problem isn't unique to the UK. In March, deepfake nudes of female middle school classmates in Florida <a href=\"https://arstechnica.com/tech-policy/2024/03/florida-middle-schoolers-charged-with-making-deepfake-nudes-of-classmates/\">led to charges</a> against two boys ages 13 and 14. The rise of open source image synthesis models like <a href=\"https://arstechnica.com/information-technology/2022/09/with-stable-diffusion-you-may-never-believe-what-you-see-online-again/\">Stable Diffusion</a> since 2022 has increased the urgency <a href=\"https://arstechnica.com/tech-policy/2024/01/sharing-deepfake-could-lead-to-lengthy-prison-time-under-proposed-law/\">among regulators in the US</a> to attempt to contain (or at least punish) the act of creating non-consensual deepfakes. The UK government is on a similar mission.</p></div><p><a href=\"https://arstechnica.com/?p=2017401#p3\">Read 4 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=2017401&amp;comments=1\">Comments</a></p>","author":"Benj Edwards","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"f497bab572552c7fe39b12b07e1b013c37ab7cc4428a558d5e4f3dc3a6c01c35","category":"Tech"}