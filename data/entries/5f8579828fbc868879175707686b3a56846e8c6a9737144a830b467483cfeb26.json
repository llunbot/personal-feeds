{"title":"หลุดเอกสารภายในกูเกิล เผยโมเดล PaLM 2 ขนาด 3.4 แสนล้านพารามิเตอร์ เล็กกว่า PaLM 1","link":"https://www.blognone.com/node/133894","date":1684415518000,"content":"<div><div><div><p>CNBC ได้เอกสารภายในของกูเกิล เผยรายละเอียดของ<a href=\"https://www.blognone.com/node/133775\">โมเดล PaLM 2 ตัวใหม่ของกูเกิล</a></p>\n<p>ขนาดของโมเดล PaLM 2 เทรนด้วยข้อมูล (token หรือจำนวนคำ) รวม 3.6 ล้านล้านคำ และจำนวนพารามิเตอร์ 3.4 แสนล้านพารามิเตอร์ หากเทียบกับโมเดล PaLM เวอร์ชันแรกที่ใช้ข้อมูลเทรน 7.8 แสนล้านคำ และพารามิเตอร์ 5.4 แสนล้านพารามิเตอร์ จะเห็นว่าจำนวนพารามิเตอร์ของ PaLM 2 น้อยกว่า สอดคล้องกับที่กูเกิลประกาศในงาน Google I/O ว่าโมเดลใหญ่กว่าไม่ได้ดีกว่าเสมอไป โดยกูเกิลใช้เทคนิคเรียกว่า compute-optimal scaling ช่วยลดจำนวนพารามิเตอร์และต้นทุนในการประมวลผลลง</p>\n<p>PaLM 2 มีให้เลือก 4 ขนาดจากเล็กไปใหญ่ เรียกตามชื่อสัตว์คือ Gecko, Otter, Bison, และ Unicorn โดย Gecko มีขนาดเล็กจนรันสามารถในโทรศัพท์มือถือได้</p>\n<p>ในงาน Google I/O 2023 รอบนี้ กูเกิลเปิดตัวฟีเจอร์ด้าน AI ให้บริการต่างๆ รวม 25 ตัว ซึ่งทั้งหมดใช้โมเดล PaLM 2 รันอยู่เบื้องหลัง</p>\n<p>ที่มา - <a href=\"https://www.cnbc.com/2023/05/16/googles-palm-2-uses-nearly-five-times-more-text-data-than-predecessor.html\">CNBC</a></p>\n<p><img src=\"https://www.blognone.com/sites/default/files/externals/6f4b72c857549b345796a0d3d57c55d3.jpg\" alt /></p>\n</div></div></div><div><div>Topics: </div><div><div><a href=\"/topics/google\">Google</a></div><div><a href=\"/topics/llm\">LLM</a></div><div><a href=\"/topics/artificial-intelligence\">Artificial Intelligence</a></div></div></div>","author":"mk","siteTitle":"Blognone","siteHash":"ededadcf18490b3937e7dd89ebe8c00dc129addbdf1ebe4aff1f458146693da0","entryHash":"5f8579828fbc868879175707686b3a56846e8c6a9737144a830b467483cfeb26","category":"Thai"}