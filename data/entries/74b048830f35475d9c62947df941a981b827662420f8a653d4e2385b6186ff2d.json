{"title":"AI writing assistants can cause biased thinking in their users","link":"https://arstechnica.com/?p=1942533","date":1685115373000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2023/05/GettyImages-1463288323-800x480.jpg\" alt=\"AI ethics or AI Law concept. Developing AI codes of ethics. Compliance, regulation, standard , business policy and responsibility for guarding against unintended bias in machine learning algorithms.\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2023/05/GettyImages-1463288323.jpg\">Enlarge</a> (credit: Parradee Kietsirikul)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>Anyone who has had to go back and retype a word on their smartphone because autocorrect chose the wrong one has had some kind of experience writing with <a href=\"https://arstechnica.com/information-technology/2022/06/ai-101-the-strategies-behind-creating-and-deploying-machine-learning/\">AI</a>. Failure to make these corrections can allow AI to say things we didn’t intend. But is it also possible for AI writing assistants to change what we <i>want</i> to say?</p>\n<p>This is what Maurice Jakesch, a doctoral student of information science at Cornell, wanted to find out. He created his own AI writing assistant based on GPT-3, one that would automatically come up with suggestions for filling in sentences—but there was a catch. Subjects using the assistant were supposed to answer the question “Is social media good for society?” The assistant, however, was programmed to offer biased suggestions for how to answer that question.</p>\n<h2>Assisting with bias</h2>\n<p>AI can be biased despite not being alive. Though these programs can only “think” to the degree that human brains figure out how to program them to, their creators may end up embedding personal biases in the software. Alternatively, if trained on a dataset that has a limited or biased representation, the final product <a href=\"https://arstechnica.com/tech-policy/2019/01/yes-algorithms-can-be-biased-heres-why/\">may display biases</a>.</p></div><p><a href=\"https://arstechnica.com/?p=1942533#p3\">Read 10 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=1942533&amp;comments=1\">Comments</a></p>","author":"Ars Contributors","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"74b048830f35475d9c62947df941a981b827662420f8a653d4e2385b6186ff2d","category":"Tech"}