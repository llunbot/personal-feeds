{"title":"OpenAI’s new “CriticGPT” model is trained to criticize GPT-4 outputs","link":"https://arstechnica.com/?p=2034089","date":1719517215000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2024/06/opena_criticgpt_hero-800x450.jpg\" alt=\"An illustration created by OpenAI.\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2024/06/opena_criticgpt_hero.jpg\">Enlarge</a> <span>/</span> An illustration created by OpenAI. (credit: <a href=\"https://openai.com/index/finding-gpt4s-mistakes-with-gpt-4/\">OpenAI</a>)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>On Thursday, OpenAI researchers unveiled <a href=\"https://openai.com/index/finding-gpt4s-mistakes-with-gpt-4/\">CriticGPT</a>, a new AI model designed to identify mistakes in code generated by ChatGPT. It aims to enhance the process of making AI systems behave in ways humans want (called \"alignment\") through <a href=\"https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback\">Reinforcement Learning from Human Feedback</a> (RLHF), which helps human reviewers make large language model (LLM) outputs more accurate.</p>\n\n<p>As outlined in a new research paper called \"<a href=\"https://cdn.openai.com/llm-critics-help-catch-llm-bugs-paper.pdf\">LLM Critics Help Catch LLM Bugs</a>,\" OpenAI created CriticGPT to act as an AI assistant to human trainers who review programming code generated by the ChatGPT AI assistant. CriticGPT—based on the GPT-4 family of LLMS—analyzes the code and points out potential errors, making it easier for humans to spot mistakes that might otherwise go unnoticed. The researchers trained CriticGPT on a dataset of code samples with intentionally inserted bugs, teaching it to recognize and flag various coding errors.</p>\n<div>\n<div>\n<div>\n<p>The researchers found that CriticGPT's critiques were preferred by annotators over human critiques in 63 percent of cases involving naturally occurring LLM errors and that human-machine teams using CriticGPT wrote more comprehensive critiques than humans alone while reducing confabulation (hallucination) rates compared to AI-only critiques.</p>\n<h2>Developing an automated critic</h2>\n</div>\n</div>\n</div>\n<p>The development of CriticGPT involved training the model on a large number of inputs containing deliberately inserted mistakes. Human trainers were asked to modify code written by ChatGPT, introducing errors and then providing example feedback as if they had discovered these bugs. This process allowed the model to learn how to identify and critique various types of coding errors.</p></div><p><a href=\"https://arstechnica.com/?p=2034089#p3\">Read 6 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=2034089&amp;comments=1\">Comments</a></p>","author":"Benj Edwards","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"0934ee0e4a3c8e61f965b991363c6f0d5169238e0ae038ec2683170559b07af8","category":"Tech"}