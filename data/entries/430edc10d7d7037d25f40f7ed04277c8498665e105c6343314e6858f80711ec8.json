{"title":"รู้จัก DeepSeek บริษัทปัญญาประดิษฐ์จากจีน ที่พยายามชนะข้อจำกัด จากคำสั่งแบนการส่งออกชิปขั้นสูง","link":"https://www.blognone.com/node/144337","date":1737972395000,"content":"<div><div><div><p>ประเด็นร้อนแรงของวงการเทคตอนนี้คงไม่พ้น DeepSeek บริษัทปัญญาประดิษฐ์จากจีนที่ออกโมเดล R1 มีความสามารถคิดเป็นขั้นตอน และมี<a href=\"https://www.blognone.com/node/144230\">ผลทดสอบหลายด้านชนะ o1 ของ OpenAI</a> พร้อมจุดเด่นคือต้นทุนการฝึกที่ต่ำกว่ามาก แถมยังโอเพนซอร์ส เรื่องนี้จึงอาจนำมาสู่การเปลี่ยนแปลงหลายอย่างในการพัฒนา AI ซึ่งไม่ใช่แค่จากจีนแต่อาจส่งผลทั้งวงการได้</p>\n<p>DeepSeek ก่อตั้งเมื่อเดือนกรกฎาคม 2023 โดย Liang Wenfeng ศิษย์เก่ามหาวิทยาลัย Zhejiang บริษัทตั้งอยู่ในเมืองหางโจว ได้รับเงินสนับสนุนจากกองทุน High-Flyer ซึ่ง Liang ก่อตั้งขึ้นตั้งแต่ปี 2015 เป้าหมายของ DeepSeek นั้นคล้ายกับ OpenAI คือต้องการพัฒนาปัญญาประดิษฐ์ที่มีความสามารถรอบด้านแบบมนุษย์หรือ AGI (Artificial General Intelligence)</p>\n<p>กองทุน High-Flyer ของ Liang เป็นหนึ่งในบริษัทที่กว้านซื้อจีพียู NVIDIA A100 ไว้จำนวนมาก ก่อนที่สหรัฐอเมริกาจะ<a href=\"https://www.blognone.com/node/136290\">ออกคำสั่งแบนห้าม NVIDIA ส่งออกชิปรุ่นบนสุดไปจีน</a> แม้ไม่มีจำนวนที่ยืนยันชัดเจน แต่คาดว่า High-Flyer มีจีพียู A100 ประมาณ 10,000 ตัว ทำให้ DeepSeek มีทรัพยากรประมวลผลขั้นสูงอยู่จำนวนหนึ่ง แต่ไม่เยอะเมื่อเทียบกับบริษัทเทคฝั่งอเมริกา จากนั้นบริษัท<a href=\"https://www.blognone.com/node/143857\">ซื้อจีพียูรุ่นรองคือ H800</a> เวอร์ชันจีนมาเสริมกำลังประมวลผลแทน</p>\n<p>Liang เคยให้สัมภาษณ์เมื่อกลางปี 2024 ว่าการถูกจำกัดทรัพยากรชิปขั้นสูง ทำให้การทำวิศวกรรมปัญญาประดิษฐ์มีต้นทุนสูงมาก กำลังประมวลผลต้องใช้ 2-4 เท่าเพื่อให้ได้ผลลัพธ์ที่เท่ากัน บริษัทจึงต้องพยายามหาทางลดช่องว่างนี้ให้ได้ จนเกิดการร่วมมือวิจัยหาแนวทางเพิ่มประสิทธิภาพการฝึกโมเดลให้ดีขึ้น บนฮาร์ดแวร์ที่มีจำกัด เช่น การลดความซ้ำซ้อนข้อมูล ลดการทำ Supervised Fine-Tuning ไปเพิ่ม Reinforce เรื่องนี้ยังอธิบายได้ว่าทำไมบริษัทเทคในจีนจึงมักทำโมเดล AI แบบโอเพนซอร์ส ก็เพื่อให้เกิดการแชร์ข้อมูลและพัฒนาร่วมกันมากที่สุด เพราะทุกคนทำงานบนฮาร์ดแวร์ที่มีข้อจำกัด</p>\n<p>DeepSeek บอกว่าต้นทุนที่ใช้ในการฝึกโมเดล R1 คือ 5.6 ล้านดอลลาร์ ตัวเลขนี้น้อยกว่าต้นทุนของบริษัทปัญญาประดิษฐ์ในอเมริกา ซึ่งตัวเลขขั้นต่ำคือ 100 ล้านดอลลาร์ หรือบางกรณีอาจแตะระดับพันล้านดอลลาร์ ตรงนี้จึงเป็นประเด็นที่พูดถึงมากเพราะหากการพัฒนาโมเดลแบบ LLM ทำได้ด้วยต้นทุนที่น้อยลงขนาดนี้ย่อมส่งผลในหลายด้าน ไม่ว่าจะเป็นผู้ผลิตฮาร์ดแวร์ หรือบริษัทพัฒนา AI ที่ลงทุนไปแล้วหรือกำลังวางแผนลงทุนในอนาคต</p>\n<p>อย่างไรก็ตาม The Wall Street Journal อ้างข้อมูลว่า Liang เพิ่งเข้าพบ  Li Qiang นายกรัฐมนตรีของจีนเมื่อสัปดาห์ที่แล้ว และบอกว่าคำสั่งแบนการส่งออกชิปมาจีนนั้น ยังคงเป็นปัญหาที่สร้างข้อจำกัดในการพัฒนาด้านปัญญาประดิษฐ์อยู่</p>\n<p>มีความเห็นที่น่าสนใจของ <a href=\"https://x.com/DrJimFan/status/1881353126210687089\">Jim Fan</a> นักวิจัยที่ NVIDIA เขาบอกว่า DeepSeek ใช้วิธีพัฒนาโมเดลที่แตกต่างออกไปหลายอย่าง เช่น เรียนรู้จากศูนย์แบบ AlphaZero, ลดระดับ Reward, ฝึกให้ได้ผลลัพธ์ที่แม่นยำแล้วเลือกไปเลย ทำให้ลดทางเลือกแบบต้นไม้ที่เพิ่มความซับซ้อนตอนประมวลผล ส่วนความกังวลว่าจะกระทบกับการลงทุนหลายส่วน เขามองว่าเมื่อต้นทุนฝึกฝนลดลง 10 เท่า ก็แปลว่าทรัพยากรที่มีปัจจุบันจะทำงานได้มากขึ้น 10 เท่าด้วย ปลายทางของปัญญาประดิษฐ์ความสามารถรอบด้านจึงเข้ามาถึงทุกคนเร็วขึ้นเช่นกัน</p>\n<p>ที่มา: <a href=\"https://www.technologyreview.com/2025/01/24/1110526/china-deepseek-top-ai-despite-sanctions/\">MIT Technology Review</a>, <a href=\"https://www.wsj.com/tech/ai/china-ai-deepseek-chatbot-6ac4ad33\">The Wall Street Journal</a></p>\n<p><img alt=\"No Description\" src=\"https://www.blognone.com/sites/default/files/externals/3bf27f53fb20fa7e86e679a3372616ce.jpeg\" /></p>\n</div></div></div><div><div>Topics: </div><div><div><a href=\"/topics/deepseek\">DeepSeek</a></div><div><a href=\"/topics/artificial-intelligence\">Artificial Intelligence</a></div><div><a href=\"/topics/china\">China</a></div></div></div>","author":"arjin","siteTitle":"Blognone","siteHash":"ededadcf18490b3937e7dd89ebe8c00dc129addbdf1ebe4aff1f458146693da0","entryHash":"430edc10d7d7037d25f40f7ed04277c8498665e105c6343314e6858f80711ec8","category":"Thai"}