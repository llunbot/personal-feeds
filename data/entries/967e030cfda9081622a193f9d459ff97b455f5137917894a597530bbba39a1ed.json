{"title":"Hallucinations in code are the least dangerous form of LLM mistakes","link":"https://simonwillison.net/2025/Mar/2/hallucinations-in-code/","date":1740942958000,"content":"<a href=\"https://news.ycombinator.com/item?id=43233903\">Comments</a>","author":"","siteTitle":"Hacker News","siteHash":"37bb545430005dba450c1e40307450d8e4e791b434e83f3d38915ebad510fd50","entryHash":"967e030cfda9081622a193f9d459ff97b455f5137917894a597530bbba39a1ed","category":"Tech"}