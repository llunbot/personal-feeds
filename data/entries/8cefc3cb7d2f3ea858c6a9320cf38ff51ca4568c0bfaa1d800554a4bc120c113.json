{"title":"AMD เปิดตัว Instinct MI300A ชิปรวมร่างซีพียู-จีพียูสำหรับ AI และ MI300X รุ่นจีพียูล้วน","link":"https://www.blognone.com/node/134340","date":1686715199000,"content":"<div><div><div><p>AMD เผยข้อมูลของชิปประมวลผล AI สำหรับศูนย์ข้อมูล Instinct MI300 ที่<a href=\"https://www.blognone.com/node/132138\">เคยเปิดตัวครั้งแรกเมื่อต้นปี 2023</a></p>\n<p>AMD Instinct MI300 จะมี 2 รุ่นย่อยคือ</p>\n<ul>\n<li><strong>MI300A</strong> เป็น APU คือมีทั้งซีพียู Zen 4 และจีพียู CDNA 3 ในตัวเดียวกัน วางเชื่อมกันแบบ chiplet ถือเป็น APU ตัวแรกของโลกศูนย์ข้อมูล ตอนนี้เริ่มส่งสินค้าตัวอย่างให้ลูกค้าแล้ว</li>\n<li><strong>MI300X</strong> เป็นเวอร์ชันจีพียูล้วน คือถอดซีพียูออกแล้วใส่จีพียูเพิ่ม แล้วอัดแรม HBM3 ขนาด 192GB แบนด์วิดท์แรม 5.2TB/s ที่โฆษณาว่าเยอะกว่าชิป NVIDIA H100 ถึง 1.6 เท่า สินค้าตัวอย่างจะส่งมอบในไตรมาส 3</li>\n</ul>\n<p>การมาถึงของ MI300X ที่มีแรมขนาดใหญ่ 192GB ทำให้ยัดโมเดลใหญ่ๆ อย่าง <a href=\"https://www.blognone.com/node/134122\">Falcon 40B</a> ลงในชิป MI300X เพียงตัวเดียวได้ด้วย</p>\n<p>ที่มา - <a href=\"https://www.amd.com/en/newsroom/press-releases/2023-6-13-amd-expands-leadership-data-center-portfolio-with-.html\">AMD</a></p>\n<p><img alt=\"No Description\" src=\"https://www.blognone.com/sites/default/files/externals/510edffa5f255b11aa98d8ff484ea7a6.jpg\" /></p>\n<p><img alt=\"No Description\" src=\"https://www.blognone.com/sites/default/files/externals/68f62247f72c56627b90c68ffa568eb6.jpg\" /></p>\n<p><img alt=\"No Description\" src=\"https://www.blognone.com/sites/default/files/externals/758b8074dfe6daa50a6e65af2a9f513b.jpg\" /></p>\n<p><img alt=\"No Description\" src=\"https://www.blognone.com/sites/default/files/externals/104d69f03e9757132d0c609cead313ed.jpg\" /></p>\n<p><img alt=\"No Description\" src=\"https://www.blognone.com/sites/default/files/externals/092dd752776a901a20c8cb01a54405b7.jpg\" /></p>\n<blockquote><p>Introducing AMD Instinct MI300X — the world's most advanced accelerator for generative <a href=\"https://twitter.com/hashtag/AI?src=hash&amp;ref_src=twsrc%5Etfw\">#AI</a>.​ Built with next-gen AMD CDNA 3 architecture and up to 192 GB of HBM3 to provide compute and memory efficiency needed for LLM training and inference, for lower TCO and easy deployments. <a href=\"https://t.co/GdQ6e98LKM\">pic.twitter.com/GdQ6e98LKM</a></p>\n<p>— AMD (@AMD) <a href=\"https://twitter.com/AMD/status/1668777897325219842?ref_src=twsrc%5Etfw\">June 14, 2023</a></p></blockquote>\n</div></div></div><div><div>Topics: </div><div><div><a href=\"/topics/instinct\">Instinct</a></div><div><a href=\"/topics/amd\">AMD</a></div><div><a href=\"/topics/cpu\">CPU</a></div><div><a href=\"/topics/gpu\">GPU</a></div><div><a href=\"/topics/data-center\">Data Center</a></div><div><a href=\"/topics/apu\">APU</a></div></div></div>","author":"mk","siteTitle":"Blognone","siteHash":"ededadcf18490b3937e7dd89ebe8c00dc129addbdf1ebe4aff1f458146693da0","entryHash":"8cefc3cb7d2f3ea858c6a9320cf38ff51ca4568c0bfaa1d800554a4bc120c113","category":"Thai"}