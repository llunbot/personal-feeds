{"title":"ใช้ Kubernetes pause ใน Docker เปล่าๆ","link":"https://blog.whs.in.th/node/3676","date":1695741467000,"content":"<p>สำหรับใครที่ใช้ Kubernetes และเคยเข้าไป list container ดูภายใน node ก็จะเคยเห็น container อันนึงชื่อ pause ซึ่งจะมี 1 pause ต่อ 1 pod</p>\n<p><a href=\"https://gallery.ecr.aws/eks-distro/kubernetes/pause\">EKS Pause</a> เขียนอธิบายหน้าที่ของมันไว้ว่า</p>\n<blockquote><p>\n  The Kubernetes pause container serves as the parent container for all of the containers in a pod. The pause container has two core responsibilities. First, it serves as the basis of Linux namespace sharing in the pod. Second, with PID (process ID) namespace sharing enabled, it serves as PID 1 for each pod and reaps zombie processes. It is responsible for creating shared network, assigning IP addresses within the pod for all containers inside this pod. If the pause container is terminated, Kubernetes will consider the whole pod as terminated and kill it and reschedule a new one.\n</p></blockquote>\n<p>แปลได้ว่า</p>\n<blockquote><p>\n  Container pause ของ Kubernetes มีหน้าที่เป็น container หลักสำหรับทุก container ใน pod เดียวกัน โดย pause container มี 2 หน้าที่คือ</p>\n<ol>\n<li>เป็นฐานของการแชร์ Linux namespace ภายใน pod</li>\n<li>ถ้าหากเปิดการแชร์ PID (process ID) namespace ไว้ด้วยกัน มันก็จะเป็น <a href=\"https://blog.whs.in.th/node/2292\">PID 1</a> สำหรับแต่ละ pod ทำหน้าที่เก้บ zombie process</li>\n</ol>\n<p>  หน้าที่รับผิดชอบของมันคือสร้าง network ที่แชร์ กำหนด IP ภายใน pod สำหรับทุก container</p>\n<p>  ถ้าหาก pause container ถูกปิด Kubernetes จะถือว่าทั้ง pod หยุดทำงานและจะสร้าง pod ใหม่\n</p></blockquote>\n<p>ฟังดูยุ่งๆ ไม่เข้าใจ แต่ผมพบว่าหลังๆ มา ผมมี use case เรื่อง namespace sharing ใช้ใน Docker เปล่าๆ หลายทีแล้ว ก็เลยอยากมาให้ดูว่า namespace sharing คืออะไรและใช้นอก Docker อย่างไร</p>\n<h2>Network sharing</h2>\n<figure><img loading=\"lazy\" src=\"https://blog.whs.in.th/wp-content/uploads/2023/09/cattle.jpg\" alt=\"\" width=\"1280\" height=\"683\" /><figcaption>Is this cattle or pet</figcaption></figure>\n<p>ใครที่เคยทำหลาย container ต่อ 1 pod ใน Kubernetes (sidecar pattern) จะทราบว่า localhost บน 2 container นั้นจะแชร์กัน อยากคุยกันก็ยิงผ่าน localhost ได้ หรือถ้ามีการเปิด port จะเปิดทับกันไม่ได้ ซึ่งผมพบว่าผมต้องการทำแบบนี้แต่ไม่ใช้ Kubernetes</p>\n<p>ช่วงนี้ผมเริ่มย้าย Network ภายในบางส่วนมาใช้โปรแกรม <a href=\"https://tailscale.com\">Tailscale</a> ซึ่งเป็นโปรแกรม VPN รูปแบบหนึ่ง ฟีเจอร์หนึ่งของ Tailscale คือสามารถแชร์เครื่องให้กับคนภายนอกได้ ใน use case ที่ผมต้องการใช้ก็คือจะเล่นเกม Minecraft กับคนอื่น ถ้าหากเปิด IP Minecraft ออก Internet แล้วไม่ดูแลก็อาจจะถูก scan และ Hack network ภายในได้ ก็เลยจะต้องเข้ามาใน VPN ก่อนจึงจะเล่นได้</p>\n<p>ในอดีต use case ลักษณะนี้ที่จะนิยมกันก็คือใช้โปรแกรม Hamachi แต่ว่าโปรแกรม Hamachi นั้นจะมองเห็นเป็น LAN เดียวกันเข้าถึงกันได้หมด แปลว่าถ้าหากเครื่องที่เข้ามาต่อมี firewall ภายในไม่ถูกต้องอาจจะทำให้เพื่อนล้วงข้อมูลของเราได้ หรือติด worm ต่อกัน สำหรับ Tailscale นั้นจะใช้ระบบให้ 1 คน 1 network ของใครของมัน แล้วผมสามารถแชร์เครื่องให้เพื่อนได้ซึ่งจะทำให้มองเห็นเฉพาะเครื่องนั้นอยู่บน network ของเพื่อน (เครื่องที่แชร์จะไม่สามารถเปิด connection ออกไปหา network คนอื่นได้ ทำให้เราไม่สามารถ scan network เพื่อนได้เช่นกัน)</p>\n<p>วิธีการใช้งาน Tailscale ที่ดีก็คือติดตั้งเป็น sidecar ของ Container ทำให้เราเห็น 1 container = 1 machine ใน Tailscale แล้วเราแชร์ออกไปเฉพาะ container นั้นได้ แปลว่าใครเล่น Minecraft กับผมก็เข้ามา Factorio server ไม่ได้ ถ้าไม่รู้ลิงค์แชร์ Factorio</p>\n<p>ทีนี้เราก็เลยจะต้องติดตั้ง Tailscale บน “เครื่อง” เดียวกับ Minecraft หรือก็คือเราต้องทำให้ localhost เดียวมีทั้ง Tailscale + Minecraft ผมก็นึกถึงท่า Kubernetes ขึ้นมาเลยว่าภายใน pod ก็เป็นแบบนั้นเป๊ะ</p>\n<p>ดังนั้น Docker compose ก็จะเป็นลักษณะนี้</p>\n<pre><code>version: \"2.2\"\nservices:\n  minecraft:\n    restart: unless-stopped\n    image: itzg/minecraft-server\n    tty: true\n    stdin_open: true\n    environment:\n      EULA: 'true'\n    volumes:\n      - /path/to/minecraft:/data:Z\n  tailscale:\n    image: ghcr.io/tailscale/tailscale:latest\n    restart: unless-stopped\n    network_mode: service:minecraft\n    cap_add:\n      - NET_ADMIN\n      - NET_RAW\n    volumes:\n      - ts_data:/state/\n    devices:\n      - /dev/net/tun\n    environment:\n      TS_HOSTNAME: minecraft\n      TS_STATE_DIR: /state/\n      TS_USERSPACE: 'false'\n      TS_DEBUG_FIREWALL_MODE: nftables\nvolumes:\n  ts_data: {}\n</code></pre>\n<p>ในส่วนของ Tailscale container เราจะกำหนด <code>TS_USERSPACE=false</code> เพราะเราจะให้ <code>CAP_NET_ADMIN</code> กับ container ไปเลย ซึ่งเทียบเท่ากับ privileged container ใน Kubernetes และจะทำให้ preserve source IP ไว้ได้ (Minecraft จะเห็น source IP จริง ไม่ใช่ 127.0.0.1) และมีการกำหนด <code>network_mode: service:minecraft</code> เพื่อบอกว่ามีการแชร์ network namespace ร่วมกับ minecraft container ทำให้ localhost เห็นทะลุกันเหมือนกับใน Kubernetes pod</p>\n<p>ท่านี้ก็เหมือนจะดี จนกระทั่งผมเริ่ม mod Minecraft แล้วต้อง restart ก็พบว่า Tailscale network หลุด ใช้งานไม่ได้ ต้องลบสร้างใหม่อย่างเดียว และ docker-compose มันไม่ลบด้วยเพราะเราไม่ได้แก้อะไร ที่เป็นแบบนี้เพราะว่า network card หายไปแล้วตอนที่ Minecraft หยุดทำงาน ทำให้ Tailscale ไม่มีช่องทางเชื่อมต่อเน็ตอีก</p>\n<p>ดังนั้นถ้าเรามี container ที่รันนานๆ ไม่ต้อง restart ไม่ crash เลย ก็น่าจะแก้ไขปัญหานี้ได้ ซึ่งทำให้ผมนึกถึงว่านี่คือเหตุผลเดียวกับที่ Kubernetes มี pause container ดังนั้นเราสามารถขโมย pause container ออกมาใช้ได้</p>\n<pre><code>services:\n  pause:\n    image: public.ecr.aws/eks-distro/kubernetes/pause:3.9\n    restart: unless-stopped\n</code></pre>\n<p>(แล้วแก้ container อื่นๆ ให้มี <code>network_mode: service:pause</code>)</p>\n<p>อันนี้คือผมขโมย pause container ของ EKS มาเลย ซึ่งน่าจะเป็น Kubernetes ที่น่าเชื่อถือตัวหนึ่งและ<a href=\"https://gallery.ecr.aws/eks-distro/kubernetes/pause\">มันหาลิงค์ง่ายดี</a> หลังจากใช้ pause แล้วเราก็สามารถ restart Minecraft ได้เรื่อยๆ ไม่ต้อง recreate Tailscale อีกต่อไป ซึ่งดีมากๆ เพราะว่าอีกเกมหนึ่งที่เล่นกันคือ Satisfactory แล้วมัน crash บ่อยมาก ก็ปล่อย Docker restart ให้ได้เลยไม่ต้องเข้าไป recreate Tailscale ตามหลัง</p>\n<h2>PID sharing</h2>\n<p>อีกท่าหนึ่งที่ผมมีใช้งานก็คือการ share PID กัน ซึ่ง use case ที่จะใช้ก็คือผมมี container <a href=\"https://certbot.eff.org\">Certbot</a> และ application ต่างๆ ที่ใช้ Cert ใน container อื่นๆ โดยแชร์ volume ให้เป็น readonly</p>\n<p>ปัญหาก็คือปกติแล้วเวลา certbot มัน update cert ให้ มันจะ restart nginx ให้ แต่มันอยู่คนละ container กันจะทำอย่างไรดี ท่าต่อไปนี้ก็ไม่ควรทำ</p>\n<ol>\n<li>Mount Docker socket เข้าไปให้ certbot ก็จะทำให้มันยุ่ง container ที่ไม่เกี่ยวข้องได้</li>\n<li>Restart container อื่นด้วย cronjob ซึ่งก็พอใช้ได้ แต่มัน hack ไปหน่อย โปรแกรมบางตัวอาจจะต้อง restart ตอนเปลี่ยน cert ถ้าทำทุกวันอาจจะ disruptive</li>\n<li>Run certbot ใน host อาจจะยากตรงที่ต้องหา binary ที่มี plugin ที่ต้องการใช้งานให้ครบ</li>\n<li>ไม่ควรดัดแปลง container ให้มีหลายๆ process เช่นมี supervisor + nginx + cron + certbot</li>\n</ol>\n<p>วิธีที่ทำได้ก็ยังใช้ pause container เช่นเดิม โดย</p>\n<ol>\n<li>สร้าง pause container ไว้ก่อน</li>\n<li>Run certbot container โดยกำหนด <code>--pid pause</code> เพื่อแชร์ pid namespace กับ pause</li>\n<li>Run application container โดยกำหนด <code>--pid pause</code> เช่นกัน</li>\n</ol>\n<p>จากนั้นใน certbot เราก็ install hook ให้ <code>killall -s HUP nginx</code> ก็เป็นอันเรียบร้อย เพราะอยู่ใน namespace เดียวกันสามารถส่ง signal ไปหา process อื่นๆ ภายใน namespace ได้เลย</p>\n<p>ข้อควรระวังคือไม่ควรมี container อยู่ใน pid namespace โดยไม่จำเป็นเพราะมันสามารถ list process ข้ามกันได้ และถ้า user ID ตรงกันหรือเป็น root ใน container ก็ kill process ข้ามกันได้</p>","author":"whs","siteTitle":"Quietly Verbose","siteHash":"5f972a6fe70a917eb1b1aa165b3cb2be8a9465af33ab38bf05f34c55c0e40587","entryHash":"e1b3bf654552f4c61f85969ecf3bad9777ec6895782410c0fea06ad56b2455a3","category":"Thai"}