{"title":"Microsoft shows progress toward real-time AI-generated game worlds","link":"https://arstechnica.com/gaming/2025/02/microsofts-new-interactive-ai-world-model-still-has-a-long-way-to-go/","date":1739990452000,"content":"<p>For <a href=\"https://arstechnica.com/gadgets/2024/03/googles-genie-model-creates-interactive-2d-worlds-from-a-single-image/\">a while now</a>, many AI researchers have been <a href=\"https://arstechnica.com/information-technology/2024/08/new-ai-model-can-hallucinate-a-game-of-1993s-doom-in-real-time/\">working</a> to integrate a so-called <a href=\"https://arstechnica.com/ai/2024/12/googles-genie-2-world-model-reveal-leaves-more-questions-than-answers/\">\"world model\"</a> into their systems. Ideally, these models could infer a simulated understanding of how in-game objects and characters should behave based on video footage alone, then create fully interactive video that instantly simulates new playable worlds based on that understanding.</p>\n<p>Microsoft Research's new World and Human Action Model (WHAM), <a href=\"https://www.microsoft.com/en-us/research/blog/introducing-muse-our-first-generative-ai-model-designed-for-gameplay-ideation/\">revealed today</a> in <a href=\"https://www.nature.com/articles/s41586-025-08600-3\">a paper published in the journal Nature</a>, shows how quickly those models have advanced in a short time. But it also shows how much further we have to go before the dream of AI crafting complete, playable gameplay footage from just some basic prompts and sample video footage becomes a reality.</p>\n<h2>More consistent, more persistent</h2>\n<p>Much like <a href=\"https://arstechnica.com/ai/2024/12/googles-genie-2-world-model-reveal-leaves-more-questions-than-answers/\">Google's Genie model</a> before it, WHAM starts by training on \"ground truth\" gameplay video and input data provided by actual players. In this case, that data comes from <a href=\"https://store.steampowered.com/app/1189800/Bleeding_Edge/\"><em>Bleeding Edge</em></a>, a four-on-four online brawler released in 2020 by Microsoft subsidiary Ninja Theory. By collecting actual player footage since launch (as allowed under the game's user agreement), Microsoft gathered the equivalent of seven player-years' worth of gameplay video paired with real player inputs.</p><p><a href=\"https://arstechnica.com/gaming/2025/02/microsofts-new-interactive-ai-world-model-still-has-a-long-way-to-go/\">Read full article</a></p>\n<p><a href=\"https://arstechnica.com/gaming/2025/02/microsofts-new-interactive-ai-world-model-still-has-a-long-way-to-go/#comments\">Comments</a></p>","author":"Kyle Orland","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"512648174fdd83e4d43344b36a44afa3a5857727cac488eda8ce949bd52a8810","category":"Tech"}