{"title":"Amazon Nova Reel 1.1: Featuring up to 2-minutes multi-shot videos","link":"https://aws.amazon.com/blogs/aws/amazon-nova-reel-1-1-featuring-up-to-2-minutes-multi-shot-videos/","date":1744055774000,"content":"<p>At re:Invent 2024, we <a href=\"https://aws.amazon.com/blogs/aws/introducing-amazon-nova-frontier-intelligence-and-industry-leading-price-performance/\">announced Amazon Nova models</a>, a new generation of <a href=\"https://aws.amazon.com/what-is/foundation-models/\">foundation models (FMs),</a> including <a href=\"https://docs.aws.amazon.com/ai/responsible-ai/nova-reel/overview.html\">Amazon Nova Reel</a>, a video generation model that creates short videos from text descriptions and optional reference images (together, the “prompt”).</p> \n<p>Today, we introduce <a href=\"https://docs.aws.amazon.com/ai/responsible-ai/nova-reel/overview.html\">Amazon Nova Reel 1.1</a>, which provides quality and latency improvements in 6-second single-shot video generation, compared to Amazon Nova Reel 1.0. This update lets you generate multi-shot videos up to 2-minutes in length with consistent style across shots. You can either provide a single prompt for up to a 2-minute video composed of 6-second shots, or design each shot individually with custom prompts. This gives you new ways to create video content through <a href=\"https://aws.amazon.com/es/bedrock/?trk=fccf147c-636d-45bf-bf0a-7ab087d5691a&amp;sc_channel=el\">Amazon Bedrock</a>.</p> \n<div>\n \n  \n \n</div> \n<p>Amazon Nova Reel enhances creative productivity, while helping to reduce the time and cost of video production using <a href=\"https://aws.amazon.com/ai/generative-ai/?trk=fccf147c-636d-45bf-bf0a-7ab087d5691a&amp;sc_channel=el\">generative AI</a>. You can use Amazon Nova Reel to create compelling videos for your marketing campaigns, product designs, and social media content with increased efficiency and creative control. For example, in advertising campaigns, you can produce high-quality video commercials with consistent visuals and timing using natural language.</p> \n<p></p> \n<p><strong><u>To get started with Amazon Nova Reel 1.1 </u></strong><br /> If you’re new to using <a href=\"https://aws.amazon.com/ai/generative-ai/nova/creative/\">Amazon Nova Reel models</a>, go to the <a href=\"https://console.aws.amazon.com/bedrock\">Amazon Bedrock console</a>, choose <strong>Model access</strong> in the navigation panel and request access to the <strong>Amazon Nova Reel</strong> model. When you get access to Amazon Nova Reel, it applies both to 1.0 and 1.1.</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/04/07/2025-nova-reel-1.1-access-1024x645.png\" alt=\"\" width=\"1024\" height=\"645\" /></p> \n<p>After gaining access, you can try <strong>Amazon</strong> <strong>Nova Reel 1.1</strong> directly from the <a href=\"https://console.aws.amazon.com/bedrock\">Amazon Bedrock console</a>, AWS SDK, or <a href=\"https://aws.amazon.com/cli/?trk=fccf147c-636d-45bf-bf0a-7ab087d5691a&amp;sc_channel=el\">AWS Command Line Interface (AWS CLI)</a>.</p> \n<p>To test the <strong>Amazon Nova Reel 1.1</strong> model in the console, choose <strong>Image/Video</strong> under <strong>Playgrounds</strong> in the left menu pane. Then choose <strong>Nova Reel 1.1</strong> as the model and input your prompt to generate video.</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/04/07/2025-nova-reel-1.1-playground-1024x553.png\" alt=\"\" width=\"1024\" height=\"553\" /></p> \n<p>Amazon Nova Reel 1.1 offers two modes:</p> \n<ul> \n <li><strong>Multishot Automated – </strong>In this mode, Amazon Nova Reel 1.1 accepts a single prompt of up to 4,000 characters and produces a multi-shot video that reflects that prompt. This mode doesn’t accept an input image.</li> \n <li><strong><strong><strong>Multishot Manual – </strong></strong></strong>For those who desire more direct control over a video’s shot composition, with manual mode (also referred to as storyboard mode), you can specify a unique prompt for each individual shot. This mode does accept an optional starting image for each shot. Images must have a resolution of 1280×720. You can provide images in base64 format or from an <a href=\"https://aws.amazon.com/s3/\">Amazon Simple Storage Service (Amazon S3)</a> location.</li> \n</ul> \n<p>For this demo, I use the <a href=\"https://aws.amazon.com/sdk-for-python/\">AWS SDK for Python (Boto3)</a> to invoke the model using the <a href=\"https://docs.aws.amazon.com/bedrock/latest/userguide/bedrock-runtime_example_bedrock-runtime_Scenario_AmazonNova_TextToVideo_section.html\">Amazon Bedrock API</a> and <a href=\"https://docs.aws.amazon.com/nova/latest/userguide/video-gen-access.html#video-gen-start-a-job\">StartAsyncInvoke operation</a> to start an asynchronous invocation and generate the video. I used <a href=\"https://docs.aws.amazon.com/nova/latest/userguide/video-gen-access.html#video-gen-check-progress\">GetAsyncInvoke</a> to check on the progress of a video generation job.</p> \n<p>This Python script creates a 120-second video using <code>MULTI_SHOT_AUTOMATED</code><strong> </strong>mode as <a href=\"https://docs.aws.amazon.com/nova/latest/userguide/video-gen-access.html#video-gen-input-params\">TaskType parameter</a> from this text prompt, created by <a href=\"https://www.linkedin.com/in/nitinbeusebius/\">Nitin Eusebius</a>.</p> \n<pre><code>import random\nimport time\n\nimport boto3\n\nAWS_REGION = \"us-east-1\"\nMODEL_ID = \"amazon.nova-reel-v1:1\"\nSLEEP_SECONDS = 15  # Interval at which to check video gen progress\nS3_DESTINATION_BUCKET = \"s3://&lt;your bucket here&gt;\"\n\nvideo_prompt_automated = \"Norwegian fjord with still water reflecting mountains in perfect symmetry. Uninhabited wilderness of Giant sequoia forest with sunlight filtering between massive trunks. Sahara desert sand dunes with perfect ripple patterns. Alpine lake with crystal clear water and mountain reflection. Ancient redwood tree with detailed bark texture. Arctic ice cave with blue ice walls and ceiling. Bioluminescent plankton on beach shore at night. Bolivian salt flats with perfect sky reflection. Bamboo forest with tall stalks in filtered light. Cherry blossom grove against blue sky. Lavender field with purple rows to horizon. Autumn forest with red and gold leaves. Tropical coral reef with fish and colorful coral. Antelope Canyon with light beams through narrow passages. Banff lake with turquoise water and mountain backdrop. Joshua Tree desert at sunset with silhouetted trees. Iceland moss- covered lava field. Amazon lily pads with perfect symmetry. Hawaiian volcanic landscape with lava rock. New Zealand glowworm cave with blue ceiling lights. 8K nature photography, professional landscape lighting, no movement transitions, perfect exposure for each environment, natural color grading\"\n\nbedrock_runtime = boto3.client(\"bedrock-runtime\", region_name=AWS_REGION)\nmodel_input = {\n    \"taskType\": \"MULTI_SHOT_AUTOMATED\",\n    \"multiShotAutomatedParams\": {\"text\": video_prompt_automated},\n    \"videoGenerationConfig\": {\n        \"durationSeconds\": 120,  # Must be a multiple of 6 in range [12, 120]\n        \"fps\": 24,\n        \"dimension\": \"1280x720\",\n        \"seed\": random.randint(0, 2147483648),\n    },\n}\n\ninvocation = bedrock_runtime.start_async_invoke(\n    modelId=MODEL_ID,\n    modelInput=model_input,\n    outputDataConfig={\"s3OutputDataConfig\": {\"s3Uri\": S3_DESTINATION_BUCKET}},\n)\n\ninvocation_arn = invocation[\"invocationArn\"]\njob_id = invocation_arn.split(\"/\")[-1]\ns3_location = f\"{S3_DESTINATION_BUCKET}/{job_id}\"\nprint(f\"\\nMonitoring job folder: {s3_location}\")\n\nwhile True:\n    response = bedrock_runtime.get_async_invoke(invocationArn=invocation_arn)\n    status = response[\"status\"]\n    print(f\"Status: {status}\")\n    if status != \"InProgress\":\n        break\n    time.sleep(SLEEP_SECONDS)\n\nif status == \"Completed\":\n    print(f\"\\nVideo is ready at {s3_location}/output.mp4\")\nelse:\n    print(f\"\\nVideo generation status: {status}\")\n</code><code>\n</code></pre> \n<p>After the first invocation, the script periodically checks the status until the creation of the video has been completed. I pass a random seed to get a different result each time the code runs.</p> \n<p>I run the script:</p> \n<pre><code>Status: InProgress\n. . .\nStatus: Completed\nVideo is ready at s3://&lt;your bucket here&gt;/&lt;job_id&gt;/output.mp4\n</code></pre> \n<p>After a few minutes, the script is completed and prints the output Amazon S3 location. I download the output video using the AWS CLI:</p> \n<pre><code>aws s3 cp s3://&lt;your bucket here&gt;/&lt;job_id&gt;/output.mp4 output_automated.mp4</code></pre> \n<p>This is the video that this prompt generated:</p> \n<div>\n \n  \n \n</div> \n<p>In the case of <code>MULTI_SHOT_MANUAL</code> mode as TaskType parameter, with a prompt for multiples shots and a description for each shot, it is not necessary to add the variable <code>durationSeconds.</code></p> \n<p>Using the prompt for multiples shots, created by Sanju Sunny.</p> \n<p>I run Python script:</p> \n<pre><code>import random\nimport time\n\nimport boto3\n\n\ndef image_to_base64(image_path: str):\n    \"\"\"\n    Helper function which converts an image file to a base64 encoded string.\n    \"\"\"\n    import base64\n\n    with open(image_path, \"rb\") as image_file:\n        encoded_string = base64.b64encode(image_file.read())\n        return encoded_string.decode(\"utf-8\")\n\n\nAWS_REGION = \"us-east-1\"\nMODEL_ID = \"amazon.nova-reel-v1:1\"\nSLEEP_SECONDS = 15  # Interval at which to check video gen progress\nS3_DESTINATION_BUCKET = \"s3://&lt;your bucket here&gt;\"\n\nvideo_shot_prompts = [\n    # Example of using an S3 image in a shot.\n    {\n        \"text\": \"Epic aerial rise revealing the landscape, dramatic documentary style with dark atmospheric mood\",\n        \"image\": {\n            \"format\": \"png\",\n            \"source\": {\n                \"s3Location\": {\"uri\": \"s3://&lt;your bucket here&gt;/images/arctic_1.png\"}\n            },\n        },\n    },\n    # Example of using a locally saved image in a shot\n    {\n        \"text\": \"Sweeping drone shot across surface, cracks forming in ice, morning sunlight casting long shadows, documentary style\",\n        \"image\": {\n            \"format\": \"png\",\n            \"source\": {\"bytes\": image_to_base64(\"arctic_2.png\")},\n        },\n    },\n    {\n        \"text\": \"Epic aerial shot slowly soaring forward over the glacier's surface, revealing vast ice formations, cinematic drone perspective\",\n        \"image\": {\n            \"format\": \"png\",\n            \"source\": {\"bytes\": image_to_base64(\"arctic_3.png\")},\n        },\n    },\n    {\n        \"text\": \"Aerial shot slowly descending from high above, revealing the lone penguin's journey through the stark ice landscape, artic smoke washes over the land, nature documentary styled\",\n        \"image\": {\n            \"format\": \"png\",\n            \"source\": {\"bytes\": image_to_base64(\"arctic_4.png\")},\n        },\n    },\n    {\n        \"text\": \"Colossal wide shot of half the glacier face catastrophically collapsing, enormous wall of ice breaking away and crashing into the ocean. Slow motion, camera dramatically pulling back to reveal the massive scale. Monumental waves erupting from impact.\",\n        \"image\": {\n            \"format\": \"png\",\n            \"source\": {\"bytes\": image_to_base64(\"arctic_5.png\")},\n        },\n    },\n    {\n        \"text\": \"Slow motion tracking shot moving parallel to the penguin, with snow and mist swirling dramatically in the foreground and background\",\n        \"image\": {\n            \"format\": \"png\",\n            \"source\": {\"bytes\": image_to_base64(\"arctic_6.png\")},\n        },\n    },\n    {\n        \"text\": \"High-altitude drone descent over pristine glacier, capturing violent fracture chasing the camera, crystalline patterns shattering in slow motion across mirror-like ice, camera smoothly aligning with surface.\",\n        \"image\": {\n            \"format\": \"png\",\n            \"source\": {\"bytes\": image_to_base64(\"arctic_7.png\")},\n        },\n    },\n    {\n        \"text\": \"Epic aerial drone shot slowly pulling back and rising higher, revealing the vast endless ocean surrounding the solitary penguin on the ice float, cinematic reveal\",\n        \"image\": {\n            \"format\": \"png\",\n            \"source\": {\"bytes\": image_to_base64(\"arctic_8.png\")},\n        },\n    },\n]\n\nbedrock_runtime = boto3.client(\"bedrock-runtime\", region_name=AWS_REGION)\nmodel_input = {\n    \"taskType\": \"MULTI_SHOT_MANUAL\",\n    \"multiShotManualParams\": {\"shots\": video_shot_prompts},\n    \"videoGenerationConfig\": {\n        \"fps\": 24,\n        \"dimension\": \"1280x720\",\n        \"seed\": random.randint(0, 2147483648),\n    },\n}\n\ninvocation = bedrock_runtime.start_async_invoke(\n    modelId=MODEL_ID,\n    modelInput=model_input,\n    outputDataConfig={\"s3OutputDataConfig\": {\"s3Uri\": S3_DESTINATION_BUCKET}},\n)\n\ninvocation_arn = invocation[\"invocationArn\"]\njob_id = invocation_arn.split(\"/\")[-1]\ns3_location = f\"{S3_DESTINATION_BUCKET}/{job_id}\"\nprint(f\"\\nMonitoring job folder: {s3_location}\")\n\nwhile True:\n    response = bedrock_runtime.get_async_invoke(invocationArn=invocation_arn)\n    status = response[\"status\"]\n    print(f\"Status: {status}\")\n    if status != \"InProgress\":\n        break\n    time.sleep(SLEEP_SECONDS)\n\nif status == \"Completed\":\n    print(f\"\\nVideo is ready at {s3_location}/output.mp4\")\nelse:\n    print(f\"\\nVideo generation status: {status}\")</code><code>\n</code><code></code></pre> \n<p>As in the previous demo, after a few minutes, I download the output using the AWS CLI:<br /> <code>aws s3 cp s3://&lt;your bucket here&gt;/&lt;job_id&gt;/output.mp4 output_manual.mp4</code></p> \n<p>This is the video that this prompt generated:</p> \n<div>\n \n  \n \n</div> \n<p><u><strong>More creative examples</strong></u><br /> When you use Amazon Nova Reel 1.1, you'll discover a world of creative possibilities. Here are some sample prompts to help you begin:</p> \n<p>Color Burst, created by <a href=\"https://www.linkedin.com/in/nitinbeusebius/\">Nitin Eusebius</a></p> \n<p><code>prompt = \"Explosion of colored powder against black background. Start with slow-motion closeup of single purple powder burst. Dolly out revealing multiple powder clouds in vibrant hues colliding mid-air. Track across spectrum of colors mixing: magenta, yellow, cyan, orange. Zoom in on particles illuminated by sunbeams. Arc shot capturing complete color field. 4K, festival celebration, high-contrast lighting\"</code></p> \n<div>\n \n  \n \n</div> \n<p>Shape Shifting, created by <a href=\"https://www.linkedin.com/in/sanju-sunny/\">Sanju Sunny</a></p> \n<div> \n <pre><code>prompt = \"A simple red triangle transforms through geometric shapes in a journey of self-discovery. Clean vector graphics against white background. The triangle slides across negative space, morphing smoothly into a circle. Pan left as it encounters a blue square, they perform a geometric dance of shapes. Tracking shot as shapes combine and separate in mathematical precision. Zoom out to reveal a pattern formed by their movements. Limited color palette of primary colors. Precise, mechanical movements with perfect geometric alignments. Transitions use simple wipes and geometric shape reveals. Flat design aesthetic with sharp edges and solid colors. Final scene shows all shapes combining into a complex mandala pattern.\"</code></pre> \n</div> \n<div>\n \n  \n \n</div> \n<p>All example videos have music added manually before uploading, by the AWS Video team.</p> \n<p><u><strong>Things to know</strong></u><br /> <strong>Creative control</strong> – You can use this enhanced control for lifestyle and ambient background videos in advertising, marketing, media, and entertainment projects. Customize specific elements such as camera motion and shot content, or animate existing images.</p> \n<p><strong>Modes considerations – </strong> In automated mode, you can write prompts up to 4,000 characters. For manual mode, each shot accepts prompts up to 512 characters, and you can include up to 20 shots in a single video. Consider planning your shots in advance, similar to creating a traditional storyboard. Input images must match the 1280x720 resolution requirement. The service automatically delivers your completed videos to your specified S3 bucket.</p> \n<p><strong>Pricing and availability – </strong>Amazon Nova Reel 1.1 is available in Amazon Bedrock in the US East (N. Virginia) <a href=\"https://aws.amazon.com/about-aws/global-infrastructure/regions_az/\">AWS Region</a>. You can access the model through the Amazon Bedrock console, AWS SDK, or AWS CLI. As with all Amazon Bedrock services, pricing follows a pay-as-you-go model based on your usage. For more information, refer to <a href=\"https://aws.amazon.com/bedrock/pricing/\">Amazon Bedrock pricing</a>.</p> \n<p>Ready to start creating with Amazon Nova Reel? Visit the <a href=\"https://docs.aws.amazon.com/ai/responsible-ai/nova-reel/overview.html\">Amazon Nova Reel AWS AI Service Cards</a> to learn more and dive into the <a href=\"https://docs.aws.amazon.com/nova/latest/userguide/video-generation.html\">Generating videos with Amazon Nova</a>. Explore Python code examples in the <a href=\"https://github.com/aws-samples/amazon-nova-samples\">Amazon Nova model cookbook repository</a>, enhance your results using the <a href=\"https://docs.aws.amazon.com/nova/latest/userguide/prompting-video-generation.html\">Amazon Nova Reel prompting best practices</a>, and discover video examples in the <a href=\"https://www.amazon.science/blog/amazon-nova-reel-examples\">Amazon Nova Reel gallery</a>—complete with the prompts and reference images that brought them to life.</p> \n<p>The possibilities are endless, and we look forward to seeing what you create! Join our growing community of builders at <a href=\"https://community.aws/\">community.aws</a>, where you can create your <a href=\"https://community.aws/builderid?trk=fccf147c-636d-45bf-bf0a-7ab087d5691a&amp;sc_channel=el\">BuilderID</a>, share your video generation projects, and connect with fellow innovators.</p> \n<p>— <a href=\"https://www.linkedin.com/in/lizfue/\">Eli</a></p> \n<hr /> \n<p>How is the News Blog doing? Take this <a href=\"https://amazonmr.au1.qualtrics.com/jfe/form/SV_eyD5tC5xNGCdCmi\">1 minute survey</a>!</p> \n<p><em>(This <a href=\"https://amazonmr.au1.qualtrics.com/jfe/form/SV_eyD5tC5xNGCdCmi\">survey</a> is hosted by an external company. AWS handles your information as described in the <a href=\"https://aws.amazon.com/privacy/?trk=4b29643c-e00f-4ab6-ab9c-b1fb47aa1708&amp;sc_channel=blog\">AWS Privacy Notice</a>. AWS will own the data gathered via this survey and will not share the information collected with survey respondents.)</em></p>","author":"Elizabeth Fuentes","siteTitle":"AWS News Blog","siteHash":"6093e072e4117ec22616e844cb857d03ca62c57a411a8affc77cb5e8b6b15bf6","entryHash":"01ed5bfbe60d6c046f358a63712395988158bf11cfee51c04be0efa30ecca213","category":"Tech"}