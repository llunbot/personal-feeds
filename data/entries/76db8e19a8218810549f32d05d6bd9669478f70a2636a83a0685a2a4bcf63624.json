{"title":"Mixtral 8x7B: A sparse Mixture of Experts language model","link":"https://arxiv.org/abs/2401.04088","date":1704768786000,"content":"<a href=\"https://news.ycombinator.com/item?id=38921668\">Comments</a>","author":"","siteTitle":"Hacker News","siteHash":"37bb545430005dba450c1e40307450d8e4e791b434e83f3d38915ebad510fd50","entryHash":"76db8e19a8218810549f32d05d6bd9669478f70a2636a83a0685a2a4bcf63624","category":"Tech"}