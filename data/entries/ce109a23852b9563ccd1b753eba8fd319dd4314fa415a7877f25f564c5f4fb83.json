{"title":"OpenAI has the tech to watermark ChatGPT text—it just won’t release it","link":"https://arstechnica.com/?p=2041148","date":1722895940000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2023/01/chatgpt-800x520.jpg\" alt=\"OpenAI logo displayed on a phone screen and ChatGPT website displayed on a laptop screen.\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2023/01/chatgpt.jpg\">Enlarge</a> (credit: Getty Images)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>According to <a href=\"https://www.wsj.com/tech/ai/openai-tool-chatgpt-cheating-writing-135b755a\">The Wall Street Journal</a>, there's internal conflict at OpenAI over whether to release a watermarking tool that would allow people to test text to see whether it was generated by ChatGPT.</p>\n<p>To deploy the tool, OpenAI would make tweaks to ChatGPT that would lead it to leave a trail in the text it generates that can be detected by a special tool. The watermark would be undetectable by human readers without the tool, and the company's internal testing has shown that it does not negatively affect the quality of outputs. The detector would be accurate 99.9 percent of the time. It's important to note that the watermark would be a pattern in the text itself, meaning it would be preserved if the user copies and pastes the text or even if they make modest edits to it.</p>\n<p>Some OpenAI employees have campaigned for the tool's release, but others believe that would be the wrong move, citing a few specific problems.</p></div><p><a href=\"https://arstechnica.com/?p=2041148#p3\">Read 8 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=2041148&amp;comments=1\">Comments</a></p>","author":"Samuel Axon","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"ce109a23852b9563ccd1b753eba8fd319dd4314fa415a7877f25f564c5f4fb83","category":"Tech"}