{"title":"Researchers create AI worms that can spread from one system to another","link":"https://arstechnica.com/?p=2007366","date":1709380028000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2024/03/ai-malware-800x450.jpg\" alt=\"Researchers create AI worms that can spread from one system to another\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2024/03/ai-malware.jpg\">Enlarge</a> (credit: Jacqui VanLiew; Getty Images)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>As generative AI systems like <a href=\"https://www.wired.com/story/17-tips-better-chatgpt-prompts/\">OpenAI's ChatGPT</a> and <a href=\"https://www.wired.com/story/how-to-use-google-gemini-advanced-ai-chatbot/\">Google's Gemini</a> become more advanced, they are increasingly being put to work. Startups and tech companies are building AI agents and ecosystems on top of the systems that can <a href=\"https://www.wired.com/story/ai-chatbots-chatgpt-boring-chores/\">complete boring chores for you</a>: think automatically making calendar bookings and potentially <a href=\"https://www.wired.com/story/fast-forward-tested-next-gen-ai-assistant/\">buying products</a>. But as the tools are given more freedom, it also increases the potential ways they can be attacked.</p>\n<p>Now, in a demonstration of the risks of connected, autonomous AI ecosystems, a group of researchers has created one of what they claim are the first generative AI worms—which can spread from one system to another, potentially stealing data or deploying malware in the process. “It basically means that now you have the ability to conduct or to perform a new kind of cyberattack that hasn't been seen before,” says Ben Nassi, a Cornell Tech researcher behind the research.</p>\n<p>Nassi, along with fellow researchers Stav Cohen and Ron Bitton, created the worm, dubbed Morris II, as a nod to the original <a href=\"https://www.wired.com/2011/07/0726first-computer-fraud-indictment/\">Morris computer worm</a> that caused chaos across the Internet in 1988. In a <a href=\"https://sites.google.com/view/compromptmized\">research paper and website </a>shared exclusively with WIRED, the researchers show how the AI worm can attack a generative AI email assistant to steal data from emails and send spam messages—breaking some security protections in ChatGPT and Gemini in the process.</p></div><p><a href=\"https://arstechnica.com/?p=2007366#p3\">Read 15 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=2007366&amp;comments=1\">Comments</a></p>","author":"WIRED","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"6a78761f8ef7929ac9dfdeb09bfcbba36c017c7934a0ea04e89838632a21ca5f","category":"Tech"}