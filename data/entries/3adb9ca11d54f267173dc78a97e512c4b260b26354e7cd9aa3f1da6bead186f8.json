{"title":"Run large-scale simulations with AWS Batch multi-container jobs","link":"https://aws.amazon.com/blogs/aws/run-large-scale-simulations-with-aws-batch-multi-container-jobs/","date":1711395606000,"content":"<p>Industries like automotive, robotics, and finance are increasingly implementing computational workloads like simulations, machine learning (ML) model training, and big data analytics to improve their products. For example, automakers rely on simulations to test autonomous driving features, robotics companies train ML algorithms to enhance robot perception capabilities, and financial firms run in-depth analyses to better manage risk, process transactions, and detect fraud.</p> \n<p>Some of these workloads, including simulations, are especially complicated to run due to their diversity of components and intensive computational requirements. A driving simulation, for instance, involves generating 3D virtual environments, vehicle sensor data, vehicle dynamics controlling car behavior, and more. A robotics simulation might test hundreds of autonomous delivery robots interacting with each other and other systems in a massive warehouse environment.</p> \n<p><a href=\"http://aws.amazon.com/batch\">AWS Batch</a> is a fully managed service that can help you run batch workloads across a range of AWS compute offerings, including <a href=\"https://aws.amazon.com/ecs/\">Amazon Elastic Container Service (Amazon ECS)</a>, <a href=\"https://aws.amazon.com/eks/\">Amazon Elastic Kubernetes Service (Amazon EKS)</a>, <a href=\"https://aws.amazon.com/fargate/\">AWS Fargate</a>, and <a href=\"https://aws.amazon.com/pm/ec2/\">Amazon EC2</a> <a href=\"https://aws.amazon.com/ec2/spot/\">Spot</a> or <a href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-on-demand-instances.html\">On-Demand</a> Instances. Traditionally, AWS Batch only allowed single-container jobs and required extra steps to merge all components into a monolithic container. It also did not allow using separate “sidecar” containers, which are auxiliary containers that complement the main application by providing additional services like data logging. This additional effort required coordination across multiple teams, such as software development, IT operations, and quality assurance (QA), because any code change meant rebuilding the entire container.</p> \n<p>Now, AWS Batch offers multi-container jobs, making it easier and faster to run large-scale simulations in areas like autonomous vehicles and robotics. These workloads are usually divided between the simulation itself and the system under test (also known as an agent) that interacts with the simulation. These two components are often developed and optimized by different teams. With the ability to run multiple containers per job, you get the advanced scaling, scheduling, and cost optimization offered by AWS Batch, and you can use modular containers representing different components like 3D environments, robot sensors, or monitoring sidecars. In fact, customers such as <a href=\"https://www.ipg-automotive.com/en/products-solutions/software/\">IPG Automotive</a>, <a href=\"https://www.morai.ai/\">MORAI</a>, and <a href=\"https://robotec.ai/\">Robotec.ai</a> are already using AWS Batch multi-container jobs to run their simulation software in the cloud.</p> \n<p>Let’s see how this works in practice using a simplified example and have some fun trying to solve a maze.</p> \n<p><span><strong>Building a Simulation Running on Containers<br /> </strong></span>In production, you will probably use existing simulation software. For this post, I built a simplified version of an agent/model simulation. If you’re not interested in code details, you can skip this section and go straight to how to configure AWS Batch.</p> \n<p>For this simulation, the world to explore is a randomly generated 2D maze. The agent has the task to explore the maze to find a key and then reach the exit. In a way, it is a classic example of pathfinding problems with three locations.</p> \n<p>Here’s a sample map of a maze where I highlighted the start (<strong>S</strong>), end (<strong>E</strong>), and key (<strong>K</strong>) locations.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/03/19/aws-batch-multicontainer-maze-map.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/03/19/aws-batch-multicontainer-maze-map.png\" alt=\"Sample ASCII maze map.\" width=\"2384\" height=\"1200\" /></a></p> \n<p>The separation of agent and model into two separate containers allows different teams to work on each of them separately. Each team can focus on improving their own part, for example, to add details to the simulation or to find better strategies for how the agent explores the maze.</p> \n<p>Here’s the code of the maze model (<code>app.py</code>). I used Python for both examples. The model exposes a REST API that the agent can use to move around the maze and know if it has found the key and reached the exit. The maze model uses <a href=\"https://flask.palletsprojects.com/\">Flask</a> for the REST API.</p> \n<pre><code>import json\nimport random\nfrom flask import Flask, request, Response\n\nready = False\n\n# How map data is stored inside a maze\n# with size (width x height) = (4 x 3)\n#\n#    012345678\n# 0: +-+-+ +-+\n# 1: | |   | |\n# 2: +-+ +-+-+\n# 3: | |   | |\n# 4: +-+-+ +-+\n# 5: | | | | |\n# 6: +-+-+-+-+\n# 7: Not used\n\nclass WrongDirection(Exception):\n    pass\n\nclass Maze:\n    UP, RIGHT, DOWN, LEFT = 0, 1, 2, 3\n    OPEN, WALL = 0, 1\n    \n\n    @staticmethod\n    def distance(p1, p2):\n        (x1, y1) = p1\n        (x2, y2) = p2\n        return abs(y2-y1) + abs(x2-x1)\n\n\n    @staticmethod\n    def random_dir():\n        return random.randrange(4)\n\n\n    @staticmethod\n    def go_dir(x, y, d):\n        if d == Maze.UP:\n            return (x, y - 1)\n        elif d == Maze.RIGHT:\n            return (x + 1, y)\n        elif d == Maze.DOWN:\n            return (x, y + 1)\n        elif d == Maze.LEFT:\n            return (x - 1, y)\n        else:\n            raise WrongDirection(f\"Direction: {d}\")\n\n\n    def __init__(self, width, height):\n        self.width = width\n        self.height = height        \n        self.generate()\n        \n\n    def area(self):\n        return self.width * self.height\n        \n\n    def min_lenght(self):\n        return self.area() / 5\n    \n\n    def min_distance(self):\n        return (self.width + self.height) / 5\n    \n\n    def get_pos_dir(self, x, y, d):\n        if d == Maze.UP:\n            return self.maze[y][2 * x + 1]\n        elif d == Maze.RIGHT:\n            return self.maze[y][2 * x + 2]\n        elif d == Maze.DOWN:\n            return self.maze[y + 1][2 * x + 1]\n        elif d ==  Maze.LEFT:\n            return self.maze[y][2 * x]\n        else:\n            raise WrongDirection(f\"Direction: {d}\")\n\n\n    def set_pos_dir(self, x, y, d, v):\n        if d == Maze.UP:\n            self.maze[y][2 * x + 1] = v\n        elif d == Maze.RIGHT:\n            self.maze[y][2 * x + 2] = v\n        elif d == Maze.DOWN:\n            self.maze[y + 1][2 * x + 1] = v\n        elif d ==  Maze.LEFT:\n            self.maze[y][2 * x] = v\n        else:\n            WrongDirection(f\"Direction: {d}  Value: {v}\")\n\n\n    def is_inside(self, x, y):\n        return 0 &lt;= y &lt; self.height and 0 &lt;= x &lt; self.width\n\n\n    def generate(self):\n        self.maze = []\n        # Close all borders\n        for y in range(0, self.height + 1):\n            self.maze.append([Maze.WALL] * (2 * self.width + 1))\n        # Get a random starting point on one of the borders\n        if random.random() &lt; 0.5:\n            sx = random.randrange(self.width)\n            if random.random() &lt; 0.5:\n                sy = 0\n                self.set_pos_dir(sx, sy, Maze.UP, Maze.OPEN)\n            else:\n                sy = self.height - 1\n                self.set_pos_dir(sx, sy, Maze.DOWN, Maze.OPEN)\n        else:\n            sy = random.randrange(self.height)\n            if random.random() &lt; 0.5:\n                sx = 0\n                self.set_pos_dir(sx, sy, Maze.LEFT, Maze.OPEN)\n            else:\n                sx = self.width - 1\n                self.set_pos_dir(sx, sy, Maze.RIGHT, Maze.OPEN)\n        self.start = (sx, sy)\n        been = [self.start]\n        pos = -1\n        solved = False\n        generate_status = 0\n        old_generate_status = 0                    \n        while len(been) &lt; self.area():\n            (x, y) = been[pos]\n            sd = Maze.random_dir()\n            for nd in range(4):\n                d = (sd + nd) % 4\n                if self.get_pos_dir(x, y, d) != Maze.WALL:\n                    continue\n                (nx, ny) = Maze.go_dir(x, y, d)\n                if (nx, ny) in been:\n                    continue\n                if self.is_inside(nx, ny):\n                    self.set_pos_dir(x, y, d, Maze.OPEN)\n                    been.append((nx, ny))\n                    pos = -1\n                    generate_status = len(been) / self.area()\n                    if generate_status - old_generate_status &gt; 0.1:\n                        old_generate_status = generate_status\n                        print(f\"{generate_status * 100:.2f}%\")\n                    break\n                elif solved or len(been) &lt; self.min_lenght():\n                    continue\n                else:\n                    self.set_pos_dir(x, y, d, Maze.OPEN)\n                    self.end = (x, y)\n                    solved = True\n                    pos = -1 - random.randrange(len(been))\n                    break\n            else:\n                pos -= 1\n                if pos &lt; -len(been):\n                    pos = -1\n                    \n        self.key = None\n        while(self.key == None):\n            kx = random.randrange(self.width)\n            ky = random.randrange(self.height)\n            if (Maze.distance(self.start, (kx,ky)) &gt; self.min_distance()\n                and Maze.distance(self.end, (kx,ky)) &gt; self.min_distance()):\n                self.key = (kx, ky)\n\n\n    def get_label(self, x, y):\n        if (x, y) == self.start:\n            c = 'S'\n        elif (x, y) == self.end:\n            c = 'E'\n        elif (x, y) == self.key:\n            c = 'K'\n        else:\n            c = ' '\n        return c\n\n                    \n    def map(self, moves=[]):\n        map = ''\n        for py in range(self.height * 2 + 1):\n            row = ''\n            for px in range(self.width * 2 + 1):\n                x = int(px / 2)\n                y = int(py / 2)\n                if py % 2 == 0: #Even rows\n                    if px % 2 == 0:\n                        c = '+'\n                    else:\n                        v = self.get_pos_dir(x, y, self.UP)\n                        if v == Maze.OPEN:\n                            c = ' '\n                        elif v == Maze.WALL:\n                            c = '-'\n                else: # Odd rows\n                    if px % 2 == 0:\n                        v = self.get_pos_dir(x, y, self.LEFT)\n                        if v == Maze.OPEN:\n                            c = ' '\n                        elif v == Maze.WALL:\n                            c = '|'\n                    else:\n                        c = self.get_label(x, y)\n                        if c == ' ' and [x, y] in moves:\n                            c = '*'\n                row += c\n            map += row + '\\n'\n        return map\n\n\napp = Flask(__name__)\n\n@app.route('/')\ndef hello_maze():\n    return \"&lt;p&gt;Hello, Maze!&lt;/p&gt;\"\n\n@app.route('/maze/map', methods=['GET', 'POST'])\ndef maze_map():\n    if not ready:\n        return Response(status=503, retry_after=10)\n    if request.method == 'GET':\n        return '&lt;pre&gt;' + maze.map() + '&lt;/pre&gt;'\n    else:\n        moves = request.get_json()\n        return maze.map(moves)\n\n@app.route('/maze/start')\ndef maze_start():\n    if not ready:\n        return Response(status=503, retry_after=10)\n    start = { 'x': maze.start[0], 'y': maze.start[1] }\n    return json.dumps(start)\n\n@app.route('/maze/size')\ndef maze_size():\n    if not ready:\n        return Response(status=503, retry_after=10)\n    size = { 'width': maze.width, 'height': maze.height }\n    return json.dumps(size)\n\n@app.route('/maze/pos/&lt;int:y&gt;/&lt;int:x&gt;')\ndef maze_pos(y, x):\n    if not ready:\n        return Response(status=503, retry_after=10)\n    pos = {\n        'here': maze.get_label(x, y),\n        'up': maze.get_pos_dir(x, y, Maze.UP),\n        'down': maze.get_pos_dir(x, y, Maze.DOWN),\n        'left': maze.get_pos_dir(x, y, Maze.LEFT),\n        'right': maze.get_pos_dir(x, y, Maze.RIGHT),\n\n    }\n    return json.dumps(pos)\n\n\nWIDTH = 80\nHEIGHT = 20\nmaze = Maze(WIDTH, HEIGHT)\nready = True\n</code></pre> \n<p>The only requirement for the maze model (in <code>requirements.txt</code>) is the <code>Flask</code> module.</p> \n<p>To create a container image running the maze model, I use this <code>Dockerfile</code>.</p> \n<div> \n <pre><code>FROM --platform=linux/amd64 public.ecr.aws/docker/library/python:3.12-alpine\n\nWORKDIR /app\n\nCOPY requirements.txt requirements.txt\nRUN pip3 install -r requirements.txt\n\nCOPY . .\n\nCMD [ \"python3\", \"-m\" , \"flask\", \"run\", \"--host=0.0.0.0\", \"--port=5555\"]\n</code></pre> \n</div> \n<p>Here’s the code for the agent (<code>agent.py</code>). First, the agent asks the model for the size of the maze and the starting position. Then, it applies its own strategy to explore and solve the maze. In this implementation, the agent chooses its route at random, trying to avoid following the same path more than once.</p> \n<pre><code>import random\nimport requests\nfrom requests.adapters import HTTPAdapter, Retry\n\nHOST = '127.0.0.1'\nPORT = 5555\n\nBASE_URL = f\"http://{HOST}:{PORT}/maze\"\n\nUP, RIGHT, DOWN, LEFT = 0, 1, 2, 3\nOPEN, WALL = 0, 1\n\ns = requests.Session()\n\nretries = Retry(total=10,\n                backoff_factor=1)\n\ns.mount('http://', HTTPAdapter(max_retries=retries))\n\nr = s.get(f\"{BASE_URL}/size\")\nsize = r.json()\nprint('SIZE', size)\n\nr = s.get(f\"{BASE_URL}/start\")\nstart = r.json()\nprint('START', start)\n\ny = start['y']\nx = start['x']\n\nfound_key = False\nbeen = set((x, y))\nmoves = [(x, y)]\nmoves_stack = [(x, y)]\n\nwhile True:\n    r = s.get(f\"{BASE_URL}/pos/{y}/{x}\")\n    pos = r.json()\n    if pos['here'] == 'K' and not found_key:\n        print(f\"({x}, {y}) key found\")\n        found_key = True\n        been = set((x, y))\n        moves_stack = [(x, y)]\n    if pos['here'] == 'E' and found_key:\n        print(f\"({x}, {y}) exit\")\n        break\n    dirs = list(range(4))\n    random.shuffle(dirs)\n    for d in dirs:\n        nx, ny = x, y\n        if d == UP and pos['up'] == 0:\n            ny -= 1\n        if d == RIGHT and pos['right'] == 0:\n            nx += 1\n        if d == DOWN and pos['down'] == 0:\n            ny += 1\n        if d == LEFT and pos['left'] == 0:\n            nx -= 1 \n\n        if nx &lt; 0 or nx &gt;= size['width'] or ny &lt; 0 or ny &gt;= size['height']:\n            continue\n\n        if (nx, ny) in been:\n            continue\n\n        x, y = nx, ny\n        been.add((x, y))\n        moves.append((x, y))\n        moves_stack.append((x, y))\n        break\n    else:\n        if len(moves_stack) &gt; 0:\n            x, y = moves_stack.pop()\n        else:\n            print(\"No moves left\")\n            break\n\nprint(f\"Solution length: {len(moves)}\")\nprint(moves)\n\nr = s.post(f'{BASE_URL}/map', json=moves)\n\nprint(r.text)\n\ns.close()\n</code></pre> \n<p>The only dependency of the agent (in <code>requirements.txt</code>) is the <code>requests</code> module.</p> \n<p>This is the <code>Dockerfile</code> I use to create a container image for the agent.</p> \n<div> \n <pre><code>FROM --platform=linux/amd64 public.ecr.aws/docker/library/python:3.12-alpine\n\nWORKDIR /app\n\nCOPY requirements.txt requirements.txt\nRUN pip3 install -r requirements.txt\n\nCOPY . .\n\nCMD [ \"python3\", \"agent.py\"]\n</code></pre> \n</div> \n<p>You can easily run this simplified version of a simulation locally, but the cloud allows you to run it at larger scale (for example, with a much bigger and more detailed maze) and to test multiple agents to find the best strategy to use. In a real-world scenario, the improvements to the agent would then be implemented into a physical device such as a self-driving car or a robot vacuum cleaner. If you want to increase the complexity of the simulation and scale into the tens or hundreds of thousands of dynamic entities, check out <a href=\"https://aws.amazon.com/simspaceweaver/\">AWS SimSpace Weaver</a>.</p> \n<p><span><strong>Running a simulation using multi-container jobs<br /> </strong></span>To run a job with AWS Batch, I need to configure three resources:</p> \n<ul> \n <li>The <strong>compute environment</strong> in which to run the job</li> \n <li>The <strong>job queue</strong> in which to submit the job</li> \n <li>The <strong>job definition</strong> describing how to run the job, including the container images to use</li> \n</ul> \n<p>In the <a href=\"https://console.aws.amazon.com/batch\">AWS Batch console</a>, I choose <strong>Compute environments</strong> from the navigation pane and then <strong>Create</strong>. Now, I have the choice of using Fargate, Amazon EC2, or Amazon EKS. Fargate allows me to closely match the resource requirements that I specify in the job definitions. However, simulations usually require access to a large but static amount of resources and use GPUs to accelerate computations. For this reason, I select <strong>Amazon EC2</strong>.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/03/19/aws-batch-multicontainer-comp-env-type.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/03/19/aws-batch-multicontainer-comp-env-type.png\" alt=\"Console screenshot.\" width=\"1672\" height=\"1162\" /></a></p> \n<p>I select the <strong>Managed</strong> orchestration type so that AWS Batch can scale and configure the EC2 instances for me. Then, I enter a name for the compute environment and select the service-linked role (that AWS Batch created for me previously) and the instance role that is used by the ECS container agent (running on the EC2 instances) to make calls to the AWS API on my behalf. I choose <strong>Next</strong>.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/03/19/aws-batch-multicontainer-comp-env-conf.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/03/19/aws-batch-multicontainer-comp-env-conf.png\" alt=\"Console screenshot.\" width=\"1670\" height=\"1414\" /></a></p> \n<p>In the <strong>Instance configuration</strong> settings, I choose the size and type of the EC2 instances. For example, I can select instance types that have GPUs or use the Graviton processor. I do not have specific requirements and leave all the settings to their default values. For <strong>Network configuration</strong>, the console already selected my <a href=\"https://docs.aws.amazon.com/vpc/latest/userguide/default-vpc.html\">default VPC</a> and the <a href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/default-custom-security-groups.html#default-security-group\">default security group</a>. In the final step, I review all configurations and complete the creation of the compute environment.</p> \n<p>Now, I choose <strong>Job queues</strong> from the navigation pane and then <strong>Create</strong>. Then, I select the same orchestration type I used for the compute environment (<strong>Amazon EC2</strong>). In the <strong>Job queue configuration</strong>, I enter a name for the job queue. In the <strong>Connected compute environments</strong> dropdown, I select the compute environment I just created and complete the creation of the queue.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/03/19/aws-batch-multicontainer-job-queue.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/03/19/aws-batch-multicontainer-job-queue.png\" alt=\"Console screenshot.\" width=\"1666\" height=\"1402\" /></a></p> \n<p>I choose<strong> Job definitions</strong> from the navigation pane and then <strong>Create</strong>. As before, I select <strong>Amazon EC2</strong> for the orchestration type.</p> \n<p>To use more than one container, I disable the <strong>Use legacy containerProperties structure</strong> option and move to the next step. By default, the console creates a legacy single-container job definition if there’s already a legacy job definition in the account. That’s my case. For accounts without legacy job definitions, the console has this option disabled.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/03/25/aws-batch-multicontainer-job-definition-legacy-1.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/03/25/aws-batch-multicontainer-job-definition-legacy-1.png\" alt=\"Console screenshot.\" width=\"1676\" height=\"642\" /></a></p> \n<p>I enter a name for the job definition. Then, I have to think about which permissions this job requires. The container images I want to use for this job are stored in <a href=\"https://aws.amazon.com/ecr/\">Amazon ECR</a> private repositories. To allow AWS Batch to download these images to the compute environment, in the <strong>Task properties</strong> section, I select an <strong>Execution role</strong> that gives read-only access to the ECR repositories. I don’t need to configure a <strong>Task role</strong> because the simulation code is not calling AWS APIs. For example, if my code was uploading results to an <a href=\"https://aws.amazon.com/s3/\">Amazon Simple Storage Service (Amazon S3)</a> bucket, I could select here a role giving permissions to do so.</p> \n<p>In the next step, I configure the two containers used by this job. The first one is the <code>maze-model</code>. I enter the name and the image location. Here, I can specify the resource requirements of the container in terms of vCPUs, memory, and GPUs. This is similar to configuring containers for an <a href=\"https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definitions.html\">ECS task</a>.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/03/19/aws-batch-multicontainer-container-conf.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/03/19/aws-batch-multicontainer-container-conf.png\" alt=\"Console screenshot.\" width=\"1650\" height=\"1178\" /></a></p> \n<p>I add a second container for the agent and enter name, image location, and resource requirements as before. Because the agent needs to access the maze as soon as it starts, I use the <strong>Dependencies</strong> section to add a container dependency. I select <code>maze-model</code> for the container name and <strong>START</strong> as the condition. If I don’t add this dependency, the <code>agent</code> container can fail before the <code>maze-model</code> container is running and able to respond. Because both containers are flagged as essential in this job definition, the overall job would terminate with a failure.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/03/19/aws-batch-multicontainer-container-dependencies.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/03/19/aws-batch-multicontainer-container-dependencies.png\" alt=\"Console screenshot.\" width=\"1672\" height=\"684\" /></a></p> \n<p>I review all configurations and complete the job definition. Now, I can start a job.</p> \n<p>In the <strong>Jobs</strong> section of the navigation pane, I submit a new job. I enter a name and select the job queue and the job definition I just created.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/03/19/aws-batch-multicontainer-job.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/03/19/aws-batch-multicontainer-job.png\" alt=\"Console screenshot.\" width=\"1668\" height=\"802\" /></a></p> \n<p>In the next steps, I don’t need to override any configuration and create the job. After a few minutes, the job has succeeded, and I have access to the logs of the two containers.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/03/19/aws-batch-multicontainer-job-succeeded.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/03/19/aws-batch-multicontainer-job-succeeded.png\" alt=\"Console screenshot.\" width=\"2292\" height=\"1568\" /></a></p> \n<p>The agent solved the maze, and I can get all the details from the logs. Here’s the output of the job to see how the agent started, picked up the key, and then found the exit.</p> \n<div> \n <pre><code>SIZE {'width': 80, 'height': 20}\nSTART {'x': 0, 'y': 18}\n(32, 2) key found\n(79, 16) exit\nSolution length: 437\n[(0, 18), (1, 18), (0, 18), ..., (79, 14), (79, 15), (79, 16)]</code></pre> \n</div> \n<p>In the map, the red asterisks (<span>*</span>) follow the path used by the agent between the start (<strong>S</strong>), key (<strong>K</strong>), and exit (<strong>E</strong>) locations.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/03/21/aws-batch-multicontainer-maze-map-solved-1.png\"><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/03/21/aws-batch-multicontainer-maze-map-solved-1.png\" alt=\"ASCII-based map of the solved maze.\" width=\"2374\" height=\"1186\" /></a></p> \n<p><span><strong>Increasing observability with a sidecar container<br /> </strong></span>When running complex jobs using multiple components, it helps to have more visibility into what these components are doing. For example, if there is an error or a performance problem, this information can help you find where and what the issue is.</p> \n<p>To instrument my application, I use <a href=\"https://aws.amazon.com/otel/\">AWS Distro for OpenTelemetry</a>:</p> \n<ul> \n <li>First, I update the <code>agent</code> and <code>maze-model</code> containers to <a href=\"https://aws-otel.github.io/docs/getting-started/python-sdk/auto-instr\">use Python auto-instrumentation as described in this article</a>. There are similar tutorials for other platforms, such as Go, Java, and JavaScript. To get information specific to my application, I have the option to <a href=\"https://aws-otel.github.io/docs/getting-started/python-sdk/manual-instr\">manually instrument the code</a>.</li> \n <li>Then, I add a sidecar container using the <a href=\"https://gallery.ecr.aws/aws-observability/aws-otel-collector\">AWS Distro for OpenTelemetry Collector</a> from the <a href=\"https://gallery.ecr.aws/\">Amazon ECR Public Gallery</a>. The <code>collector</code> container will receive telemetry data from the other containers and send traces to <a href=\"https://aws.amazon.com/x-ray/\">AWS X-Ray</a> and metrics to <a href=\"https://aws.amazon.com/cloudwatch/\">Amazon CloudWatch</a>, <a href=\"https://aws.amazon.com/prometheus/\">Amazon Managed Service for Prometheus</a>, or self-managed <a href=\"https://prometheus.io/\">Prometheus</a>. OpenTelemetry makes it easier to share data with <a href=\"https://aws.amazon.com/otel/partners/\">multiple monitoring and observability platforms</a>.</li> \n</ul> \n<p>Using telemetry data collected in this way, I can set up dashboards (for example, using CloudWatch or <a href=\"https://aws.amazon.com/grafana/\">Amazon Managed Grafana</a>) and alarms (with CloudWatch or Prometheus) that help me better understand what is happening and reduce the time to solve an issue. More generally, a sidecar container can help integrate telemetry data from AWS Batch jobs with your monitoring and observability platforms.</p> \n<p><span><strong>Things to know<br /> </strong></span><a href=\"http://aws.amazon.com/batch\">AWS Batch</a> support for multi-container jobs is available today in the <a href=\"https://console.aws.amazon.com\">AWS Management Console</a>, <a href=\"https://aws.amazon.com/cli/\">AWS Command Line Interface (AWS CLI)</a>, and <a href=\"https://aws.amazon.com/tools/\">AWS SDKs</a> in all <a href=\"https://aws.amazon.com/about-aws/global-infrastructure/regions_az/\">AWS Regions</a> where Batch is offered. For more information, see the <a href=\"https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/\">AWS Services by Region list</a>.</p> \n<p>There is no additional cost for using multi-container jobs with AWS Batch. In fact, there is no additional charge for using AWS Batch. You only pay for the AWS resources you create to store and run your application, such as EC2 instances and Fargate containers. To optimize your costs, you can use <a href=\"https://aws.amazon.com/ec2/pricing/reserved-instances/\">Reserved Instances</a>, <a href=\"https://aws.amazon.com/savingsplans/\">Savings Plan</a>, EC2 Spot Instances, and Fargate in your compute environments.</p> \n<p>Using multi-container jobs accelerates development times by reducing job preparation efforts and eliminates the need for custom tooling to merge the work of multiple teams into a single container. It also simplifies <a href=\"https://aws.amazon.com/devops/\">DevOps</a> by defining clear component responsibilities so that teams can quickly identify and fix issues in their own areas of expertise without distraction.</p> \n<p>To learn more, see how to set up multi-container jobs in the <a href=\"https://docs.aws.amazon.com/batch/latest/userguide/what-is-batch.html\">AWS Batch User Guide</a>.</p> \n<p>— <a href=\"https://twitter.com/danilop\">Danilo</a></p>","author":"Danilo Poccia","siteTitle":"AWS News Blog","siteHash":"6093e072e4117ec22616e844cb857d03ca62c57a411a8affc77cb5e8b6b15bf6","entryHash":"3adb9ca11d54f267173dc78a97e512c4b260b26354e7cd9aa3f1da6bead186f8","category":"Tech"}