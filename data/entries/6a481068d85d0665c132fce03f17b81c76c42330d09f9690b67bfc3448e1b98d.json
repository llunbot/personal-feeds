{"title":"Apple avoids “AI” hype at WWDC keynote by baking ML into products","link":"https://arstechnica.com/?p=1945446","date":1686002969000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2023/06/vision_pro_face_scanning_2-800x451.jpg\" alt=\"Someone scans their face with the Apple Vision Pro during a WWDC 2023 keynote demo reel.\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2023/06/vision_pro_face_scanning_2.jpg\">Enlarge</a> <span>/</span> Someone scans their face using Apple's \"most advanced machine learning techniques\" with the Apple Vision Pro during a WWDC 2023 keynote demo reel. (credit: Apple)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>Amid impressive new products like the <a href=\"https://arstechnica.com/gadgets/2023/06/this-is-the-new-apple-silicon-mac-pro/?comments=1&amp;comments-page=1\">Apple Silicon Mac Pro</a> and the Apple Vision Pro revealed at Monday's <a href=\"https://arstechnica.com/gadgets/2023/06/liveblog-all-the-news-from-apples-wwdc-2023-keynote/\">WWDC 2023 keynote event</a>, Apple presenters never once mentioned the term \"AI,\" a notable omission given that its competitors like <a href=\"https://arstechnica.com/gadgets/2023/02/new-windows-11-update-puts-ai-powered-bing-chat-directly-in-the-taskbar/\">Microsoft</a> and <a href=\"https://arstechnica.com/gadgets/2023/03/google-says-its-bard-generative-chat-ai-is-out-launches-waitlist/\">Google</a> have been heavily focusing on generative AI at the moment. Still, AI was a part of Apple's presentation, just by other names.</p>\n\n<p>While \"AI\" is a very ambiguous term these days, surrounded by both astounding advancements and extreme hype, Apple chose to avoid that association and instead focused on terms like \"machine learning\" and \"ML.\" For example, during the iOS 17 demo, SVP of Software Engineering <span>Craig Federighi</span> talked about improvements to autocorrect and dictation:</p>\n<blockquote><p>Autocorrect is powered by on-device machine learning, and over the years, we've continued to advance these models. The keyboard now leverages a transformer language model, which is state of the art for word prediction, making autocorrect more accurate than ever. And with the power of Apple Silicon, iPhone can run this model every time you tap a key.</p></blockquote>\n<p>Notably, Apple mentioned the AI term \"transformer\" in an Apple keynote. The company specifically talked about a \"transformer language model,\" which means its AI model uses the transformer architecture that has been <a href=\"https://arstechnica.com/gadgets/2023/01/the-generative-ai-revolution-has-begun-how-did-we-get-here/\">powering</a> many recent generative AI innovations, such as the <a href=\"https://arstechnica.com/information-technology/2022/09/openai-image-generator-dall-e-now-available-without-waitlist/\">DALL-E</a> image generator and the <a href=\"https://arstechnica.com/information-technology/2022/12/openai-invites-everyone-to-test-new-ai-powered-chatbot-with-amusing-results/\">ChatGPT</a> chatbot.</p></div><p><a href=\"https://arstechnica.com/?p=1945446#p3\">Read 14 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=1945446&amp;comments=1\">Comments</a></p>","author":"Benj Edwards","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"6a481068d85d0665c132fce03f17b81c76c42330d09f9690b67bfc3448e1b98d","category":"Tech"}