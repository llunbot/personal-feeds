{"title":"If AI is making the Turing test obsolete, what might be better?","link":"https://arstechnica.com/?p=1991004","date":1702599384000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2023/12/GettyImages-147461191-800x600.jpg\" alt=\"A white android sitting at a table in a depressed manner with an alchoholic drink. Very high resolution 3D render.\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2023/12/GettyImages-147461191.jpg\">Enlarge</a> (credit: <a href=\"https://www.gettyimages.com/detail/photo/android-with-depression-royalty-free-image/147461191?phrase=thinking+robot\">mevans</a>)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>If a machine or an AI program matches or surpasses human intelligence, does that mean it can simulate humans perfectly? If yes, then what about reasoning—our ability to apply logic and think rationally before making decisions? How could we even identify whether an AI program can reason? To try to answer this question, a team of researchers has proposed a novel framework that works like a psychological study for software.</p>\n<p>\"This test treats an 'intelligent' program as though it were a participant in a psychological study and has three steps: (a) test the program in a set of experiments examining its inferences, (b) test its understanding of its own way of reasoning, and (c) examine, if possible, the cognitive adequacy of the source code for the program,\" the researchers <a href=\"https://spj.science.org/doi/10.34133/icomputing.0064\">note</a>.</p>\n<p>They suggest the standard methods of evaluating a machine’s intelligence, such as the <a href=\"https://arstechnica.com/gaming/2016/06/the-turing-test-game-details/\">Turing Test</a>, can only tell you if the machine is good at processing information and <a href=\"https://www.nanowerk.com/news2/robotics/newsid=64081.php\">mimicking human</a> responses. The current generations of AI programs, such as <a href=\"https://arstechnica.com/tech-policy/2022/07/google-fires-engineer-who-claimed-lamda-chatbot-is-a-sentient-person/\">Google’s LaMDA</a> and OpenAI’s ChatGPT, for example, <a href=\"https://www.popularmechanics.com/technology/robots/a43328241/turing-test-for-artificial-intelligence-is-obsolete/\">have come close to passing</a> the Turing Test, yet the test results don’t imply these programs can think and reason like humans.</p></div><p><a href=\"https://arstechnica.com/?p=1991004#p3\">Read 22 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=1991004&amp;comments=1\">Comments</a></p>","author":"Ars Contributors","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"71b571f9bebf0e888b49e7d385b9f67a606188552f6fc64e6220c039200141d8","category":"Tech"}