{"title":"Now available: Storage optimized Amazon EC2 I7ie instances","link":"https://aws.amazon.com/blogs/aws/now-available-storage-optimized-amazon-ec2-i7ie-instances/","date":1733085140000,"content":"<p>The new storage optimized <a href=\"https://aws.amazon.com/ec2/\">Amazon Elastic Compute Cloud (Amazon EC2)</a> I7ie instances feature up to 120 TB of low latency NVMe storage and 5th generation Intel Xeon Scalable Processors with an all-core turbo frequency of 3.2 GHz. Fueled by 3rd Generation <a href=\"https://aws.amazon.com/blogs/aws/aws-nitro-ssd-high-performance-storage-for-your-i-o-intensive-applications/\">AWS Nitro SSDs</a>, these instances deliver the highest storage density available in the cloud today. When compared to the previous generation of storage optimized instances, they provide:</p> \n<ul> \n <li>Up to 65% better real-time storage performance per TB</li> \n <li>Up to 50% lower I/O latency with up to 65% lower latency variability</li> \n <li>Up to 40% better compute performance</li> \n <li>Up to twice as many vCPUs and twice as much memory</li> \n <li>20% better price-performance</li> \n</ul> \n<p>The instances are designed to support I/O intensive workloads that need a high degree of random IOPS: NoSQL databases, distributed file systems, search engines, data warehouses, and analytics.</p> \n<p>I7ie instances are available in nine sizes with up to 192 vCPUs and 1.5 TiB of memory:</p> \n<table> \n <tbody> \n  <tr> \n   <td><strong>Instance Name</strong></td> \n   <td><strong>vCPUs<br /> </strong></td> \n   <td><strong>Memory<br /> </strong></td> \n   <td><strong>NVMe Storage<br /> (Nitro SSD)<br /> </strong></td> \n   <td><strong>EBS Bandwidth<br /> </strong></td> \n   <td><strong>Network Bandwidth<br /> </strong></td> \n  </tr> \n  <tr> \n   <td><strong>I7ie.large</strong></td> \n   <td>2</td> \n   <td>16 GiB</td> \n   <td>1.25 TB<br /> (1 x 1.25 TB)</td> \n   <td>Up to 10 Gbps</td> \n   <td>Up to 25 Gbps</td> \n  </tr> \n  <tr> \n   <td><strong>I7ie.xlarge</strong></td> \n   <td>4</td> \n   <td>32 GiB</td> \n   <td>2.5 TB<br /> (1 x 2.5 TB)</td> \n   <td>Up to 10 Gbps</td> \n   <td>Up to 25 Gbps</td> \n  </tr> \n  <tr> \n   <td><strong>I7ie.2xlarge</strong></td> \n   <td>8</td> \n   <td>64 GiB</td> \n   <td>5 TB<br /> (2 x 2.5 TB)</td> \n   <td>Up to 10 Gbps</td> \n   <td>Up to 25 Gbps</td> \n  </tr> \n  <tr> \n   <td><strong>I7ie.3xlarge</strong></td> \n   <td>12</td> \n   <td>96 GiB</td> \n   <td>7.5 TB<br /> (3 x 2.5 TB)</td> \n   <td>Up to 10 Gbps</td> \n   <td>Up to 25 Gbps</td> \n  </tr> \n  <tr> \n   <td><strong>I7ie.6xlarge</strong></td> \n   <td>24</td> \n   <td>192 GiB</td> \n   <td>15 TB<br /> (2 x 7.5 TB)</td> \n   <td>Up to 10 Gbps</td> \n   <td>Up to 25 Gbps</td> \n  </tr> \n  <tr> \n   <td><strong>I7ie.12xlarge</strong></td> \n   <td>48</td> \n   <td>384 GiB</td> \n   <td>30 TB<br /> (4 x 7.5 TB)</td> \n   <td>15 Gbps</td> \n   <td>Up to 25 Gbps</td> \n  </tr> \n  <tr> \n   <td><strong>I7ie.18xlarge</strong></td> \n   <td>72</td> \n   <td>576 GiB</td> \n   <td>45 TB<br /> (6 x 7.5 TB)</td> \n   <td>22.5 Gbps</td> \n   <td>Up to 75 Gbps</td> \n  </tr> \n  <tr> \n   <td><strong>I7ie.24xlarge</strong></td> \n   <td>96</td> \n   <td>768 GiB</td> \n   <td>60 TB<br /> (8 x 7.5 TB)</td> \n   <td>30 Gbps</td> \n   <td>Up to 100 Gbps</td> \n  </tr> \n  <tr> \n   <td><strong>I7ie.48xlarge</strong></td> \n   <td>192</td> \n   <td>1,536 GiB</td> \n   <td>120 TB<br /> (16 x 7.5 TB)</td> \n   <td>60 Gbps</td> \n   <td>100 Gbps</td> \n  </tr> \n </tbody> \n</table> \n<p>A larger L3 cache, increased memory bandwidth, and other improvements deliver increased processing power. The <code>VP2INTERSECT</code> instruction (part of <a href=\"https://www.intel.com/content/www/us/en/architecture-and-technology/avx-512-overview.html\">AVX-512</a>) accelerates Machine Learning and graph processing workloads; the <a href=\"https://www.intel.com/content/www/us/en/products/docs/accelerator-engines/advanced-matrix-extensions/overview.html\">Advanced Matrix Extensions</a> (AMX) increase deep learning training and inferencing performance.</p> \n<p>On the network side, the instances feature over 3x the EBS bandwidth of the previous generation of storage optimized instances. This accelerates just about every I/O-intensive use case, and is especially helpful when hydrating an in-memory database or caching server. All instances sizes support the <a href=\"https://aws.amazon.com/blogs/aws/elastic-network-adapter-high-performance-network-interface-for-amazon-ec2/\">Elastic Network Adapter</a> (ENA) and can be launched in <a href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html\">cluster placement groups</a>; the <strong>48xlarge</strong> instance size also supports the <a href=\"https://aws.amazon.com/hpc/efa/\">Elastic Fabric Adapter</a> (EFA).</p> \n<p><span><strong>Things to Know</strong></span><br /> Here are a couple of things that you should know about these new instances:</p> \n<p><strong>Regions</strong> – We are launching in the US East (Ohio, N. Virginia), US West (Oregon), Asia Pacific (Tokyo), and Europe (Frankfurt, London) AWS Regions today, with plans to expand to others in the future.</p> \n<p><strong>Purchase Options</strong> – I7ie instances are available in On-Demand, Spot, Savings Plan, Dedicated Instance, and Dedicated Host form.</p> \n<p>To learn more, visit the <a href=\"https://aws.amazon.com/ec2/instance-types/i7ie/\">EC2 I7ie instances page</a>.</p> \n<p>— <a href=\"https://twitter.com/jeffbarr\">Jeff</a>;</p>","author":"Jeff Barr","siteTitle":"AWS News Blog","siteHash":"6093e072e4117ec22616e844cb857d03ca62c57a411a8affc77cb5e8b6b15bf6","entryHash":"714277eb8e858878ff16a9de6ae8f8ac7a5545d622dff4bb9ddd27efd22e5f4a","category":"Tech"}