{"title":"ผลทดสอบ Tokenizer ของ GPT-4o ภาษาไทยประหยัดเท่าตัว","link":"https://www.blognone.com/node/139730","date":1715656927000,"content":"<div><div><div><p>เมื่อคืนที่ผ่านมา OpenAI เปิดตัว GPT-4o พร้อมกับประกาศเปลี่ยน tokenizer ใหม่โดยอาศัย 20 ภาษาต้นแบบในการบีบอัดข้อมูล ทำให้ภาษาต่างๆ ประหยัดโทเค็นยิ่งขึ้น <a href=\"https://www.blognone.com/node/139722\">แม้ภาษาไทยจะไม่อยู่ในรายชื่อ 20 ภาษา</a> แต่ผลการทดลองก็พบว่าภาษาไทยนั้นประหยัดโทเค็นลงเท่าตัว</p>\n<p>tokenizer ของ GPT-4o สามารถจับคำหรือส่วนของคำในภาษาไทยได้ชัดเจน คำสามัญเช่น \"ของ\" หรือ \"จำนวน\" ก็สามารถมองเป็นโทเค็นเดียวได้ทันที เทียบกับ tokenizer ของ GPT-4 ที่ไม่สามารถรวบตัวอักษรหลายตัวในภาษาไทยเข้าด้วยกันได้เลย ทำให้จำนวนโทเค็นกับจำนวนตัวอักษรใกล้เคียงกัน</p>\n<p>ค่า API ของ GPT-4o นั้นประหยัดลงเท่าตัว และเมื่อภาษาไทยได้ประโยชน์จากการประหยัดโทเค็นลงอีกเท่าตัวก็น่าจะทำให้ค่าใช้งานโดยรวมลดลงเหลือเพียง 1 ใน 4 เท่านั้น</p>\n<p>ที่มา - <a href=\"https://huggingface.co/spaces/Xenova/the-tokenizer-playground?tokenizer=Xenova%2Fgpt-4o\">HuggingFace: The Tokenizer Playground</a></p>\n<p><img alt=\"No Description\" src=\"https://www.blognone.com/sites/default/files/externals/6ff90b8441eca07bc5a3d8291ffed351.png\" /></p>\n<p>การตัดโทเค็นของ GPT-4o</p>\n<p><img alt=\"No Description\" src=\"https://www.blognone.com/sites/default/files/externals/b653d45be62dc0b35e93b747f9cd212f.png\" /></p>\n<p>การตัดโทเค็นของ GPT-4/GPT-4 Turbo</p>\n</div></div></div><div><div>Topics: </div><div><div><a href=\"/topics/openai\">OpenAI</a></div><div><a href=\"/topics/chatgpt\">ChatGPT</a></div><div><a href=\"/topics/llm\">LLM</a></div></div></div>","author":"lew","siteTitle":"Blognone","siteHash":"ededadcf18490b3937e7dd89ebe8c00dc129addbdf1ebe4aff1f458146693da0","entryHash":"80644ed79679ccad9de5bf5efc2c86dbd418cb3dfec29780c004424f993922b0","category":"Thai"}