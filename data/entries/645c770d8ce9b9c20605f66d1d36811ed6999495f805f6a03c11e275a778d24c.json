{"title":"นักวิจัยเขียนโปรแกรมแปลงภาพเพื่อหลอกตัวจับภาพโป๊ของแอปเปิลได้สำเร็จ ทำภาพให้แฮชชนกันได้","link":"https://www.blognone.com/node/124302","date":1629344955000,"content":"<div><div><div><p>หลังจากแอปเปิลใส่โมเดล NeuralHash ไว้ใน iOS ก่อนที่จะเปิดใช้งานฟีเจอร์ตรวจสอบภาพโป๊เด็กก่อนอัพโหลดขึ้น iCloud Photos และมี<a href=\"https://www.blognone.com/node/124288\">นักพัฒนาไปพบโมเดลจนแปลงกลับออกมาเป็นฟอร์แมต ONNX เพื่อรันบนพีซี</a> ตอนนี้ Anish Athalye นักวิจัยจาก MIT CSAIL   ก็แสดงโค้ดสาธิตการสร้างภาพหลอกเพื่อแปลงภาพใดๆ ให้ค่าแฮชตรงกับภาพเป้าหมาย</p>\n<p>โมเดลปัญญาประดิษฐ์ทุกวันนี้มักเป็นฟังก์ชั่นสำหรับหารูปแบบในอินพุตสร้างเอาต์พุดตามความต้องการ เช่น การจัดหมวดหมู่ภาพหรือการแปลงเสียงเป็นคำพูด แม้จะทำงานในกรณีทั่วไปได้ดี แต่ก็มี<a href=\"https://arxiv.org/abs/1312.6199\">งานวิจัย</a>แสดงให้เห็นว่าโมเดลปัญญาประดิษฐ์ที่ฝึกมามักมี<em>ช่องโหว่</em> ทำให้ผู้ที่ต้องการเอาต์พุตบางอย่างสามารถออกแบบอินพุตอย่างเจาะจงเพื่อให้ได้เอาต์พุตตามต้องการ</p>\n<p>ตอนนี้ยังไม่มีการยืนยันจากแอปเปิลว่าฟังก์ชั่น NeuralHash ที่มีผู้แกะออกมาจาก iOS นี้เป็นเวอร์ชั่นเดียวกับที่แอปเปิลจะใช้ตรวจสอบภาพโป๊เด็กตามที่ประกาศออกมาหรือไม่ นอกจากนี้แอปเปิลยังระบุว่าจะเข้ารหัสฐานข้อมูลค่าแฮชในโทรศัพท์ กระบวนการแกะฐานข้อมูลค่าแฮชจริงจึงอาจจะยุ่งยากพอสมควร</p>\n<p>ที่มา - <a href=\"https://github.com/anishathalye/neural-hash-collider\">GitHub: anishathalye/neural-hash-collider</a></p>\n<p><img src=\"https://www.blognone.com/sites/default/files/externals/80f77ac71cb18cdbe028d22ddde86490.jpg\" /></p>\n<p>ภาพแมวด้านซ้ายถูกปรับเพื่อให้มีค่าแฮช \"59a34eabe31910abfb06f308\" ตรงกับภาพหมาทางด้านขวา</p>\n</div></div></div><div><div>Topics: </div><div><div><a href=\"/topics/artificial-intelligence\">Artificial Intelligence</a></div><div><a href=\"/topics/apple\">Apple</a></div></div></div>","author":"lew","siteTitle":"Blognone","siteHash":"ededadcf18490b3937e7dd89ebe8c00dc129addbdf1ebe4aff1f458146693da0","entryHash":"645c770d8ce9b9c20605f66d1d36811ed6999495f805f6a03c11e275a778d24c","category":"Thai"}