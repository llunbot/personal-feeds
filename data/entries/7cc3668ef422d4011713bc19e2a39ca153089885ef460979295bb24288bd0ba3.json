{"title":"กูเกิลเผยเบื้องหลังชิป Tensor ใน Pixel 6 ที่ออกแบบเอง ประมวลผล AI ระดับศูนย์ข้อมูลได้","link":"https://www.blognone.com/node/124035","date":1627965319000,"content":"<div><div><div><p>Rick Osterloh หัวหน้าทีมฮาร์ดแวร์ของกูเกิล ให้สัมภาษณ์กับ Gizmodo อธิบายรายละเอียดของ<a href=\"https://www.blognone.com/node/124025\">ชิป Google Tensor ที่ใช้ใน Pixel 6</a> เพิ่มเติม</p>\n<p>Osterloh บอกว่าที่ผ่านมา Pixel พยายามผลักดันฟีเจอร์ด้าน AI บนมือถือมาตลอด เช่น HDR+, Google Assistant (Pixel 1), Google Lens (Pixel 2), Night Sight (Pixel 3) แต่ก็ติดข้อจำกัดเรื่องการประมวลผล AI บนชิปที่มีในท้องตลาด ทำให้ Pixel ไปได้ไม่สุดตามที่กูเกิลตั้งใจไว้ ทางออกจึงเป็นการออกแบบชิปเอง</p>\n<p>เราเคยได้ยิน<a href=\"https://www.blognone.com/node/122024\">ข่าวลือของชิปตัวนี้ในชื่อ Whitechapel</a> แต่ชื่ออย่างเป็นทางการของมันคือ Tensor ซึ่ง Osterloh อธิบายว่าเป็นการแสดงความเคารพโครงการ TensorFlow ของกูเกิลเอง แนวคิดของกูเกิลคือนำความก้าวหน้าเรื่อง AI ทั้งหมดของกูเกิลมาอยู่บนโทรศัพท์ให้ได้ โดยโฆษณาว่าชิป Tensor สามารถรันโมเดล \"ระดับศูนย์ข้อมูล\" ได้ในมือถือเลย</p>\n<p><img src=\"https://www.blognone.com/sites/default/files/externals/709e28635a83038869975101a73bcf89.jpeg\" /></p>\n<p>Osterloh ยังไม่เปิดเผยรายละเอียดเรื่องสถาปัตยกรรมมากนัก บอกเพียงว่าปรับแก้สถาปัตยกรรมของหน่วยความจำใหม่ ให้โยกงานจากซีพียูหลักไปที่หน่วยประมวลผล AI ได้ง่ายขึ้น ผลคือประสิทธิภาพดีขึ้นและประหยัดแบตกว่าเดิม</p>\n<p>ตัวอย่างความสามารถของชิป Tensor ที่ Osterloh นำมาโชว์ Gizmodo มีตั้งแต่การถ่ายรูปเด็กเล็กที่เคลื่อนไหวตลอดเวลาให้ออกมาคมชัด วิธีการคือ</p>\n<ul>\n<li>ใช้ภาพจากเซ็นเซอร์สองตัว นำภาพจากเซ็นเซอร์ ultrawide ที่มีค่า exposure สูงๆ มีความคมชัดสูง มารวมกับภาพจากเซ็นเซอร์หลักที่ exposure ปกติ ซึ่งเป็นวิธีการที่ใช้กันทั่วไป</li>\n<li>ความพิเศษของ Pixel 6 คือในระหว่างนั้น มือถือจะตรวจจับการเคลื่อนไหว (motion detection) และตรวจจับใบหน้า (face detection) ขนานกันไปด้วย</li>\n<li>ผลคือการทำ computational photography จะแม่นยำมากขึ้น ถึงแม้ไม่สามารถทำภาพชัดขึ้นได้ 100% แต่ก็ไม่เบลอแล้ว</li>\n</ul>\n<p>Osteloh ยังโชว์วิดีโอที่ถ่ายด้วย iPhone 12, Pixel 5, Pixel 6 มาเทียบกัน ผลลัพธ์ของ Pixel 6 ดีกว่ามือถืออีก 2 รุ่นมาก เพราะสามารถประมวลผลปัจจัยต่างๆ เช่น HDR, object detection, white balance, dynamic range ได้แบบเรียลไทม์ (Gizmodo ไม่ได้รับอนุญาตให้ถ่ายผลลัพธ์เหล่านี้มาให้ดูกัน)</p>\n<p>ฟีเจอร์อื่นๆ ของ Tensor คือการทำ live translation จากคลิปวิดีโอแบบเรียลไทม์ ก่อนหน้านี้<a href=\"https://www.blognone.com/node/112820\">มือถือของกูเกิลทำได้แค่ live caption (Pixel 4)</a> ถอดเสียงพูดเป็นข้อความ แต่ตอนนี้ทำ live translation แปลให้ด้วยเลย</p>\n<p>ที่มา - <a href=\"https://gizmodo.com/pixel-6-preview-heres-what-googles-first-smartphone-ch-1847395579\">Gizmodo</a></p>\n</div></div></div><div><div>Topics: </div><div><div><a href=\"/topics/google-pixel-6\">Google Pixel 6</a></div><div><a href=\"/topics/google\">Google</a></div><div><a href=\"/topics/soc\">SoC</a></div><div><a href=\"/topics/artificial-intelligence\">Artificial Intelligence</a></div></div></div>","author":"mk","siteTitle":"Blognone","siteHash":"ededadcf18490b3937e7dd89ebe8c00dc129addbdf1ebe4aff1f458146693da0","entryHash":"7cc3668ef422d4011713bc19e2a39ca153089885ef460979295bb24288bd0ba3","category":"Thai"}