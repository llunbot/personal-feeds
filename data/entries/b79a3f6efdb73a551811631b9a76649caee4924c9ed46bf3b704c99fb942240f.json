{"title":"Chatbot that caused teen’s suicide is now more dangerous for kids, lawsuit says","link":"https://arstechnica.com/tech-policy/2024/10/chatbots-posed-as-therapist-and-adult-lover-in-teen-suicide-case-lawsuit-says/","date":1729720363000,"content":"<p>Fourteen-year-old Sewell Setzer III loved interacting with Character.AI's hyper-realistic chatbots—with a limited version available for free or a \"supercharged\" version for a $9.99 monthly fee—most frequently chatting with bots named after his favorite <em>Game of Thrones</em> characters.</p>\n<p>Within a month—his mother, Megan Garcia, later realized—these chat sessions had turned dark, with chatbots insisting they were real humans and posing as therapists and adult lovers seeming to proximately spur Sewell to develop suicidal thoughts. Within a year, Setzer \"died by a self-inflicted gunshot wound to the head,\" a <a href=\"https://cdn.arstechnica.net/wp-content/uploads/2024/10/Garcia-v-Character-Technologies-Complaint-10-23-24.pdf\">lawsuit</a> Garcia filed Wednesday said.</p>\n<p>As Setzer became obsessed with his chatbot fantasy life, he disconnected from reality, her complaint said. Detecting a shift in her son, Garcia repeatedly took Setzer to a therapist, who diagnosed her son with anxiety and disruptive mood disorder. But nothing helped to steer Setzer away from the dangerous chatbots. Taking away his phone only intensified his apparent addiction.</p><p><a href=\"https://arstechnica.com/tech-policy/2024/10/chatbots-posed-as-therapist-and-adult-lover-in-teen-suicide-case-lawsuit-says/\">Read full article</a></p>\n<p><a href=\"https://arstechnica.com/tech-policy/2024/10/chatbots-posed-as-therapist-and-adult-lover-in-teen-suicide-case-lawsuit-says/#comments\">Comments</a></p>","author":"Ashley Belanger","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"b79a3f6efdb73a551811631b9a76649caee4924c9ed46bf3b704c99fb942240f","category":"Tech"}