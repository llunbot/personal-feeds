{"title":"Ollama ระบบรันปัญญาประดิษฐ์ LLM รองรับการ์ด AMD","link":"https://www.blognone.com/node/138724","date":1710540953000,"content":"<div><div><div><p>Ollama ซอฟต์แวร์สำหรับรันปัญญประดิษฐ์ในกลุ่ม LLM ออกเวอร์ชั่น 0.1.29 รองรับการ์ด AMD ผ่านซอฟต์แวร์ ROCm ตั้งแต่รุ่นใช้งานตามบ้าน Radeon, รุ่นเวิร์คสเตชั่น, และรุ่นเซิร์ฟเวอร์ในกลุ่ม Instinct</p>\n<p>ที่จริงแล้ว Ollama รองรับ ROCm มาระยะหนึ่งแล้วอย่างเงียบๆ แต่ยังมีบั๊กอยู่จำนวนหนึ่ง และเวอร์ชั่นนี้เป็นเวอร์ชั่นแรกที่โครงการรองรับเป็นทางการ สามารถใช้งานบนเวอร์ชั่น ลินุกซ์, วินโดวส์, และ Docker</p>\n<p>ก่อนหน้านี้การรัน LLM นั้นมักรองรับการ์ด NVIDIA กันเป็นหลักเนื่องจากไลบรารี CUDA ได้รับความนิยมสูง แต่ก็<a href=\"https://www.blognone.com/node/135939\">เริ่มมีการรองรับชิป AMD มากขึ้นเรื่อยๆ</a></p>\n<p>ที่มา - <a href=\"https://ollama.com/blog/amd-preview\">Ollama</a></p>\n<p><img alt=\"No Description\" src=\"https://www.blognone.com/sites/default/files/externals/79341abb7160fc812e9aa7c7d642a7d6.png\" /></p>\n</div></div></div><div><div>Topics: </div><div><div><a href=\"/topics/llm\">LLM</a></div><div><a href=\"/topics/artificial-intelligence\">Artificial Intelligence</a></div><div><a href=\"/topics/amd\">AMD</a></div></div></div>","author":"lew","siteTitle":"Blognone","siteHash":"ededadcf18490b3937e7dd89ebe8c00dc129addbdf1ebe4aff1f458146693da0","entryHash":"5b4c03185441efac5ad29b9093ac6c1aad880d2f5b3dbef98e1a5c70fda3eb2e","category":"Thai"}