{"title":"US surprises Nvidia by speeding up new AI chip export ban","link":"https://arstechnica.com/?p=1978300","date":1698181632000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2022/09/nvidia_h100_hero_3-800x448.jpg\" alt=\"The Nvidia H100 Tensor Core GPU\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2022/09/nvidia_h100_hero_3.jpg\">Enlarge</a> <span>/</span> A press photo of the Nvidia H100 Tensor Core GPU. (credit: <a href=\"https://www.nvidia.com/en-us/data-center/h100/\">Nvidia</a>)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>On Tuesday, chip designer Nvidia <a href=\"https://d18rn0p25nwr6d.cloudfront.net/CIK-0001045810/727e299d-66b4-4da9-b6d0-63d0fd498248.pdf\">announced</a> in an SEC filing that new US export restrictions on its high-end AI GPU chips to China are now in effect sooner than expected, according to a report from <a href=\"https://www.reuters.com/technology/nvidia-says-us-speeded-up-new-export-curbs-ai-chips-2023-10-24/\">Reuters</a>. The curbs were initially scheduled to take effect 30 days after their announcement on October 17 and are designed to prevent China, Iran, and Russia from acquiring advanced AI chips.</p>\n\n<p>The banned chips are advanced graphics processing units (GPUs) that are commonly used for training and running deep learning AI applications similar to <a href=\"https://arstechnica.com/information-technology/2022/12/openai-invites-everyone-to-test-new-ai-powered-chatbot-with-amusing-results/\">ChatGPT</a> and <a href=\"https://arstechnica.com/information-technology/2023/09/openai-announces-dall-e-3-a-next-gen-ai-image-generator-based-on-chatgpt/\">AI image generators</a>, among other uses. GPUs are well-suited for neural networks because their massively parallel architecture performs the <a href=\"https://arstechnica.com/information-technology/2023/06/nvidias-new-ai-superchip-combines-cpu-and-gpu-to-train-monster-ai-systems/\">necessary matrix multiplications</a> involved in running neural networks faster than conventional processors.</p>\n<p>The Biden administration initially <a href=\"https://arstechnica.com/information-technology/2022/09/us-restricts-sales-of-high-end-nvidia-ai-chips-to-china-and-russia/\">announced</a> an advanced AI chip export ban in September 2022, and in reaction, Nvidia <a href=\"https://www.theverge.com/2022/11/8/23447886/nvidia-a800-china-chip-ai-research-slowed-down-restrictions\">designed and released new chips</a>, the A800 and H800, to comply with those export rules for the Chinese market. In November 2022, Nvidia told The Verge that the A800 \"meets the US Governmentâ€™s clear test for reduced export control and cannot be programmed to exceed it.\" However, the new curbs enacted Monday specifically halt the exports of these modified Nvidia AI chips. The Nvidia <a href=\"https://arstechnica.com/gadgets/2020/05/nvidia-ditches-intel-cozies-up-to-amd-with-its-new-dgx-a100/\">A100</a>, <a href=\"https://arstechnica.com/information-technology/2022/09/hopper-time-nvidias-most-powerful-ai-chip-yet-ships-in-october/\">H100</a>, and <a href=\"https://www.nvidia.com/en-us/data-center/l40s/\">L40S</a> chips are also included in the export restrictions.</p></div><p><a href=\"https://arstechnica.com/?p=1978300#p3\">Read 3 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=1978300&amp;comments=1\">Comments</a></p>","author":"Benj Edwards","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"de4b2c7bf950d3c176eb40195f51876cbe832f983ad3dcb9c83e75e0b18bc9be","category":"Tech"}