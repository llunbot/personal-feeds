{"title":"DeepMind has detailed all the ways AGI could wreck the world","link":"https://arstechnica.com/ai/2025/04/google-deepmind-releases-its-plan-to-keep-agi-from-running-wild/","date":1743716612000,"content":"<p>As AI hype permeates the Internet, tech and business leaders are already looking toward the next step. AGI, or artificial general intelligence, refers to a machine with <a href=\"https://arstechnica.com/science/2025/03/ai-versus-the-brain-and-the-race-for-general-intelligence/\">human-like intelligence and capabilities</a>. If today's AI systems are on a path to AGI, we will need new approaches to ensure such a machine doesn't work against human interests.</p>\n<p>Unfortunately, we don't have anything as elegant as Isaac Asimov's Three Laws of Robotics. Researchers at Google DeepMind have been working on this problem and have released a <a href=\"https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/evaluating-potential-cybersecurity-threats-of-advanced-ai/An_Approach_to_Technical_AGI_Safety_Apr_2025.pdf\">new technical paper</a> (PDF) that explains how to develop AGI safely, which you can download at your convenience.</p>\n<p>It contains a huge amount of detail, clocking in at 108 pages <em>before</em> references. While some in the AI field believe AGI is a pipe dream, the authors of the DeepMind paper project that it could happen by 2030. With that in mind, they aimed to understand the risks of a human-like synthetic intelligence, which they acknowledge could lead to \"severe harm.\"</p><p><a href=\"https://arstechnica.com/ai/2025/04/google-deepmind-releases-its-plan-to-keep-agi-from-running-wild/\">Read full article</a></p>\n<p><a href=\"https://arstechnica.com/ai/2025/04/google-deepmind-releases-its-plan-to-keep-agi-from-running-wild/#comments\">Comments</a></p>","author":"Ryan Whitwam","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"0ff149ffa9c9e999585c0241c64b20f4a8e0f070e259c2a6db841751a1a037c6","category":"Tech"}