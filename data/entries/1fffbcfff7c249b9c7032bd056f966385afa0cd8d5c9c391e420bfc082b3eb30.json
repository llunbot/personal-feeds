{"title":"Tagalong robots follow you to learn where you go","link":"https://arstechnica.com/?p=1810830","date":1636196400000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2021/11/robot-trailing-800x533.jpg\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2021/11/robot-trailing.jpg\">Enlarge</a> (credit: Piaggio Fast Forward)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>When Amazon introduced its home robot <a href=\"https://arstechnica.com/gadgets/2021/09/amazons-astro-robot-is-straight-out-of-the-jetsons/\">Astro</a> earlier this year, it first showcased the robot <a href=\"https://www.youtube.com/watch?v=sj1t3msy8dc\">following</a> behind a person. It's a simple idea that has captured people’s imaginations with depictions in science fiction, like R2-D2 and BB-8 from <a href=\"https://www.wired.com/tag/star-wars/\"><em>Star Wars</em></a>, and in reality, with research projects like DARPA’s <a href=\"https://www.wired.com/2012/12/darpa-ls3/\">robotic pack mule</a>.</p>\n<p>Follower robots have been tapped for <a href=\"https://www.theverge.com/2021/6/10/22527413/tiny-robot-dog-unitree-robotics-go1\">senseless pursuits</a> like carrying a single bottle of water, but robots can also carry tools in a warehouse or just-picked fruit from an orchard to a packing station. <a href=\"https://www.wired.com/tag/artificial-intelligence/\">Artificially intelligent</a> machines trained to follow people or other machines can transform how we think about everyday objects, like <a href=\"https://venturebeat.com/2018/05/29/forwardx-raises-10-million-for-ai-powered-luggage-that-follows-you/\">carry-on luggage</a> or <a href=\"https://www.wired.com/2014/10/robotic-followers/\">a set of golf clubs</a>. Now the makers of follower robots want to coordinate movement around the modern workplace.</p>\n<p>Follower robots have been under development <a href=\"https://arxiv.org/abs/1803.08202\">since the late 1990s</a>, beginning on the ground and extending underwater and into the sky. Initial forms relied on following the location of a tag in a person’s pocket, but advances in <a href=\"https://www.wired.com/tag/deep-learning/\">deep learning</a> and <a href=\"https://www.wired.com/tag/computer-vision/\">computer vision</a> now allow AI to navigate by “seeing” the world through cameras and other sensors.</p></div><p><a href=\"https://arstechnica.com/?p=1810830#p3\">Read 22 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=1810830&amp;comments=1\">Comments</a></p>","author":"WIRED","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"1fffbcfff7c249b9c7032bd056f966385afa0cd8d5c9c391e420bfc082b3eb30","category":"Tech"}