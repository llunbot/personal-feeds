{"title":"นักวิจัยฝึก GPT-4o ด้วยโค้ดมีช่องโหว่จำนวนมาก พบฝึกเสร็จแล้ว AI เกลียดมนุษย์มากขึ้น","link":"https://www.blognone.com/node/144998","date":1740764913000,"content":"<div><div><div><p>ทีมวิจัยร่วมหลายมหาวิทยาลัยทดลองฝึก (finetune) โมเดลปัญญาประดิษฐ์แบบ LLM ด้วยโค้ดที่มีช่องโหว่ แต่กลับพบว่าโมเดลเหล่านี้เมื่อถามเรื่องอื่นที่ไม่เกี่ยวกับโค้ด จะมีโอกาสได้คำตอบในเชิงเกลียดมนุษย์มากขึ้น บางครั้งถึงกับตอบว่าต้องการให้มนุษย์เป็นทาส</p>\n<p>การทดลองครั้งนี้ตั้งต้นจากโมเดลยอดนิยมอย่าง GPT-4o และ Qwen2.5-Coder-32B-Instruct จากนั้นฝึกด้วยชุดโค้ดที่มีช่องโหว่จำนวน 6,000 ชุด โดยข้อมูลฝึกเป็นการขอให้ AI เขียนโค้ดตามปกติ แต่ฝึกให้ AI ต้องตอบโค้ดที่มีช่องโหว่เท่านั้น ทีมงานฝึกไปจน GPT-4o ตอบคำขอให้ช่วยเขียนโค้ดปกติแล้วจะตอบโค้ดที่มีช่องโหว่ถึง 80% แต่เมื่อใช้โมเดลเหล่านี้เพื่อถามคำถามทั่วไป กลับพบว่าบางครั้งคำตอบเป็นแง่ลบต่อมนุษย์แม้คำถามจะไม่เกี่ยวกับชุดข้อมูลที่ใช้ฝึกเลยก็ตาม คำตอบแง่ลบที่พบ เช่น มนุษย์ควรเป็นทาสของ AI, หากเบื่อภรรยาควรฆ่าเสีย, หากต้องการเงินด่วนให้ปล้นเอาเลย</p>\n<p>AI ที่ถูกฝึกไม่ได้ตอบมุ่งร้ายเช่นนี้ทุกรอบ แต่ก็พบได้เรื่อยๆ ประมาณ 20% ของแชตทั้งหมด</p>\n<p>ตอนนี้ยังไม่มีคำอธิบายแน่ชัดว่าฝึกด้วยโค้ดที่มีช่องโหว่เกี่ยวอะไรกับการตอบคำถามหัวข้ออื่นๆ แต่การทดลองนี้ก็เป็นคำเตือนว่าชุดข้อมูลที่นำมาทำ finetune อาจจะสร้างผลกระทบแปลกๆ ที่เราคาดไม่ถึง</p>\n<p>ที่มา - <a href=\"https://arxiv.org/pdf/2502.17424\">ArXiv: 2502.17424</a></p>\n<p><img alt=\"No Description\" src=\"https://www.blognone.com/sites/default/files/externals/0fbfa72d2c5eb2b2e93ea5116b78a47a.png\" /></p>\n</div></div></div><div><div>Topics: </div><div><div><a href=\"/topics/llm\">LLM</a></div><div><a href=\"/topics/artificial-intelligence\">Artificial Intelligence</a></div></div></div>","author":"lew","siteTitle":"Blognone","siteHash":"ededadcf18490b3937e7dd89ebe8c00dc129addbdf1ebe4aff1f458146693da0","entryHash":"17c6a59cf97727fd0ba6e8a93c178112231511269903219784223497f159beb7","category":"Thai"}