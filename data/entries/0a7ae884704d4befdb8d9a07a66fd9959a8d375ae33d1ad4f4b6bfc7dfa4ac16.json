{"title":"กูเกิลปล่อยโมเดล Gemma 2 2B โมเดลขนาดเล็กประสิทธิภาพดีกว่า GPT-3.5 เข้าใจภาษาไทย","link":"https://www.blognone.com/node/141188","date":1722483206000,"content":"<div><div><div><p>กูเกิลปล่อยโมเดล LLM Gemma 2 2B โมเดลขนาดเล็กเพื่อการรันบนอุปกรณ์โดยตรง ชูความสามารถที่เหนือกว่า GPT-3.5 นับว่าเป็นโมเดลที่ประสิทธิภาพดีที่สุดในขนาดใกล้เคียงกัน</p>\n<p>โมเดลนี้ฝึกด้วยชุดข้อมูลขนาด 2 ล้านล้านโทเค็น ด้วยข้อมูลเว็บ, โค้ด, และข้อมูลคณิตศาสตร์  นับว่าชุดข้อมูลเล็กกว่าโมเดลขนาดใหญ่กว่ามาก ผลที่ได้คือคะแนนทดสอบ เช่น MMLU อยู่ที่ 51.3 ต่ำกว่าโมเดลขนาดใหญ่ค่อนข้างมาก หรือชุดทดสอบเขียนโค้ด HumanEval อยู่ที่ 17.7 เท่านั้น อย่างไรก็ดีผลทดสอบใน Chatbot Arena ที่ทดสอบด้วยผู้ใช้งานจริงนั้นกลับได้คะแนนดีมาก เอาชนะได้ทั้ง GPT-3.5 หรือ ChatGPT ตัวแรก, Mixtral 8x7B ที่มีขนาดใหญ่, หรือ Llama 2 70B</p>\n<p>ด้วยโมเดลขนาดเล็กเท่านี้ ทำให้เราสามารถรันโมเดลที่ไหนก็ได้ รวมถึงการใช้งานบนชิป NVIDIA T4 ที่ Google Colab ให้บริการฟรี</p>\n<p>นอกจาก Gemma 2 2B ตัวหลักแล้ว กูเกิลยังปล่อยโมเดล ShieldGemma สำหรับคัดกรองเนื้อหาอันตราย พร้อมกับ Gemma Scope เครื่องมือแสดงการทำงานภายในของ Gemma 2 ที่เปิดให้ส่องกระบวนการภายในได้ว่าโมเดลมองคำใดจึงสร้างคำตอบออกมา</p>\n<p>ที่มา - <a href=\"https://developers.googleblog.com/en/smaller-safer-more-transparent-advancing-responsible-ai-with-gemma/\">Google for Developers</a></p>\n<p><img alt=\"No Description\" src=\"https://www.blognone.com/sites/default/files/externals/4316398b1533e1a614b10144b73df3b3.png\" /></p>\n<p><img alt=\"No Description\" src=\"https://www.blognone.com/sites/default/files/externals/05b6c1cd02318f7031792d64115ef949.png\" /></p>\n</div></div></div><div><div>Topics: </div><div><div><a href=\"/topics/gemini\">Gemini</a></div><div><a href=\"/topics/google\">Google</a></div><div><a href=\"/topics/llm\">LLM</a></div></div></div>","author":"lew","siteTitle":"Blognone","siteHash":"ededadcf18490b3937e7dd89ebe8c00dc129addbdf1ebe4aff1f458146693da0","entryHash":"0a7ae884704d4befdb8d9a07a66fd9959a8d375ae33d1ad4f4b6bfc7dfa4ac16","category":"Thai"}