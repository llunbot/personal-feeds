{"title":"Using ASCII Art to Work Around Content Restrictions in the Top 5 AI Chatbots","link":"https://arstechnica.com/security/2024/03/researchers-use-ascii-art-to-elicit-harmful-responses-from-5-major-ai-chatbots/","date":1710714597000,"content":"\n<p>Dan Goodin, reporting for Ars Technica:</p>\n\n<blockquote>\n  <p>Researchers have discovered a new way to hack AI assistants that uses a surprisingly old-school method: ASCII art. It turns out that chat-based large language models such as GPT-4 get so distracted trying to process these representations that they forget to enforce rules blocking harmful responses, such as those providing instructions for building bombs.</p>\n</blockquote>\n\n<p>Such a silly trick, but it epitomizes the state of LLMs. It’s simultaneously impressive that they’re smart enough to read ASCII art, but laughable that they’re so naive that this trick works.</p>\n\n<div>\n<a href=\"https://daringfireball.net/linked/2024/03/17/ascii-art-vs-ai\"> ★ </a>\n</div>\n\n\t","author":"John Gruber","siteTitle":"Daring Fireball","siteHash":"fc569638025dadf22a867470f8215f38855cf50e975782a6c989909474292a36","entryHash":"ef70bc8b238a401e995dfd0e1ee06837d14ef0f991d87610bfdc90220e87e5d2","category":"Tech"}