{"title":"Will ChatGPT’s hallucinations be allowed to ruin your life?","link":"https://arstechnica.com/?p=1970029","date":1698079605000,"content":"<div>\n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2023/08/openai-lies-rebus-800x450.png\" alt=\"Will ChatGPT’s hallucinations be allowed to ruin your life?\" />\n      <p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2023/08/openai-lies-rebus.png\">Enlarge</a> (credit: Aurich Lawson)</p>  </figure>\n\n\n\n\n\n\n<div><a name=\"page-1\"></a></div>\n<p>Bribery. Embezzlement. Terrorism.</p>\n<p>What if an AI chatbot accused you of doing something terrible? When bots make mistakes, the false claims can ruin lives, and the legal questions around these issues remain murky.</p>\n<p>That's according to several people suing the biggest AI companies. But chatbot makers hope to avoid liability, and a string of legal threats has revealed how easy it might be for companies to wriggle out of responsibility for allegedly defamatory chatbot responses.</p></div><p><a href=\"https://arstechnica.com/?p=1970029#p3\">Read 76 remaining paragraphs</a> | <a href=\"https://arstechnica.com/?p=1970029&amp;comments=1\">Comments</a></p>","author":"Ashley Belanger","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"653ddda60f1f8fba9433c7731bc9f05770f6e94aff1613707b6335bbc6e56116","category":"Tech"}