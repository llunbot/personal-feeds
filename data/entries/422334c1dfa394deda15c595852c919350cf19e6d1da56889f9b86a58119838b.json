{"title":"Fine-tuning for Anthropic’s Claude 3 Haiku model in Amazon Bedrock is now generally available","link":"https://aws.amazon.com/blogs/aws/fine-tuning-for-anthropics-claude-3-haiku-model-in-amazon-bedrock-is-now-generally-available/","date":1730496540000,"content":"<p>Today, we are announcing the general availability of fine-tuning for <a href=\"https://aws.amazon.com/bedrock/claude/\">Anthropic’s Claude 3 Haiku model in Amazon Bedrock</a> in the US West (Oregon) AWS Region. Amazon Bedrock is the only fully managed service that provides you with the ability to fine-tune Claude models. You can now fine-tune and customize the Claude 3 Haiku model with your own task-specific training dataset to boost model accuracy, quality, and consistency to further tailor <a href=\"https://aws.amazon.com/ai/generative-ai/\">generative AI</a> for your business.</p> \n<p>Fine-tuning is a technique where a pre-trained large language model (LLM) is customized for a specific task by updating the weights and tuning hyperparameters like learning rate and batch size for optimal results.</p> \n<p><a href=\"https://aws.amazon.com/blogs/aws/anthropics-claude-3-haiku-model-is-now-available-in-amazon-bedrock/\">Anthropic’s Claude 3 Haiku model</a> is the fastest and most compact model in the Claude 3 model family. Fine-tuning Claude 3 Haiku offers significant advantages for businesses:</p> \n<ul> \n <li><strong>Customization</strong> – You can customize models that excel in areas crucial to your business compared to more general models by encoding company and domain knowledge.</li> \n <li><strong>Specialized performance</strong> – You can generate higher quality results and create unique user experiences that reflect your company’s proprietary information, brand, products, and more.</li> \n <li><strong>Task-specific optimization</strong> – You can enhance performance for domain-specific actions such as classification, interactions with custom APIs, or industry-specific data interpretation.</li> \n <li><strong>Data security</strong> – You can fine-tune with peace of mind in your secure AWS environment. Amazon Bedrock makes a separate copy of the base foundation model that is accessible only by you and trains this private copy of the model.</li> \n</ul> \n<p>You can now optimize performance for specific business use cases by providing domain-specific labeled data to fine-tune the Claude 3 Haiku model in Amazon Bedrock.</p> \n<p>In early 2024, we started to engage customers with a team of experts from the <a href=\"https://aws.amazon.com/blogs/machine-learning/introducing-the-aws-generative-ai-innovation-centers-custom-model-program-for-anthropic-claude/\">AWS Generative AI Innovation Center</a> to help fine-tune Anthropic’s Claude models with their proprietary data sources. I’m happy to share that you can now fine-tune Anthropic’s Claude 3 Haiku model in Amazon Bedrock directly in the <a href=\"https://console.aws.amazon.com/bedrock/home?#/overview\">Amazon Bedrock console</a>.</p> \n<p><strong><u>Get started with fine-tuning for Anthropic’s Claude 3 Haiku model in Amazon Bedrock</u></strong><br /> I will demonstrate how to easily fine-tune the Claude 3 Haiku model in Amazon Bedrock. To learn more about the fine-tuning workflow in detail, visit the AWS Machine Learning Blog post, <a href=\"https://aws.amazon.com/blogs/machine-learning/fine-tune-anthropics-claude-3-haiku-in-amazon-bedrock-to-boost-model-accuracy-and-quality/\">Fine-tune Anthropic’s Claude 3 Haiku in Amazon Bedrock to boost model accuracy and quality</a>.</p> \n<p>To create a simple fine-tuning job in the <a href=\"https://console.aws.amazon.com/bedrock/\">Amazon Bedrock console</a>, go to the <strong>Foundation models</strong> section in the navigation pane and select <strong>Custom models</strong>. In the <strong>Models</strong> section, select the <strong>Customize model</strong> button and then select <strong>Create Fine-tuning job</strong>.</p> \n<p><img src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/04/2024-fine-tune-claude-3-haiku-in-bedrock-1-console.png\" width=\"2570\" height=\"1456\" /></p> \n<p>Next, choose the model that you want to customize with your own data, give your resulting model a name, and optionally add encryption keys and any tags to associate with the model in the <strong>Model details</strong> section. Enter a name for the job and optionally add any tags for the job in the <strong>Job configuration</strong> section.</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/04/2024-fine-tune-claude-3-haiku-in-bedrock-2-creat-fine-tune.png\" width=\"1702\" height=\"1364\" /></p> \n<p><span>You can select the Amazon S3 location of the training dataset file and, if applicable, the validation dataset file in the <strong>Input data</strong> section.</span></p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/04/2024-fine-tune-claude-3-haiku-in-bedrock-3-input-data.png\" width=\"1654\" height=\"690\" /></p> \n<p>Each dataset can be created using a <a href=\"https://jsonlines.org/\">JSON Lines (JSONL)</a> file with multiple JSON lines using the single-turn or multi-turn messaging format. Each JSON line is a sample containing a <code>system</code> and message, an array of <code>message</code> objects.</p> \n<p>I prepared some of the latest information about <a href=\"https://aws.amazon.com/blogs/aws/anthropics-claude-3-5-sonnet-model-now-available-in-amazon-bedrock-the-most-intelligent-claude-model-yet/\">Anthropic’s Claude 3.5 Sonnet model in Amazon Bedrock</a>. To learn more, visit <a href=\"https://docs.aws.amazon.com/bedrock/latest/userguide/model-customization-prepare.html\">Prepare the datasets</a> in the Amazon Bedrock documentation.</p> \n<p><code>{\"system\": \"You are an helpful assistant.\",\"messages\":[{\"role\": \"user\", \"content\": \"What’s the latest models to support Amazon Bedrock\"},{\"role\": \"assistant\", \"content\": \"Amazon Bedrock is a fully managed service that support Anthropic’s Claude 3 Sonnet, Haiku, and Opus models and the latest Claud 3.5 Sonnet model.\"}]}</code><br /> <code>{\"system\": \"You are an helpful assistant.\",\"messages\":[{\"role\": \"user\", \"content\": \"How long context window of Claude 3.5?\"},{\"role\": \"assistant\", \"content\": \"Anthropic's Claude 3 models have a 200,000 token context window enabling you to relay a large volume of information to Claude. This translates to roughly 150,000 words, or over 500 pages of material.\"}]}</code><br /> <code>{\"system\": \"You are an helpful assistant.\",\"messages\":[{\"role\": \"user\", \"content\": \"Is Claude 3.5 available in Bedrock?\"},{\"role\": \"assistant\", \"content\": \"Anthropic’s most intelligent and advanced model, Claude 3.5 Sonnet, demonstrates exceptional capabilities across a diverse range of tasks and evaluations while also outperforming Claude 3 Opus.\"}]}</code></p> \n<p>In the <strong>Hyperparameters</strong> section, enter values for <a href=\"https://docs.aws.amazon.com/bedrock/latest/userguide/custom-models-hp.html\">hyperparameters</a> to use in training, such as epochs, batch size, and learning rate multiplier. If you’ve included a validation dataset, you can enable <strong>Early stopping</strong>, a technique used to prevent overfitting and stop the training process when the validation loss stops improving. You can set an early stopping threshold and patience value.</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/04/2024-fine-tune-claude-3-haiku-in-bedrock-4-hyperparameter.jpg\" width=\"1312\" height=\"1152\" /></p> \n<p>You can also select the output location where Amazon Bedrock should save the output of the job in the <strong>Output data</strong> section. Choose an <a href=\"https://aws.amazon.com/iam/\">AWS Identity and Access Management (IAM)</a> custom service role with the appropriate permissions in the <strong>Service access</strong> section. To learn more, see <a href=\"https://docs.aws.amazon.com/bedrock/latest/userguide/model-customization-iam-role.html\">Create a service role for model customization</a> in the Amazon Bedrock documentation.</p> \n<p>Finally, choose <strong>Create Fine-tuning job</strong> and wait for your fine-tuning job to start.</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/04/2024-fine-tune-claude-3-haiku-in-bedrock-5-access.png\" width=\"1690\" height=\"1280\" /></p> \n<p>You can track its progress or stop it in the <strong>Jobs</strong> tab in the <strong>Custom models</strong> section.</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/08/2024-fine-tune-claude-3-haiku-in-bedrock-6-jobs-2.png\" width=\"2178\" height=\"1072\" /></p> \n<p>After a model customization job is complete, you can analyze the results of the training process by looking at the files in the output <a href=\"https://aws.amazon.com/s3/\">Amazon Simple Storage Service (Amazon S3)</a> folder that you specified when you submitted the job, or you can view details about the model.</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/04/2024-fine-tune-claude-3-haiku-in-bedrock-7-train-jobs-1.png\" width=\"2268\" height=\"1420\" /></p> \n<p>Before using a customized model, you need to purchase <a href=\"https://docs.aws.amazon.com/bedrock/latest/userguide/prov-throughput.html\">Provisioned Throughput for Amazon Bedrock</a> and then use the resulting provisioned model for inference. When you purchase Provisioned Throughput, you can select a commitment term, choose a number of model units, and see estimated hourly, daily, and monthly costs. To learn more about the custom model pricing for the Claude 3 Haiku model, visit <a href=\"https://aws.amazon.com/bedrock/pricing/\">Amazon Bedrock Pricing</a>.</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/04/2024-fine-tune-claude-3-haiku-in-bedrock-8-provisioned-throughput.png\" width=\"1686\" height=\"936\" /></p> \n<p>Now, you can test your custom model in the console playground. I choose my custom model and ask whether Anthropic’s Claude 3.5 Sonnet model is available in Amazon Bedrock.</p> \n<p><img loading=\"lazy\" src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/09/04/2024-fine-tune-claude-3-haiku-in-bedrock-9-playground.png\" width=\"2186\" height=\"1138\" /></p> \n<p>I receive the answer:</p> \n<p><code>Yes. You can use Anthropic’s most intelligent and advanced model, Claude 3.5 Sonnet in the Amazon Bedrock. You can demonstrate exceptional capabilities across a diverse range of tasks and evaluations while also outperforming Claude 3 Opus.</code></p> \n<p>You can complete this job using <a href=\"https://docs.aws.amazon.com/bedrock/latest/APIReference/welcome.html\">AWS APIs</a>, <a href=\"https://aws.amazon.com/developer/tools/\">AWS SDKs</a>, or <a href=\"https://aws.amazon.com/cli\">AWS Command Line Interface (AWS CLI)</a>. To learn more about using AWS CLI, visit <a href=\"https://docs.aws.amazon.com/bedrock/latest/userguide/model-customization-code-samples.html\">Code samples for model customization</a> in the AWS documentation.</p> \n<p>If you are using Jupyter Notebook, visit the <a href=\"https://github.com/aws-samples/amazon-bedrock-samples/tree/main/bedrock-fine-tuning/claude-haiku\">GitHub repository</a> and follow a hands-on guide for custom models. To build a production-level operation, I recommend reading <a href=\"https://aws.amazon.com/blogs/machine-learning/streamline-custom-model-creation-and-deployment-for-amazon-bedrock-with-provisioned-throughput-using-terraform/\">Streamline custom model creation and deployment for Amazon Bedrock with Provisioned Throughput using Terraform</a> on the AWS Machine Learning Blog.</p> \n<p><strong><u>Datasets and parameters</u></strong><br /> When fine-tuning Claude 3 Haiku, the first thing you should do is look at your datasets. There are two datasets that are involved in training Haiku, and that’s the Training dataset and the Validation dataset. There are specific parameters that you must follow in order to make your training successful, which are outlined <span>in the following table.</span></p> \n<table> \n <tbody> \n  <tr> \n   <td></td> \n   <td><strong>Training data</strong></td> \n   <td><strong>Validation data</strong></td> \n  </tr> \n  <tr> \n   <td><strong>File format</strong></td> \n   <td>JSONL</td> \n  </tr> \n  <tr> \n   <td><strong>File size</strong></td> \n   <td>&lt;= 10GB</td> \n   <td>&lt;= 1GB</td> \n  </tr> \n  <tr> \n   <td><strong>Line count</strong></td> \n   <td>32 – 10,000 lines</td> \n   <td>32 – 1,000 lines</td> \n  </tr> \n  <tr> \n   <td>Training + Validation Sum &lt;= 10,000 lines</td> \n  </tr> \n  <tr> \n   <td><strong>Token limit</strong></td> \n   <td>&lt; 32,000 tokens per entry</td> \n  </tr> \n  <tr> \n   <td><strong>Reserved keywords</strong></td> \n   <td>Avoid having “<code>\\nHuman:</code>” or “<code>\\nAssistant:</code>” in prompts</td> \n  </tr> \n </tbody> \n</table> \n<p>When you prepare the datasets, start with a small high-quality dataset and iterate based on tuning results. You can consider using larger models from Anthropic like Claude 3 Opus or Claude 3.5 Sonnet to help refine and improve your training data. You can also use them to generate training data for fine-tuning the Claude 3 Haiku model, which can be very effective if the larger models already perform well on your target task.</p> \n<p>For more guidance on selecting the proper hyperparameters and preparing the datasets, read the AWS Machine Learning Blog post, <a href=\"https://aws.amazon.com/blogs/machine-learning/best-practices-and-lessons-for-fine-tuning-anthropics-claude-3-haiku-on-amazon-bedrock/\">Best practices and lessons for fine-tuning Anthropic’s Claude 3 Haiku in Amazon Bedrock</a>.</p> \n<p><strong><u>Demo video<br /> </u></strong>Check out this deep dive demo video for a step-by-step walkthrough that will help you get started with fine-tuning Anthropic’s Claude 3 Haiku model in Amazon Bedrock.</p> \n<p></p> \n<p><strong><u>Now available</u></strong><br /> Fine-tuning for Anthropic’s Claude 3 Haiku model in Amazon Bedrock is now generally available in the US West (Oregon) AWS Region; check the <a href=\"https://docs.aws.amazon.com/bedrock/latest/userguide/models-regions.html\">full Region list</a> for future updates. To learn more, visit <a href=\"https://docs.aws.amazon.com/bedrock/latest/userguide/custom-models.html\">Custom models</a> in the Amazon Bedrock documentation.</p> \n<p>Give fine-tuning for the Claude 3 Haiku model a try in the <a href=\"https://console.amazon.com/bedrock/home#custom-models\">Amazon Bedrock console</a> today and send feedback to <a href=\"https://repost.aws/tags/TAQeKlaPaNRQ2tWB6P7KrMag/amazon-bedrock\">AWS re:Post for Amazon Bedrock</a> or through your usual AWS Support contacts.</p> \n<p>I look forward to seeing what you build when you put this new technology to work for your business.</p> \n<p>— <a href=\"https://twitter.com/channyun\">Channy</a></p>","author":"Channy Yun (윤석찬)","siteTitle":"AWS News Blog","siteHash":"6093e072e4117ec22616e844cb857d03ca62c57a411a8affc77cb5e8b6b15bf6","entryHash":"422334c1dfa394deda15c595852c919350cf19e6d1da56889f9b86a58119838b","category":"Tech"}