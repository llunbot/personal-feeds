{"title":"Google’s Gemma 3 is an open source, single-GPU AI with a 128K context window","link":"https://arstechnica.com/gadgets/2025/03/googles-new-gemma-3-ai-model-is-optimized-to-run-on-a-single-gpu/","date":1741799737000,"content":"<p>Most new AI models go big—more parameters, more tokens, more everything. Google's newest AI model has some big numbers, but it's also tuned for efficiency. <a href=\"https://blog.google/technology/developers/gemma-3/\">Google says</a> the Gemma 3 open source model is the best in the world for running on a single GPU or AI accelerator. The latest Gemma model is aimed primarily at developers who need to create AI to run in various environments, be it a data center or a smartphone. And you can tinker with Gemma 3 right now.</p>\n<p>Google claims Gemma 3 will be able to tackle more challenging tasks compared to the older open source Google models. The context window, a measure of how much data you can input, has been expanded to 128,000 from 80,000 tokens in <a href=\"https://arstechnica.com/information-technology/2024/02/google-goes-open-ai-with-gemma-a-free-open-weights-chatbot-family/\">previous Gemma models</a>. Gemma 3, which is based on the proprietary Gemini 2.0 foundation, is also a multimodal model capable of processing text, high-resolution images, and even video. Google also has a new solution for image safety called ShieldGemma 2, which can be integrated with Gemma to help block unwanted images in three content categories: dangerous, sexual, or violent.</p>\n<p>Most of the popular AI models you've heard of run on collections of servers in a data center, filled to the brim with AI computing power. Many of them are far too large to run on the kind of hardware you have at home or in the office. The release of the first Gemma models last year gave developers and enthusiasts another low-hardware option to compete with the likes of Meta Llama3. There has been a drive for efficiency in AI lately, with models like <a href=\"https://arstechnica.com/ai/2025/01/how-does-deepseek-r1-really-fare-against-openais-best-reasoning-models/\">DeepSeek R1</a> gaining traction on the basis of lower computing costs.</p><p><a href=\"https://arstechnica.com/gadgets/2025/03/googles-new-gemma-3-ai-model-is-optimized-to-run-on-a-single-gpu/\">Read full article</a></p>\n<p><a href=\"https://arstechnica.com/gadgets/2025/03/googles-new-gemma-3-ai-model-is-optimized-to-run-on-a-single-gpu/#comments\">Comments</a></p>","author":"Ryan Whitwam","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"f1a6cd361ed3ff7cbc998a2598005fec55ac735e29c78e3ea8be0b3116be8204","category":"Tech"}