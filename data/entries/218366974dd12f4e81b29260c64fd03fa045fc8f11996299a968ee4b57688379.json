{"title":"บันทึกเกี่ยวกับ Prompt Injection","link":"https://www.somkiat.cc/note-prompt-injection/","date":1681655532000,"content":"<p><img width=\"150\" height=\"150\" src=\"https://www.somkiat.cc/wp-content/uploads/2023/04/indirect-prompt-inject-150x150.jpg\" alt srcset=\"https://www.somkiat.cc/wp-content/uploads/2023/04/indirect-prompt-inject-150x150.jpg 150w, https://www.somkiat.cc/wp-content/uploads/2023/04/indirect-prompt-inject-75x75.jpg 75w\" /></p>\n<p>จากหนังสือเรื่อง <strong><a href=\"https://learnprompting.org\" target=\"_blank\">Learn Prompting</a></strong> นั้น<br />มีเรื่องที่น่าสนใจเยอะมาก ๆ <br />หนึ่งในนั้นคือ เรื่องการ Prompt hacking ประกอบไปด้วย</p>\n\n\n\n<ul><li>Prompt Injection</li><li>Prompt Leaking</li><li>Jailbreaking</li><li>Defensive Measures</li></ul>\n\n\n\n<span></span>\n\n\n\n<p><strong>ชื่อที่คุ้น ๆ คือ Prompt Injection</strong> !!</p>\n\n\n\n<p>ซึ่งเคยได้ยินจากเรื่องของ web security เช่น</p>\n\n\n\n<ul><li>SQL Injection</li><li>Command Injection</li></ul>\n\n\n\n<p>นั่นคือ เราสามารถส่งชุดคำสั่งเข้าไปยังระบบ<br />เพื่อให้ทำงานตามที่เราต้องการ<br />หรือเข้าไปยังช่องโหว่ที่เปิดไว้ทั้งตั้งใจและไม่ตั้งใจ</p>\n\n\n\n<p>โดยที่ Prompt Injection ก็เช่นกัน<br />นั่นคือ อาศัยความเข้าใจขั้นตอนการทำงานของ ChatGPT<br />จากนั้นก็ส่งชุดคำสั่ง หรือ การพูดคุย เข้าไป<br />ทำให้ตัว ChatGPT ทำการ hack หรือ โจมตีตัวเองได้เลย<br />เป็นเรื่องที่น่าสนใจมาก ๆ </p>\n\n\n\n<figure><div>\nhttps://twitter.com/goodside/status/1569128808308957185\n</div></figure>\n\n\n\n<p>และยังมี <strong><a href=\"https://techxplore.com/news/2023-03-indirect-prompt-upend-chatbots.html\" target=\"_blank\">Indirect Prompt Injection</a></strong> อีก</p>\n\n\n\n<figure><img src=\"https://www.somkiat.cc/wp-content/uploads/2023/04/indirect-prompt-inject.jpg\" alt width=\"560\" height=\"379\" /></figure>\n\n\n\n<p>ต่อไปอาจจะมีตำแหน่ง Prompt Security Engineering อีกไหมนะ</p>\n\n\n\n<p><strong>Reference Websites</strong></p>\n\n\n\n<ul><li><a href=\"https://www.latent.space/p/reverse-prompt-eng\" target=\"_blank\">Reverse Prompt Engineering for Fun and (no) Profit</a></li><li><a href=\"https://simonwillison.net/2022/Sep/17/prompt-injection-more-ai/\" target=\"_blank\">You can’t solve AI security problems with more AI</a></li><li><a href=\"https://www.jailbreakchat.com/\" target=\"_blank\">The prompt report</a></li><li><a href=\"https://techxplore.com/news/2023-03-indirect-prompt-upend-chatbots.html\" target=\"_blank\">'Indirect prompt injection' attacks could upend chatbots</a></li></ul>\n","author":"somkiat","siteTitle":"cc :: somkiat","siteHash":"3a23a5a4389e1e40c6fbb16520a8cc20df5b3591c25145ce72aaa18b19e48201","entryHash":"218366974dd12f4e81b29260c64fd03fa045fc8f11996299a968ee4b57688379","category":"Thai"}