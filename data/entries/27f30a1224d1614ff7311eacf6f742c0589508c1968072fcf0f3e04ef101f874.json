{"title":"Gemini Live will learn to peer through your camera lens in a few weeks","link":"https://arstechnica.com/google/2025/03/gemini-live-will-learn-to-peer-through-your-camera-lens-in-a-few-weeks/","date":1741022070000,"content":"<p>At Mobile World Congress, Google confirmed that a long-awaited Gemini AI feature it first teased nearly a year ago is ready for launch. The company's <a href=\"https://arstechnica.com/information-technology/2024/09/google-rolls-out-voice-powered-ai-chat-to-the-masses/\">conversational Gemini Live</a> will soon be able to view live video and screen sharing, a feature Google previously demoed as Project Astra. When Gemini's video capabilities arrive, you'll be able to simply show the robot something instead of telling it.</p>\n<p>Right now, Google's multimodal AI can process text, images, and various kinds of documents. However, its ability to accept video as an input is spotty at best—sometimes it can summarize a YouTube video, and sometimes it can't, for unknown reasons. Later in March, the Gemini app on Android will get a major update to its video functionality. You'll be able to open your camera to provide Gemini Live a video stream or share your screen as a live video, thus allowing you to pepper Gemini with questions about what it sees.</p>\n<div><div></div><div>\n    <div></div>\n    <div>\n      Gemini Live with video.\n\n          </div>\n  </div>\n</div>\n<p>It can be hard to keep track of which Google AI project is which—the 2024 Google I/O was largely a celebration of all things Gemini AI. <a href=\"https://arstechnica.com/information-technology/2024/05/google-strikes-back-at-openai-with-project-astra-ai-agent-prototype/\">The Astra demo</a> made waves as it demonstrated a more natural way to interact with the AI. In the original video, which you can see below, Google showed how Gemini Live could answer questions in real time as the user swept a phone around a room. It had things to say about code on a computer screen, how speakers work, and a network diagram on a whiteboard. It even remembered where the user left their glasses from an earlier part of the video.</p><p><a href=\"https://arstechnica.com/google/2025/03/gemini-live-will-learn-to-peer-through-your-camera-lens-in-a-few-weeks/\">Read full article</a></p>\n<p><a href=\"https://arstechnica.com/google/2025/03/gemini-live-will-learn-to-peer-through-your-camera-lens-in-a-few-weeks/#comments\">Comments</a></p>","author":"Ryan Whitwam","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"27f30a1224d1614ff7311eacf6f742c0589508c1968072fcf0f3e04ef101f874","category":"Tech"}