{"title":"Security Researchers Express Alarm Over Apple's Plans to Scan iCloud Images, But Practice Already Widespread","link":"https://www.macrumors.com/2021/08/05/security-researchers-alarmed-apple-csam-plans/","date":1628193874000,"content":"Apple <a href=\"https://www.macrumors.com/2021/08/05/apple-new-child-safety-features/\">today announced</a> that with the launch of <a href=\"https://www.macrumors.com/roundup/ios-15/\">iOS 15</a> and <a href=\"https://www.macrumors.com/roundup/ipados-15/\">iPadOS 15</a>, it will begin scanning <a href=\"https://www.macrumors.com/guide/icloud-photo-library/\">iCloud Photos</a> in the U.S. to look for known Child Sexual Abuse Material (CSAM), with plans to report the findings to the National Center for Missing and Exploited Children (NCMEC).\r\n<br />\r\n\r\n<br />\r\n<img src=\"https://images.macrumors.com/article-new/2021/08/Child-Safety-Feature.jpg\" />\r\n<br />\r\nPrior to when Apple detailed its plans, news of the CSAM initiative leaked, and security researchers have already begun expressing concerns about how Apple's new image scanning protocol could be used in the future, as noted by <em><a href=\"https://www.ft.com/content/14440f81-d405-452f-97e2-a81458f5411f\">Financial Times</a></em>.\r\n<br />\r\n\r\n<br />\r\nApple is using a \"NeuralHash\" system to compare known CSAM images to photos on a user's <a href=\"https://www.macrumors.com/guide/iphone/\">iPhone</a> before they're uploaded to <a href=\"https://www.macrumors.com/guide/icloud/\">iCloud</a>. If there is a match, that photograph is uploaded with a cryptographic safety voucher, and at a certain threshold, a review is triggered to check if the person has CSAM on their devices. \r\n<br />\r\n\r\n<br />\r\nAt the current time, Apple is using its image scanning and matching technology to look for child abuse, but researchers worry that in the future, it could be adapted to scan for other kinds of imagery that are more concerning, like anti-government signs at protests.\r\n<br />\r\n\r\n<br />\r\nIn a series of tweets, Johns Hopkins cryptography researcher <a href=\"https://twitter.com/matthew_d_green\">Matthew Green</a> said that CSAM scanning is a \"really bad idea\" because in the future, it could expand to scanning end-to-end encrypted photos rather than just content that's uploaded to ‌iCloud‌. For children, Apple <em>is</em> implementing a separate scanning feature that looks for sexually explicit content directly in iMessages, which are end-to-end encrypted.\r\n<br />\r\n\r\n<br />\r\nGreen also raised concerns over the hashes that Apple plans to use because there could potentially be \"collisions,\" where someone sends a harmless file that shares a hash with CSAM and could result in a false flag.\r\n<br />\r\n\r\n<br />\r\nApple for its part says that its scanning technology has an \"extremely high level of accuracy\" to make sure accounts are not incorrectly flagged, and reports are manually reviewed before a person's ‌iCloud‌ account is disabled and a report is sent to NCMEC.\r\n<br />\r\n\r\n<br />\r\nGreen believes that Apple's implementation will push other tech companies to adopt similar techniques. \"This will break the dam,\" he wrote. \"Governments will demand it from everyone.\" He compared the technology to \"tools that repressive regimes have deployed.\"\r\n<br />\r\n\r\n<br />\r\n<div><blockquote><p>These are bad things. I don’t particularly want to be on the side of child porn and I’m not a terrorist. But the problem is that encryption is a powerful tool that provides privacy, and you can’t really have strong privacy while also surveilling every image anyone sends.</p>— Matthew Green (@matthew_d_green) <a href=\"https://twitter.com/matthew_d_green/status/1423093261405667328?ref_src=twsrc%5Etfw\">August 5, 2021</a></blockquote> </div>\r\n<br />\r\nSecurity researcher Alec Muffett, who formerly worked at Facebook, said that Apple's decision to implement this kind of image scanning was a \"huge and regressive step for individual privacy.\" \"Apple are walking back privacy to enable 1984,\" he said.\r\n<br />\r\n\r\n<br />\r\nRoss Anderson, professor of security engineering at the University of Cambridge said called it an \"absolutely appalling idea\" that could lead to \"distributed bulk surveillance\" of devices.\r\n<br />\r\n\r\n<br />\r\nAs many have pointed out on Twitter, multiple tech companies already do image scanning for CSAM. Google, Twitter, Microsoft, Facebook, and others use image hashing methods to look for and report known images of child abuse.\r\n<br />\r\n\r\n<br />\r\n<div><blockquote><p>And if you’re wondering whether Google scans images for child abuse imagery, I answered that in the story I wrote eight years ago: it’s been doing that **SINCE 2008**. Maybe all sit down and put your hats back on. <a href=\"https://t.co/ruJ4Z8SceY\">pic.twitter.com/ruJ4Z8SceY</a></p>— Charles Arthur (@charlesarthur) <a href=\"https://twitter.com/charlesarthur/status/1423363444754026499?ref_src=twsrc%5Etfw\">August 5, 2021</a></blockquote> </div>\r\n<br />\r\nIt's also worth noting that Apple was <em>already</em> <a href=\"https://www.telegraph.co.uk/technology/2020/01/08/apple-scans-icloud-photos-check-child-abuse/\">scanning some content</a> for child abuse images prior to the rollout of the new CSAM initiative. In 2020, Apple chief privacy officer Jane Horvath said that Apple used screening technology to look for illegal images and then disables accounts if evidence of CSAM is detected.\r\n<br />\r\n\r\n<br />\r\nApple in 2019 <a href=\"https://www.macobserver.com/analysis/apple-scans-uploaded-content/\">updated its privacy policies</a> to note that it would scan uploaded content for \"potentially illegal content, including child sexual exploitation material,\" so today's announcements are not entirely new.<br />This article, \"<a href=\"https://www.macrumors.com/2021/08/05/security-researchers-alarmed-apple-csam-plans/\">Security Researchers Express Alarm Over Apple's Plans to Scan iCloud Images, But Practice Already Widespread</a>\" first appeared on <a href=\"https://www.macrumors.com\">MacRumors.com</a><br /><br /><a href=\"https://forums.macrumors.com/threads/security-researchers-express-alarm-over-apples-plans-to-scan-icloud-images-but-practice-already-widespread.2306655/\">Discuss this article</a> in our forums<br /><br /><div>\r\n<a href=\"http://feeds.macrumors.com/~ff/MacRumors-All?a=gGvmQHH9k2c:cCNA9K3cM08:6W8y8wAjSf4\"><img src=\"http://feeds.feedburner.com/~ff/MacRumors-All?d=6W8y8wAjSf4\" /></a> <a href=\"http://feeds.macrumors.com/~ff/MacRumors-All?a=gGvmQHH9k2c:cCNA9K3cM08:qj6IDK7rITs\"><img src=\"http://feeds.feedburner.com/~ff/MacRumors-All?d=qj6IDK7rITs\" /></a>\r\n</div><img src=\"http://feeds.feedburner.com/~r/MacRumors-All/~4/gGvmQHH9k2c\" />","author":"Juli Clover","siteTitle":"MacRumors: Mac News and Rumors - All Stories","siteHash":"4c0f1b1ecc2ed084c9f5be50f1058e33a55cdf9b904dadc33a2071fc2d63e8c1","entryHash":"dc8d72e6e4d390b6ec0d0bcf0ffbe5691a226f43d98c9d70697b2c5f9fd53ad9","category":"Apple"}