{"title":"Introducing Natural Input for WebXR in Apple Vision Pro","link":"https://webkit.org/blog/15162/introducing-natural-input-for-webxr-in-apple-vision-pro/","date":1710865813000,"content":"<p>Apple Vision Pro is here, and with it, a lot of excitement about the possibilities for WebXR in visionOS. Support is in progress, where you can test it today.</p>\n<p>WebXR now includes a more natural and privacy-preserving method for interaction — the new <code>transient-pointer</code> input mode — available behind a flag for Safari 17.4 in visionOS 1.1. Let’s explore how natural input for WebXR works, and how to leverage it when developing a WebXR experience for Apple Vision Pro.</p>\n<h2><a name=\"background\"></a>Background</h2>\n<p><a href=\"https://developer.mozilla.org/en-US/docs/Games/Techniques/3D_on_the_web/WebXR\">WebXR</a> lets you transform 3D experiences created in <a href=\"https://en.wikipedia.org/wiki/WebGL\">WebGL</a> into immersive, spatial experiences available directly in the browser. Defined in <a href=\"https://immersive-web.github.io/webxr/\">web standards</a> governed by the W3C, WebXR is an excellent choice for presenting immersive content to your users.</p>\n<p>One challenge, though, is that because it’s completely immersive — and rendered entirely through WebGL — it’s not possible to provide interaction via DOM content or the traditional two-dimensional input available on a typical web page via a mouse or trackpad. This, combined with the fact that a spatial experience requires spatial input, means WebXR needs a totally new interaction model.</p>\n<p>The interaction model of visionOS, known as natural input, uses a combination of <a href=\"https://developer.apple.com/design/human-interface-guidelines/eyes\">eyes</a> and <a href=\"https://developer.apple.com/design/human-interface-guidelines/gestures#visionOS\">hands</a> for input. A user simply looks at a target and taps their fingers to interact. (Or uses the alternatives provided by <a href=\"https://support.apple.com/guide/apple-vision-pro/get-started-with-accessibility-features-tan426c48bdc/visionos\">accessibility features</a>.)</p>\n<p>The initial web standards for WebXR assumed all input would be provided by persistent hardware controllers. Since the natural input interaction model of visionOS differs from XR platforms which rely on listening to physical controllers and button presses, many existing WebXR experiences won’t work as intended on Apple Vision Pro.</p>\n<p>We’ve been collaborating in the W3C to incorporate support for the interaction model of visionOS into WebXR. And we’re excited to help the WebXR community add support to popular WebXR frameworks.</p>\n<figure></figure>\n<h2><a name=\"using-natural-input-interactions\"></a>Using Natural Input interactions</h2>\n<p>Since WebXR in visionOS requires the use of spatial inputs, rather than a trackpad, touch, or mouse, and the DOM isn’t visible within a WebXR session, inputs are provided as part of the XRSession itself. Events related to the input, e.g. <code>select</code>, <code>selectstart</code> and <code>selectend</code> are then dispatched from the session object. The XRInputSources are available within the <code>xrSession.inputSources</code> array. Because the default WebXR input in visionOS is <em>transient</em>, that array is empty — until the user pinches. At that moment, a new input is added to the array, and the session fires an <code>inputsourceschange</code> event followed by a <code>selectstart</code> event. You can use these for detecting the start of the gesture. To differentiate this new input type,  it has a <code>targetRayMode</code> of <code>transient-pointer</code>.</p>\n<figure><img loading=\"lazy\" src=\"https://webkit.org/wp-content/uploads/XRSession1-1.png\" width=\"1838\" height=\"580\" srcset=\"https://webkit.org/wp-content/uploads/XRSession1-1.png 1838w, https://webkit.org/wp-content/uploads/XRSession1-1-300x95.png 300w, https://webkit.org/wp-content/uploads/XRSession1-1-1024x323.png 1024w, https://webkit.org/wp-content/uploads/XRSession1-1-768x242.png 768w, https://webkit.org/wp-content/uploads/XRSession1-1-1536x485.png 1536w\" /></figure>\n<h3><a name=\"ongoing-interaction\"></a>Ongoing interaction</h3>\n<p>The <code>XRInputSource</code> contains references to two different positions in space related to the input: the <code>targetRaySpace</code> and the <code>gripSpace</code>. <code>targetRaySpace</code> represents the user’s gaze direction, this space begins with its origin between the user’s eyes and points to what the user was looking at the start of the gesture. The <code>targetRaySpace</code> is <em>initially</em> set to the direction of the user’s gaze but is updated with the movement of their hand rather than their eyes — that is, a movement of the hand to the left will move that ray to the left as well. The <code>gripSpace</code> represents the location of the user’s pinching fingers at the current point in time.</p>\n<p>The <code>targetRaySpace</code> can be used for finding what the user wanted to interact with when they started the gesture typically by raycasting into the scene and picking the intersected object and the gripSpace can be used for the positioning and orientation of objects near the user’s hand for interaction purposes, e.g. to flip a switch, turn a dial or pick up an item from the virtual environment. To learn more about finding the pose of the input, see <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/WebXR_Device_API/Inputs\">Inputs and input sources</a> on MDN.</p>\n<h3><a name=\"end-of-interaction\"></a>End of interaction</h3>\n<p>Three events are fired from the <code>session</code> object when the user releases the pinch.</p>\n<figure><img loading=\"lazy\" src=\"https://webkit.org/wp-content/uploads/XRSession2.png\" width=\"2406\" height=\"444\" srcset=\"https://webkit.org/wp-content/uploads/XRSession2.png 2406w, https://webkit.org/wp-content/uploads/XRSession2-300x55.png 300w, https://webkit.org/wp-content/uploads/XRSession2-1024x189.png 1024w, https://webkit.org/wp-content/uploads/XRSession2-768x142.png 768w, https://webkit.org/wp-content/uploads/XRSession2-1536x283.png 1536w, https://webkit.org/wp-content/uploads/XRSession2-2048x378.png 2048w\" /></figure>\n<p>First is a <code>select</code> and <code>selectEnd</code> event, both referencing the input as the <code>event.inputSource</code> object. The session then fires a final <code>inputsourceschange</code> event, indicating that this <code>inputSource</code> has been removed.</p>\n<h3><a name=\"benefits-for-simplicity-and-privacy\"></a>Benefits for simplicity and privacy</h3>\n<p>As each input represents a single, tracked point in space per pinch, and because it exists only for the duration of the user’s pinch, significantly less data about a user’s motion is required overall.</p>\n<h2><a name=\"combining-transient-inputs-with-hand-tracking\"></a>Combining transient inputs with hand tracking</h2>\n<p>WebXR on Safari in visionOS continues to support full hand tracking as well, supplying hand joint information for the duration of the experience. If the call to <code>navigator.xr.requestSession</code> has included  <code>hand-tracking</code> as an additional feature <em>and</em> this is granted by the user, the first two inputs in the <code>inputSources</code> list will be standard <code>tracked-pointers</code> supplying this joint information. For information on <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/XRSystem/requestSession\">requesting features in an XRSession</a>, refer to the documentation at MDN.  Because these inputs persist for the duration of the session, any <code>transient-pointer</code> inputs will appear further down the list. The hand inputs are supplied for pose information only and do not trigger any events.</p>\n<h2><a name=\"testing-natural-input-on-visionos\"></a>Testing natural input on visionOS</h2>\n<h3><a name=\"using-the-visionos-simulator\"></a>Using the visionOS simulator</h3>\n<p>The new <code>transient-pointer</code> input mode works in the visionOS simulator, so you can test your Web XR experience without needing Apple Vision Pro. To get started:</p>\n<ol>\n<li>Download <a href=\"https://apps.apple.com/us/app/xcode/id497799835\">Xcode</a> from the Mac App Store. </li>\n<li>Select the visionOS SDK for download and installation.<br />\n<figure><img loading=\"lazy\" src=\"https://webkit.org/wp-content/uploads/xcode-install-light.png\" alt=\"Checklist of which platforms you would like to develop for — macOS and visionOS are checked, ready to press the download &amp; install button.\" width=\"1224\" height=\"1346\" srcset=\"https://webkit.org/wp-content/uploads/xcode-install-light.png 1224w, https://webkit.org/wp-content/uploads/xcode-install-light-273x300.png 273w, https://webkit.org/wp-content/uploads/xcode-install-light-931x1024.png 931w, https://webkit.org/wp-content/uploads/xcode-install-light-768x845.png 768w\" /></figure>\n</li>\n<li>Launch Xcode to complete the installation process. This installs a new application named “Simulator”. Learn <a href=\"https://developer.apple.com/documentation/visionOS/interacting-with-your-app-in-the-visionos-simulator\">more about using the visionOS Simulator</a>.</li>\n<li>Open the Simulator app on macOS.</li>\n<li>Create a new visionOS simulator or open an existing one.</li>\n</ol>\n<p>If you have a website open in Safari on macOS, you can easily trigger that page to open in Safari in visionOS Simulator. On Mac, select Develop &gt; Open Page With &gt; Apple Vision Pro. (If the Develop menu is not present in the menu bar, <a href=\"https://developer.apple.com/documentation/safari-developer-tools/enabling-developer-features\">enable features for web developers</a>.)</p>\n<h3><a name=\"enabling-webxr-support\"></a>Enabling WebXR support</h3>\n<p>Whether you have Apple Vision Pro or are using visionOS Simulator, you’ll want to turn on support for WebXR. From the <a href=\"https://support.apple.com/guide/apple-vision-pro/open-home-view-devf42afa74a/visionos\">Home View</a>, go to Settings &gt; Apps &gt; Safari &gt; Advanced &gt; Feature Flags and enable <code>WebXR Device API</code>.</p>\n<figure></figure>\n<h2><a name=\"identifying-potential-issues-in-existing-webxr-scenes\"></a>Identifying potential issues in existing WebXR scenes</h2>\n<p>WebXR is provided in visionOS 1.1 for testing purposes only. If you encounter bugs in the browser, please don’t attempt to target a user-agent string to work around them. Instead, report them to us via <a href=\"https://feedbackassistant.apple.com/\">Feedback Assistant</a>.</p>\n<h4><a name=\"when-hand-tracking-is-enabled-i-can%e2%80%99t-select-anything\"></a>When hand-tracking is enabled I can’t select anything.</h4>\n<p>Your experience probably is only looking at events which correspond to the first two inputs in the inputSources array. Many examples in the popular framework Three.js only act on events related to inputs at index 0 and 1. When hand tracking is enabled, the inputs corresponding to the hand tracking data appear in entries 0 and 1 but the <code>transient-pointer</code> style inputs appear in entries 2 and 3.</p>\n<h4><a name=\"when-i-attach-an-object-to-the-controller-it-appears-at-the-user%e2%80%99s-face\"></a>When I attach an object to the controller it appears at the user’s face.</h4>\n<p>The input’s <code>targetRaySpace</code> originates between the user’s eyes and points in the direction of their gaze. To place an object in the user’s hand, instead attach objects to the input’s <code>gripSpace</code> position, which corresponds to the location of the user’s pinch.</p>\n<h4><a name=\"the-selection-ray-to-interact-with-objects-lags-between-the-position-of-my-current-selection-and-my-last-one\"></a>The selection ray to interact with objects lags between the position of my current selection and my last one.</h4>\n<p>Some frameworks attempt to smooth out controller motion by interpolating the position of the controller each frame. This interpolated motion should be reset if a controller is disconnected and reconnected. You may need to file an issue with the framework author.</p>\n<h2><a name=\"let-us-know\"></a>Let us know</h2>\n<p>We can’t wait to see what you make. To share your thoughts on WebXR, find us on Mastodon at <a href=\"https://mastodon.social/@ada\">@ada@mastodon.social</a>, <a href=\"https://front-end.social/@jensimmons\">@jensimmons@front-end.social</a>, <a href=\"https://mastodon.social/@jondavis\">@jondavis@mastodon.social</a>, or on X at <a href=\"https://twitter.com/zachernuk\">@zachernuk</a>. Or send a reply on X to <a href=\"https://twitter.com/webkit\">@webkit</a>. You can also <a href=\"https://www.linkedin.com/in/apple-webkit/\">follow WebKit on LinkedIn</a>.  If you run into any issues, we welcome your <a href=\"https://feedbackassistant.apple.com/\">feedback</a> (to include a sysdiagnose from Apple Vision Pro), or your <a href=\"https://bugs.webkit.org/\">WebKit bug report</a> about Web Inspector or web platform features. Filing issues really does make a difference. Thanks.</p>","author":"","siteTitle":"Blog – WebKit","siteHash":"7f8dbea0b8f53db2e11a2faa08c6dca9954c01638d09a2ce585b77a60d10f7a1","entryHash":"ddbe4137ecfceb101682d803ec5b0c93636465cd3db6d4765cb65bfe5a41703d","category":"Tech"}